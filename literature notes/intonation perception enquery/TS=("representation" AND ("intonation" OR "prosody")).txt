PT	AU	BA	BE	GP	AF	BF	CA	TI	SO	SE	BS	LA	DT	CT	CY	CL	SP	HO	DE	ID	AB	C1	C3	RP	EM	RI	OI	FU	FP	FX	CR	NR	TC	Z9	U1	U2	PU	PI	PA	SN	EI	BN	J9	JI	PD	PY	VL	IS	PN	SU	SI	MA	BP	EP	AR	DI	DL	D2	EA	PG	WC	WE	SC	GA	PM	OA	HC	HP	DA	UT
J	Chien, PJ; Friederici, AD; Hartwigsen, G; Sammler, D				Chien, Pei-Ju; Friederici, Angela D.; Hartwigsen, Gesa; Sammler, Daniela			Intonation processing increases task-specific fronto-temporal connectivity in tonal language speakers	HUMAN BRAIN MAPPING				Article								Language comprehension depends on tight functional interactions between distributed brain regions. While these interactions are established for semantic and syntactic processes, the functional network of speech intonation - the linguistic variation of pitch - has been scarcely defined. Particularly little is known about intonation in tonal languages, in which pitch not only serves intonation but also expresses meaning via lexical tones. The present study used psychophysiological interaction analyses of functional magnetic resonance imaging data to characterise the neural networks underlying intonation and tone processing in native Mandarin Chinese speakers. Participants categorised either intonation or tone of monosyllabic Mandarin words that gradually varied between statement and question and between Tone 2 and Tone 4. Intonation processing induced bilateral fronto-temporal activity and increased functional connectivity between left inferior frontal gyrus and bilateral temporal regions, likely linking auditory perception and labelling of intonation categories in a phonological network. Tone processing induced bilateral temporal activity, associated with the auditory representation of tonal (phonemic) categories. Together, the present data demonstrate the breadth of the functional intonation network in a tonal language including higher-level phonological processes in addition to auditory representations common to both intonation and tone.												10	11											JAN	2021	42	1					161	174		10.1002/hbm.25214	http://dx.doi.org/10.1002/hbm.25214		SEP 2020										2026-01-16	WOS:000573645300001
J	Tang, C; Hamilton, LS; Chang, EF				Tang, C.; Hamilton, L. S.; Chang, E. F.			Intonational speech prosody encoding in the human auditory cortex	SCIENCE				Article								Speakers of all human languages regularly use intonational pitch to convey linguistic meaning, such as to emphasize a particular word. Listeners extract pitch movements from speech and evaluate the shape of intonation contours independent of each speaker's pitch range. We used high-density electrocorticography to record neural population activity directly from the brain surface while participants listened to sentences that varied in intonational pitch contour, phonetic content, and speaker. Cortical activity at single electrodes over the human superior temporal gyrus selectively represented intonation contours. These electrodes were intermixed with, yet functionally distinct from, sites that encoded different information about phonetic features or speaker identity. Furthermore, the representation of intonation contours directly reflected the encoding of speaker-normalized relative pitch but not absolute pitch.												92	104											AUG 25	2017	357	6353					797	801		10.1126/science.aam8577	http://dx.doi.org/10.1126/science.aam8577												2026-01-16	WOS:000408327900042
J	Col, G				Col, Gilles			Prosody and emergence of the senses: propositions for a cognitive study of intonation	CANADIAN JOURNAL OF LINGUISTICS-REVUE CANADIENNE DE LINGUISTIQUE				Article								This paper aims at giving English intonation a driving role in the building and the emergence of meaning. It presents four propositions, going from the perception of intonation to its role in the representation of meaning. First, the concept of intonational form, based on the gestalt model of good form, is introduced. Second, the fundamental characteristic of intonational form is its dynamic nature. Third, intonation is positioned in the semantic layer, and is on par with the other linguistic components (syntax, lexicon, grammar). Finally, it is the evolution of the verbal scene that gives intonation its fundamental role.												0	0											NOV	2007	52	3					255	+		10.1353/cjl.2008.0025	http://dx.doi.org/10.1353/cjl.2008.0025												2026-01-16	WOS:000253955100002
J	Reichel, UD				Reichel, Uwe D.			Linking bottom-up intonation stylization to discourse structure	COMPUTER SPEECH AND LANGUAGE				Article								A new approach for intonation stylization that enables the extraction of an intonation representation from prosodically unlabeled data is introduced. This approach yields global and local intonation contour classes arising from a contour-based, parametric and superpositional intonation stylization. Based on findings about the linguistic interpretation of the contour classes derived from corpus statistics and perception experiments, we created simple prediction models for the partial generation of intonation contours from discourse structure defined by discourse segment boundaries and the information status of nouns within these segments. The predicted intonation contours were evaluated by human judgments of adequacy that yielded a high accordance. (C) 2014 Elsevier Ltd. All rights reserved.												8	8											NOV	2014	28	6					1340	1365		10.1016/j.csl.2014.03.005	http://dx.doi.org/10.1016/j.csl.2014.03.005												2026-01-16	WOS:000340850000006
J	Gussenhoven, C; Van der Vliet, P				Gussenhoven, C; Van der Vliet, P			The phonology of tone and intonation in the Dutch dialect of Venlo	JOURNAL OF LINGUISTICS				Article; Proceedings Paper	17th DGfS Meeting	MAR, 1995	GOTTINGEN, GERMANY					The Dutch dialect of Venlo has a lexical tone opposition comparable to the distinction between Accent I and Accent II in Scandinavian. The two word tone patterns are realised in a variety of different ways, depending on the intonation contour, on whether the word has a focus tone, and on whether it occurs finally or nonfinally in the intonational phrase (IP). Twelve such contexts are identified, and an autosegmental-metrical analysis is presented of the contours for the word tones in each of these. The analysis is instructive because of its clear illustration of the distinction between the phonological underlying representation and the phonological surface representation, as well as of the distinction between the latter representation and the phonetic realisation. In addition, because of the complexity of its tonal phonology, the dialect is of considerable typological interest for the study of word prosody and intonation.												43	47											MAR	1999	35	1					99	135		10.1017/S0022226798007324	http://dx.doi.org/10.1017/S0022226798007324												2026-01-16	WOS:000080648200004
J	Prieto, P; Esteve-Gibert, N; Shattuck-Hufnagel, S				Prieto, Pilar; Esteve-Gibert, Nuria; Shattuck-Hufnagel, Stefanie			Towards a novel conceptualization of prosody that accounts for spoken and visual signals	GESTURE				Article								Prosody influences speech organization by signaling phrasal prominence, grouping patterns, and speakers' pragmatic intentions. While traditionally viewed as restricted to speech, research shows prosody is also conveyed visually. This article reviews research showing strong parallels between spoken prosody and co-speech gestures in prominence marking, grouping phrasal structures, and signaling pragmatic intent. We extend this discussion and propose a modality-neutral prosodic framework hypothesis comprising three propositions: (a) prosody should be viewed as a modality-neutral grammar component that operates as an abstract level of representation while adapting to different sensory channels and language modalities; (b) in spoken languages, prosody is implemented flexibly through two distinct channels, spoken and gestural, which enable to mark prominence, grouping and meaning in a multimodal way; (c) parallel implementations are found in the way prosody is manifested in spoken and sign languages. A modality-neutral view of prosody will enrich current formal and developmental theories of language.												2	2											DEC 31	2024	23	1-2					119	159		10.1075/gest.25012.pri	http://dx.doi.org/10.1075/gest.25012.pri		JUL 2025										2026-01-16	WOS:001529840300001
J	Inspector, M; Manor, D; Amir, N; Kushnir, T; Karni, A				Inspector, Michael; Manor, David; Amir, Noam; Kushnir, Tamar; Karni, Avi			A Word by Any Other Intonation: FMRI Evidence for Implicit Memory Traces for Pitch Contours of Spoken Words in Adult Brains	PLOS ONE				Article								Objectives: Intonation may serve as a cue for facilitated recognition and processing of spoken words and it has been suggested that the pitch contour of spoken words is implicitly remembered. Thus, using the repetition suppression (RS) effect of BOLD-fMRI signals, we tested whether the same spoken words are differentially processed in language and auditory brain areas depending on whether or not they retain an arbitrary intonation pattern. Experimental design: Words were presented repeatedly in three blocks for passive and active listening tasks. There were three prosodic conditions in each of which a different set of words was used and specific task-irrelevant intonation changes were applied: (i) All words presented in a set flat monotonous pitch contour (ii) Each word had an arbitrary pitch contour that was set throughout the three repetitions. (iii) Each word had a different arbitrary pitch contour in each of its repetition. Principal findings: The repeated presentations of words with a set pitch contour, resulted in robust behavioral priming effects as well as in significant RS of the BOLD signals in primary auditory cortex (BA 41), temporal areas (BA 21 22) bilaterally and in Broca's area. However, changing the intonation of the same words on each successive repetition resulted in reduced behavioral priming and the abolition of RS effects. Conclusions: Intonation patterns are retained in memory even when the intonation is task-irrelevant. Implicit memory traces for the pitch contour of spoken words were reflected in facilitated neuronal processing in auditory and language associated areas. Thus, the results lend support for the notion that prosody and specifically pitch contour is strongly associated with the memory representation of spoken words.												6	6											DEC 31	2013	8	12							e82042	10.1371/journal.pone.0082042	http://dx.doi.org/10.1371/journal.pone.0082042												2026-01-16	WOS:000329325200010
J	Upegui, EPV				Velasquez Upegui, Eva Patricia			THE INTONATION OF TRANSACTIONAL INTERROGATIVE SENTENCES IN THE SPANISH SPOKEN IN COLOMBIA	FORMA Y FUNCION				Article								The article presents the description and analysis of the intonation of different transactional interrogative sentences, that is, those aimed at the exchange of information. The data analyzed corresponds to the Spanish spoken in Colombia, specifically in four cities: Bogota, Cali, Medellin and Cartagena. The sp-tobi transcription system was used for the prosodic representation, within the theoretical-methodological framework of the autosegmental metric model (MA). Overall, two prosodic configurations were found to be associated to dialectal groups: L+H* L% in Medellin and H+L* HH% in Bogota and Cali; Cartagena presents both configurations in the nuclear tone.												0	0											JUL-DEC	2014	27	2					207	246		10.15446/fyf.v27n2.47672	http://dx.doi.org/10.15446/fyf.v27n2.47672												2026-01-16	WOS:000434568100008
J	Nagy, P; Németh, G				Nagy, Peter; Nemeth, Geza			Improving HMM speech synthesis of interrogative sentences by pitch track transformations	SPEECH COMMUNICATION				Article								Modeling interrogative sentence prosody is a challenging task due to the significant variation of questions. Prosody is produced by intonation, intensity and duration features. Intonation clearly identifies the type of question in most European languages. If only limited training data is available from certain sentence types, synthetic intonation often lacks accuracy, richness and detail due to averaging, inherent in statistical approaches. In this paper, we discuss two rule-based solutions to improve intonation of interrogative sentences. The first approach utilizes a pitch prediction algorithm where a rule-set forms the pitch pattern. The output pattern is combined with an HMM generated F-0 contour and the resulting pattern is used for speech synthesis. Our second solution uses key points to define a scaling function. The position of the key points is described by a rule-set, and the value at intermediate points is calculated in training time in a data-driven way in order to maintain the characteristics of the speakers' voice. The proposed two hybrid rule-based-HMM systems were evaluated by speech experts and by perceptual tests. Our evaluation shows that both approaches could significantly improve the prosodic representation of questions in our framework without deteriorating the perceived naturalness of synthetic speech. The pitch contours generated by the systems were compared and evaluated according to how well they could reproduce the unique characteristics of different Hungarian interrogative sentence types. The analysis shows that both of the methods could successfully model the required patterns. In a separate perception test the interrogative prosody identification rate of the solutions was also measured. The results demonstrate that applying our proposed methods the identification rate of questions could be improved significantly. Although our work focuses on our mother tongue-Hungarian- the methodology can be extended to other languages. (C) 2016 Elsevier B.V. All rights reserved.												3	4											SEP	2016	82						97	112		10.1016/j.specom.2016.06.005	http://dx.doi.org/10.1016/j.specom.2016.06.005												2026-01-16	WOS:000381951700008
S	Byrd, D; Krivokapic, J		Liberman, MY; Partee, BH		Byrd, Dani; Krivokapic, Jelena			Cracking Prosody in Articulatory Phonology	ANNUAL REVIEW OF LINGUISTICS, VOL 7	Annual Review of Linguistics			Article; Book Chapter								Articulatory Phonology advances an account of phonological structure in which dynamically defined vocal tract tasks-gestures-are simultaneously and isomorphically units of cognitive representation and units of physical action. This paradigm has fundamentally altered our understanding of the linguistic representation of words. This article reviews the relatively recent incorporation of prosody into Articulatory Phonology. A capsule review of the Articulatory Phonology theoretical framework is presented, and the notions of phrasal and prominence organization are introduced as the key aspects of linguistic prosodic structure under consideration. Parameter dynamics, activation dynamics, and prosodic modulation gestures, such as the p-gesture, are outlined. The review is extended to touch on rhythm, intonation, and pauses and to consider innovations for integrating multiple aspects of prosodic structure under this dynamical approach. Finally, a range of questions emerges, crystallizing outstanding issues ranging from the abstract and theoretical to the interactive and functional.												22	27												2021	7						31	53		10.1146/annurev-linguistics-030920-050033	http://dx.doi.org/10.1146/annurev-linguistics-030920-050033												2026-01-16	WOS:000614614700004
J	Wennerstrom, A				Wennerstrom, Ann			Rich pitch The humorous effects of deaccent and L plus H* pitch accent	PRAGMATICS & COGNITION				Article								This paper argues that intonation contributes to the humorous meaning of a certain class of jokes. Examples of both canned and spontaneous jokes show that two intonation patterns, the intonation of contrast, or "L+H* pitch accent", and the intonation of given information, or "deaccent", can contribute to a humorous effect. Both of these patterns act as cohesive devises in discourse: they trigger a mental search in the mind of a hearer for a cohesive tie that may not be obvious from the lexicogrammatical structure alone. A punch line effect is created if this search yields an unexpected incongruity between the hearer's initial mental model of the joke discourse and a humorous alternative. The hearer must shift his "script" (Raskin 1984) of the discourse in an unexpected way. To the extent that intonation facilitates processing by directing attention to particular elements in the information structure of the discourse (Chafe 1994), the processing of jokes depends in part on their intonation. The implications of this premise for the processing of humorous texts will be discussed for the two intonation patterns in question. It is argued that intonation analysis can lead to a broader understanding of cognitive processes and structures.												2	4												2011	19	2					310	332		10.1075/pc.19.2.07wen	http://dx.doi.org/10.1075/pc.19.2.07wen												2026-01-16	WOS:000301125100007
J	Poiré, F				Poiré, F			Focal accent and emphatic prominence in the description of French intonation	CANADIAN JOURNAL OF LINGUISTICS-REVUE CANADIENNE DE LINGUISTIQUE				Article								Many questions about the expressive or distinctive character of focal accent and emphatic prominence remain unanswered in studies concerning natural language prosody. Recent works show that fundamental frequency variation underlies a categorial perception that permits a differenciation in the representation of these two types of prominence. Using data from French, the contribution of each type of prominence to the intonation contour is analyzed. This study reconciles the difference in expressive character and phonological description associated with each prominence type through the use of association rules linking tones and text in different prosodic domains. An instrumental study of 280 utterances documents the phonetic particularities in the production of both prominences, and in neutral utterances.												0	1											SEP-DEC	2000	45	3-4					275	+		10.1017/S0008413100017710	http://dx.doi.org/10.1017/S0008413100017710												2026-01-16	WOS:000171980600004
J	Escudero-Mancebo, D; Cardeñoso-Payo, V				Escudero-Mancebo, David; Cardenoso-Payo, Valentin			Applying data mining techniques to corpus based prosodic modeling	SPEECH COMMUNICATION				Article								This article presents MEMOInt, a methodology to automatically extract the intonation patterns which characterize a given corpus, with applications in text-to-specch systems. Easy to understand information about the form of the characteristic patterns found in the corpus can be obtained from MEMOint in a way which allows easy comparison with other proposals. A visual representation of the relationship between the set of prosodic features which could have been selected to label the corpus and the intonation contour patterns is also easy to obtain. The particular function-form correspondence associated to the given corpus is represented by means of a list of dictionaries of classes of parameterized FO patterns, where the access key is given by a sequence of prosodic features. MEMOInt can also be used to obtain valuable information about the relative impact of the use of different parameterization techniques of FO contours or of different types of intonation units and information about the relevance of different prosodic features. The methodology has been specifically designed to provide a successful strategy to solve the data sparseness problem which usually affects corpora as a consequence of the inherent high variability of the intonation phenomenon. (c) 2007 Elsevier B.V. All rights reserved.												14	14											MAR	2007	49	3					213	229		10.1016/j.specom.2007.01.008	http://dx.doi.org/10.1016/j.specom.2007.01.008												2026-01-16	WOS:000245965900005
J	Henriksen, N				Henriksen, Nicholas			Initial peaks and final falls in the intonation of Manchego Spanish wh-questions	PROBUS				Article								This paper investigates the phonetics and phonology of initial peaks and final falls in wh-questions produced by speakers of the variety of Spanish spoken in the Castile-La Mancha (Manchego) region of Spain. The acoustic analysis is based on speech data for nine speakers, and the goal is to identify how utterance-initial and utterance-final F-0 gestures relate to broader issues in intonational phonology and the prosodic signaling of wh-questions. The findings for left periphery constituents provide evidence for a H tone at the utterance boundary for all speakers, although the exact autosegmental representation cannot be provided due to variability in peak alignment patterns. The findings for right periphery constituents indicate two distinct speaker groups based on nuclear syllable and posttonic gestures. Specifically, the continuum of final falls is motivated by contrasting bitonal nuclear pitch accent configurations: H + L-star vs. jL + H-star. The boundary L% specification is argued for all speakers in spite of seemingly divergent posttonic gestures. The experimental findings speak to cross-linguistic issues such as prominence marking in wh-question intonation, the syntax-prosody interface in wh-questions, and the internal structure of pitch accent configurations.												7	9											MAY	2014	26	1					83	133		10.1515/probus-2013-0003	http://dx.doi.org/10.1515/probus-2013-0003												2026-01-16	WOS:000338417200003
J	Romano, A				Romano, Antonio			PLURALITY OF LANGUAGES, DATA AND METHODS FOR A GENERAL MODEL OF MELODIC VARIATION IN ROMANCE DIALECTS	DIALECTOLOGIA				Article								Speech prosody depends on multiple factors and presents a significant variation among world languages. Interaction between sentence intonation, stress, information patterning and stylistic effects produce local phenomena contributing to complex outcomes that should be studied in accordance with the specific phonology of each language. However, the description of this interaction relies on traditional approaches and various representation methods: different interpretation models are then applied at each level. If, on the one hand, we begin to manage some tools for a general study which seem to bring to light prosodic universals, on the other hand, a too radical approach to prosodic typology may cause the risk of deleting features which are essential from a dialectological point of view. Based on a series of examples concerning the intonational variation in the Romance area, I will try to show in this paper the need to keep using an ecological approach towards languages prosodic diversity.												0	0												2016					VI		29	55															2026-01-16	WOS:000411684800003
J	Honbolygó, F; Török, A; Bánréti, Z; Hunyadi, L; Csépe, V				Honbolygo, Ferenc; Torok, Agoston; Banreti, Zoltan; Hunyadi, Laszlo; Csepe, Valeria			ERP correlates of prosody and syntax interaction in case of embedded sentences	JOURNAL OF NEUROLINGUISTICS				Article								Understanding spoken language depends on processing the delicate combination of grammatical structure, meaning and prosody of utterances. Previous studies have established that prosody influences the processing of sentences when the grammatical structure is ambiguous, however it is unclear how closely prosody and Syntax are related when there is no ambiguity. In an event-related brain potential (ERP) study, we investigated the processing of embedded normal and pseudosentences in which all function and content words were replaced by meaningless words. Sentences could have either natural prosodic structure or incongruent prosodic structure, where the prosody deviated from the one expected based on the syntactic structure, but otherwise the sentences were unambiguous. The resulting ERP components (CPS) showed that the constructiOn of prosodic structure was similar in normal and pseudosentences, thus suggesting that prosody has an abstract, recursive representation, independent of other linguistic information. Moreover, we found evidence that the incongruent prosody was not only detected (shown by the RAN), but it induced neural reintegration processes (shown by the P600) in spite of the syntactic structure of sentences being intact. These results suggest that the prosodic structure is a mandatory constituent of sentence structure building whenever it is present. (C) 2015 Elsevier Ltd. All rights reserved.												10	11											FEB	2016	37						22	33		10.1016/j.jneuroling.2015.08.001	http://dx.doi.org/10.1016/j.jneuroling.2015.08.001												2026-01-16	WOS:000366228000003
J	Tyler, J				Tyler, Joseph			Prosodic correlates of discourse boundaries and hierarchy in discourse production	LINGUA				Article								A well-formed discourse is more than just a series of well-formed sentences. While often left implicit, this structure to discourse is sometimes overtly cued. And though most attention in this area has focused on lexicalized cues like discourse markers, prosody can also convey information about the structure of discourse. This paper presents the results of a production study examining prosodic correlates of discourse structure in readings of a newspaper article. Prosodic measures of pause duration, pitch, intensity and speech rate were found to significantly correlate with discourse structural measures of boundary size, discourse coordination/subordination, and their interaction. This interaction effect shows that the effect of boundary size on an utterance's prosody often depends on whether that utterance is coordinated or subordinated, and vice versa. These results expand our understanding of how prosody correlates with discourse structure, setting the stage for follow-up perception studies of what prosodic variation listeners use in discourse interpretation. (C) 2013 Elsevier B.V. All rights reserved.												13	14											SEP	2013	133						101	126		10.1016/j.lingua.2013.04.005	http://dx.doi.org/10.1016/j.lingua.2013.04.005												2026-01-16	WOS:000322556300006
J	Trauner, DA; Ballantyne, A; Friedland, S; Chase, C				Trauner, DA; Ballantyne, A; Friedland, S; Chase, C			Disorders of affective and linguistic prosody in children after early unilateral brain damage	ANNALS OF NEUROLOGY				Article								Prosody is that quality of speech that imparts meaning by changes in intonation, pitch, and stress. The right hemisphere (RH) appears to be dominant for affective prosody in adults, while the left hemisphere (LH) mediates the more linguistic aspects of nonverbal communication. Few similar studies have been reported of individuals who suffered early unilateral brain damage, when brain reorganization or plasticity might be expected to play a role in ameliorating the adverse effects of focal brain damage. In this study, comprehension and expression of affective and linguistic prosody were tested in subjects with documented unilateral brain damage of pre- or perinatal onset and in matched controls. Both RH- and LH-lesion groups demonstrated difficulty on tasks involving expression of affective prosody, and on tests of linguistic prosody, compared with controls. Only the RH-lesion group was impaired on an affective comprehension task. The results indicate that even after very early unilateral brain damage, prosodic deficits may be present. However, only for affective comprehension does the side of the lesion appear to determine such deficits. The findings suggest that during brain development there is not clear brain lateralization for prosody and there may be bilateral representation for these skills during early development. There may be limitations to the ability of the developing brain to reorganize after early injury.												49	53											MAR	1996	39	3					361	367		10.1002/ana.410390313	http://dx.doi.org/10.1002/ana.410390313												2026-01-16	WOS:A1996UC47300012
J	Giorgi, A; Petrocchi, E				Giorgi, Alessandra; Petrocchi, Erika			Silent imperatives: A multimodal approach to warning expressions	INTERCULTURAL PRAGMATICS				Article								This article argues in favor of a formal model that views language as an integrated multimodal system where syntax, prosody, and gestures are linked. It demonstrates that specific syntactic structures trigger sensorimotor realizations, which include intonation, phonology, and gestures. We argue that gestures, in particular non-lexical co-speech gestures, are not merely an additional channel but a fundamental part of grammar, integrated into the same system that governs word order and phonological realization. We suggest a syntactic representation of warning expressions that combines syntactic and pragmatic aspects, based on Italian data and experimental evidence. Specifically, we argue that warnings always include a warning call, which can be either lexical in content or expressed solely through special prosody and gestures.												0	0											NOV 25	2025	22	5					1013	1048		10.1515/ip-2025-5006	http://dx.doi.org/10.1515/ip-2025-5006												2026-01-16	WOS:001639528900006
J	Gandour, J; Tong, YX; Wong, D; Talavage, T; Dzemidzic, M; Xu, YS; Li, XJ; Lowe, M				Gandour, J; Tong, YX; Wong, D; Talavage, T; Dzemidzic, M; Xu, YS; Li, XJ; Lowe, M			Hemispheric roles in the perception of speech prosody	NEUROIMAGE				Article; Proceedings Paper	11th Annual Meeting of the Cognitive-Neuroscience-Society	APR, 2004	San Francisco, CA					Speech prosody is processed in neither a single region nor a specific hemisphere, but engages multiple areas comprising a large-scale spatially distributed network in both hemispheres. It remains to be elucidated whether hemispheric lateralization is based on higher-level prosodic representations or lower-level encoding of acoustic cues, or both. A cross-language (Chinese; English) fMRI study was conducted to examine brain activity elicited by selective attention to Chinese intonation (I) and tone (T) presented in three-syllable (I3, T3) and one-syllable (I1, T1) utterance pairs in a speeded response, discrimination paradigm. The Chinese group exhibited greater activity than the English in a left inferior parietal region across tasks (I1, I3, T1, T3). Only the Chinese group exhibited a leftward asymmetry in inferior parietal and posterior superior temporal (I1, I3, T1, T3), anterior temporal (I1, I3, T1, T3), and frontopolar (I1, I3) regions. Both language groups shared a rightward asymmetry in the mid portions of the superior temporal sulcus and middle frontal gyrus irrespective of prosodic unit or temporal interval. Hemispheric laterality effects enable us to distinguish brain activity associated with higher-order prosodic representations in the Chinese group from that associated with lower-level acoustic/auditory processes that are shared among listeners regardless of language experience. Lateralization is influenced by language experience that shapes the internal prosodic representation of an external auditory signal. We propose that speech prosody perception is mediated primarily by the RH, but is left-lateralized to task-dependent regions when language processing is required beyond the auditory analysis of the complex sound. (C) 2004 Elsevier Inc. All rights reserved.												180	211											SEP	2004	23	1					344	357		10.1016/j.neuroimage.2004.06.004	http://dx.doi.org/10.1016/j.neuroimage.2004.06.004												2026-01-16	WOS:000223645000037
J	Burred, JJ; Ponsot, E; Goupil, L; Liuni, M; Aucouturier, JJ				Burred, Juan Jose; Ponsot, Emmanuel; Goupil, Louise; Liuni, Marco; Aucouturier, Jean-Julien			CLEESE: An open-source audio-transformation toolbox for data-driven experiments in speech and music cognition	PLOS ONE				Article								Over the past few years, the field of visual social cognition and face processing has been dramatically impacted by a series of data-driven studies employing computer-graphics tools to synthesize arbitrary meaningful facial expressions. In the auditory modality, reverse correlation is traditionally used to characterize sensory processing at the level of spectral or spectro-temporal stimulus properties, but not higher-level cognitive processing of e.g. words, sentences or music, by lack of tools able to manipulate the stimulus dimensions that are relevant for these processes. Here, we present an open-source audio-transformation toolbox, called CLEESE, able to systematically randomize the prosody/melody of existing speech and music recordings. CLEESE works by cutting recordings in small successive time segments (e.g. every successive 100 milliseconds in a spoken utterance), and applying a random parametric transformation of each segment's pitch, duration or amplitude, using a new Python-language implementation of the phase-vocoder digital audio technique. We present here two applications of the tool to generate stimuli for studying intonation processing of interrogative vs declarative speech, and rhythm processing of sung melodies.												17	17											APR 4	2019	14	4							e0205943	10.1371/journal.pone.0205943	http://dx.doi.org/10.1371/journal.pone.0205943												2026-01-16	WOS:000463314500003
J	Scheerer, NE; Shafai, F; Stevenson, RA; Iarocci, G				Scheerer, Nichole E.; Shafai, Fakhri; Stevenson, Ryan A.; Iarocci, Grace			Affective Prosody Perception and the Relation to Social Competence in Autistic and Typically Developing Children	JOURNAL OF ABNORMAL CHILD PSYCHOLOGY				Article								Individuals diagnosed with autism spectrum disorder (ASD) have difficulty perceiving and expressing emotions. Since prosodic changes in speech (i.e. changes in intonation, stress, rhythm, etc.) are crucial for extracting information about the emotional state of a speaker, an inability to perceive and interpret these prosodic changes may be related to impairments in social communication. This study used non-verbal emotional voice-clips to examine the ability of autistic and typically-developing children (7-13 years old) to extract affect from changes in prosody. This research also explored whether difficulty extracting affective intent from changes in prosody may be related to social competence. Autistic (n = 26) and typically-developing (n = 26) children accurately matched emotional voice-clips to emotion words, suggesting autistic children can accurately extract the affective meaning conveyed by changes in prosody. Autistic children were less accurate at matching the voice-clips to emotional faces, suggesting that autistic children may struggle to make use of prosodic information in a social context. Across both autistic and typically-developing children, prosody-face matching accuracy was found to predict overall social competence, as well as social inferencing abilities, suggesting that the inability to utilize affective information derived from a speaker's voice may interfere with effective social communication.												18	20											JUL	2020	48	7					965	975		10.1007/s10802-020-00644-5	http://dx.doi.org/10.1007/s10802-020-00644-5		APR 2020										2026-01-16	WOS:000526329100001
J	den Ouden, DB; Dickey, MW; Anderson, C; Christianson, K				den Ouden, Dirk-Bart; Dickey, Michael Walsh; Anderson, Catherine; Christianson, Kiel			Neural correlates of early-closure garden-path processing: Effects of prosody and plausibility	QUARTERLY JOURNAL OF EXPERIMENTAL PSYCHOLOGY				Article								Functional magnetic resonance imaging (fMRI) was used to investigate neural correlates of early-closure garden-path sentence processing and use of extrasyntactic information to resolve temporary syntactic ambiguities. Sixteen participants performed an auditory picture verification task on sentences presented with natural versus flat intonation. Stimuli included sentences in which the garden-path interpretation was plausible, implausible because of a late pragmatic cue, or implausible because of a semantic mismatch between an optionally transitive verb and the following noun. Natural sentence intonation was correlated with left-hemisphere temporal activation, but also with activation that suggests the allocation of more resources to interpretation when natural prosody is provided. Garden-path processing was associated with upregulation in bilateral inferior parietal and right-hemisphere dorsolateral prefrontal and inferior frontal cortex, while differences between the strength and type of plausibility cues were also reflected in activation patterns. Region of interest (ROI) analyses in regions associated with complex syntactic processing are consistent with a role for posterior temporal cortex supporting access to verb argument structure. Furthermore, ROI analyses within left-hemisphere inferior frontal gyrus suggest a division of labour, with the anterior-ventral part primarily involved in syntactic-semantic mismatch detection, the central part supporting structural reanalysis, and the posterior-dorsal part showing a general structural complexity effect.												19	20											MAY 3	2016	69	5			SI		926	949		10.1080/17470218.2015.1028416	http://dx.doi.org/10.1080/17470218.2015.1028416												2026-01-16	WOS:000372102000006
J	Singh, L; Chee, M				Singh, Leher; Chee, Melissa			Rise and fall: Effects of tone and intonation on spoken word recognition in early childhood	JOURNAL OF PHONETICS				Article								A crucial component of word learning is the ability to recognize words in spite of the varying forms they assume. This may be particularly challenging in tone languages as learners have to develop tone representations in the face of intonational variation in order to accurately recognize words. The effects of intonational variation on word recognition of tone-marked words in Mandarin Chinese were investigated in toddlers and preschoolers using a cross-sectional design. Participants were presented with known words where intonation (question/statement) and tone (rising/falling) were independently manipulated. Results demonstrated that word recognition in toddlers was heavily influenced by changes in the pitch contour of a tone due to intonational variation. In contrast, preschool were able to recognize tone-marked words regardless of simultaneous intonational variation, demonstrating a comparatively robust representation of lexical tone. Results chart an evolution in integrating pitch cues to tone and intonation over the first few years of life. (C) 2016 Elsevier Ltd. All rights reserved.												30	31											MAR	2016	55						109	118		10.1016/j.wocn.2015.12.005	http://dx.doi.org/10.1016/j.wocn.2015.12.005												2026-01-16	WOS:000372394300007
J	Qu, LY; Weber, C; Wang, W; Jin, J; Gao, YM; Li, TH; Wermter, S				Qu, Leyuan; Weber, Cornelius; Wang, Wei; Jin, Jia; Gao, Yingming; Li, Taihao; Wermter, Stefan			Disentanglement of Prosody Representations via Diffusion Models and Scheduled Gradient Reversal	IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS				Article								Prosody plays a fundamental role in human speech and communication, facilitating intelligibility and conveying emotional and cognitive states. Extracting accurate prosodic information from speech is vital for building assistive technology, such as controllable speech synthesis, speaking style transfer, and speech emotion recognition (SER). However, it is challenging to disentangle speaker-independent prosody representations since prosodic attributes, such as intonation, excessively entangle with speaker-specific attributes, e.g., pitch. In this article, we propose a novel model, called Diffsody, to disentangle and refine prosody representations: 1) to disentangle prosody representations, we leverage the expressive generative ability of a diffusion model by conditioning it on quantified semantic information and pretrained speaker embeddings. Additionally, a prosody encoder automatically learns prosody representations used for spectrogram reconstruction in an unsupervised fashion; and 2) to refine and learn speaker-invariant prosody representations, a scheduled gradient reversal layer (sGRL) is proposed and integrated into the prosody encoder of Diffsody. We extensively evaluate Diffsody through qualitative and quantitative means. t-SNE visualization and speaker verification experiments demonstrate the efficacy of the sGRL method in preventing speaker-specific information leakage. Experimental results on speaker-independent SER and automatic depression detection (ADD) tasks demonstrate that Diffsody can efficiently factorize speaker-independent prosody representations, resulting in a significant boost in SER and ADD. In addition, Diffsody synergistically integrates with the semantic representation model WavLM, which leads to a discernibly elevated performance, outperforming contemporary methods in both SER and ADD tasks. Furthermore, the Diffsody model exhibits promising potential for various practical applications, such as voice or style conversion. Some audio samples can be found on our https://leyuanqu.github.io/Diffsody/demo website.												1	1											AUG	2025	36	8					15043	15054		10.1109/TNNLS.2025.3534822	http://dx.doi.org/10.1109/TNNLS.2025.3534822		FEB 2025										2026-01-16	WOS:001470595300001
J	Straub, K; Wilson, C; McCollum, C; Badecker, W				Straub, K; Wilson, C; McCollum, C; Badecker, W			Prosodic structure and wh-questions	JOURNAL OF PSYCHOLINGUISTIC RESEARCH				Article								This study examines the influence of wh-gaps on the prosodic contour of spoken utterances. A previous study (Nagel, Shapiro, & Nawy, 1994) claimed that the phonological representation of a sentence containing a filler-gap dependency explicitly encodes the location of the syntactic gap. In support of this hypothesis, Nagel et at. presented evidence that the word immediately preceding a gap is lengthened and that there is a reliable increase in pitch excursion across the gap location. Our study challenges Nagel et al.'s claim. We argue that their materials confounded the presence/absence of a gap with other factors that are known to affect intonational phrasing independently. We show that, when these factors are separated, the evidence that syntactic gaps are explicitly encoded in the phonological representation of a sentence disappears.												5	5											JUL	2001	30	4					379	394		10.1023/A:1010469607504	http://dx.doi.org/10.1023/A:1010469607504												2026-01-16	WOS:000170597100002
J	Cheng, LLS; Downing, LJ				Cheng, Lisa Lai-Shen; Downing, Laura J.			Recursion and the Definition of Universal Prosodic Categories	LANGUAGES				Article								It is widely agreed that prosodic constituents should mirror syntactic constituents (unless high-ranking prosodic constraints interfere). Because recursion is a feature of syntactic representations, one expects recursion in prosodic representations as well. However, it is of current controversy what kinds of syntactic representation motivate prosodic recursion. In this paper, the use of Phonological Phrase recursion is reviewed in several case studies, chosen because prosodic recursion mostly does not reflect syntactic recursion as defined in current syntactic theory. We provide reanalyses that do not appeal to prosodic recursion (unless syntactically motivated), showing that Phonological Phrase recursion is not necessary to capture the relevant generalizations. The more restrictive use of prosodic recursion we argue for has the following conceptual advantages. It allows for more consistent cross-linguistic generalizations about the syntax-prosody mapping so that prosodic representations more closely reflect syntactic ones. It allows the fundamental syntactic distinctions between clause (and other phases) and phrase to be reflected in the prosodic representation, and it allows cross-linguistic generalizations to be made about the prosodic domain of intonational processes, such as downstep and continuation rise.												5	5											SEP	2021	6	3							125	10.3390/languages6030125	http://dx.doi.org/10.3390/languages6030125												2026-01-16	WOS:000700640400001
J	Gronnum, N; Vazquez-Larruscaín, M; Basboll, H				Gronnum, Nina; Vazquez-Larruscain, Miguel; Basboll, Hans			Danish Stod: Laryngealization or Tone	PHONETICA				Article								In the light of previous acoustic analyses of Danish stod and Danish intonation, we discuss two different phonological theories. In one, stod is an autonomous laryngeal syllable prosody. In the other, stod is the phonetic manifestation of an HL tonal pattern compressed within one syllable. The tonal representation is found to be contradicted by the phonetic reality, and it cannot account for the structurally determined alternation between non-stod and stod in inflection and derivation, nor for latent stod or stod in compounds. Furthermore, stod patterns are largely constant across regional varieties of Danish, but tonal patterns over the relevant structural domains are highly variable. Thus, stod may occur on any kind of tonal configuration, anywhere in the speaker's pitch range, a variability which is hard to reconcile with a fixed HL representation. Copyright (C) 2013 S. Karger AG, Basel												21	24												2013	70	1-2					66	92		10.1159/000354640	http://dx.doi.org/10.1159/000354640												2026-01-16	WOS:000326439900003
J	Schweitzer, K; Walsh, M; Calhoun, S; Schütze, H; Möbius, B; Schweitzer, A; Dogil, G				Schweitzer, Katrin; Walsh, Michael; Calhoun, Sasha; Schuetze, Hinrich; Moebius, Bernd; Schweitzer, Antje; Dogil, Grzegorz			Exploring the relationship between intonation and the lexicon: Evidence for lexicalised storage of intonation	SPEECH COMMUNICATION				Article								In Germanic languages like English and German, intonation is usually thought to be 'post-lexical'. That is, it is usually assumed that the choice of intonation contour and the form of the realised contour itself are largely independent of the words used. We present three corpus experiments which show clear evidence of lexical storage of intonation, contrary to these assumptions. Specifically, in each experiment, we show that distributional properties of words affect the prosodic realisation of those words, including accent and boundary placement, and the shape of pitch accents. The first experiment looks at the frequency of occurrence of a given word with a particular pitch accent type and its effect on the shape of accents on that word. We found that the more frequently a word and an accent type appear together, the greater the amplitude of the accent. The second experiment investigates the effect of both the absolute and relative frequency of occurrence of a given word with a particular accent type and their effect on the variability of the shape of these accents. We found that while absolute frequency increases the variability in pitch accent shape, relative frequency reduces it. The final experiment looks at the effect of the relative frequency of a word in its lexical (trigram) context on both variability in its prosodic context and on accent shape variability. We found that both kinds of prosodic variability decrease as the relative frequency of the word in its lexical context increases. We argue that all of these findings are expected within an exemplar approach assuming storage of tonal information with lexical items, and discuss the implications of this for the production and mental representation of intonation. (C) 2014 Elsevier B.V. All rights reserved.												19	23											FEB	2015	66						65	81		10.1016/j.specom.2014.09.006	http://dx.doi.org/10.1016/j.specom.2014.09.006												2026-01-16	WOS:000348261700005
J	Hyman, LM				Hyman, Larry M.			In defense of prosodic typology: A response to Beckman & Venditti	LINGUISTIC TYPOLOGY				Article								In two recent handbook articles, Beckman & Venditti (2010, 2011) present overviews of tone and intonation which take issue with both traditional typology and recent attempts to bring clarity to the study of prosodic typology. In the course of their coverage Beckman & Venditti question the "usefulness" of distinguishing prosodic systems by "tonemic function alone" (e.g., lexical tone, stress, intonation) and raise the question "Is typology needed?" Within this context I once again argue for a "property-driven" approach to prosodic typology whose goal is not to classify languages into prosodic types, rather to accurately characterize the same vs. different ways in which prosodic properties are exploited. We thus ask (i) whether a given language has word-level contrastive pitch ("tone"), word-level metrical structure ("stress"), both, or neither; (ii) if yes, what does the prosodic system do with the tones and/or stress, both at the word level and postlexically? Given the level-ordered nature of phonological systems, only after the first two questions are dealt with can we move on to the the question with which Beckman & Venditti are most concerned: (iii) how are the surface or output word-prosodic properties integrated with phrase-and utterance-level intonation? While Beckman & Venditti question the usefulness of "broad-stroke typologies" which have traditionally distinguished tone, stress, and intonation, their disposition to minimize systemic differences in favor of surface comparisons of phonetic realizations raises important questions concerning levels of representation and the nature of phonological typology itself.												10	14											AUG	2012	16	3					341	385		10.1515/lingty-2012-0014	http://dx.doi.org/10.1515/lingty-2012-0014												2026-01-16	WOS:000209107800002
J	Liu, XL; Xu, Y; Zhang, WJ; Tian, X				Liu, Xiaoluan; Xu, Yi; Zhang, Wenjia; Tian, Xing			Multiple prosodic meanings are conveyed through separate pitch ranges: Evidence from perception of focus and surprise in Mandarin Chinese	COGNITIVE AFFECTIVE & BEHAVIORAL NEUROSCIENCE				Article								F0 variation is a crucial feature in speech prosody, which can convey linguistic information such as focus and paralinguistic meanings such as surprise. How can multiple layers of information be represented with F0 in speech: are they divided into discrete layers of pitch or overlapped without clear divisions? We investigated this question by assessing pitch perception of focus and surprise in Mandarin Chinese. Seventeen native Mandarin listeners rated the strength of focus and surprise conveyed by the same set of synthetically manipulated sentences. An fMRI experiment was conducted to assess neural correlates of the listeners' perceptual response to the stimuli. The results showed that behaviourally, the perceptual threshold for focus was 3 semitones and that for surprise was 5 semitones above the baseline. Moreover, the pitch range of 5-12 semitones above the baseline signalled both focus and surprise, suggesting a considerable overlap between the two types of prosodic information within this range. The neuroimaging data positively correlated with the variations in behavioural data. Also, a ceiling effect was found as no significant behavioural differences or neural activities were shown after reaching a certain pitch level for the perception of focus and surprise respectively. Together, the results suggest that different layers of prosodic information are represented in F0 through different pitch ranges: paralinguistic information is represented at a pitch range beyond that used by linguistic information. Meanwhile, the representation of paralinguistic information is achieved without obscuring linguistic prosody, thus allowing F0 to represent the two layers of information in parallel.												5	5											DEC	2021	21	6					1164	1175		10.3758/s13415-021-00930-9	http://dx.doi.org/10.3758/s13415-021-00930-9		JUL 2021										2026-01-16	WOS:000679637500002
J	de Moraes, JA; Colamarco, M				de Moraes, Joao Antonio; Colamarco, Manuela			Are you asking me or requesting me?	REVISTA DE ESTUDOS DA LINGUAGEM				Article								In this paper the intonation contours of yes/no questions and requests in Brazilian Portuguese are compared. Speech synthesis was used to evaluate the relevance of the F0 configuration of nuclear and prenuclear pitch accents in the distinction between these two intonational patterns. Thirty-one resynthesized melodic versions of the sentence "Na festa destranca?" (At the party do you unlock it?/ At the party would you please unlock it?) - which is ambiguous in Portuguese in its interpretation as a question or as a request - have been created. These versions, placed in four auditory tests, have been judged by twenty listeners who evaluated the effects of the modifications in the original sentence, in favor of its interpretation either as a question or as a request. The results of the perception tests show that the opposition between the two melodic contours is due to the direction of the F0 curve in the nuclear pitch accent, rising in the yes/no question and falling in the request. A phonological representation of these patterns, based on distinct temporal alignments of the F0 peak in the final stressed syllables, is proposed.												0	0											JUL-DEC	2007	15	2					113	126															2026-01-16	WOS:000215908700006
J	Khapekar, A; Mishra, N; Mandava, VL; Rao, TKRK; Pagidipati, B; Devarasetty, P; Muniyandy, E				Khapekar, Amit; Mishra, Nidhi; Mandava, Vijaya Lakshmi; Rao, T. K. Rama Krishna; Pagidipati, Bhuvaneswari; Devarasetty, Prasad; Muniyandy, Elangovan			Leveraging Intelligent Speech Training to Elevate Phonetic Accuracy and Prosodic Fluency in English Learners	INTERNATIONAL JOURNAL OF ADVANCED COMPUTER SCIENCE AND APPLICATIONS				Article								The successful teaching of pronunciation, as well as prosody, is the significant challenge that still remains to the English as Foreign Learning (EFL) students. Traditional pedagogical theories tend to focus on segmental phoneme accuracy but ignore suprasegmental components (stress or rhythm and intonation) which are natural and intelligible speech components. The currently available systems of computer-assisted pronunciation training (CAPT) are useful, but limited by the fact that they are based on limited acoustic models and incomplete coverage of prosodic characteristics, leading to less than optimal accuracy and limited pedagogical suitability. To overcome these shortcomings, the current paper proposes Attention-Guided Cross-Lingual Self-Supervised Learning (AG-CLSSL), a new model that is both able to combine phoneme-level representations of XLS-R (wav2vec2-large-xlsr-53) and prosodic representations of the pitch, energy, and duration through a Phoneme-Prosody Cross-Attention Fusion (PP-CAF) process. This conglomeration allows the joint and context specific representation of the speech that is further refined by the multi-task Transformer-based scoring model to jointly assess the accuracy of pronunciation, the consistency of the prosody and the general intelligibility. The framework is implemented in Python, with support of PyTorch and Hugging Face Transformers and is trained on an evaluated corpus of EFL learner speech (n=100) with a variety of L1 backgrounds, including Mandarin, Hindi, and Spanish. Experimental assessments indicate significant performance improvement with 55.4% decrease in Phoneme Error rate, 52.0 percent decrease in Word Error rate, 43.3 percent increase in Stress Placement Accuracy and 34.9 percent increase in Pitch Alignment Score. The total acoustic similarity to native speech went up by 36.1, which demonstrates the ability of AG-CLSSL to progress articulatory accuracy as well as the naturalness of prosody and provide interpretable and attention-directed information on scalable AI-based pronunciation and prosody training.												0	0												2025	16	11					756	768															2026-01-16	WOS:001638684400001
J	Titov, E				Titov, Elena			Morphosyntactic encoding of information structure in Akan	GLOSSA-A JOURNAL OF GENERAL LINGUISTICS				Article								This paper investigates the interpretive and formal properties of the so-called focus construction in Akan. It argues that Akan has only one true morphological focus marker, namely na, whereas the marker de(epsilon) that has been analysed in the linguistic literature on Akan as a focus marker (Boadi 1974; Saah 1988; Boadi 1990; Saah 1994; Marfo and Bodomo 2005) is in fact a marker of contrastive topic. The proposed analysis relies on the idea that the Akan morphological markers na and de(epsilon) carry out exactly the same interpretive function as the falling and rising prosodic markers, respectively, found in intonation languages. It is shown that a number of controversies associated with Akan information-structural marking can be accounted for by assuming a certain parallelism with intonation languages. It is demonstrated that particular types of information-structural partitioning are cross-linguistically encoded via a marked strategy, with the parametric variation resulting from the difference in the choice of the linguistic tool - syntactic, morphological or prosodic - used to create a marked representation.												7	8											FEB 11	2019	4	1							27	10.5334/gjgl.576	http://dx.doi.org/10.5334/gjgl.576												2026-01-16	WOS:000458388700001
J	Spaai, GWG; Derksen, ES; Hermes, DJ; Kaufholz, PAP				Spaai, GWG; Derksen, ES; Hermes, DJ; Kaufholz, PAP			Teaching intonation to young deaf children with the Intonation Meter	FOLIA PHONIATRICA ET LOGOPAEDICA				Article								Incorrect production of intonation contours is a common phonatory problem in prelingually, profoundly deaf speakers. To help deaf speakers improve this, a visual display system for teaching intonation has been developed. In this system, called the Intonation Meter, visual feedback of intonation is given as a continuous representation of the pitch contour containing only the perceptually relevant aspects of the intonation pattern. This pitch-contour representation is supposed to facilitate the interpretation of the visual feedback of the pitch contour. A study was carried out, using a Single-Subject Design, in which subjects alternately received intonation training by means of regular methods and intonation training by means of regular methods in which also use was made of the Intonation Meter, to evaluate the effectiveness of the Intonation Meter for teaching intonation to young deaf children. Prelingually profoundly deaf children aged 6 to 7 years and 9 to 11 years participated in this study. The results showed that the 9 to 11 year old children showed most progress when the Intonation Meter was used in intonation training whereas the 6 to 7 year olds progressed well irrespective of whether or not the Intonation Meter was used, which is in accordance with the theory of a critical period for language learning. Alternatively, it is hypothesized that the cognitive requirements of the visual feedback might be too advanced for very young children to be helpful in learning to produce certain pitch contours.												2	2											JAN-FEB	1996	48	1					22	34		10.1159/000266379	http://dx.doi.org/10.1159/000266379												2026-01-16	WOS:A1996UE14600003
J	Xu, Y; Prom-on, S				Xu, Yi; Prom-on, Santitham			Toward invariant functional representations of variable surface fundamental frequency contours: Synthesizing speech melody via model-based stochastic learning	SPEECH COMMUNICATION				Article								Variability has been one of the major challenges for both theoretical understanding and computer synthesis of speech prosody. In this paper we show that economical representation of variability is the key to effective modeling of prosody. Specifically, we report the development of PENTAtrainer-A trainable yet deterministic prosody synthesizer based on an articulatory functional view of speech. We show with testing results on Thai, Mandarin and English that it is possible to achieve high-accuracy predictive synthesis of fundamental frequency contours with very small sets of parameters obtained through stochastic learning from real speech data. The first key component of this system is syllable-synchronized sequential target approximation implemented as the qTA model, which is designed to simulate, for each tonal unit, a wide range of contextual variability with a single invariant target. The second key component is the automatic learning of function-specific targets through stochastic global optimization, guided by a layered pseudo-hierarchical functional annotation scheme, which requires the manual labeling of only the temporal domains of the functional units. The results in terms of synthesis accuracy demonstrate that effective modeling of the contextual variability is the key also to effective modeling of function-related variability. Additionally, we show that, being both theory-based and trainable (hence data-driven), computational systems like PENTAtrainer can serve as an effective modeling tool in basic research, with which the level of falsifiability in theory testing can be raised, and also a closer link between basic and applied research in speech science can be developed. (C) 2013 Elsevier B.V. All rights reserved.												51	53											FEB	2014	57						181	208		10.1016/j.specom.2013.09.013	http://dx.doi.org/10.1016/j.specom.2013.09.013												2026-01-16	WOS:000328180100014
J	Cruttenden, A				Cruttenden, A			Mancunian intonation and intonational representation	PHONETICA				Article								There has been little systematic description of the intonation of English accents other than RP and General American. In the first part of this article the characteristics of the tones of Mancunian intonation are described together with a functional categorisation of these tones, in which a dichotomy is proposed between Open and Closed varieties. In the second part the description is related to the current model of intonation known as ToBl and the inadequacies of a representation of Mancunian tones in a standard and a modified form of ToBl are revealed. A more radical modification of the ToBl approach based on tonal features is proposed. Copyright (C) 2001 S. Karger AG, Basel.												10	17											JAN-JUN	2001	58	1-2					53	80		10.1159/000028488	http://dx.doi.org/10.1159/000028488												2026-01-16	WOS:000165823200003
J	Lelandais, M; Thiberge, G				Lelandais, Manon; Thiberge, Gabriel			The role of prosody and hand gestures in the perception of boundaries in speech	SPEECH COMMUNICATION				Article								This paper investigates the use of prosodic, gestural, and syntactic information in the perception of boundaries in extracts of spontaneous speech in British English. Experiment 1 aimed at investigating the effect of prosody on naive participants' perception of boundary strength. 13 naive listeners had to rate boundary strength for 64 extracts on a 5-point scale. The stimuli all contained three tone-units, the second being a syntactic subordinate construction, which was established as a variable. The prosodic cues at the boundary between the tone-units were also established as variables, and were subject to manipulation (addition of a single cue associated with the perception of a prosodic boundary). Experiment 2 aimed at assessing the effect of gesture on naive participants' perception of boundary strength. In Experiment 2, 24 naive listeners had to measure boundary strength for 24 extracts on a 5-point scale. The stimuli all contained three tone-units, the second being a syntactic subordinate construction, which was established as a variable. The hand gestures produced in co-occurrence with the tone-units were established as variables, and were subject to manipulation. Results show that prosody modulates perceived boundary strength, but not gesture, based on the variables we included. Silent pauses have the strongest effect on perceived boundary strength, but final syllabic lengthening and pitch reset also have separate effects as single predictors. Our data also shows a trend concerning the production of two identical hand gestures in terms of configuration and trajectory.												3	3											MAY	2023	150						41	65		10.1016/j.specom.2023.05.001	http://dx.doi.org/10.1016/j.specom.2023.05.001		MAY 2023										2026-01-16	WOS:001000636200001
J	Wang, SM; Chen, LP; Ai, Y; Hu, YJ; Ling, ZH				Wang, Shiming; Chen, Li-Ping; Ai, Yang; Hu, Yajun; Ling, Zhen-Hua			PhonemeVec: A Phoneme-Level Contextual Prosody Representation For Speech Synthesis	ACM TRANSACTIONS ON ASIAN AND LOW-RESOURCE LANGUAGE INFORMATION PROCESSING				Article								Recently, fine-grained prosody representations have emerged and attracted growing attention to address the one-to-many problem in text-to-speech (TTS). In this article, we propose the PhonemeVec, a pre-trained prosody representations with considering the contextual information. To obtain the contextual prosody representations, we improve the data2vec framework according to the characteristics of prosody to extract the PhonemeVec from the low-band mel-spectrogram, and pre-train on a 960 hours Chinese corpus with high quality and diverse pronunciation. PhonemeVec is subsequently integrated into FastSpeech2, supervising the prosody modeling of the text encoder. Experiments conducted on the Blizzard Challenge 2019 dataset show that the integration of PhonemeVec results in the synthesis of more natural speech. Additionally, objective evaluations confirm that the application of PhonemeVec reduces the distortions between the generated speech and original recordings in terms of duration and F0.												1	1											MAR	2025	24	3							29	10.1145/3711828	http://dx.doi.org/10.1145/3711828												2026-01-16	WOS:001472945100005
J	Schirmer, A				Schirmer, Annett			Mark My Words: Tone of Voice Changes Affective Word Representations in Memory	PLOS ONE				Article								The present study explored the effect of speaker prosody on the representation of words in memory. To this end, participants were presented with a series of words and asked to remember the words for a subsequent recognition test. During study, words were presented auditorily with an emotional or neutral prosody, whereas during test, words were presented visually. Recognition performance was comparable for words studied with emotional and neutral prosody. However, subsequent valence ratings indicated that study prosody changed the affective representation of words in memory. Compared to words with neutral prosody, words with sad prosody were later rated as more negative and words with happy prosody were later rated as more positive. Interestingly, the participants' ability to remember study prosody failed to predict this effect, suggesting that changes in word valence were implicit and associated with initial word processing rather than word retrieval. Taken together these results identify a mechanism by which speakers can have sustained effects on listener attitudes towards word referents.												15	17											FEB 15	2010	5	2							e9080	10.1371/journal.pone.0009080	http://dx.doi.org/10.1371/journal.pone.0009080												2026-01-16	WOS:000274474700001
J	Vujovic, S				Vujovic, Sandra			THE FUNCTIONS OF PROSODIC ELEMENTS IN TV TALK SHOWS IN ENGLISH	LINGUA MONTENEGRINA				Article								This paper is a part of the MA thesis "Prosody in TV Talk Shows (analysed material is in English)". It explores the role of prosody in achieving the cohesion of a text, as well as the connection of prosody with the lexicogrammatical structure within the same field.												0	0												2010	5						133	145															2026-01-16	WOS:000420803700008
J	He, WJ; Zhao, YY; Lin, P; He, YX; Feng, AQ				He, Weijun; Zhao, Yongyong; Lin, Pei; He, Yuxin; Feng, And Qi			Long-Term Fundamental Frequency Modeling Based on Wavelet Packet Transform for Voice Conversion	JOURNAL OF THE AUDIO ENGINEERING SOCIETY				Article								Prosody conversion is an important part in voice conversion, where fundamental frequency (F0), which carries important speaker individuality information (e.g., tone, intonation, etc.), is regarded as one of the key prosodic features in the excitation model for speech synthesis. In a conventional approach based on continuous wavelet transform for modeling F0, analysis is carried out on a frame level and is prone to losing high-frequency information in the process of decomposition and reconstruction. In order to address this problem, the paper shows a representation of long-term fundamental frequency based on Wavelet Packet Transform (WPT). Specifically, the long-term F0 is decomposed using WPT, and a joint vector is formed by combining the resulted average power spectrum. Furthermore, the method is applied in a voice conversion system. Voice conversion experiments are conducted on Chinese and English speech data to evaluate the performance of the proposed method. The results show that the proposed method is obviously better than the method based on wavelet transform in all conversion scenarios but performs a little worse than the method based on mean and variance in same-gender conversion scenario.												1	1											MAR	2024	72	3								10.17743/jaes.2022.0126	http://dx.doi.org/10.17743/jaes.2022.0126												2026-01-16	WOS:001266152900005
J	Odéjobí, OA; Wong, SHS; Beaumont, AJ				Odejobi, Odetunji A.; Wong, Shun Ha Sylvia; Beaumont, Anthony J.			A fuzzy decision tree-based duration model for Standard Yoruba text-to-speech synthesis	COMPUTER SPEECH AND LANGUAGE				Article								In this paper, we present syllable-based duration modelling in the context of a prosody model for Standard Yoruba (SY) text-to-speech (TTS) synthesis applications. Our prosody model is conceptualised around a modular holistic framework. This framework is implemented using the Relational Tree (R-Tree) techniques. An important feature of our R-Tree framework is its flexibility in that it facilitates the independent implementation of the different dimensions of prosody, i.e. duration. intonation, and intensity, using different techniques and their subsequent integration. We applied the Fuzzy Decision Tree (FDT) technique to model the duration dimension. In order to evaluate the effectiveness of FDT in duration modelling. we have also developed a Classification And Regression Tree (CART) based duration model using the same speech data. Each of these models was integrated into Our R-Tree based prosody model. We performed both quantitative (i.e. Root Mean Square Error (RMSE) and Correlation (Corr)) and qualitative (i.e. intelligibility and naturalness) evaluations on the two duration models. The results show that CART models the training data more accurately than FDT. The FDT model, however, shows a better ability to extrapolate from the training data since it achieved a better accuracy for the test data set. Our qualitative evaluation results show that our FDT model produces synthesised speech that is perceived to be more natural than our CART model. In addition, we also observed that the expressiveness of FDT is much better than that of CART. That is because the representation in FDT is not restricted to a set of piece-wise or discrete constant approximation. We, therefore, conclude that the FDT approach is a practical approach for duration modelling in SY TTS applications. (c) 2006 Elsevier Ltd. All rights reserved.												7	9											APR	2007	21	2					325	349		10.1016/j.csl.2006.06.005	http://dx.doi.org/10.1016/j.csl.2006.06.005												2026-01-16	WOS:000242491800006
J	FELDSTEIN, RF				FELDSTEIN, RF			PARADIGMATIC REPRESENTATION OF COMMON SLAVIC PROSODY	LINGUISTICS				Article																				0	0												1978					SI		101	118															2026-01-16	WOS:A1978HA29500004
J	Tian, QB; Yap, NT; Ng, CF; Yahya, Y				Tian, Qingbo; Yap, Ngee Thai; Ng, Chwee Fang; Yahya, Yasir			A Contrastive Analysis of English and Chinese Intonation Systems: An Auto-Segmental Metrical Framework	CHINESE JOURNAL OF APPLIED LINGUISTICS				Article								Intonation refers to the use of supra-segmental features to convey pragmatic meanings at the sentence level in a linguistically structured way. The difference in intonation between the native language and a foreign language may influence second language learners' acquisition of intonation. The purpose of this study is to explore the similarities and differences at the level of phonological representation between English and Chinese intonation systems. This study investigated English and Chinese intonation systems, respectively, from both form and meaning under the Auto-Segmental Metrical framework by referring to previous studies and illustrating examples. The results showed that in terms of form, there were notable differences in the structural elements and their inventories between the intonation systems of English and Chinese. In terms of meaning, assertions were represented by different structural elements in English and Chinese intonation systems; the types of structural elements in English intonation possessed the capability to convey complex and subtle meanings, contrasting with the comparatively simpler nature of Chinese intonation.The results reveal that Chinese EFL learners demonstrate considerable difficulties in the production of the structural elements of English intonation and their combinations due to L1 intonation interference.												0	0											AUG 26	2025	48	3					366	400		10.1515/CJAL-2025-0301	http://dx.doi.org/10.1515/CJAL-2025-0301												2026-01-16	WOS:001561514400005
J	Chow, I; Brown, S				Chow, Ivan; Brown, Steven			A Musical Approach to Speech Melody	FRONTIERS IN PSYCHOLOGY				Article								We present here a musical approach to speech melody, one that takes advantage of the intervallic precision made possible with musical notation. Current phonetic and phonological approaches to speech melody either assign localized pitch targets that impoverish the acoustic details of the pitch contours and/or merely highlight a few salient points of pitch change, ignoring all the rest of the syllables. We present here an alternative model using musical notation, which has the advantage of representing the pitch of all syllables in a sentence as well as permitting a specification of the intervallic excursions among syllables and the potential for group averaging of pitch use across speakers. We tested the validity of this approach by recording native speakers of Canadian English reading unfamiliar test items aloud, spanning from single words to full sentences containing multiple intonational phrases. The fundamental-frequency trajectories of the recorded items were converted from hertz into semitones, averaged across speakers, and transcribed into musical scores of relative pitch. Doing so allowed us to quantify local and global pitch-changes associated with declarative, imperative, and interrogative sentences, and to explore the melodic dynamics of these sentence types. Our basic observation is that speech is atonal. The use of a musical score ultimately has the potential to combine speech rhythm and melody into a unified representation of speech prosody, an important analytical feature that is not found in any current linguistic approach to prosody.												22	25											MAR 5	2018	9								247	10.3389/fpsyg.2018.00247	http://dx.doi.org/10.3389/fpsyg.2018.00247												2026-01-16	WOS:000426547500001
J	Mary, L; Yegnanarayana, B				Mary, Leena; Yegnanarayana, B.			Extraction and representation of prosodic features for language and speaker recognition	SPEECH COMMUNICATION				Article								In this paper, we propose a new approach for extracting and representing prosodic features directly from the speech signal. We hypothesize that prosody is linked to linguistic units such as syllables, and it is manifested in terms of changes in measurable parameters such as fundamental frequency (F-0), duration and energy. In this work, syllable-like unit is chosen as the basic unit for representing the prosodic characteristics. Approximate segmentation of continuous speech into syllable-like units is obtained by locating the vowel onset points (VOP) automatically. The knowledge of the VOPs serve as reference for extracting prosodic features from the speech signal. Quantitative parameters are used to represent F-0 and energy contour in each region between two consecutive VOPs. Prosodic features extracted using this approach may be useful in applications such as recognition of language or speaker, where explicit phoneme/syllable boundaries are not easily available. The effectiveness of the derived prosodic features for language and speaker recognition is evaluated in the case of NIST language recognition evaluation 2003 and the extended data task of NIST speaker recognition evaluation 2003, respectively. (c) 2008 Elsevier B.V. All rights reserved.												141	155											OCT	2008	50	10					782	796		10.1016/j.specom.2008.04.010	http://dx.doi.org/10.1016/j.specom.2008.04.010												2026-01-16	WOS:000260702200002
J	Pierrehumbert, JB				Pierrehumbert, JB			Phonetic diversity, statistical learning, and acquisition of phonology	LANGUAGE AND SPEECH				Article; Proceedings Paper	Workshop on Early Phonological Acquisition	OCT, 2001	CARRY LE ROUET, FRANCE					In learning to perceive and produce speech, children master complex language-specific patterns. Daunting language-specific variation is found both in the segmental domain and in the domain of prosody and intonation. This article reviews the challenges posed by results in phonetic typology and sociolinguistics for the theory of language acquisition. It argues that categories are initiated bottom-up from statistical modes in use of the phonetic space, and sketches how exemplar theory can be used to model the updating of categories once they are initiated. It also argues that bottom-up initiation of categories is successful thanks to the perception-production loop operating in the speech community. The behavior of this loop means that the superficial statistical properties of speech available to the infant indirectly reflect the contrastiveness and discriminability of categories in the adult grammar. The article also argues that the developing system is refined using internal feedback from type statistics over the lexicon, once the lexicon is well-developed. The application of type statistics to a system initiated with surface statistics does not cause a fundamental reorganization of the system. Instead, it exploits confluences across levels of representation which characterize human language and make bootstrapping possible.												340	432												2003	46		2-3				115	154		10.1177/00238309030460020501	http://dx.doi.org/10.1177/00238309030460020501												2026-01-16	WOS:000187961200003
J	Braun, B; Kochanski, G; Grabe, E; Rosner, BS				Braun, Bettina; Kochanski, Greg; Grabe, Esther; Rosner, Burton S.			Evidence for attractors in English intonation	JOURNAL OF THE ACOUSTICAL SOCIETY OF AMERICA				Article								Although the pitch of the human voice is continuously variable, some linguists contend that intonation in speech is restricted to a small, limited set of patterns. This claim is tested by asking subjects to mimic a block of 100 randomly generated intonation contours and then to imitate themselves in several successive sessions. The produced f(0) contours gradually converge towards a limited set of distinct, previously recognized basic English intonation patterns. These patterns are "attractors" in the space of possible, intonation English contours. The convergence does not occur immediately. Seven of the ten participants show continued convergence toward their attractors after the first iteration. Subjects retain and use information beyond phonological contrasts, suggesting that intonational phonology is not a complete description of their mental representation of intonation. (c) 2006 Acoustical Society of America.												38	41											JUN	2006	119	6					4006	4015		10.1121/1.2195267	http://dx.doi.org/10.1121/1.2195267												2026-01-16	WOS:000238463000052
S	Blin, L; Edgington, M		Sojka, P; Kopecek, I; Pala, K		Blin, L; Edgington, M			Prosody prediction from tree-like structure similarities	TEXT, SPEECH AND DIALOGUE, PROCEEDINGS	LECTURE NOTES IN ARTIFICIAL INTELLIGENCE			Article; Proceedings Paper	3rd International Workshop on Text, Speech and Dialogue (TSD 2000)	SEP 13-16, 2000	BRNO, CZECH REPUBLIC					We present ongoing work on prosody prediction for speech synthesis. This approach considers sentences as tree-like structures and decides on the prosody from a corpus of such structures using machine learning techniques. The prediction is achieved from the prosody of the closest sentence of the corpus through tree similarity measurements in a nearest neighbour context. We introduce a syntactic structure and a performance structure representation, the tree similarity metrics considered, and then we discuss the prediction method. Experiments are currently under process to qualify this approach.												1	1												2000	1902						369	374															2026-01-16	WOS:000170595900062
J	Hashimoto, RI; Okada, R; Aoki, R; Nakamura, M; Ohta, H; Itahashi, T				Hashimoto, Ryu-ichiro; Okada, Rieko; Aoki, Ryuta; Nakamura, Motoaki; Ohta, Haruhisa; Itahashi, Takashi			Functional alterations of lateral temporal cortex for processing voice prosody in adults with autism spectrum disorder	CEREBRAL CORTEX				Article								The human auditory system includes discrete cortical patches and selective regions for processing voice information, including emotional prosody. Although behavioral evidence indicates individuals with autism spectrum disorder (ASD) have difficulties in recognizing emotional prosody, it remains understudied whether and how localized voice patches (VPs) and other voice-sensitive regions are functionally altered in processing prosody. This fMRI study investigated neural responses to prosodic voices in 25 adult males with ASD and 33 controls using voices of anger, sadness, and happiness with varying degrees of emotion. We used a functional region-of-interest analysis with an independent voice localizer to identify multiple VPs from combined ASD and control data. We observed a general response reduction to prosodic voices in specific VPs of left posterior temporal VP (TVP) and right middle TVP. Reduced cortical responses in right middle TVP were consistently correlated with the severity of autistic symptoms for all examined emotional prosodies. Moreover, representation similarity analysis revealed the reduced effect of emotional intensity in multivoxel activation patterns in left anterior superior temporal cortex only for sad prosody. These results indicate reduced response magnitudes to voice prosodies in specific TVPs and altered emotion intensity-dependent multivoxel activation patterns in adult ASDs, potentially underlying their socio-communicative difficulties.												2	2											SEP 12	2024	34	9							bhae363	10.1093/cercor/bhae363	http://dx.doi.org/10.1093/cercor/bhae363												2026-01-16	WOS:001311832500002
J	Hirst, DJ				Hirst, DJ			Form and function in the representation of speech prosody	SPEECH COMMUNICATION				Article; Proceedings Paper	2nd International Conference on Speech Prosody	MAR, 2004	Nara, JAPAN					The way in which prosody contributes to meaning is still, today, a poorly understood process corresponding to a mapping between two levels of representation, for neither of which there is any general consensus. It is argued that annotation of prosody generally consists in describing both prosodic function and prosodic form, but that it would be preferable to clearly distinguish the two levels. One elementary annotation system for prosodic function, IF-annotation, is, it has been argued, sufficient to capture at least those aspects of prosodic function which influence syntactic interpretation. The annotation of prosodic form can be carried out automatically by means of an F0 modelling algorithm, MOMEL, and an automatic coding scheme, INTSINT. The resulting annotation is under-determined by the IF-annotation, but defining mapping rules between representations of function and representation of form could provide an interesting means of establishing an enriched functional annotation system through analysis by synthesis. (c) 2005 Elsevier B.V. All rights reserved.												49	65											JUL	2005	46	3-4					334	347		10.1016/j.specom.2005.02.020	http://dx.doi.org/10.1016/j.specom.2005.02.020												2026-01-16	WOS:000230804200008
J	Ota, M; Yamane, N; Mazuka, R				Ota, Mitsuhiko; Yamane, Naoto; Mazuka, Reiko			The Effects of Lexical Pitch Accent on Infant Word Recognition in Japanese	FRONTIERS IN PSYCHOLOGY				Article								Learners of lexical tone languages (e.g., Mandarin) develop sensitivity to tonal contrasts and recognize pitch-matched, but not pitch-mismatched, familiar words by 11 months. Learners of non-tone languages (e.g., English) also show a tendency to treat pitch patterns as lexically contrastive up to about 18 months. In this study, we examined if this early-developing capacity to lexically encode pitch variations enables infants to acquire a pitch accent system, in which pitch-based lexical contrasts are obscured by the interaction of lexical and non-lexical (i.e., intonational) features. Eighteen 17-month-olds learning Tokyo Japanese were tested on their recognition of familiar words with the expected pitch or the lexically opposite pitch pattern. In early trials, infants were faster in shifting their eyegaze from the distractor object to the target object than in shifting from the target to distractor in the pitch-matched condition. In later trials, however, infants showed faster distractor-to-target than target-to-distractor shifts in both the pitch-matched and pitch-mismatched conditions. We interpret these results to mean that, in a pitch-accent system, the ability to use pitch variations to recognize words is still in a nascent state at 17 months.												4	4											JAN 12	2018	8								2354	10.3389/fpsyg.2017.02354	http://dx.doi.org/10.3389/fpsyg.2017.02354												2026-01-16	WOS:000419922400001
J	Inbar, M; Grossman, E; Landau, AN				Inbar, Maya; Grossman, Eitan; Landau, Ayelet N.			Sequences of Intonation Units form a ∼ 1 Hz rhythm	SCIENTIFIC REPORTS				Article								Studies of speech processing investigate the relationship between temporal structure in speech stimuli and neural activity. Despite clear evidence that the brain tracks speech at low frequencies (similar to 1 Hz), it is not well understood what linguistic information gives rise to this rhythm. In this study, we harness linguistic theory to draw attention to Intonation Units (IUs), a fundamental prosodic unit of human language, and characterize their temporal structure as captured in the speech envelope, an acoustic representation relevant to the neural processing of speech. IUs are defined by a specific pattern of syllable delivery, together with resets in pitch and articulatory force. Linguistic studies of spontaneous speech indicate that this prosodic segmentation paces new information in language use across diverse languages. Therefore, IUs provide a universal structural cue for the cognitive dynamics of speech production and comprehension. We study the relation between IUs and periodicities in the speech envelope, applying methods from investigations of neural synchronization. Our sample includes recordings from every-day speech contexts of over 100 speakers and six languages. We find that sequences of IUs form a consistent low-frequency rhythm and constitute a significant periodic cue within the speech envelope. Our findings allow to predict that IUs are utilized by the neural system when tracking speech. The methods we introduce here facilitate testing this prediction in the future (i.e., with physiological data).												28	32											SEP 28	2020	10	1							15846	10.1038/s41598-020-72739-4	http://dx.doi.org/10.1038/s41598-020-72739-4												2026-01-16	WOS:000577327200021
J	Li, ZM; Lian, AP; Yodkamlue, B				Li, Zhongmin; Lian, Andrew-Peter; Yodkamlue, Butsakorn			Learning English Intonation Through Exposure to Resynthesized Self-produced Stimuli	GEMA ONLINE JOURNAL OF LANGUAGE STUDIES				Article								EFL learners are prone to having problems in pronunciation, while their problems in intonation are more salient. The Chinese EFL pronunciation classroom has long been criticized for teacher-centered, "one-size-fits-all" teaching, which is inefficient and ineffective for solving individual student's specific pronunciation problems. This study conducted an experiment to examine the effectiveness of exposure to resynthesized self-produced stimuli for intonation learning. The participants were 66 first year English majors studying at a university in China. The treatment was a form of English intonation training wherein the students in the experimental group used their resynthesized self-produced stimuli (their own voices) as the pronunciation model for learning while the control group used a model produced by a native speaker. After the training, the results of the intonation production test showed that the experimental group outperformed the control group in eight intonation patterns. The students' problems in intonation support Mennen's (2007) claim that intonation learning involves a first stage of acquiring the phonological representations of intonation patterns and a second stage of acquiring the phonetic realizations of those patterns. The results of this study revealed that exposure to resynthesized self-produced stimuli for intonation learning was as effective as the native speaker model for helping the students form the phonological representations of intonation patterns, while it was more effective than the native speaker model for facilitating the students to produce more accurate phonetic realizations of those patterns.												3	6											FEB	2020	20	1					54	76		10.17576/gema-2020-2001-04	http://dx.doi.org/10.17576/gema-2020-2001-04												2026-01-16	WOS:000518406500004
J	Ferrari, A; Lala, L				Ferrari, Angela; Lala, Letizia			The applications of the comma in contemporary Italian. From the phono-syntactic perspective to the textual perspective	LANGUE FRANCAISE				Article								Angela Ferrari & Letizia Lala, The applications of the comma in contemporary Italian. From the phono-syntactic perspective to the textual perspective Our study focuses on comma use in contemporary Italian, specifically on texts that are by competent writers, with a medium to formal register and, for reasons of method, non-literary. From a descriptive point of view, we will show that comma use increasingly follows uniformities of a "textual" nature, in that it relates to creating and prioritizing textual units. From an explanatory point of view, we will first demonstrate that any treatment of comma use in terms of syntax and intonation exclusively is bound to fail since the generalizations that it will lead to are either false or break down in offshoots of exceptions and special cases; we will then argue that a significant set of syntactical uses may be reinterpreted from a textual perspective, enabling a more rational, consistent, and realistic representation of comma use.												4	5											DEC	2011		172					53	+															2026-01-16	WOS:000299753700004
J	Bellegarda, JR; Silverman, KEA; Lenzo, K; Anderson, V				Bellegarda, JR; Silverman, KEA; Lenzo, K; Anderson, V			Statistical prosodic modeling: From corpus design to parameter estimation	IEEE TRANSACTIONS ON SPEECH AND AUDIO PROCESSING				Article								The increasing availability of carefully designed and collected speech corpora opens up new possibilities for the statistical estimation of formal multivariate prosodic models. At Apple Computer, statistical prosodic modeling exploits the Victoria corpus, recently created to broadly support ongoing speech synthesis research and development. This corpus is composed of five constituent parts. each designed to cover a specific aspect of speech synthesis: polyphones, prosodic contests, reiterant speech, function word sequences, and continuous speech. This paper focuses on the use of the Victoria corpus in the statistical estimation of duration and pitch models for Apple's next-generation test-to-speech system in Macintosh OS X. Duration modeling relies primarily on the subcorpus of prosodic contexts, which is instrumental tb uncover empirical evidence in favor of a piece-wise linear transformation in the well-known sums-of-products approach. Pitch modeling relies primarily on the subcorpus of reiterant speech, which makes possible the optimization of superpositional pitch models with more accurate underlying smooth contours. Experimental results illustrate the improved prosodic representation resulting from these new duration and pitch models.												32	36											JAN	2001	9	1					52	66		10.1109/89.890071	http://dx.doi.org/10.1109/89.890071												2026-01-16	WOS:000165856700007
J	Zarrabi, A; Jeulin, M; Bardet, P; Commere, P; Naccache, L; Aucouturier, JJ; Ponsot, E; Villain, M				Adl Zarrabi, Aynaz; Jeulin, Melissa; Bardet, Pauline; Commere, Pauline; Naccache, Lionel; Aucouturier, Jean-Julien; Ponsot, Emmanuel; Villain, Marie			A simple psychophysical procedure separates representational and noise components in impairments of speech prosody perception after right-hemisphere stroke	SCIENTIFIC REPORTS				Article								After a right hemisphere stroke, more than half of the patients are impaired in their capacity to produce or comprehend speech prosody. Yet, and despite its social-cognitive consequences for patients, aprosodia following stroke has received scant attention. In this report, we introduce a novel, simple psychophysical procedure which, by combining systematic digital manipulations of speech stimuli and reverse-correlation analysis, allows estimating the internal sensory representations that subtend how individual patients perceive speech prosody, and the level of internal noise that govern behavioral variability in how patients apply these representations. Tested on a sample of N = 22 right-hemisphere stroke survivors and N = 21 age-matched controls, the representation + noise model provides a promising alternative to the clinical gold standard for evaluating aprosodia (MEC): both parameters strongly associate with receptive, and not expressive, aprosodia measured by MEC within the patient group; they have better sensitivity than MEC for separating high-functioning patients from controls; and have good specificity with respect to non-prosody-related impairments of auditory attention and processing. Taken together, individual differences in either internal representation, internal noise, or both, paint a potent portrait of the variety of sensory/cognitive mechanisms that can explain impairments of prosody processing after stroke.												1	1											JUL 2	2024	14	1							15194	10.1038/s41598-024-64295-y	http://dx.doi.org/10.1038/s41598-024-64295-y												2026-01-16	WOS:001262145700126
J	YAMASHITA, Y; MIZOGUCHI, R; MIZUTANI, N; KAKUSHO, O				YAMASHITA, Y; MIZOGUCHI, R; MIZUTANI, N; KAKUSHO, O			SPEECH SYNTHESIS FROM CONCEPT REPRESENTATION IN GENERAL SPEECH OUTPUT INTERFACE	SYSTEMS AND COMPUTERS IN JAPAN				Article								The goal of this paper is to realize natural and high-quality speech output from various problem-solvers implemented on a computer. The framework for the general speech output interface is discussed, and the basic architecture is designed for SOCS (Speech Output from Case Structure representation). This is the speech synthesis system based on the concept representation converting the input to the interface into speech. The important issue in such a framework is to define a mechanism to transmit information from the problem-solver to the speech output interface. From such a viewpoint, the representation based on the case structure and the phrase patterns is defined as the concept representation to describe the inputs to the interface and the speech synthesis system from the standpoint of problem-solver, speech synthesis, and the dialogue management. The concept inputted to the interface is modified by the dialogue manager and is converted into the speech by SOCS. In SOCS, the prosody as well as the sentence is generated based on the concept representation. The pause markers generated in the sentence generation determine the positions of the pause and the F(phi) resetting. The prosodic patterns also are generated by the prosody modification function described in the custom template.												0	0											MAR	1994	25	3					1	17															2026-01-16	WOS:A1994PL90100001
J	Tian, QB; Yap, NT; Ng, CF; Yahya, Y				Tian, Qingbo; Yap, Ngee Thai; Ng, Chwee Fang; Yahya, Yasir			The Effect of English Proficiency on the Production of English Intonation by Chinese EFL Learners	PERTANIKA JOURNAL OF SOCIAL SCIENCE AND HUMANITIES				Article								English intonation is an integral component of English pronunciation teaching. However, as students' proficiency levels in English pronunciation improve, it remains unclear whether their intonation levels also develop. The present study, based on the second language intonation learning theory, aims to investigate the influence of English proficiency on Chinese EFL learners' production of English pitch accents, edge tones, and intonation patterns from the perspective of phonological representation. Two language groups of participants took part in a reading task: native English speakers (12) and Chinese EFL learners (36). The learners were classified into three groups based on their scores in the Chivox National Spoken English Test, ranked from high to low: the advanced, intermediate, and elementary groups. The reading task comprised 90 dialogue pairs. The participants were required to read part B of each dialogue pair aloud, but afterwards, only the Chinese EFL learners attended the semi-structured interview. The results showed that the native English speakers only demonstrated significant differences from each learner group in four of the ten intonation types involving the three aspects of English intonation, which may indicate regional variations in American English and difficulties distinguishing (H*) and (L+H*). In addition, there were no significant differences between the three learner groups in producing the ten intonation types, which maybe attributed to their similar learning experiences.												0	1											SEP	2024	32	3					909	931		10.47836/pjssh.32.3.06	http://dx.doi.org/10.47836/pjssh.32.3.06												2026-01-16	WOS:001342191500006
J	Koester, D				Koester, Dirk			Prosody in parsing morphologically complex words: Neurophysiological evidence	COGNITIVE NEUROPSYCHOLOGY				Article								Little is known about the neurophysiological correlates of lexical prosody in the comprehension of compound words, i.e., morphologically complex words. Here, it is investigated whether lexical prosody influences the decomposition of spoken compound words. In order to explore the neurophysiological correlates (event-related potentials, ERP) of a compound prosody, German native speakers had to judge the number agreement between numerals and nouns which did or did not agree in 50% of the cases. Importantly, the nouns carried either a compound or non-compound (single noun) prosody. The compound prosody led to increased reaction times (RTs) and reduced judgement accuracy. Critically, number violations for words with a compound prosody elicited an increased ERP negativity that was delayed by about 600ms relative to a left-anterior negativity elicited by number violations for a single noun prosody. The ERP effect for the compound prosody preceded the according behavioural response by about 200ms and the ERP peak latency effect correlated with the RT effect. These findings suggest that the ERP effect for the compound prosody could be functionally related to the accurate judgement performance for the compound prosody. The results suggest, more generally, that prosody plays a critical role in auditory compound comprehension and morphological processing.												3	5											FEB 17	2014	31	1-2			SI		147	163		10.1080/02643294.2013.857649	http://dx.doi.org/10.1080/02643294.2013.857649												2026-01-16	WOS:000335196800008
S	Spiliotopoulos, D; Xydas, G; Kouroupetroglou, G		Matousek, V; Mautner, P; Pavelka, T		Spiliotopoulos, D; Xydas, G; Kouroupetroglou, G			Diction based prosody modeling in table-to-speech synthesis	TEXT, SPEECH AND DIALOGUE, PROCEEDINGS	Lecture Notes in Artificial Intelligence			Article; Proceedings Paper	8th International Conference on Text, Speech and Dialogue	SEP 12-15, 2005	Karlovy Vary, CZECH REPUBLIC					Transferring a structure from the visual modality to the aural one presents a difficult challenge. In this work we are experimenting with prosody modeling for the synthesized speech representation of tabulated structures. This is achieved by analyzing naturally spoken descriptions of data tables and a following feedback by blind and sighted users. The derived prosodic phrase accent and pause break placement and values are examined in terms of successfully conveying semantically important visual information through prosody control in Table-to-Speech synthesis. Finally, the quality of the information provision of synthesized tables when utilizing the proposed prosody specification is studied against plain synthesis.												11	11												2005	3658						294	301															2026-01-16	WOS:000232264700038
J	Alcaraz-Mármol, G; Soto-Almela, J				Alcaraz-Marmol, Gema; Soto-Almela, Jorge			Refugees in the Spanish press: A corpus-assisted study of the semantic prosody of the term refugiado from a diachronic perspective	SINTAGMA				Article								This paper explores the semantic prosody of the lemma refugiado in the Spanish press over a 7-year period (2010-16) with the aim of examining the discursive representation of refugees in this textual genre. The study is concerned with diachronic and quantitative aspects, while focusing on the negative lexical units collocating with refugiado. The research is based on the analysis of a 1.8-million-word corpus of Spanish news articles about refugees that were extracted from the digital libraries of El Pais and El Mundo. The results show that the frequency of refugiado increases over the 2010-16 period, and so does its negative semantic prosody. This negativity -which is much higher in the last two years under study- is constructed through certain consistent collocates, seasonal collocates and patterns of language associated with refugees' massive occupation and victimization.												4	4												2018	30						95	113		10.21001/sintagma.2018.30.06	http://dx.doi.org/10.21001/sintagma.2018.30.06												2026-01-16	WOS:000452641200006
J	Van Hedger, SC; Heald, SLM; Uddin, S; Nusbaum, HC				Van Hedger, Stephen C.; Heald, Shannon L. M.; Uddin, Sophia; Nusbaum, Howard C.			A Note by Any Other Name: Intonation Context Rapidly Changes Absolute Note Judgments	JOURNAL OF EXPERIMENTAL PSYCHOLOGY-HUMAN PERCEPTION AND PERFORMANCE				Article								Absolute pitch (AP) judgments, by definition, do not require a reference note, and thus might be viewed as context independent. Here, we specifically test whether short-term exposure to particular intonation contexts influences AP categorization on a rapid time scale and whether such context effects can change from moment to moment. In Experiment 1, participants heard duets in which a "lead" instrument always began before a "secondary" instrument. Both instruments independently varied on intonation (flat, in-tune, or sharp). Despite participants being instructed to judge only the intonation of the secondary instrument, we found that participants treated the lead instrument's intonation as "in-tune" and intonation judgments of the secondary instrument were relativized against this standard. In Experiment 2, participants heard a short antecedent context melody (flat, in-tune, or sharp) followed by an isolated target note (flat, in-tune, or sharp). Target note intonation judgments were once again relativized against the context melody's intonation, though only for notes that were experienced in the context or implied by the context key signature. Moreover, maximally contrastive intonation combinations of context and target engendered systematic note misclassifications. For example, a flat melody resulted in a greater likelihood of misclassifying a "sharp F-sharp" as a "G." These results highlight that both intonation and note category judgments among AP possessors are rapidly modified by the listening environment on the order of seconds, arguing against an invariant mental representation of the absolute pitches of notes. Implications for general auditory theories of perception are discussed.												10	12											AUG	2018	44	8					1268	1282		10.1037/xhp0000536	http://dx.doi.org/10.1037/xhp0000536												2026-01-16	WOS:000439924500010
J	Zeng, YY; Parrell, B; Niziolek, CA				Zeng, Yuyu; Parrell, Benjamin; Niziolek, Caroline A.			Transfer of Sensorimotor Adaptation Reveals Independent Prosodic Representation After Segment-Prosody Coordination in Speech Production	JOURNAL OF EXPERIMENTAL PSYCHOLOGY-LEARNING MEMORY AND COGNITION				Article; Early Access								In speech production, there is a long-standing debate regarding whether word-level prosodic structure has an independent representation separable from segments. Using a novel assay of sensorimotor adaptation, we observe straightforward evidence supporting an independent prosodic structure even after its coordination with the segments. Participants exposed to opposing formant perturbations applied to the two syllables of a single trained word (e.g., "bedhead" -> "bidhad") adapted separately to counteract the syllable-specific perturbations (i.e., producing "badhid") and, critically, transferred the learned adaptation to untrained words based purely on shared prosodic structure (words with the same prosody but novel syllables, e.g., producing "breastfed" like "brastfid"). This evidence for an independent word-level prosodic representation, which has been hard to detect in previous studies, highlights the usefulness of sensorimotor adaptation as a tool for language production research.												0	0											2025 DEC 8	2025										10.1037/xlm0001551	http://dx.doi.org/10.1037/xlm0001551		DEC 2025										2026-01-16	WOS:001631803300001
J	Kentner, G				Kentner, Gerrit			Linguistic rhythm guides parsing decisions in written sentence comprehension	COGNITION				Article								Various recent studies attest that reading involves creating an implicit prosodic representation of the written text which may systematically affect the resolution of syntactic ambiguities in sentence comprehension. Research up to now suggests that implicit prosody itself depends on a partial syntactic analysis of the text, raising the question of whether implicit prosody contributes to the parsing process, or whether it merely interprets the syntactic analysis. The present reading experiments examine the influence of stress-based linguistic rhythm on the resolution of local lexical-syntactic ambiguities in German. Both speech production data from unprepared oral reading and eye-tracking results from silent reading demonstrate that readers favor syntactic analyses that allow for a prosodic representation in which stressed and unstressed syllables alternate rhythmically. The findings contribute evidence confirming immediate and guiding effects of linguistic rhythm on the earliest stages of syntactic parsing in reading. (C) 2011 Elsevier B.V. All rights reserved.												43	52											APR	2012	123	1					1	20		10.1016/j.cognition.2011.11.012	http://dx.doi.org/10.1016/j.cognition.2011.11.012												2026-01-16	WOS:000301474000001
J	Zora, H; Rudner, M; Magnusson, AKM				Zora, Hatice; Rudner, Mary; Magnusson, Anna K. Montell			Concurrent affective and linguistic prosody with the same emotional valence elicits a late positive ERP response	EUROPEAN JOURNAL OF NEUROSCIENCE				Article								Change in linguistic prosody generates a mismatch negativity response (MMN), indicating neural representation of linguistic prosody, while change in affective prosody generates a positive response (P3a), reflecting its motivational salience. However, the neural response to concurrent affective and linguistic prosody is unknown. The present paper investigates the integration of these two prosodic features in the brain by examining the neural response to separate and concurrent processing by electroencephalography (EEG). A spoken pair of Swedish words-['fa:s epsilon n] phase and ['fa:s epsilon n] damn-that differed in emotional semantics due to linguistic prosody was presented to 16 subjects in an angry and neutral affective prosody using a passive auditory oddball paradigm. Acoustically matched pseudowords['va:s epsilon m] and ['va:s epsilon m]-were used as controls. Following the constructionist concept of emotions, accentuating the conceptualization of emotions based on language, it was hypothesized that concurrent affective and linguistic prosody with the same valence-angry ['fa:s epsilon n] damn-would elicit a unique late EEG signature, reflecting the temporal integration of affective voice with emotional semantics of prosodic origin. In accordance, linguistic prosody elicited an MMN at 300-350 ms, and affective prosody evoked a P3a at 350-400 ms, irrespective of semantics. Beyond these responses, concurrent affective and linguistic prosody evoked a late positive component (LPC) at 820-870 ms in frontal areas, indicating the conceptualization of affective prosody based on linguistic prosody. This study provides evidence that the brain does not only distinguish between these two functions of prosody but also integrates them based on language and experience.												13	15											JUN	2020	51	11					2236	2249		10.1111/ejn.14658	http://dx.doi.org/10.1111/ejn.14658		JAN 2020										2026-01-16	WOS:000509972400001
J	Xu, HJ; Armony, JL				Xu, Hanjian; Armony, Jorge L.			Influence of emotional prosody, content, and repetition on memory recognition of speaker identity	QUARTERLY JOURNAL OF EXPERIMENTAL PSYCHOLOGY				Article								Recognising individuals through their voice requires listeners to form an invariant representation of the speaker's identity, immune to episodic changes that may occur between encounters. We conducted two experiments to investigate to what extent within-speaker stimulus variability influences different behavioural indices of implicit and explicit identity recognition memory, using short sentences with semantically neutral content. In Experiment 1, we assessed how speaker recognition was affected by changes in prosody (fearful to neutral, and vice versa in a between-group design) and speech content. Results revealed that, regardless of encoding prosody, changes in prosody, independent of content, or changes in content, when prosody was kept unchanged, led to a reduced accuracy in explicit voice recognition. In contrast, both groups exhibited the same pattern of response times (RTs) for correctly recognised speakers: faster responses to fearful than neutral stimuli, and a facilitating effect for same-content stimuli only for neutral sentences. In Experiment 2, we investigated whether an invariant representation of a speaker's identity benefitted from exposure to different exemplars varying in emotional prosody (fearful and happy) and content (Multi condition), compared to repeated presentations of a single sentence (Uni condition). We found a significant repetition priming effect (i.e., reduced RTs over repetitions of the same voice identity) only for speakers in the Uni condition during encoding, but faster RTs when correctly recognising old speakers from the Multi, compared to the Uni, condition. Overall, our findings confirm that changes in emotional prosody and/or speech content can affect listeners' implicit and explicit recognition of newly familiarised speakers.												8	8											JUL	2021	74	7					1185	1201		10.1177/1747021821998557	http://dx.doi.org/10.1177/1747021821998557												2026-01-16	WOS:000661919200004
J	Popovic, B; Knezevic, D; Secujski, M; Pekar, D				Popovic, Branislav; Knezevic, Dragan; Secujski, Milan; Pekar, Darko			AUTOMATIC PROSODY GENERATION IN A TEXT-TO-SPEECH SYSTEM FOR HEBREW	FACTA UNIVERSITATIS-SERIES ELECTRONICS AND ENERGETICS				Article								The paper presents the module for automatic prosody generation within a system for automatic synthesis of high-quality speech based on arbitrary text in Hebrew. The high quality of synthesis is due to the high accuracy of automatic prosody generation, enabling the introduction of elements of natural sentence prosody of Hebrew. Automatic morphological annotation of text is based on the application of an expert algorithm relying on transformational rules. Syntactic-prosodic parsing is also rule based, while the generation of the acoustic representation of prosodic features is based on classification and regression trees. A tree structure generated during the training phase enables accurate prediction of the acoustic representatives of prosody, namely, durations of phonetic segments as well as temporal evolution of fundamental frequency and energy. Such an approach to automatic prosody generation has lead to an improvement in the quality of synthesized speech, as confirmed by listening tests.												1	1											SEP	2014	27	3					467	477		10.2298/FUEE1403467P	http://dx.doi.org/10.2298/FUEE1403467P												2026-01-16	WOS:000421916700013
J	Degano, G; Donhauser, PW; Gwilliams, L; Merlo, P; Golestani, N				Degano, Giulio; Donhauser, Peter W.; Gwilliams, Laura; Merlo, Paola; Golestani, Narly			Speech prosody enhances the neural processing of syntax	COMMUNICATIONS BIOLOGY				Article								Human language relies on the correct processing of syntactic information, as it is essential for successful communication between speakers. As an abstract level of language, syntax has often been studied separately from the physical form of the speech signal, thus often masking the interactions that can promote better syntactic processing in the human brain. However, behavioral and neural evidence from adults suggests the idea that prosody and syntax interact, and studies in infants support the notion that prosody assists language learning. Here we analyze a MEG dataset to investigate how acoustic cues, specifically prosody, interact with syntactic representations in the brains of native English speakers. More specifically, to examine whether prosody enhances the cortical encoding of syntactic representations, we decode syntactic phrase boundaries directly from brain activity, and evaluate possible modulations of this decoding by the prosodic boundaries. Our findings demonstrate that the presence of prosodic boundaries improves the neural representation of phrase boundaries, indicating the facilitative role of prosodic cues in processing abstract linguistic features. This work has implications for interactive models of how the brain processes different linguistic features. Future research is needed to establish the neural underpinnings of prosody-syntax interactions in languages with different typological characteristics. An MEG study in native English speakers on naturalistic speech comprehension suggests that prosodic boundaries enhance the neural encoding of syntactic phrase boundaries.												9	11											JUN 20	2024	7	1							748	10.1038/s42003-024-06444-7	http://dx.doi.org/10.1038/s42003-024-06444-7												2026-01-16	WOS:001252136800002
J	Koduri, GK; Ishwar, V; Serrà, J; Serra, X				Koduri, Gopala Krishna; Ishwar, Vignesh; Serra, Joan; Serra, Xavier			Intonation Analysis of Ragas in Carnatic Music	JOURNAL OF NEW MUSIC RESEARCH				Article								Intonation is a fundamental music concept that has a special relevance in Indian art music. It is characteristic of a raga and key to the musical expression of the artist. Describing intonation is of importance to several music information retrieval tasks such as developing similarity measures based on ragas and artists. In this paper, we first assess raga intonation qualitatively by analysing varnarns, a particular form of Carnatic music compositions. We then approach the task of automatically obtaining a compact representation of the intonation of a recording from its pitch track. We propose two approaches based on the parametrization of pitch-value distributions: performance pitch histograms, and context-based svara distributions obtained by categorizing pitch contours based on the melodic context. We evaluate both approaches on a large Carnatic music collection and discuss their merits and limitations. We finally go through different kinds of contextual information that can be obtained to further improve the two approaches.												15	19											JAN 2	2014	43	1			SI		72	93		10.1080/09298215.2013.866145	http://dx.doi.org/10.1080/09298215.2013.866145												2026-01-16	WOS:000334075500006
J	Janseitova, S; Kaliakbarova, L; Balagazova, S; Kaldayakova, A				Janseitova, Svetlana; Kaliakbarova, Layla; Balagazova, Svetlana; Kaldayakova, Aisulu			MUSICAL TERMINOID REMARKS AS A MEANS OF INTERPRETATIVE READING OF THE TEXT AND DETERMINANTS OF MUSICAL INTONATION CHARACTERISTICS	ACTA HISTRIAE				Article								Musical remarks, as a specialist's communicative space, the environment of his linguistic existence, have their own terminological system and are a symbolic representation of knowledge, providing mutual understanding between scientists in musicological field The problem of inseparable unity of composer's style and expressive-verbal means of musical intonation has been studied insufficiently in both linguistics and musicology. Pragmatic analysis of musicological texts, in particular, the piano and vocal scores, will give the possibility to identify music as the intonation-artistic activity, which is not just a reflection, but an expression of personality sense; to reveal the peculiarities of musicological discourse functions through describing the key strategies and tactics of composer and performer's verbal behavior, reflected in musical terminoid remarks.												0	0												2015	23	2					265	284															2026-01-16	WOS:000359879600006
J	Merchie, A; Ranty, Z; Zarrabi, AA; Bonnet-Brilhault, F; Houy-Durand, E; Aucouturier, JJ; Gomot, M				Merchie, Annabelle; Ranty, Zoe; Zarrabi, Aynaz Adl; Bonnet-Brilhault, Frederique; Houy-Durand, Emmanuelle; Aucouturier, Jean-Julien; Gomot, Marie			Intact representation of vocal smile in autism: A reverse correlation approach	RESEARCH IN AUTISM				Article								Atypical emotional prosody production and perception have been reported in autism. However, it is unclear whether these particularities are associated with unusual mental representations of vocal emotions. The objective of the current study was to explore the mental representation of vocal smile in autistic adults. Twenty-nine autistic (ASD) and 29 neurotypical (NT) adults performed an auditory reverse correlation task, that affords the opportunity to extract acoustic features of mental representation and their variability. Most ASD participants (17) based their representation of vocal smile on similar acoustic features as NT participants and no difference in the level of internal noise was observed. However, comparisons between groups revealed a more typical representation in NT than in ASD. Subsequent cluster analysis revealed that the difference of typicality was explained by a small subset of ASD participants displaying different representations. A correlation analysis also revealed that the typicality was positively correlated with the empathetic level within both groups. While most autistic adults have a preserved mental representation of vocal smiles, a subset shows less robust and typical representations, which is linked to lower levels of empathy. This study highlights that the perception of vocal smiles in autism is more nuanced than previously reported, with empathy playing a substantial role in shaping these mental representations.												1	1											JUN	2025	124								202599	10.1016/j.reia.2025.202599	http://dx.doi.org/10.1016/j.reia.2025.202599		APR 2025										2026-01-16	WOS:001594289000007
J	Hualde, JI; Prieto, P				Hualde, Jose I.; Prieto, Pilar			Towards an International Prosodic Alphabet (IPrA)	LABORATORY PHONOLOGY				Article								In this article we present a set of arguments in favor of having access to two levels of prosodic representation, broad phonetic and phonological, and the motivations for developing a set of cross-linguistically transparent and consistent labels (e. g., an International Prosodic Alphabet, IPrA) based on the Autosegmental-Metrical (AM) framework and the ToBI notation. Regarding segmental phonology, as well as lexical suprasegmentals (lexical tone and stress), both the use of two levels of representation and the existence of an international phonetic alphabet have proved to be very useful. The same benefits of adopting these conventions are likely to accrue in the study of intonation.												55	64											JUN 30	2016	7	1								10.5334/labphon.11	http://dx.doi.org/10.5334/labphon.11												2026-01-16	WOS:000399684600002
J	Ito, K; Jincho, N; Minai, U; Yamane, N; Mazuka, R				Ito, Kiwako; Jincho, Nobuyuki; Minai, Utako; Yamane, Naoto; Mazuka, Reiko			Intonation facilitates contrast resolution: Evidence from Japanese adults and 6-year olds	JOURNAL OF MEMORY AND LANGUAGE				Article								Two eye-tracking experiments tested how pitch prominence on a prenominal adjective affects contrast resolution in Japanese adult and 6-year old listeners. Participants located two animals in succession on displays with multiple colored animals. In Experiment 1, adults' fixations to the contrastive target (pink cat -> GREEN cat) were facilitated by a pitch expansion on the adjective while infelicitous pitch expansion (purple rabbit ->. ORANGE monkey) led to a garden-path effect, i.e., frequent fixations to the incorrect target (orange rabbit). In 6-year olds, only the facilitation effect surfaced. Hypothesizing that the interval between the two questions may not have given enough time for children to overcome their tendency to perseverate on the first target. Experiment 2 used longer intervals and confirmed a garden-path effect in 6-year olds. These results demonstrate that Japanese 6-year olds can make use of contrast-marking pitch prominence when time allows an establishment of proper discourse representation. (C) 2011 Elsevier Inc. All rights reserved.												49	57											JAN	2012	66	1					265	284		10.1016/j.jml.2011.09.002	http://dx.doi.org/10.1016/j.jml.2011.09.002												2026-01-16	WOS:000299188500017
J	Lee, EK; Fraundorf, S				Lee, Eun-Kyung; Fraundorf, Scott			DO L1-L2 DIFFERENCES IN DISCOURSE PROCESSING REFLECT PROCESSING DEMANDS OR DIFFICULTY OF FORM-FUNCTION MAPPING? EVIDENCE FROM SELF-PACED LISTENING OF CONTRASTIVE PROSODY	STUDIES IN SECOND LANGUAGE ACQUISITION				Article								We examined what causes L1-L2 differences in sensitivity to prominence cues in discourse processing. Participants listened to recorded stories in segment-by-segment fashion at their own pace. Each story established a pair of contrasting items, and one item from the pair was rementioned and manipulated to carry either a contrastive or presentational pitch accent. By directly comparing the current self-paced listening data to previously obtained experimenter-paced listening data, we tested whether reducing online-processing demands allows L2 learners to show a nativelike behavior, such that contrastive pitch accents facilitate later ruling out the salient alternative. However, reduced time pressure failed to lead even higher proficiency L1-Korean learners of English to reach a nativelike level, suggesting that L2 learners' nonnativelike processing and representation of the prominence cue in spoken discourse processing can be due to the inherent difficulty of fully learning a complex form-function mapping rather than to online-processing demands.												2	3											SEP	2022	44	4					942	966	PII S0272263121000619	10.1017/S0272263121000619	http://dx.doi.org/10.1017/S0272263121000619		OCT 2021										2026-01-16	WOS:000792378600001
J	Hardiman, DP; Nuraniwati, T				Hardiman, Denitha Putri; Nuraniwati, Tri			Semantic Preference and Semantic Prosody of the Collocations of Sustainable in NOW Corpus	3L-LANGUAGE LINGUISTICS LITERATURE-THE SOUTHEAST ASIAN JOURNAL OF ENGLISH LANGUAGE STUDIES				Article								Sustainability has dominated the conversation about climate change since the early 2000s. The presence of Sustainable Development Goals strengthened the connection between the two (SDGs) set up by the United Nations General Assembly in 2015, with Goal Number 13 being climate action concerning the ever-worsening climate change. Ever since the word 'sustainable' has been heavily circulated in the media, it has been associated with various words from fashion to finance. Utilising the News on the Web (NOW) Corpus, the study explores the representation of the word 'sustainable' in media concerning climate change discussion under semantic prosody and semantic preference analysis. Using collocations of the node word, semantic preference determines the semantic set related to the node word, while semantic prosody interprets the environment in which the node word pertains. The collocations are semantically labelled with the help of an automatic semantic tagger UCREL Semantic Analysis System (USAS) to find the semantic preference. At the same time, the concordance lines in NOW Corpus are examined to determine the semantic prosody. The study finds that the word 'sustainable' tends to be associated with semantic sets related to the environment, Sustainable Development Goals, social issues and humanity, as well as money. It also indicates that the node word has positive prosody. The representation of the word 'sustainable' in the media is seen as favourable, not only as a way of living but also as a way of behaving in many aspects encompassing our lives.												2	2												2023	29	1					184	199		10.17576/3L-2023-2901-13	http://dx.doi.org/10.17576/3L-2023-2901-13												2026-01-16	WOS:000998801200013
J	Suni, A; Simko, J; Aalto, D; Vainio, M				Suni, Antti; Simko, Juraj; Aalto, Daniel; Vainio, Martti			Hierarchical representation and estimation of prosody using continuous wavelet transform	COMPUTER SPEECH AND LANGUAGE				Article								Prominences and boundaries are the essential constituents of prosodic structure in speech. They provide for means to chunk the speech stream into linguistically relevant units by providing them with relative saliences and demarcating them within utterance structures. Prominences and boundaries have both been widely used in both basic research on prosody as well as in text-to-speech synthesis. However, there are no representation schemes that would provide for both estimating and modelling them in a unified fashion. Here we present an unsupervised unified account for estimating and representing prosodic prominences and boundaries using a scale-space analysis based on continuous wavelet transform. The methods are evaluated and compared to earlier work using the Boston University Radio News corpus. The results show that the proposed method is comparable with the best published supervised annotation methods. (C) 2016 Elsevier Ltd. All rights reserved												44	45											SEP	2017	45						123	136		10.1016/j.csl.2016.11.001	http://dx.doi.org/10.1016/j.csl.2016.11.001												2026-01-16	WOS:000403510500007
J	Arnhold, A; Porretta, V; Chen, A; Verstegen, SAJM; Mok, I; Järvikivi, J				Arnhold, Anja; Porretta, Vincent; Chen, Aoju; Verstegen, Saskia A. J. M.; Mok, Ivy; Jarvikivi, Juhani			(Mis) understanding your native language: Regional accent impedes processing of information status	PSYCHONOMIC BULLETIN & REVIEW				Article								Native-speaker listeners constantly predict upcoming units of speech as part of language processing, using various cues. However, this process is impeded in second-language listeners, as well as when the speaker has an unfamiliar accent. Whereas previous research has largely concentrated on the pronunciation of individual segments in foreign-accented speech, we show that regional accent impedes higher levels of language processing, making native listeners' processing resemble that of second-language listeners. In Experiment 1, 42 native speakers of Canadian English followed instructions spoken in British English to move objects on a screen while their eye movements were tracked. Native listeners use prosodic cues to information status to disambiguate between two possible referents, a new and a previously mentioned one, before they have heard the complete word. By contrast, the Canadian participants, similarly to second-language speakers, were not able to make full use of prosodic cues in the way native British listeners do. In Experiment 2, 19 native speakers of Canadian English rated the British English instructions used in Experiment 1, as well as the same instructions spoken by a Canadian imitating the British English prosody. While information status had no effect for the Canadian imitations, the original stimuli received higher ratings when prosodic realization and information status of the referent matched than for mismatches, suggesting a native-like competence in these offline ratings. These findings underline the importance of expanding psycholinguistic models of second language/dialect processing and representation to include both prosody and regional variation.												6	6											AUG	2020	27	4					801	808		10.3758/s13423-020-01731-w	http://dx.doi.org/10.3758/s13423-020-01731-w		MAY 2020										2026-01-16	WOS:000531328000001
J	DALESSANDRO, C; MERTENS, P				DALESSANDRO, C; MERTENS, P			AUTOMATIC PITCH CONTOUR STYLIZATION USING A MODEL OF TONAL PERCEPTION	COMPUTER SPEECH AND LANGUAGE				Article								A new quantitative model of tonal perception for continuous speech is described. The paper illustrates its ability for automatic stylization of pitch contours, with applications to prosodic analysis and speech synthesis in mind, and evaluates it in a perception experiment. After a discussion of the psyche-acoustics of tonal perception, and an overview of existing tonal perception models and systems for automatic analysis of intonation, the model and its computer implementation are described in detail. It includes parameter extraction, segmentation into syllables, perceptual integration of short term pitch change, tonal segment computation, and pitch contour stylization. This is followed by a perception experiment in which subjects are asked to distinguish original signals from resynthesized signals with automatically stylized pitch contours. The aim of this experiment is to show the usefulness of the model as a basis for intonation representation, and to study the influence of the model parameters. It is shown that the stylization obtained with the model is an economic representation of intonation which can be useful for speech synthesis and prosodic analysis. (C) 1995 Academic Press Limited												54	62											JUL	1995	9	3					257	288		10.1006/csla.1995.0013	http://dx.doi.org/10.1006/csla.1995.0013												2026-01-16	WOS:A1995RM53800003
J	Sridhar, VKR; Bangalore, S; Narayanan, SS				Sridhar, Vivek Kumar Rangarajan; Bangalore, Srinivas; Narayanan, Shrikanth S.			Exploiting acoustic and syntactic features for automatic prosody labeling in a maximum entropy framework	IEEE TRANSACTIONS ON AUDIO SPEECH AND LANGUAGE PROCESSING				Article								In this paper, we describe a maximum entropy-based automatic prosody labeling framework that exploits both language and speech information. We apply the proposed framework to both prominence and phrase structure detection within the Tones and Break Indices (ToBI) annotation scheme. Our framework utilizes novel syntactic features in the form of supertags and a quantized acoustic-prosodic feature representation that is similar to linear parameterizations of the prosodic contour. The proposed model is trained discriminatively and is robust in the selection of appropriate features for the task of prosody detection. The proposed maximum entropy acoustic-syntactic model achieves pitch accent and,boundary tone detection accuracies of 86.0% and 93.1% on the Boston University Radio News corpus, and, 79.8% and 90.3% on the Boston Directions corpus. The phrase structure detection through prosodic break index labeling provides accuracies of 84% and 87% on the two corpora, respectively. The reported results are significantly better than previously reported results and demonstrate the strength of maximum entropy model in jointly modeling simple lexical, syntactic, and acoustic features for automatic prosody labeling.												63	74											MAY	2008	16	4					797	811		10.1109/TASL.2008.917071	http://dx.doi.org/10.1109/TASL.2008.917071												2026-01-16	WOS:000258033600011
J	Sisman, B; Zhang, MY; Li, HZ				Sisman, Berrak; Zhang, Mingyang; Li, Haizhou			Group Sparse Representation With WaveNet Vocoder Adaptation for Spectrum and Prosody Conversion	IEEE-ACM TRANSACTIONS ON AUDIO SPEECH AND LANGUAGE PROCESSING				Article								The statistical approach to voice conversion typically consists of a feature conversion module followed by a vocoder. So far, the feature conversion studies are mainly focused on the conversion of spectrum. However, speaker identity is also characterized by prosodic features, such as fundamental frequency (F0) and energy contour among others. In this paper, we study the transformation of speaker characteristics both in terms of spectrum and prosody. We propose two novel techniques that effectively use a limited amount of source-target training data and leverage a large general speech corpus to improve the voice conversion quality. First, we study the phonetic sparse representation under the group sparsity mathematical formulation. We use phonetic posteriorgrams (PPGs) together with spectral and prosody features to form tandem feature in the phonetic dictionary. The tandem feature allow us to estimate an activation matrix that is less dependent on source speakers, thus providing a better voice conversion quality. Second, we study the use of WaveNet vocoder that can be trained on general speech corpus from multiple speakers and adapted on target speaker data to improve the vocoding quality. We benefit from the large general speech databases that are used to train the PPG generator, and the WaveNet vocoder. The experiments show that the proposed conversion framework outperforms the traditional spectrum and prosody conversion techniques in both objective and subjective evaluations.												34	42											JUN	2019	27	6					1085	1097		10.1109/TASLP.2019.2910637	http://dx.doi.org/10.1109/TASLP.2019.2910637												2026-01-16	WOS:000466224000004
J	Taylor, P				Taylor, P			Analysis and synthesis of intonation using the Tilt model	JOURNAL OF THE ACOUSTICAL SOCIETY OF AMERICA				Article								This paper introduces the Tilt intonational model and describes how this model can be used to automatically analyze and synthesize intonation. In the model, intonation is represented as a linear sequence of events, which can be pitch accents or boundary tones. Each event is characterized by continuous parameters representing amplitude, duration, and tilt (a measure of the shape of the event). The paper describes an event detector, in effect an intonational recognition system, which produces a transcription of an utterance's intonation. The features and parameters of the event detector are discussed and performance figures are shown on a variety of read and spontaneous speaker independent conversational speech databases. Given the event locations, algorithms are described which produce an automatic analysis of each event in terms of the Tilt parameters. Synthesis algorithms are also presented which generate F0 contours from Tilt representations. The accuracy of these is shown by comparing synthetic F0 contours to real F0 contours. The paper concludes with an extensive discussion on linguistic representations of intonation and gives evidence that the Tilt model goes a long way to satisfying the desired goals of such a representation in that it has the right number of degrees of freedom to be able to describe and synthesize intonation accurately. (C) 2000 Acoustical Society of America. [S0001-4966(00)01802-6].												164	186											MAR	2000	107	3					1697	1714		10.1121/1.428453	http://dx.doi.org/10.1121/1.428453												2026-01-16	WOS:000085767800058
J	Pelachaud, C; Badler, NI; Steedman, M				Pelachaud, C; Badler, NI; Steedman, M			Generating facial expressions for speech	COGNITIVE SCIENCE				Article								This article reports results from a program that produces high-quality animation of facial expressions and head movements as automatically as possible in conjunction with meaning-based speech synthesis, including spoken intonation, The goal of the research is as much to test and define our theories of the formal semantics for such gestures, as to produce convincing animation. Towards this end, we have produced a high-level programming language for three-dimensional (3-D) animation of facial expressions, We have been concerned primarily with expressions conveying information correlated with the intonation of the voice: This includes the differences of timing, pitch, and emphasis that are related to such semantic distinctions of discourse as ''focus.'' ''topic,'' and ''comment,'' ''theme'' and ''rheme.'' or ''given'' and ''new'' information, We ore also interested in the relation of affect or emotion to facial expression. Until now, systems have not embodied such rule-governed translation from spoken utterance meaning to facial expressions. Our system embodies rules that describe and coordinate these relations: intonation/information, intonation/effect, and facial expressions/effect. A meaning representation includes discourse information: What is contrastive/background information in the given context, and what is the ''topic'' or ''theme'' of the discourse? The system maps the meaning representation into how accents and their placement ore chosen, how they are conveyed over facial expression, and how speech and facial expressions ore coordinated. This determines a sequence of functional groups: lip shapes, conversational signals, punctuators, regulators, and manipulators. Our algorithms then impose synchrony, create coarticulation effects, end determine affectual signals, eye and head movements. The lowest level representation is the Facial Action Coding System (FACS), which makes the generation system portable to other facial models.												136	167											JAN-MAR	1996	20	1					1	46															2026-01-16	WOS:A1996UK38100001
J	Sonntag, GP; Portele, T				Sonntag, GP; Portele, T			PURR - A method for prosody evaluation and investigation	COMPUTER SPEECH AND LANGUAGE				Article								Since intelligibility of synthetic speech is no longer the main criterion on which to base quality judgements, reliable methods for prosody evaluation become more important. We propose a method called PURR (Prosody Unveiling through Restricted Representation) to evaluate the prosodic component of a synthesis system without the interference of other system components. In PURR, the stimuli are reduced to their prosodic content. The method has proven to be suitable for test designs with naive listeners. It can be used for comparative studies as well as for diagnostic analyses and is, therefore, a useful tool for basic research on the perception of prosodic phenomena. In this paper we first describe how the best signal manipulation method was determined using perception tests. The appropriateness of the resulting signal is further assessed in a recognition test of syntactic structure. We then report on further validations of the proposed method: different ways of synthetic prosody modelling are evaluated, both in comparison with human prosody and amongst different synthesis systems. (C) 1998 Academic Press.												29	31											OCT	1998	12	4					437	451		10.1006/csla.1998.0107	http://dx.doi.org/10.1006/csla.1998.0107												2026-01-16	WOS:000077295700011
J	Lohmann, A; Tucker, BV				Lohmann, Arne; Tucker, Benjamin, V			Testing the storage of prosody-induced phonetic detail via auditory lexical decision A case study of noun/verb homophones	MENTAL LEXICON				Article								This article reports the results of an auditory lexical decision task, testing the processing of phonetic detail of English noun/verb conversion pairs. The article builds on recent findings showing that the frequent occurrence in certain prosodic environments may lead to the storage of prosodyinduced phonetic detail as part of the lexical representation. To investigate this question with noun/verb conversion pairs, ambicategorical stimuli were used that exhibit systematic occurrence differences with regard to prosodic environment, as indicated by either a strong verb-bias, e.g., talk (N/V) or a strong noun-bias, e.g., voice (N/V). The auditory lexical decision task tests whether acoustic properties reflecting either the typical or the atypical prosodic environment impact the processing of recordings of the stimuli. In doing so assumptions about the storage of prosody-induced phonetic detail are tested that distinguish competing model architectures. The results are most straightforwardly accounted for within an abstractionist architecture, in which the acoustic signal is mapped onto a representation that is based on the canonical pronunciation of the word.												1	2												2021	16	1					133	164		10.1075/ml.19025.loh	http://dx.doi.org/10.1075/ml.19025.loh												2026-01-16	WOS:000714715900007
J	Vargas, J; McLaughlin, S				Vargas, Julio; McLaughlin, Stephen			Speech Analysis and Synthesis Based on Dynamic Modes	IEEE TRANSACTIONS ON AUDIO SPEECH AND LANGUAGE PROCESSING				Article								In this paper, the source-filter model of speech production is adapted to represent the speech signal as the superposition and convolution of a dynamic source and resonant modes. The aim is to increase the resolution of the time-instantaneous-frequency representation of each of the individual contributions of different sections of the human phonatory system. We present a framework based on dynamic mode predictors and filters, which are adapted, using gradient-based techniques, to track the modal dynamics of speech yielding a representation which is free from quasi-stationary assumptions thus allowing flexible manipulation of the speech signal. Several examples are offered including intonation modifications to illustrate the potential of the proposed approach.												3	3											NOV	2011	19	8					2566	2578		10.1109/TASL.2011.2151859	http://dx.doi.org/10.1109/TASL.2011.2151859												2026-01-16	WOS:000296889900029
J	Selkirk, EO				Selkirk, Elisabeth O.			CONTRASTIVE FOCUS, GIVENNESS AND THE UNMARKED STATUS OF "DISCOURSE-NEW"	ACTA LINGUISTICA HUNGARICA				Article								New evidence is provided for a grammatical principle that singles out contrastive focus (Rooth 1996; Truckenbrodt 1995) and distinguishes it from discourse-new "informational" focus. Since the prosody of discourse-given constituents may also be distinguished from discourse-new, a three-way distinction in representation is motivated. It is assumed that an F-feature marks just contrastive focus ( Jackendoff 1972, Rooth 1992), and that a G-feature marks discourse-given constituents (Fery-Samek-Lodovici 2006), while discourse-new is unmarked. A crucial argument for G-marking comes from second occurrence focus (SOF) prosody, which arguably derives from a syntactic representation where SOF is both F-marked and G-marked. This analysis relies on a new G-Marking Condition specifying that a contrastive focus may be G-marked only if the focus semantic value of its scope is discourse-given, i.e., only if the contrast itself is given.												59	77											DEC	2008	55	3-4					331	346		10.1556/ALing.55.2008.3-4.8	http://dx.doi.org/10.1556/ALing.55.2008.3-4.8												2026-01-16	WOS:000260004300008
J	Zhao, XX; Ito, A; Yang, XH				Zhao, Xinxian; Ito, Aine; Yang, Xiaohu			Contributions of Language-Specific and Domain-General Cognitive Abilities to the Comprehension of Focus Prosody in Jianghuai Mandarin: Effects of Age	JOURNAL OF PSYCHOLINGUISTIC RESEARCH				Article								A growing body of research has explored the cognitive factors influencing aging adults' recognition of spoken words and phrases. In contrast, research on the cognitive contributions to speech prosody comprehension in tonal languages across adulthood remains relatively limited. This study aimed to bridge this gap by investigating the contributions of language-specific and domain-general cognitive factors to focus prosody comprehension performance among aging speakers of Jianghuai Mandarin. Young, middle-aged, and older healthy native speakers of Jianghuai Mandarin (N = 30 per group) performed a focus comprehension task, where they inferred the underlying intentions conveyed by different conditions (initial focus, medial focus, and final focus) of focus prosody. They also completed a series of language-specific (acoustic representation, meaning categorization, and focus knowledge) and domain-general (inhibitory control, attention switching, and working memory) cognitive assessments pertinent to understanding focus prosody. Findings showed an age-related decline in the comprehension of focus prosody, along with different rates of reduction in language-specific and domain-general cognitive abilities. These cognitive abilities did not modulate the focus comprehension performance among the young and middle-aged groups. In the older group, however, positive associations were observed between focus comprehension performance and certain domain-general abilities, as evidenced by the strong predictive power of attention switching and working memory. The findings provide insights into the mechanisms underpinning linguistic prosody processing among aging adults.												0	0											NOV 10	2025	54	6							57	10.1007/s10936-025-10177-x	http://dx.doi.org/10.1007/s10936-025-10177-x												2026-01-16	WOS:001610753900001
J	Gnanateja, GN; Rupp, K; Llanos, F; Hect, J; German, JS; Teichert, T; Abel, TJ; Chandrasekaran, B				Gnanateja, G. Nike; Rupp, Kyle; Llanos, Fernando; Hect, Jasmine; German, James S.; Teichert, Tobias; Abel, Taylor J.; Chandrasekaran, Bharath			Cortical processing of discrete prosodic patterns in continuous speech	NATURE COMMUNICATIONS				Article								Prosody has a vital function in speech, structuring a speaker's intended message for the listener. The superior temporal gyrus (STG) is considered a critical hub for prosody, but the role of earlier auditory regions like Heschl's gyrus (HG), associated with pitch processing, remains unclear. Using intracerebral recordings in humans and non-human primate models, we investigated prosody processing in narrative speech, focusing on pitch accents-abstract phonological units that signal word prominence and communicative intent. In humans, HG encoded pitch accents as abstract representations beyond spectrotemporal features, distinct from segmental speech processing, and outperforms STG in disambiguating pitch accents. Multivariate models confirm HG's unique representation of pitch accent categories. In the non-human primate, pitch accents were not abstractly encoded, despite robust spectrotemporal processing, highlighting the role of experience in shaping abstract representations. These findings emphasize a key role for the HG in early prosodic abstraction and advance our understanding of human speech processing.												3	4											MAR 3	2025	16	1							1947	10.1038/s41467-025-56779-w	http://dx.doi.org/10.1038/s41467-025-56779-w												2026-01-16	WOS:001437303700025
J	Chen, CM				Chen, Chun-Mei			The Phonetics of Paiwan Word-Level Prosody	LANGUAGE AND LINGUISTICS				Article								In this paper the phonetic correlates of word-level prosody of an indigenous language were examined as a case of supporting the argument that phonetic representation plays a role in the documentation of phonology. Piuma Paiwan has a quality-sensitive stress in which peripheral vowels such as /i/, /u/, and /a/ are more optimal than the central schwa, and the primary stress falls on the most sonorant or the most optimal vowel. However, a schwa nucleus can bear stress in the other Paiwan dialects. On the other hand, imperative accent may result in the pitch peak aligned with the final syllable. Stressed syllables always have higher pitch than unstressed syllables, and pitch tends to be a robust cue to word-level stress and accent in Paiwan. The results suggest that word-level prosody in Paiwan is best modeled in terms of f0 realization.												6	9											JUL	2009	10	3					593	625															2026-01-16	WOS:000268293900007
J	Zatorre, RJ; Baum, SR				Zatorre, Robert J.; Baum, Shari R.			Musical Melody and Speech Intonation: Singing a Different Tune?	PLOS BIOLOGY				Article								Music and speech are often cited as characteristically human forms of communication. Both share the features of hierarchical structure, complex sound systems, and sensorimotor sequencing demands, and both are used to convey and influence emotions, among other functions [1]. Both music and speech also prominently use acoustical frequency modulations, perceived as variations in pitch, as part of their communicative repertoire. Given these similarities, and the fact that pitch perception and production involve the same peripheral transduction system (cochlea) and the same production mechanism (vocal tract), it might be natural to assume that pitch processing in speech and music would also depend on the same underlying cognitive and neural mechanisms. In this essay we argue that the processing of pitch information differs significantly for speech and music; specifically, we suggest that there are two pitch-related processing systems, one for more coarse-grained, approximate analysis and one for more fine-grained accurate representation, and that the latter is unique to music. More broadly, this dissociation offers clues about the interface between sensory and motor systems, and highlights the idea that multiple processing streams are a ubiquitous feature of neuro-cognitive architectures.												126	144											JUL	2012	10	7							e1001372	10.1371/journal.pbio.1001372	http://dx.doi.org/10.1371/journal.pbio.1001372												2026-01-16	WOS:000307161000013
J	Boutsen, F				Boutsen, F			Aprosody: A right hemisphere dysarthria?	JOURNAL OF MEDICAL SPEECH-LANGUAGE PATHOLOGY				Article								Over the years, many descriptions of aprosody have been offered. Even so, to date no clear definition of this speech disorder exists, and the relation between aprosody and dysarthria has remained elusive. This quandary has lingered because of prevailing theoretical perspectives on prosody that have undergirded motor speech classification systems such as the Mayo classification system or models of aprosody like the one developed by Ross (1981). In the former framework, prosody is placed on top of a hierarchically organized speech process, whereas in the latter it is construed to be much like language, that is, representational and highly dependent on cortex. Evidence is reviewed to show that a parallel organization of prosody that pays tribute to asymmetric hemispheric involvement in laryngeal and supralaryngeal gestures should be adopted in theories of neurogenic speech disorders.												1	1											JUN	2004	12	2					67	75															2026-01-16	WOS:000222476900005
J	Ji, JX; Zhao, XX; Li, Y; Yang, XH				Ji, Jinxin; Zhao, Xinxian; Li, Yang; Yang, Xiaohu			Age Effects on Prosodic Boundary Perception	PSYCHOLOGY AND AGING				Article								The redundancy hypothesis proposes that older listeners need a larger array of acoustic cues than younger listeners for effective speech perception. This research investigated this hypothesis by examining the aging effects on the use of prosodic cues in speech segmentation in Mandarin Chinese. We examined how younger and older listeners perceived prosodic boundaries using three main prosodic cues (pause, final lengthening, and pitch change) across eight conditions involving different cue combinations. The stimuli consisted of syntactically ambiguous phrase pairs, each containing two or three objects. Participants (22 younger listeners and 22 older listeners) performed a speech recognition task to judge the number of objects they heard. Both groups primarily relied on the pause cue for identifying prosodic boundaries, using final lengthening and pitch change as secondary cues. However, older listeners showed reduced sensitivity to these cues, compensating by integrating the primary cue pause with the secondary cue pitch change for more precise segmentation. The present study reveals older listeners' integration strategy in using prosodic cues for speech segmentation, supporting the redundancy hypothesis.												2	2											MAY	2024	39	3			SI		262	274		10.1037/pag0000811	http://dx.doi.org/10.1037/pag0000811												2026-01-16	WOS:001327885300008
J	Wagner, M				Wagner, Michael			Prosody and recursion in coordinate structures and beyond	NATURAL LANGUAGE & LINGUISTIC THEORY				Article								Generalizations about relative prosodic boundary strength are recursive. Initial evidence comes from the fragment of English consisting only of proper names and and and or. A systematic relation between the semantics, the syntactic combinatorics, and the prosodic phrasing of coordinate structures can be captured by recursively building up their prosody, in tandem with assembling their compositional meaning. Alternative edge-based approaches to prosodic phrasing fail to capture the recursive nature of the generalization, a result independent of whether or not prosodic representation itself is assumed to be recursive. The pattern generalizes beyond the grammar of coordination, despite two types of apparent counterexamples: Structures that are prosodically flat but syntactically articulated, and structures with an apparent outright mismatch between prosody and syntax. Closer inspection suggests that the syntax might actually be quite in tune with prosody. In both cases, natural language employs strategies to construe complex meaning with list-like structures rather than nested ones. The privileged status of lists may be due to processing factors.												90	103											FEB	2010	28	1					183	237		10.1007/s11049-009-9086-0	http://dx.doi.org/10.1007/s11049-009-9086-0												2026-01-16	WOS:000275123400006
J	Chiang, CY				Chiang, Chen-Yu			A parametric prosody coding approach for Mandarin speech using a hierarchical prosodic model	EURASIP JOURNAL ON AUDIO SPEECH AND MUSIC PROCESSING				Article								In this paper, a novel parametric prosody coding approach for Mandarin speech is proposed. It employs a hierarchical prosodic model (HPM) as a prosody-generating model in the encoder to analyze the speech prosody of the input utterance to obtain a parametric representation of four prosodic-acoustic features of syllable pitch contour, syllable duration, syllable energy level, and syllable-juncture pause duration for encoding. In the decoder, the four prosodic-acoustic features are reconstructed by a synthesis operation using the decoded HPM parameters. The reconstructed prosodic features are lastly used in an HMM-based speech synthesizer to generate the reconstructed speech. Objective and subjective evaluations showed that the proposed prosody coding approach encoded speech with better quality and lower data rate than the conventional segment-based coding scheme with vector or scalar quantization approach did. The reconstructed speech encoded by the proposed approach has good quality at low data rates of 81.4 and 72.7 bps for speaker-dependent and speaker-independent tasks, respectively. An application of the proposed prosody coding approach to speaking rate conversion by directly changing the HPM parameters to those of a different speaking rate is also illustrated. An informal listening test confirmed that both converted speeches of high and low speaking rate sounded very smooth.												0	0											JUL 11	2018									5	10.1186/s13636-018-0129-5	http://dx.doi.org/10.1186/s13636-018-0129-5												2026-01-16	WOS:000438819600001
J	Wilson, SJ; Parsons, K; Reutens, DC				Wilson, Sarah J.; Parsons, Kate; Reutens, David C.			Preserved singing in aphasia: A case study of the efficacy of melodic intonation therapy	MUSIC PERCEPTION				Article								THIS STUDY EXAMINED. THE EFFICACY of Melodic Intonation Therapy (MIT) in a male singer (KL) with severe Broca's aphasia. Thirty novel phrases were allocated to one of three experimental conditions: unrehearsed, rehearsed verbal production (repetition), and rehearsed verbal production with melody (MIT). The results showed superior production of MIT phrases during therapy. Comparison of performance at baseline, 1 week, and 5 weeks after therapy revealed an initial beneficial effect of both types of rehearsal; however, MIT was more durable, facilitating longer-term phrase production. Our findings suggest that MIT facilitated KL's speech praxis, and that combining melody and speech through rehearsal promoted separate storage and/or access to the phrase representation.												54	76											SEP	2006	24	1					23	35		10.1525/mp.2006.24.1.23	http://dx.doi.org/10.1525/mp.2006.24.1.23												2026-01-16	WOS:000241465600002
J	Xin, CL; Rahim, HA				Xin, Chang Li; Rahim, Hajar Abdul			From Positive to Death: A Corpus-Based Semantic Analysis of COVID-19 Representation in Malaysian English News Reports	3L-LANGUAGE LINGUISTICS LITERATURE-THE SOUTHEAST ASIAN JOURNAL OF ENGLISH LANGUAGE STUDIES				Article								More than a year after being declared a pandemic, Covid-19 has not shown any sure signs of dissipating even as the battle to curb it continues. In Malaysia, the Movement Control Order (MCO), or lockdown seems to be the most effective way to curb the spread of the disease. Unfortunately, studies show that lockdowns affect people 's livelihoods and lifestyle, as well as their emotional and mental state. This situation, in many countries, is exacerbated by the onslaught of negative news on Covid-19 and heightened news consumption via various media platforms. Given this, the objective of the current study is to analyse the representation of Covid-19 in Malaysian media based on a corpus of news reports during Malaysia's first lockdown, i.e. MCO 1.0. This was a period of uncertainty lasting six weeks beginning from 18 March 2020 which saw increased reports of mental health cases and domestic violence cases in the country. News reports published in two Malaysian English online newspapers, The Star Online and Malaysiakini during MCO 1.0 formed the corpus of study. Using collocational analysis, the study examined the semantic prosody of Covid-19 and how it is represented in Malaysian new reports. The findings show that 'Covid-19' generally occurs in the company of unfavourable associations, causing it to acquire a negative prosody and in turn negatively represented in the news reports. The unfavourable portrayal of Covid-19, coupled with the increase in news consumption may adversely affect readers' emotions and anxiety levels, which in turn, may contribute to crisis fatigue.												1	1												2021	27	4					16	28		10.17576/3L-2021-2704-02	http://dx.doi.org/10.17576/3L-2021-2704-02												2026-01-16	WOS:000733367700002
J	TRAMO, MJ; BHARUCHA, JJ				TRAMO, MJ; BHARUCHA, JJ			MUSICAL PRIMING BY THE RIGHT-HEMISPHERE POST-CALLOSOTOMY	NEUROPSYCHOLOGIA				Article								The hemispheric representation of auditory functions mediating the perception of harmony in music was investigated in two split-brain patients using a musical chord priming task. Previous experiments in normal subjects had demonstrated that the harmonic context established by a prime chord influences the accuracy of target chord intonation judgements. Only the right hemisphere of each callosotomy patient manifested the normal interaction between harmonic relatedness and intonation. The results raise the possibility that associative auditory functions which generate expectancies for harmonic progression in music are lateralized within the right hemisphere.												31	34												1991	29	4					313	325		10.1016/0028-3932(91)90045-A	http://dx.doi.org/10.1016/0028-3932(91)90045-A												2026-01-16	WOS:A1991FR85600004
J	Iwata, M; Hashimoto, R; Seki, A				Iwata, Michiru; Hashimoto, Ryusaku; Seki, Ayumi			Lexical prosodic representation and access in Japanese children with developmental dyslexia	DYSLEXIA				Article								Recent research indicates that awareness of the prosodic information present in spoken language could be an important factor for literacy development, and that adults with developmental dyslexia show impaired awareness of lexical prosodic information, while the phonological representations remain intact. We investigated lexical prosodic representation and awareness in Japanese children with and without developmental dyslexia. Lexical prosodic representation was investigated using a cross-modal fragment priming task, and awareness was examined using a fragment identification task. The task was modified for children by selecting words with higher familiarity and fewer trials. As a result, the same pattern of prosodic priming effects was observed between groups; lexical decision time was faster in the prosodic congruent condition than in the incongruent condition. In addition, accuracy and reaction time did not show group differences in the fragment identification task. Relationship between prosody and literacy development may differ between languages but the sample size were small in both groups. Further investigation with larger sample size is required.												0	0											AUG	2023	29	3					255	263		10.1002/dys.1737	http://dx.doi.org/10.1002/dys.1737		MAY 2023										2026-01-16	WOS:000985998400001
J	Fletcher, MD; Thini, N; Perry, SW				Fletcher, Mark D.; Thini, Nour; Perry, Samuel W.			Enhanced Pitch Discrimination for Cochlear Implant Users with a New Haptic Neuroprosthetic	SCIENTIFIC REPORTS				Article								The cochlear implant (CI) is the most widely used neuroprosthesis, recovering hearing for more than half a million severely-to-profoundly hearing-impaired people. However, CIs still have significant limitations, with users having severely impaired pitch perception. Pitch is critical to speech understanding (particularly in noise), to separating different sounds in complex acoustic environments, and to music enjoyment. In recent decades, researchers have attempted to overcome shortcomings in CIs by improving implant technology and surgical techniques, but with limited success. In the current study, we take a new approach of providing missing pitch information through haptic stimulation on the forearm, using our new mosaicOne_B device. The mosaicOne_B extracts pitch information in real-time and presents it via 12 motors that are arranged in ascending pitch along the forearm, with each motor representing a different pitch. In normal-hearing subjects listening to CI simulated audio, we showed that participants were able to discriminate pitch differences at a similar performance level to that achieved by normal-hearing listeners. Furthermore, the device was shown to be highly robust to background noise. This enhanced pitch discrimination has the potential to significantly improve music perception, speech recognition, and speech prosody perception in CI users.												32	34											JUN 25	2020	10	1							10354	10.1038/s41598-020-67140-0	http://dx.doi.org/10.1038/s41598-020-67140-0												2026-01-16	WOS:000546571800031
J	Kjelgaard, MM; Speer, SR				Kjelgaard, MM; Speer, SR			Prosodic facilitation and interference in the resolution of temporary syntactic closure ambiguity	JOURNAL OF MEMORY AND LANGUAGE				Article; Proceedings Paper	CUNY Sentence Processing Conference	1993	NEW YORK, NEW YORK					Subjects listened to sentences with early closure (e.g., When Roger leaves the house is dark) or late closure syntax (e.g., When Roger leaves the house it's dark) and one of three prosodies: cooperating (coinciding prosodic and syntactic boundary), baseline (phonetically neutralized prosodic boundary), and conflicting (prosodic boundary at a misleading syntactic location). Prosodic manipulations were verified by phonetic measurements and listener judgments. Four experiments demonstrated facilitation in speeded phonosyntactic grammaticality judgment, end-of-sentence comprehension, and crossmodal naming tasks: Sentences with cooperating prosody were processed more quickly than those with baseline prosody. Three experiments showed interference: Sentences with conflicting prosody were processed more slowly than those with baseline prosody. All experiments demonstrated a processing advantage for late closure structures in the conflicting and baseline conditions, but no differences between syntactic types in the cooperating condition. Cross-modal naming results showed early syntactic effects due to both high-level and intermediate-level prosodic boundaries. We argue that the initial syntactic structure assigned to an utterance can be determined by its prosodic phonological representation. (C) 1999 Academic Press.												221	268											FEB	1999	40	2					153	194		10.1006/jmla.1998.2620	http://dx.doi.org/10.1006/jmla.1998.2620												2026-01-16	WOS:000078582900001
J	Granström, B; House, D				Granström, B; House, D			Audiovisual representation of prosody in expressive speech communication	SPEECH COMMUNICATION				Article; Proceedings Paper	2nd International Conference on Speech Prosody	MAR, 2004	Nara, JAPAN					Prosody in a single speaking style-often read speech-has been studied extensively in acoustic speech. During the past few years we have expanded our interest in two directions: (1) Prosody in expressive speech communication and (2) prosody as an audiovisual expression. Understanding the interactions between visual expressions (primarily in the face) and the acoustics of the corresponding speech presents a substantial challenge. Some of the visual articulation is for obvious reasons tightly connected to the acoustics (e.g. lip and jaw movements), but there are other articulatory movements that do not show up on the outside of the face. Furthermore, many facial gestures used for communicative purposes do not affect the acoustics directly, but might nevertheless be connected on a higher communicative level in which the timing of the gestures could play an important role. In this presentation we will give some examples of recent work, primarily at KTH, addressing these questions. We will report on methods for the acquisition and modeling of visual and acoustic data, and some evaluation experiments in which audiovisual prosody is tested. The context of much of our work in this area is to create an animated talking agent capable of displaying realistic communicative behavior and suitable for use in conversational spoken language systems, e.g. a virtual language teacher. (c) 2005 Elsevier B.V. All rights reserved.												36	45											JUL	2005	46	3-4					473	484		10.1016/j.specom.2005.02.017	http://dx.doi.org/10.1016/j.specom.2005.02.017												2026-01-16	WOS:000230804200017
J	Mauchand, M; Caballero, JA; Jiang, XM; Pell, MD				Mauchand, Mael; Caballero, Jonathan A.; Jiang, Xiaoming; Pell, Marc D.			Immediate online use of prosody reveals the ironic intentions of a speaker: neurophysiological evidence	COGNITIVE AFFECTIVE & BEHAVIORAL NEUROSCIENCE				Article								In social interactions, speakers often use their tone of voice ("prosody") to communicate their interpersonal stance to pragmatically mark an ironic intention (e.g., sarcasm). The neurocognitive effects of prosody as listeners process ironic statements in real time are still poorly understood. In this study, 30 participants judged the friendliness of literal and ironic criticisms and compliments in the absence of context while their electrical brain activity was recorded. Event-related potentials reflecting the uptake of prosodic information were tracked at two time points in the utterance. Prosody robustly modulated P200 and late positivity amplitudes from utterance onset. These early neural responses registered both the speaker's stance (positive/negative) and their intention (literal/ironic). At a later timepoint (You are such a great/horrible cook), P200, N400, and P600 amplitudes were all greater when the critical word valence was congruent with the speaker's vocal stance, suggesting that irony was contextually facilitated by early effects from prosody. Our results exemplify that rapid uptake of salient prosodic features allows listeners to make online predictions about the speaker's ironic intent. This process can constrain their representation of an utterance to uncover nonliteral meanings without violating contextual expectations held about the speaker, as described by parallel-constraint satisfaction models.												23	24											FEB	2021	21	1					74	92		10.3758/s13415-020-00849-7	http://dx.doi.org/10.3758/s13415-020-00849-7		JAN 2021										2026-01-16	WOS:000606251000001
J	Coath, M; Brader, JM; Fusi, S; Denham, SL				Coath, M; Brader, JM; Fusi, S; Denham, SL			Multiple views of the response of an ensemble of spectro-temporal features support concurrent classification of utterance, prosody, sex and speaker identity	NETWORK-COMPUTATION IN NEURAL SYSTEMS				Article; Proceedings Paper	Gordon Research Conference on Sensory Coding in the Natural Environment	SEP 05-10, 2004	Queen Coll, Oxford, ENGLAND		Queen Coll			Models of auditory processing, particularly of speech, face many difficulties. These difficulties include variability among speakers, variability in speech rate and robustness to moderate distortions such as time compression. In contrast to the 'invariance of percept' (across different speakers, of different sexes, using different intonation, and so on) is the observation that we are sensitive to the identity, sex and intonation of the speaker. In previous work we have reported that a model based on ensembles of spectro-temporal feature detectors, derived from onset sensitive pre-processing of a limited class of stimuli, preserves significant information about the stimulus class. We have also shown that this is robust with respect to the exact choice of feature set, moderate time compression in the stimulus and speaker variation. Here we extend these results to show a) that by using a classifier based on a network of spiking neurons with spike-driven plasticity, the output of the ensemble constitutes an effective rate coding representation of complex sounds; and b) that the same set of spectro-temp oral features concurrently preserve information about a range of qualitatively different classes into which the stimulus might fall. We show that it is possible for multiple views of the same pattern of responses to generate different percepts. This is consistent with suggestions that multiple parallel processes exist within the auditory 'what' pathway with attentional modulation enhancing the task-relevant classification type. We also show that the responses of the ensemble are sparse in the sense that a small number of features respond for each stimulus type. This has implications for the ensembles' ability to generalise, and to respond differentially to a wide variety of stimulus classes.												13	15											JUN-SEP	2005	16	2-3					285	300		10.1080/09548980500290120	http://dx.doi.org/10.1080/09548980500290120												2026-01-16	WOS:000234525700010
J	Cameron-Faulkner, T				Cameron-Faulkner, Thea			The interaction of gesture, intonation, and eye-gaze in proto-imperatives	JOURNAL OF CHILD LANGUAGE				Article								In the present study we investigate the production of gesture, intonation, and eye-gaze within the proto-imperative behaviour of one English child aged 1; 0 to 1; 7. The study is based on the qualitative and quantitative analysis of the three behaviours. The results indicate a shift from reaching gestures to points, and from rising terminal pitch contours to non-rising contours. The analysis also highlights changes in eye-gaze to the co-participant over time. In addition we identify a significant relationship between pitch contour and gesture type within the sample, with points being more closely associated with non-rise intonation than reaching gestures. We suggest that the changes in proto-imperative behaviour signal a shift in the underlying representation of the function from a request for help to a demand for a particular object, and that this development paves the way for the subsequent conventional linguistic expression of the imperative function.												3	4											JUL	2014	41	4					842	860		10.1017/S0305000913000238	http://dx.doi.org/10.1017/S0305000913000238												2026-01-16	WOS:000337758000005
J	Ehret, J; Bönsch, A; Aspöck, L; Röhr, CT; Baumann, S; Grice, M; Fels, J; Kuhlen, TW				Ehret, Jonathan; Boensch, Andrea; Aspoeck, Lukas; Roehr, Christine T.; Baumann, Stefan; Grice, Martine; Fels, Janina; Kuhlen, Torsten W.			Do Prosody and Embodiment Influence the Perceived Naturalness of Conversational Agents' Speech?	ACM TRANSACTIONS ON APPLIED PERCEPTION				Article; Proceedings Paper	18th Symposium on Applied Perceptiion (SAP)	SEP, 2021	ELECTR NETWORK					For conversational agents' speech, either all possible sentences have to be prerecorded by voice actors or the required utterances can be synthesized. While synthesizing speech is more flexible and economic in production, it also potentially reduces the perceived naturalness of the agents among others due to mistakes at various linguistic levels. In our article, we are interested in the impact of adequate and inadequate prosody, here particularly in terms of accent placement, on the perceived naturalness and aliveness of the agents. We compare (1) inadequate prosody, as generated by off-the-shelf text-to-speech (TTS) engines with synthetic output; (2) the same inadequate prosody imitated by trained human speakers; and (3) adequate prosody produced by those speakers. The speech was presented either as audio-only or by embodied, anthropomorphic agents, to investigate the potential masking effect by a simultaneous visual representation of those virtual agents. To this end, we conducted an online study with 40 participants listening to four different dialogues each presented in the three Speech levels and the two Embodiment levels. Results confirmed that adequate prosody in human speech is perceived as more natural (and the agents are perceived as more alive) than inadequate prosody in both human (2) and synthetic speech (1). Thus, it is not sufficient to just use a human voice for an agents' speech to be perceived as natural-it is decisive whether the prosodic realisation is adequate or not. Furthermore, and surprisingly, we found no masking effect by speaker embodiment, since neither a human voice with inadequate prosody nor a synthetic voice was judged as more natural, when a virtual agent was visible compared to the audio-only condition. On the contrary, the human voice was even judged as less "alive" when accompanied by a virtual agent. In sum, our results emphasize, on the one hand, the importance of adequate prosody for perceived naturalness, especially in terms of accents being placed on important words in the phrase, while showing, on the other hand, that the embodiment of virtual agents plays a minor role in the naturalness ratings of voices.												23	24											OCT	2021	18	4							21	10.1145/3486580	http://dx.doi.org/10.1145/3486580												2026-01-16	WOS:000754533100005
J	Joo, H; D'Imperio, M				Joo, Hyunjung; D'Imperio, Mariapaola			The Perception of Lexical Pitch Accent in South Kyungsang Korean: The Relevance of Accent Shape	LANGUAGE AND SPEECH				Article; Early Access								In this study, we tested whether the perception of pitch contours within a lexical pitch accent can be better understood through tonal targets in the Autosegmental-Metrical (AM) model or as an entire tonal configuration identification. Specifically, a categorization experiment was conducted to see how South Kyungsang Korean (SKK) listeners perceive their high (H) and rising (LH) lexical pitch accents. Auditory stimuli were manipulated depending on H peak alignment (earlier vs. later), rise shape (domed or "convex" vs. scooped or "concave"), or segmental duration (shorter vs. longer). Results showed that F0 rise shape and segmental duration influenced SKK listeners' categorization, while no effect of peak alignment was observed. Specifically, they responded to more scooped shapes as an LH, while more domed shapes were mainly assigned to H responses. Moreover, shorter duration induced a H categorization, while longer duration was related to an LH. Results suggest that SKK listeners use both F0 shape and segmental duration as important cues for tonal contrast, though F0 shape shows stronger categorical effect than duration. Thus, F0 shape information is important to determine phonological representation of lexical pitch accents, as opposed to strict tonal alignment defined in Autosegmental-Metrical theory.												0	0											2025 SEP 11	2025										10.1177/00238309251368294	http://dx.doi.org/10.1177/00238309251368294		SEP 2025										2026-01-16	WOS:001568442700001
J	Iwahashi, N; Sagisaka, Y				Iwahashi, N; Sagisaka, Y			Statistical modelling of speech segment duration by constrained tree regression	IEICE TRANSACTIONS ON INFORMATION AND SYSTEMS				Article								This paper presents a new method for statistical modelling of prosody control in speech synthesis. The proposed method, which is referred to as Constrained Tree Regression (CTR), can make suitable representation of complex effects of control factors for prosody with a moderate amount of learning data. It is based on recursive splits of predictor variable spares and partial imposition of constraints of linear independence among predictor variables. It incorporates both linear and tree regressions with categorical predictor variables, which have been conventionally used for prosody control, and extends them to more general models. In addition, a hierarchical error function is presented to consider hierarchical structure in prosody control. This nea method is applied to modelling of speech segmental duration. Experimental results show that better duration models are obtained by using the proposed regression method compared with linear and tree regressions using the same number of free parameters. It is also shown that the hierarchical structure of phoneme and syllable durations can be represented efficiently using the hierarchical error function.												16	17											JUL	2000	E83D	7					1550	1559															2026-01-16	WOS:000088464200029
J	Kaksin, AD				Kaksin, Andrey D.			"... SENDS BEST GREETINGS TO THE KING": REPRESENTATION OF EVIDENTIALITY IN A. S. PUSHKIN'S FAIRY TALES	VESTNIK SLAVIANSKIKH KULTUR-BULLETIN OF SLAVIC CULTURES-SCIENTIFIC AND INFORMATIONAL JOURNAL				Article								The article explores a number of evidential meanings, like retelling someone else's speech, witnessing of an event through its outcomes (traces), surprises at the sight of something unexpected. The author seeks to show that meanings of the evidential sphere (including not only those listed above, but also some other ones, very specific) are extremely noteworthy expressed in Russian. Taking into account the main ways of expression of the specified meanings, one may say that evidentiality in Russian is expressed mainly lexically (by the use of special words) and with the help of intonation (by means of the corresponding intonation). Assuming the evidentiality an independent functional and semantic category, the author considers the possibilities of its representation (in other words - means of expression) in Russian. In the author's opinion, the most spectacular and ample use of these means is found in the works A. S. Pushkin. Its illustrations include fragments from four masterpieces of the great Russian poet ("The tale of Tsar Saltan", "The tale of the fisherman and the fish", "The tale of the dead princess and the seven knights", "The tale of the Golden Cockerel").												0	0											DEC	2017	46						148	154															2026-01-16	WOS:000423967800012
J	Filippa, M; Lima, D; Grandjean, A; Labbé, C; Coll, SY; Gentaz, E; Grandjean, DM				Filippa, M.; Lima, D.; Grandjean, A.; Labbe, C.; Coll, S. Y.; Gentaz, E.; Grandjean, D. M.			Emotional prosody recognition enhances and progressively complexifies from childhood to adolescence	SCIENTIFIC REPORTS				Article								Emotional prosody results from the dynamic variation of language's acoustic non-verbal aspects that allow people to convey and recognize emotions. The goal of this paper is to understand how this recognition develops from childhood to adolescence. We also aim to investigate how the ability to perceive multiple emotions in the voice matures over time. We tested 133 children and adolescents, aged between 6 and 17 years old, exposed to 4 kinds of linguistically meaningless emotional (anger, fear, happiness, and sadness) and neutral stimuli. Participants were asked to judge the type and intensity of perceived emotion on continuous scales, without a forced choice task. As predicted, a general linear mixed model analysis revealed a significant interaction effect between age and emotion. The ability to recognize emotions significantly increased with age for both emotional and neutral vocalizations. Girls recognized anger better than boys, who instead confused fear with neutral prosody more than girls. Across all ages, only marginally significant differences were found between anger, happiness, and neutral compared to sadness, which was more difficult to recognize. Finally, as age increased, participants were significantly more likely to attribute multiple emotions to emotional prosody, showing that the representation of emotional content becomes increasingly complex. The ability to identify basic emotions in prosody from linguistically meaningless stimuli develops from childhood to adolescence. Interestingly, this maturation was not only evidenced in the accuracy of emotion detection, but also in a complexification of emotion attribution in prosody.												14	17											OCT 13	2022	12	1							17144	10.1038/s41598-022-21554-0	http://dx.doi.org/10.1038/s41598-022-21554-0												2026-01-16	WOS:000867889200035
J	Gao, PK; Jiang, ZF; Yang, YF; Zheng, YY; Feng, GY; Li, XQ				Gao, Panke; Jiang, Zhufang; Yang, Yufang; Zheng, Yuanyi; Feng, Gangyi; Li, Xiaoqing			Temporal neural dynamics of understanding communicative intentions from speech prosody	NEUROIMAGE				Article								Understanding the correct intention of a speaker is critical for social interaction. Speech prosody is an important source for understanding speakers' intentions during verbal communication. However, the neural dynamics by which the human brain translates the prosodic cues into a mental representation of communicative intentions in real time remains unclear. Here, we recorded EEG (electroencephalograph) while participants listened to dialogues. The prosodic features of the critical words at the end of sentences were manipulated to signal either suggestion, warning, or neutral intentions. The results showed that suggestion and warning intentions evoked enhanced late positive event-related potentials (ERPs) compared to the neutral condition. Linear mixed-effects model (LMEM) regression and representational similarity analysis (RSA) analyses revealed that these ERP effects were distinctively correlated with prosodic acoustic analysis, emotional valence evaluation, and intention interpretation in different time windows; The onset latency significantly increased as the processing level of abstractness and communicative intentionality increased. Neural representations of intention and emotional information emerged and parallelly persisted over a long time window, guiding the correct identification of communicative intention. These results provide new insights into understanding the structural components of intention processing and their temporal neural dynamics underlying communicative intention comprehension from speech prosody in online social interactions.												2	3											OCT 1	2024	299								120830	10.1016/j.neuroimage.2024.120830	http://dx.doi.org/10.1016/j.neuroimage.2024.120830		SEP 2024										2026-01-16	WOS:001314109500001
J	Repp, S; Drenhaus, H				Repp, Sophie; Drenhaus, Heiner			Intonation influences processing and recall of left-dislocation sentences by indicating topic vs. focus status of dislocated referent	LANGUAGE COGNITION AND NEUROSCIENCE				Article								We tested the effects of two intonation contours on the processing and cued recall of German sentences with a left-dislocated subject vs. object: (i) a rising accent on the dislocated phrase, followed by a rising-falling hat contour on the main clause; (ii) a falling accent on the dislocated phrase, followed by a falling accent plus subsequent deaccentuation. The contours had differential effects depending on the grammatical function of the dislocated phrase (subject/object) and, for the recall, on the cue type for the recall (subject/object), in certain conditions overriding the subject-before-object preference normally found in processing. To account for the findings, we propose: (1) Contour (i) signals the topic status of the referent of the dislocated phrase. Contour (ii) signals that referent's focus status. (2) Topics are referents that serve as an address in a structured discourse representation in working memory under which information about that referent is stored. (3) Subjects are default topics, whereas objects are not, so that topic-marking an object is motivated, which results in an object-before-subject preference for sentences with topical objects during processing. (4) Retrieval of information from an address incurs a lower processing load if the appropriate address is cued than if some other referent is cued.												15	15												2015	30	3					324	346		10.1080/23273798.2014.923104	http://dx.doi.org/10.1080/23273798.2014.923104												2026-01-16	WOS:000369976200009
J	Rapoport, E				Rapoport, E			Schoenberg-Hartleben's Pierrot Lunaire: Speech - Poem - Melody - Vocal performance	JOURNAL OF NEW MUSIC RESEARCH				Article								This work presents detailed examination of the various aspects of the vocal part of Pierrot Lunaire: literary, linguistic, melodic, acoustic, and vocal performance, and their interrelations. An examination of Hartleben's German translation reveals the decisive role of characteristic linguistic features in the German language in shaping rhythms in Schoenberg's "Sprechmelodies". Vocal analysis of speech intonation contours in the spoken texts, as read aloud by two persons of German native language, brings experimental evidence and elucidates the origin of Schoenberg's "Sprechmelodies" in intonation in German speech. Intonation patterns in excerpts of Schoenberg's own speech, recorded in 1931 and 1936, also subjected to such analysis, reveal typical intonation patterns in German speech, of relevance to his "Sprechmelodies" in Pierrot Lunaire. Singing-reciting of four poems by five artists: Erika Stiedry Wagner (recorded 1941), Jan de Gaetani (rec. similar to1969), Yvonne Minton (1976), Marianne Pousseur (1992), and Christine Schaefer (1997), in Schoenberg's Pierrot Lunaire is analyzed and compared, by analysis of their Fast Fourier Transform (FFT) spectrograms. These performances, spanning almost sixty years, reflect a variety of styles and approaches to this extraordinary work. A large variety of types and (temporal) structures of vocal tones were encountered-reflecting the vocal means the artists designed (mentally) in order to capture and express the unique atmosphere of the texts, and the music, in Schoenberg's unique style of Sprechgesang. These vocal tones are decomposed into elementary units and a special notation was devised for their description and classification. This forms the basis of a detailed analysis on the microlevel of a single tone and a single syllable. Analysis of the melodic phrases of Schoenberg's "Sprechmelodien" (speech melodies) in terms of melodic segment contours by means of this notation is also described. Thus, this special notation enables a symbolic representation, or transcription, of speech intonation, singing, and "Sprechgesang" melodic contours.												6	10											MAR	2004	33	1					71	111		10.1076/jnmr.33.1.71.35393	http://dx.doi.org/10.1076/jnmr.33.1.71.35393												2026-01-16	WOS:000223718700007
J	Liu, R; Xi, JT; Jiang, ZY; Li, HZ				Liu, Rui; Xi, Jiatian; Jiang, Ziyue; Li, Haizhou			FluentEditor2: Text-Based Speech Editing by Modeling Multi-Scale Acoustic and Prosody Consistency	IEEE TRANSACTIONS ON AUDIO SPEECH AND LANGUAGE PROCESSING				Article								Text-based speech editing (TSE) allows users to edit speech by modifying the corresponding text directly without altering the original recording. Current TSE techniques often focus on minimizing discrepancies between generated speech and reference within edited regions during training to achieve fluent TSE performance. However, the generated speech in the edited region should maintain acoustic and prosodic consistency with the unedited region and the original speech at both the local and global levels. To maintain speech fluency, we propose a new fluency speech editing scheme based on our previous FluentEditor model, termed FluentEditor2, by modeling the multi-scale acoustic and prosody consistency training criterion in TSE training. Specifically, for local acoustic consistency, we propose hierarchical local acoustic smoothness constraint to align the acoustic properties of speech frames, phonemes, and words at the boundary between the generated speech in the edited region and the speech in the unedited region. For global prosody consistency, we propose contrastive global prosody consistency constraint to keep the speech in the edited region consistent with the prosody of the original utterance. Extensive experiments on the VCTK and LibriTTS datasets show that FluentEditor2 surpasses existing neural networks-based TSE methods, including Editspeech, Campnet, A3T, FluentSpeech, and our Fluenteditor, in both subjective and objective. Ablation studies further highlight the contributions of each module to the overall effectiveness of the system.												0	0												2025	33						4500	4514		10.1109/TASLPRO.2025.3624913	http://dx.doi.org/10.1109/TASLPRO.2025.3624913												2026-01-16	WOS:001608944200010
J	Font-Rotchés, D; Ruiz, MM				Font-Rotches, Dolors; Mateo Ruiz, Miguel			Intonation of absolute interrogatives in the Southern Spanish in spontaneous speech	ONOMAZEIN				Article								The principal objective of this paper is to verify whether the four patterns described by Castilian Spanish interrogatives in perception tests can be found in the speech of native speakers from the South of Spain (Andalusia, Extremadura, Murcia, Castile-La Mancha) and the Canary Islands. In addition, the study aims to discover whether there are specific melodic features in each area, and ultimately to identify the semantic-pragmatic meanings of each pattern. The research, based on 186 absolute questions issued in a context of spontaneous speech, has been carried out following the Melodic Analysis of Speech methodology. The results of the acoustic analysis allow us to a) demonstrate the existence of the four patterns in the five dialectal regions studied; b) determine that, from a linguistic intonation viewpoint, there appear to be no melodic features that distinguish each area, but a different pattern representation, and c) describe the social-pragmatic meanings proposed by Escandell (1998, 2002), allowing us to distinguish the pattern used in each context.												7	10												2013		28					256	275		10.7764/onomazein.28.17	http://dx.doi.org/10.7764/onomazein.28.17												2026-01-16	WOS:000333679500021
J	Jungheim, M; Miller, S; Kühn, D; Ptok, M				Jungheim, M.; Miller, S.; Kuehn, D.; Ptok, M.			Prosody, speech input and language acquisition	HNO				Article								Background. In order to acquire language, children require speech input. The prosody of the speech input plays an important role. In most cultures adults modify their code when communicating with children. Compared to normal speech this code differs especially with regard to prosody. Method. For this review a selective literature search in PubMed and Scopus was performed. Results. Prosodic characteristics are a key feature of spoken language. By analysing prosodic features, children gain knowledge about underlying grammatical structures. Child-directed speech (CDS) is modified in a way that meaningful sequences are highlighted acoustically so that important information can be extracted from the continuous speech flow more easily. CDS is said to enhance the representation of linguistic signs. Discussion. Taking into consideration what has previously been described in the literature regarding the perception of suprasegmentals, CDS seems to be able to support language acquisition due to the correspondence of prosodic and syntactic units. However, no findings have been reported, stating that the linguistically reduced CDS could hinder first language acquisition.												0	1											APR	2014	62	4					249	253		10.1007/s00106-013-2816-y	http://dx.doi.org/10.1007/s00106-013-2816-y												2026-01-16	WOS:000335726800003
J	Moffat, R; Baskent, D; Luke, R; McAlpine, D; Van Yper, L				Moffat, Ryssa; Baskent, Deniz; Luke, Robert; McAlpine, David; Van Yper, Lindsey			Cortical haemodynamic responses predict individual ability to recognise vocal emotions with uninformative pitch cues but do not distinguish different emotions	HUMAN BRAIN MAPPING				Article								We investigated the cortical representation of emotional prosody in normal-hearing listeners using functional near-infrared spectroscopy (fNIRS) and behavioural assessments. Consistent with previous reports, listeners relied most heavily on F0 cues when recognizing emotion cues; performance was relatively poor-and highly variable between listeners-when only intensity and speech-rate cues were available. Using fNIRS to image cortical activity to speech utterances containing natural and reduced prosodic cues, we found right superior temporal gyrus (STG) to be most sensitive to emotional prosody, but no emotion-specific cortical activations, suggesting that while fNIRS might be suited to investigating cortical mechanisms supporting speech processing it is less suited to investigating cortical haemodynamic responses to individual vocal emotions. Manipulating emotional speech to render F0 cues less informative, we found the amplitude of the haemodynamic response in right STG to be significantly correlated with listeners' abilities to recognise vocal emotions with uninformative F0 cues. Specifically, listeners more able to assign emotions to speech with degraded F0 cues showed lower haemodynamic responses to these degraded signals. This suggests a potential objective measure of behavioural sensitivity to vocal emotions that might benefit neurodiverse populations less sensitive to emotional prosody or hearing-impaired listeners, many of whom rely on listening technologies such as hearing aids and cochlear implants-neither of which restore, and often further degrade, the F0 cues essential to parsing emotional prosody conveyed in speech.												4	4											JUN 15	2023	44	9					3684	3705		10.1002/hbm.26305	http://dx.doi.org/10.1002/hbm.26305		MAY 2023										2026-01-16	WOS:000985087800001
J	Andics, A; Gábor, A; Gácsi, M; Faragó, T; Szabó, D; Miklósi, A				Andics, A.; Gabor, A.; Gacsi, M.; Farago, T.; Szabo, D.; Miklosi, A.			Neural mechanisms for lexical processing in dogs	SCIENCE				Article								During speech processing, human listeners can separately analyze lexical and intonational cues to arrive at a unified representation of communicative content. The evolution of this capacity can be best investigated by comparative studies. Using functional magnetic resonance imaging, we explored whether and how dog brains segregate and integrate lexical and intonational information. We found a left-hemisphere bias for processing meaningful words, independently of intonation; a right auditory brain region for distinguishing intonationally marked and unmarked words; and increased activity in primary reward regions only when both lexical and intonational information were consistent with praise. Neuralmechanisms to separately analyze and integrate word meaning and intonation in dogs suggest that this capacity can evolve in the absence of language.												137	150											SEP 2	2016	353	6303					1030	1032		10.1126/science.aaf3777	http://dx.doi.org/10.1126/science.aaf3777												2026-01-16	WOS:000382558900039
J	Sabat, M				Sabat, Marc			THREE TABLES FOR BOB	TEMPO				Article								To distinguish differences of harmony, to compose music so that players and listeners may sense these variations naturally, in real time, the representation of harmonic space in musical notation must be precise yet simple to read. Shadings of intonation are most clearly conceived in relation to consonant, untempered intervals. Intervals derived from a common frame of reference may be represented by microtonal signs, which suggest potentially tuneable intervallic relationships.												1	2											OCT	2016	70	278					47	63		10.1017/S0040298216000334	http://dx.doi.org/10.1017/S0040298216000334												2026-01-16	WOS:000385676300006
J	Miyagawa, S; Arévalo, A; Nóbrega, VA				Miyagawa, Shigeru; Arevalo, Analia; Nobrega, Vitor A.			On the representation of hierarchical structure: Revisiting Darwin's musical protolanguage	FRONTIERS IN HUMAN NEUROSCIENCE				Article								In this article, we address the tenability of Darwin's musical protolanguage, arguing that a more compelling evolutionary scenario is one where a prosodic protolanguage is taken to be the preliminary step to represent the hierarchy involved in linguistic structures within a linear auditory signal. We hypothesize that the establishment of a prosodic protolanguage results from an enhancement of a rhythmic system that transformed linear signals into speech prosody, which in turn can mark syntactic hierarchical relations. To develop this claim, we explore the role of prosodic cues on the parsing of syntactic structures, as well as neuroscientific evidence connecting the evolutionary development of music and linguistic capacities. Finally, we entertain the assumption that the capacity to generate hierarchical structure might have developed as part of tool-making in human prehistory, and hence was established prior to the enhancement of a prosodic protolinguistic system.												1	2											NOV 11	2022	16								1018708	10.3389/fnhum.2022.1018708	http://dx.doi.org/10.3389/fnhum.2022.1018708												2026-01-16	WOS:000889611000001
J	Arnold, JE; Watson, DG				Arnold, Jennifer E.; Watson, Duane G.			Synthesising meaning and processing approaches to prosody: performance matters	LANGUAGE COGNITION AND NEUROSCIENCE				Article								Words vary in acoustic prominence; for example, repeated words tend to be reduced, while focused elements tend to be acoustically prominent. We discuss two approaches to this phenomenon. On the message-based view, acoustic choices signal the speaker's meaning or pragmatics, or are guided by syntactic structure. On the facilitation-based view, reduced forms reflect facilitation of production-processing mechanisms. We argue that message-based constraints correlate systematically with production facilitation. Moreover, we argue that discourse effects on acoustic reduction may be at least partially mediated by processing facilitation. Thus, research needs to simultaneously consider both competence (message) and performance (processing) constraints on prosody, specifically in terms of the psychological mechanisms underlying acoustic reduction. To facilitate this goal, we present preliminary processing models of message- and facilitation-based approaches and outline directions for future research.												20	26											FEB 7	2015	30	1-2			SI		88	102		10.1080/01690965.2013.840733	http://dx.doi.org/10.1080/01690965.2013.840733												2026-01-16	WOS:000350338900006
J	CHURCH, BA; SCHACTER, DL				CHURCH, BA; SCHACTER, DL			PERCEPTUAL SPECIFICITY OF AUDITORY PRIMING - IMPLICIT MEMORY FOR VOICE INTONATION AND FUNDAMENTAL-FREQUENCY	JOURNAL OF EXPERIMENTAL PSYCHOLOGY-LEARNING MEMORY AND COGNITION				Article								Five experiments explored the effect of acoustic changes between study and test on implicit and explicit memory for spoken words. Study-test changes in the speaker's voice, intonation, and fundamental frequency produced significant impairments of auditory priming on implicit tests of auditory identification and stem completion but had little or no effect on explicit recall and recognition tests (Experiments 1-4). However, study-test changes in overall decibel level had no effect on priming on an auditory stem-completion test or on cued-recall performance (Experiment 5). The results are consistent with the idea that fundamental frequency information is represented in a perceptual representation system that plays an important role in auditory priming.												240	276											MAY	1994	20	3					521	533		10.1037/0278-7393.20.3.521	http://dx.doi.org/10.1037/0278-7393.20.3.521												2026-01-16	WOS:A1994NK48400002
J	Conwell, E				Conwell, Erin			Neural responses to category ambiguous words	NEUROPSYCHOLOGIA				Article								Category ambiguous words (like hug and swing) have the potential to complicate both learning and processing of language. However, uses of such words may be disambiguated by acoustic differences that depend on the category of use. This article uses an event-related potential (ERP) technique to ask whether adult native speakers of English show neural sensitivity to those differences. The results indicate that noun and verb tokens of ambiguous words produce differences in the arriplitude of the ERP response over left anterior sites as early as 100 ms following stimulus onset and persisting for over 400 ms. Nonsense words extracted from noun and verb contexts do not show such differences. These findings suggest that the acoustic differences between noun and verb tokens of ambiguous words are perceived and processed by adults and may be part of the lexical representation of the word. (c) 2015 Elsevier Ltd. All rights reserved.												10	10											MAR	2015	69						85	92		10.1016/j.neuropsychologia.2015.01.036	http://dx.doi.org/10.1016/j.neuropsychologia.2015.01.036												2026-01-16	WOS:000351250000010
J	Obin, N; Lanchantin, P				Obin, Nicolas; Lanchantin, Pierre			Symbolic Modeling of Prosody: From Linguistics to Statistics	IEEE-ACM TRANSACTIONS ON AUDIO SPEECH AND LANGUAGE PROCESSING				Article								The assignment of prosodic events (accent and phrasing) from the text is crucial in text-to-speech synthesis systems. This paper addresses the combination of linguistic and metric constraints for the assignment of prosodic events in text-to-speech synthesis. First, a linguistic processing chain is used to provide a rich linguistic description of a text. Then, a novel statistical representation based on a hierarchical HMM (HHMM) is used to model the prosodic structure of a text: the root layer represents the text, each intermediate layer a sequence of intermediate phrases, the pre-terminal layer the sequence of accents, and the terminal layer the sequence of linguistic contexts. For each intermediate layer, a segmental HMM and information fusion are used to fuse the linguistic and metric constraints for the segmentation of a text into phrases. A set of experiments conducted on multi-speaker databases with various speaking styles reports that: the rich linguistic representation improves drastically the assignment of prosodic events, and the fusion of linguistic and metric constraints significantly improves over standard methods for the segmentation of a text into phrases. These constitute substantial advances that can be further used to model the speech prosody of a speaker, a speaking style, and emotions for text-to-speech synthesis.												5	7											MAR	2015	23	3					588	599		10.1109/TASLP.2014.2387389	http://dx.doi.org/10.1109/TASLP.2014.2387389												2026-01-16	WOS:000350876100016
J	Ananthakrishnan, S; Narayanan, SS				Ananthakrishnan, Sankaranarayanan; Narayanan, Shrikanth S.			Automatic prosodic event detection using acoustic, lexical, and syntactic evidence	IEEE TRANSACTIONS ON AUDIO SPEECH AND LANGUAGE PROCESSING				Article								With the advent of prosody annotation standards such as tones and break indices (ToBI), speech technologists and linguists alike have been interested in automatically detecting prosodic events in speech. This is because the prosodic tier provides an additional layer of information over the short-term segment-level features and lexical representation of an utterance. As the prosody of an utterance is closely tied to its syntactic and semantic content in addition to its lexical content, knowledge of the prosodic events within and across utterances can assist spoken language applications such as automatic speech recognition and translation. On the other hand, corpora annotated with prosodic events are useful for building natural-sounding speech synthesizers. In this paper, we build an automatic detector and classifier for prosodic events in American English, based on their acoustic, lexical, and syntactic correlates. Following previous work in this area, we focus on accent (prominence, or "stress") and prosodic phrase boundary detection at the syllable level. Our experiments achieved a performance rate of 86.75% agreement on the accent detection task, and 91.61% agreement on the phrase boundary detection task on the Boston University Radio News Corpus.												80	94											JAN	2008	16	1					216	228		10.1109/TASL.2007.907570	http://dx.doi.org/10.1109/TASL.2007.907570												2026-01-16	WOS:000251947000021
J	Maltezou-Papastylianou, C; Russo, R; Wallace, D; Harmsworth, C; Paulmann, S				Maltezou-Papastylianou, Constantina; Russo, Riccardo; Wallace, Denise; Harmsworth, Chelsea; Paulmann, Silke			Different stages of emotional prosody processing in healthy ageing-evidence from behavioural responses, ERPs, tDCS, and tRNS	PLOS ONE				Article								Past research suggests that the ability to recognise the emotional intent of a speaker decreases as a function of age. Yet, few studies have looked at the underlying cause for this effect in a systematic way. This paper builds on the view that emotional prosody perception is a multi-stage process and explores which step of the recognition processing line is impaired in healthy ageing using time-sensitive event-related brain potentials (ERPs). Results suggest that early processes linked to salience detection as reflected in the P200 component and initial build-up of emotional representation as linked to a subsequent negative ERP component are largely unaffected in healthy ageing. The two groups show, however, emotional prosody recognition differences: older participants recognise emotional intentions of speakers less well than younger participants do. These findings were followed up by two neuro-stimulation studies specifically targeting the inferior frontal cortex to test if recognition improves during active stimulation relative to sham. Overall, results suggests that neither tDCS nor high-frequency tRNS stimulation at 2mA for 30 minutes facilitates emotional prosody recognition rates in healthy older adults.												9	9											JUL 21	2022	17	7							e0270934	10.1371/journal.pone.0270934	http://dx.doi.org/10.1371/journal.pone.0270934												2026-01-16	WOS:000911392100113
J	Chenausky, KV; Norton, AC; Tager-Flusberg, H; Schlaug, G				Chenausky, Karen, V; Norton, Andrea C.; Tager-Flusberg, Helen; Schlaug, Gottfried			Auditory-motor mapping training: Testing an intonation-based spoken language treatment for minimally verbal children with autism spectrum disorder	ANNALS OF THE NEW YORK ACADEMY OF SCIENCES				Article								We tested an intonation-based speech treatment for minimally verbal children with autism (auditory-motor mapping training, AMMT) against a nonintonation-based control treatment (speech repetition therapy, SRT). AMMT involves singing, rather than speaking, two-syllable words or phrases. In time with each sung syllable, therapist and child tap together on electronic drums tuned to the same pitches, thus coactivating shared auditory and motor neural representations of manual and vocal actions, and mimicking the "babbling and banging" stage of typical development. Fourteen children (three females), aged 5.0-10.8, with a mean Autism Diagnostic Observation Schedule-2 score of 22.9 (SD = 2.5) and a mean Kaufman Speech Praxis Test raw score of 12.9 (SD = 13.0) participated in this trial. The main outcome measure was percent syllables approximately correct. Four weeks post-treatment, AMMT resulted in a mean improvement of +12.1 (SE = 3.8) percentage points, compared to +2.8 (SE = 5.7) percentage points for SRT. This between-group difference was associated with a large effect size (Cohen's d = 0.82). Results suggest that simultaneous intonation and bimanual movements presented in a socially engaging milieu are effective factors in AMMT and can create an individualized, interactive music-making environment for spoken-language learning in minimally verbal children with autism.												10	11											SEP	2022	1515	1					266	275		10.1111/nyas.14817	http://dx.doi.org/10.1111/nyas.14817		JUN 2022										2026-01-16	WOS:000815663400001
J	Díaz, JAC				Calero Diaz, Jose Alejandro			Zoomorphic Speech Verbs and the Lexical Representation of the Illocutionary Force in Czech Language	ESLAVISTICA COMPLUTENSE				Article								The intention of this paper is to defend that the zoomorphic metaphors in speech verbs of czech language represent the illocutionary force through two different linguistic dimmentions. First, they extend -metaphorically- the animal characteristics to the human lexical domain, and second, these verbs represent lexically different manners of speaking, therefore their lexical meanings reflect the illocutionary force or speech intentions.												0	0												2013	13						99	115		10.5209/rev_ESLC.2013.v13.41482	http://dx.doi.org/10.5209/rev_ESLC.2013.v13.41482												2026-01-16	WOS:000215073100008
J	Meyer, M; Alter, K; Friederici, AD; Lohmann, G; von Cramon, DY				Meyer, M; Alter, K; Friederici, AD; Lohmann, G; von Cramon, DY			FMRI reveals brain regions mediating slow prosodic modulations in spoken sentences	HUMAN BRAIN MAPPING				Article								By means of fMRI measurements, the present study identifies brain regions in left and right peri-sylvian areas that subserve grammatical or prosodic processing. Normal volunteers heard 1) normal sentences; 2) so-called syntactic sentences comprising syntactic, but no lexical-semantic information; and 3) manipulated speech signals comprising only prosodic information, i.e., speech melody. For all conditions, significant blood oxygenation signals were recorded from the supratemporal plane bilaterally. Left hemisphere areas that surround Heschl gyrus responded more strongly during the two sentence conditions than to speech melody. This finding suggests that the anterior and posterior portions of the superior temporal region (STR) support lexical-semantic and syntactic aspects of sentence processing. In contrast, the right superior temporal region, in especially the planum temporale, responded more strongly to speech melody. Significant brain activation in the fronto-opercular cortices was observed when participants heard pseudo sentences and was strongest during the speech melody condition. In contrast, the fronto-opercular area is not prominently involved in listening to normal sentences. Thus, the functional activation in fronto-opercular regions increases as the grammatical information available in the sentence decreases. Generally, brain responses to speech melody were stronger in right than left hemisphere sites, suggesting a particular role of right cortical areas in the processing of slow prosodic modulations.												260	277											OCT	2002	17	2					73	88		10.1002/hbm.10042	http://dx.doi.org/10.1002/hbm.10042												2026-01-16	WOS:000178445100001
S	Tomokiyo, M; Chollet, G		Gelbukh, A		Tomokiyo, M; Chollet, G			VoiceUNL: A semantic representation of emotions within Universal Networking Language formalism based on a dialogue corpus analysis	COMPUTATIONAL LINGUISTICS AND INTELLIGENT TEXT PROCESSING	Lecture Notes in Computer Science			Article; Proceedings Paper	6th Annual Conference on Intelligent Text Processing and Computational Linguistics	FEB 13-19, 2005	Mexico City, MEXICO					The paper aims to propose a semantic representation of emotions for oral dialogues, based on an analysis of real-life conversations, telephone messages and recorded TV programmes, for the purposes of a speech to speech machine translation. Lexicon and phatics are one of important emotion eliciting factors as well as gestures, prosody and voice tone in oral dialogues. So, the semantic representation is made in a way where these factors are taken into account at the same time. Also, it's done within Universal Networking Language (UNL) formalism, where UW (universal word) plays an important role.												0	0												2005	3406						441	451															2026-01-16	WOS:000228725100049
J	Koester, D; Gunter, TC; Wagner, S; Friederici, AD				Koester, D; Gunter, TC; Wagner, S; Friederici, AD			Morphosyntax, prosody, and linking elements: The auditory processing of German nominal compounds	JOURNAL OF COGNITIVE NEUROSCIENCE				Article								The morphosyntactic decomposition of German compound words and a proposed function of linking elements were examined during auditory processing using event-related brain potentials. In Experiment 1, the syntactic gender agreement was manipulated between a determiner and the initial compound constituent ( the "nonhead'' constituent), and between a determiner and the last constituent ("head''). Although only the head is (morpho) syntactically relevant in German, both constituents elicited a left-anterior negativity if its gender was incongruent. This strongly suggests that compounds are morphosyntactically decomposed. Experiment 2 tested the function of those linking elements which are homophonous to plural morphemes. It has been previously suggested that these indicate the number of nonhead constituents. The number agreement was manipulated for both constituents analogous to Experiment 1. Number-incongruent heads, but not nonhead constituents, elicited an N400 and a subsequent broad negativity, suggesting that linking elements are not processed as plural morphemes. Experiment 3 showed that prosodic cues ( duration and fundamental frequency) are employed to differentiate between compounds and single nouns and, thereby, betwen linking elements and plural morphemes. Number-incongruent words elicited a broad negativity if they were produced with a single noun prosody; the same words elicited no event-related potential effect if produced with a compound prosody. A dual-route model can account for the influence of prosody on morphosyntactic processing.												65	73											NOV	2004	16	9					1647	1668		10.1162/0898929042568541	http://dx.doi.org/10.1162/0898929042568541												2026-01-16	WOS:000225712000017
J	Bozkurt, E; Yemez, Y; Erzin, E				Bozkurt, Elif; Yemez, Yucel; Erzin, Engin			Multimodal analysis of speech and arm motion for prosody-driven synthesis of beat gestures	SPEECH COMMUNICATION				Article								We propose a framework for joint analysis of speech prosody and arm motion towards automatic synthesis and realistic animation of beat gestures from speech prosody and rhythm. In the analysis stage, we first segment motion capture data and speech audio into gesture phrases and prosodic units via temporal clustering, and assign a class label to each resulting gesture phrase and prosodic unit. We then train a discrete hidden semi-Markov model (HSMM) over the segmented data, where gesture labels are hidden states with duration statistics and frame-level prosody labels are observations. The HSMM structure allows us to effectively map sequences of shorter duration prosodic units to longer duration gesture phrases. In the analysis stage, we also construct a gesture pool consisting of gesture phrases segmented from the available dataset, where each gesture phrase is associated with a class label and speech rhythm representation. In the synthesis stage, we use a modified Viterbi algorithm with a duration model, that decodes the optimal gesture label sequence with duration information over the HSMM, given a sequence of prosody labels. In the animation stage, the synthesized gesture label sequence with duration and speech rhythm information is mapped into a motion sequence by using a multiple objective unit selection algorithm. Our framework is tested using two multimodal datasets in speaker-dependent and independent settings. The resulting motion sequence when accompanied with the speech input yields natural-looking and plausible animations. We use objective evaluations to set parameters of the proposed prosody-driven gesture animation system, and subjective evaluations to assess quality of the resulting animations. The conducted subjective evaluations show that the difference between the proposed HSMM based synthesis and the motion capture synthesis is not statistically significant. Furthermore, the proposed HSMM based synthesis is evaluated significantly better than a baseline synthesis which animates random gestures based on only joint angle continuity. (C) 2016 Elsevier B.V. All rights reserved.												20	23											DEC	2016	85						29	42		10.1016/j.specom.2016.10.004	http://dx.doi.org/10.1016/j.specom.2016.10.004												2026-01-16	WOS:000390507000004
J	Peng, HY; Ma, YK; Poria, S; Li, Y; Cambria, E				Peng, Haiyun; Ma, Yukun; Poria, Soujanya; Li, Yang; Cambria, Erik			Phonetic-enriched text representation for Chinese sentiment analysis with reinforcement learning	INFORMATION FUSION				Article								The Chinese pronunciation system offers two characteristics that distinguish it from other languages: deep phonemic orthography and intonation variations. In this paper, we hypothesize that these two important properties can play a major role in Chinese sentiment analysis. In particular, we propose two effective features to encode phonetic information and, hence, fuse it with textual information. With this hypothesis, we propose Disambiguate Intonation for Sentiment Analysis (DISA), a network that we develop based on the principles of reinforcement learning. DISA disambiguates intonations for each Chinese character (pinyin) and, hence, learns precise phonetic representations. We also fuse phonetic features with textual and visual features to further improve performance. Experimental results on five different Chinese sentiment analysis datasets show that the inclusion of phonetic features significantly and consistently improves the performance of textual and visual representations and surpasses the state-of-the-art Chinese character-level representations.												39	43											JUN	2021	70						88	99		10.1016/j.inffus.2021.01.005	http://dx.doi.org/10.1016/j.inffus.2021.01.005		JAN 2021										2026-01-16	WOS:000620739900007
J	Bernard, C; Gervain, J				Bernard, Carline; Gervain, Judit			Prosodic cues to word order: what level of representation?	FRONTIERS IN PSYCHOLOGY				Article								Within language, systematic correlations exist between syntactic structure and prosody. Prosodic prominence, for instance, falls on the complement and not the head of syntactic phrases, and its realization depends on the phrasal position of the prominent element. Thus, in Japanese, a functor-final language, prominence is phrase-initial, and realized as increased pitch (boolean AND Tokyo ni "Tokyo to"), whereas in French, English, or Italian, functor-initial languages, it manifests itself as phrase-final lengthening (to Rome). Prosody is readily available in the linguistic signal even to the youngest infants. It has, therefore, been proposed that young learners might be able to exploit its correlations with syntax to bootstrap language structure. In this study, we tested this hypothesis, investigating how 8-month-old monolingual French infants processed an artificial grammar manipulating the relative position of prosodic prominence and word frequency. In Condition 1, we created a speech stream in which the two cues, prosody and frequency, were aligned, frequent words being prosodically non-prominent and infrequent ones being prominent, as is the case in natural language (functors are prosodically minimal compared to content words). In Condition 2, the two cues were misaligned, with frequent words carrying prosodic prominence, unlike in natural language. After familiarization with the aligned or the misaligned stream in a headturn preference procedure, we tested infants' preference for test items having a frequent word initial or a frequent word final word order. We found that infants' familiarized with the aligned stream showed the expected preference for the frequent word initial test items, mimicking the functor-initial word order of French. Infants in the misaligned condition showed no preference. These results suggest that infants are able to use word frequency and prosody as early cues to word order and they integrate them into a coherent representation.												38	42												2012	3								451	10.3389/fpsyg.2012.00451	http://dx.doi.org/10.3389/fpsyg.2012.00451												2026-01-16	WOS:000208864000163
J	Zhang, C				Zhang, Cen			China's image in the Spanish press during the COVID-19 pandemic	CIRCULO DE LINGUISTICA APLICADA A LA COMUNICACION				Article								This study analyzes the representation of China in the Spanish press during the COVID-19 pandemic, utilizing an analytical framework comprised of appraisal theory, transitivity system, and corpus linguistics. Our research is based on a specialized corpus consisting of 271 articles extracted from the Spanish newspapers El Pais, El Mundo, La Vanguardia, and ABC. Various analytical techniques, including keywords, collocations, and concordances, are applied to identify patterns and trends in the representation of China. The findings reveal that the Spanish newspapers have conveyed a multifaceted portrayal of China, employing various linguistic resources, both explicit and implicit, to express their attitudinal stance. The evaluative prosody towards China is variable, with instances of both positive and negative assessments. On one hand, the effectiveness of the anti-COVID measures implemented by China and the country's capacity in managing the crisis are positively appraised. On the other hand, the Chinese healthcare system is criticized, certain measures are deemed draconian, and an image of ambitious and arrogant China is constructed occasionally. This study provides significant insights into how the Spanish media represents China during the COVID-19 pandemic and contributes to an enhanced understanding of the importance and feasibility of studying images from a discursive approach.												0	0												2024		100					127	144		10.5209/clac.79617	http://dx.doi.org/10.5209/clac.79617												2026-01-16	WOS:001360298500010
S	Magne, C; Schön, D; Besson, M		Avanzini, G; Faienza, C; Minciacchi, D; Lopez, L; Majno, M		Magne, C; Schön, D; Besson, M			Prosodic and melodic processing in adults and children -: Behavioral and electrophysiologic approaches	NEUROSCIENCES AND MUSIC	ANNALS OF THE NEW YORK ACADEMY OF SCIENCES			Article; Proceedings Paper	Conference on Neurosciences and Music: Mutual Internactions and Implications on Developmental Functions	OCT 25-27, 2002	VENICE, ITALY					The results of a series of experiments aimed at directly comparing the prosodic level of processing in language with the melodic level of processing in music are reported. The first series of experiments was conducted on adults, musicians and nonmusicians, and the second one on 7- to 9-year-old musician and nonmusician children. However, as this last study is still in progress, only preliminary results will be presented. The theoretic framework within which these experiments are taking place is described. The first problem concerns the specificity of the perceptive and cognitive computations necessary to perceive and understand language. We argue that comparing language with music can provide interesting insights into this complex issue. The second problem is linked to the relationship between different types of learning. Does early musical training influence the way in which musicians process some aspects of language as prosody? These two problems are considered and the results of the experiments are described.												16	21												2003	999						461	476		10.1196/annals.1284.056	http://dx.doi.org/10.1196/annals.1284.056												2026-01-16	WOS:000188893400059
J	Robinson, D				Robinson, D			Coleridge, Mary Robinson, and the prosody of dreams	DREAMING				Article								Samuel Taylor Coleridge and Mary Robinson are two poets of the Romantic period whose poetry is ostensibly concerned with the experience of dreaming and the representation of dreams in verse. Both poets knew and admired the other, perhaps because of their shared experiences with opium and dreams. They both find the poem in his or her dreams but then fit the dream in poetic form. The metrical experiments of both poets in their dream poems are conscious acts of representing in verse the experience of dreaming. This is accomplished not merely through figurative poetic language but also through what I will call the prosody of dreams-the theory and principles of versification as they pertain to dream poetry. The prosody of dreams, then refers specifically to the way these two Romantic poets use metrical effects to represent a dream world, suggesting that, for them at least, dreams can be understood through the self-conscious approximation of the dream experience in verse. Robinson and Coleridge use poetic form and metrical experimentation to explore in verse the unfathomed depths of the unconscious mind and the creative potentialities of dreaming. Their poetry suggests that each had an intimate familiarity with the work of the other, but their strikingly similar approaches to the prosody of dreams remains a compelling intersection that has yet to be discussed. A closer look at the poetic forms of dreams created by these two pioneering dream poets, in addition to illuminating some pertinent poems by Mary Robinson, will substantially inform our understanding of Coleridge and the way he understood his dreams and of the poetic practice of representing dreams in verse.												1	3											JUN	1997	7	2					119	140		10.1037/h0094469	http://dx.doi.org/10.1037/h0094469												2026-01-16	WOS:A1997XE00500003
J	Guinda, CS				Sancho Guinda, Carmen			THE EMOTIONAL PROSODY OF U.S. FATAL AIR-ACCIDENT DOCKETS ONLINE: RISKING RISK COMMUNICATION?	VESTNIK ROSSIISKOGO UNIVERSITETA DRUZHBY NARODOV-SERIYA LINGVISTIKA-RUSSIAN JOURNAL OF LINGUISTICS				Article								Risk communication is grounded in both rationality and emotion (Fischhoff & Kadvany 2011, Boholm & Corvellec 2014). Recent investigations have proved that emotions do affect risk and danger perceptions by functioning as 'mediators' (Xie et al. 2011) and become important in decision-making. My study explores how emotion is induced by the National Transportation Safety Board of the United States of America (NTSB for short) to influence the mentalities and behaviours of its broad mixed audience and thus increase risk prevention. With that research purpose in mind, I examine an electronic corpus of over 500 online samples of fatal aviation dockets issued yearly online by the NTSB between the time span 20102015 and contained in its website databases. The emotional engagement deployed to mediate the perceptions of risk and danger by the general public constitutes a unique genre among all other world transportation agencies, since through informative vividness it pursues to activate the processes of memory, inference (i.e. judgement) and decision-making. I take Stubbs' (2001) concept of 'discursive prosody' as point of departure and resort to a blended theoretical framework that combines Narratology, Corpus Linguistics, Critical Discourse Analysis, and Proximisation (Cap 2013) and Positioning (Harre & van Langenhove 1999) Theories. I will show that the NTSB's emotional prosody is more rhetorical than lexical and that the narrative strategies of focalisation and speech representation play a salient role. To conclude I will reflect on some of the possible consequences of over-exploiting emotional engagement in risk communication.												3	3												2018	22	1					126	143		10.22363/2312-9182-2018-22-1-126-143	http://dx.doi.org/10.22363/2312-9182-2018-22-1-126-143												2026-01-16	WOS:000428112900007
J	Cubarsi, R				Cubarsi, Rafael			Extended Expressive Intonation: An Application of the Convergents and Semiconvergents in Pythagorean Tuning	AXIOMS				Article								Cyclic scales are associated with convergents and semiconvergents of the continued fraction expansions of the generator tone. After each convergent, a scale lineage ends and another begins. Along a lineage, a constant number of generic accidentals are successively added to its first scale, becoming regularly interspersed. In this way, it is easier to know where each note is to go. This process, applied to the lineage of the 7-, 12-, and 17-tone scales, is related to expressive intonation. Such a concept is extended to larger scales with added microtones and it is described how they can be chosen in terms of the starting index of the scale. An automorphism in terms of the step and co-step indices associated with the two elementary intervals provides a two-dimensional representation that shares some common features with the musical staff.												0	0											SEP 19	2025	14	9							707	10.3390/axioms14090707	http://dx.doi.org/10.3390/axioms14090707												2026-01-16	WOS:001579370700001
J	Tokimoto, S; d'Arcais, GBF				Tokimoto, S; d'Arcais, GBF			Segmentation and selection of appropriate Chinese characters in writing place names in Japanese	JOURNAL OF PSYCHOLINGUISTIC RESEARCH				Article								This paper explores the relation between an unknown place name written in hiragana (a Japanese syllabary) and its corresponding written representation in kanji (Chinese characters). We propose three principles as those operating in the selection of the appropriate Chinese characters in writing unknown place names. The three principles are concerned with the combination of on and kun readings (zyuubako-yomi), the number of segmentations. and the bimoraicity characteristics of kanji chosen. We performed two experiments to test the principles: the results supported our hypotheses. These results have some implications for the structure of the Japanese mental lexicon, for the processing load in the use of Chinese characters, and for Japanese prosody and morphology.												0	0											MAR	2001	30	2					135	145		10.1023/A:1010373727869	http://dx.doi.org/10.1023/A:1010373727869												2026-01-16	WOS:000168772000002
J	Bedoya, D; Fyfe, L; Chew, E				Bedoya, Daniel; Fyfe, Lawrence; Chew, Elaine			A Perceiver-Centered Approach for Representing and Annotating Prosodic Functions in Performed Music	FRONTIERS IN PSYCHOLOGY				Article								Musical prosody is characterized by the acoustic variations that make music expressive. However, few systematic and scalable studies exist on the function it serves or on effective tools to carry out such studies. To address this gap, we introduce a novel approach to capturing information about prosodic functions through a citizen science paradigm. In typical bottom-up approaches to studying musical prosody, acoustic properties in performed music and basic musical structures such as accents and phrases are mapped to prosodic functions, namely segmentation and prominence. In contrast, our top-down, human-centered method puts listener annotations of musical prosodic functions first, to analyze the connection between these functions, the underlying musical structures, and acoustic properties. The method is applied primarily to the exploring of segmentation and prominence in performed solo piano music. These prosodic functions are marked by means of four annotation types-boundaries, regions, note groups, and comments-in the CosmoNote web-based citizen science platform, which presents the music signal or MIDI data and related acoustic features in information layers that can be toggled on and off. Various annotation strategies are discussed and appraised: intuitive vs. analytical; real-time vs. retrospective; and, audio-based vs. visual. The end-to-end process of the data collection is described, from the providing of prosodic examples to the structuring and formatting of the annotation data for analysis, to techniques for preventing precision errors. The aim is to obtain reliable and coherent annotations that can be applied to theoretical and data-driven models of musical prosody. The outcomes include a growing library of prosodic examples with the goal of achieving an annotation convention for studying musical prosody in performed music.												1	1											JUL 21	2022	13								886570	10.3389/fpsyg.2022.886570	http://dx.doi.org/10.3389/fpsyg.2022.886570												2026-01-16	WOS:000837366900001
J	Sridhar, VKR; Bangalore, S; Narayanan, S				Sridhar, Vivek Kumar Rangarajan; Bangalore, Srinivas; Narayanan, Shrikanth			Combining lexical, syntactic and prosodic cues for improved online dialog act tagging	COMPUTER SPEECH AND LANGUAGE				Article								Prosody is ail important cue for identifying dialog acts. in this paper, we show that modeling the sequence of acoustic-prosodic values as n-gram features with a maximum entropy model for dialog act (DA) tagging can perform better than conventional approaches that use coarse representation of the prosodic contour through summative statistics of the prosodic contour. The proposed scheme for exploiting prosody results in,in absolute improvement of 8.7% over the use of most other widely used representations of acoustic correlates of prosody. the proposed scheme is discriminative and exploits context in the form of lexical, syntactic and prosodic cues from preceding discourse segments. Such a decoding scheme facilitates online DA tagging and offers robustness in the decoding process, unlike greedy decoding schemes that can potentially propagate errors. Our approach is different front traditional DA systems that use the entire conversation for offline dialog act decoding with the aid of a discourse model. In contrast, we use only static features and approximate the previous dialog act tags in terms of lexical, syntactic and prosodic information extracted from previous utterances. Experiments oil the Switchboard-DAMSL corpus, using only lexical, syntactic and prosodic cues from three previous utterances, yield a DA tagging accuracy of 72% compared to the best case scenario with accurate knowledge of previous DA tags (oracle), which results in 74% accuracy. (C) 2009 Elsevier Ltd. All rights reserved.												26	34											OCT	2009	23	4					407	422		10.1016/j.csl.2008.12.001	http://dx.doi.org/10.1016/j.csl.2008.12.001												2026-01-16	WOS:000266536400001
J	Zhao, XM; Zhang, SQ				Zhao, Xiaoming; Zhang, Shiqing			Spoken emotion recognition via locality-constrained kernel sparse representation	NEURAL COMPUTING & APPLICATIONS				Article								Spoken emotion recognition is currently a very active research topic and has attracted extensive attention in signal processing, pattern recognition, artificial intelligence, etc. In this paper, a new emotion classification method based on kernel sparse representation, named locality-constrained kernel sparse representation-based classification (LC-KSRC), is proposed for spoken emotion recognition. LC-KSRC is able to learn more discriminating sparse representation coefficients for spoken emotion recognition, since it integrates both sparsity and data locality in the kernel feature space. The proposed method is compared with six representative emotion classification methods, including linear discriminant classifier, K-nearest-neighbor, radial basis function neural networks, support vector machines, sparse representation-based classification and kernel sparse representation-based classification. Experimental results on two publicly available emotional speech databases, i.e., the Berlin database and the Polish database, demonstrate the promising performance of the proposed method on spoken emotion recognition tasks, outperforming the other used methods.												9	10											APR	2015	26	3			SI		735	744		10.1007/s00521-014-1755-1	http://dx.doi.org/10.1007/s00521-014-1755-1												2026-01-16	WOS:000351364300023
J	Crasborn, O; Van der Kooij, E				Crasborn, Onno; Van der Kooij, Els			The phonology of focus in Sign Language of the Netherlands	JOURNAL OF LINGUISTICS				Article								Signed languages are similar to spoken languages in the overall organisation of their grammars, displaying a prosodic level of organisation that is not isomorphic to the syntactic organisation. Their rich inventory of manual and non-manual features allows for a prolific range of functions if used prosodically. New data from Sign Language of the Netherlands (NGT, Nederlandse Gebarentaal) are discussed to demonstrate that focused constituents are not marked by a single prosodic feature, but rather by multiple properties that can also have other functions in the prosodic phonology of the language. These findings are integrated in an overall model of sign language prosody that emphasises the distinction between phonetic appearance and phonological representation and that allows for the interaction of linguistic and paralinguistic cues in visual communication.												28	32											NOV	2013	49	3					515	565		10.1017/S0022226713000054	http://dx.doi.org/10.1017/S0022226713000054												2026-01-16	WOS:000325851300001
J	Féry, C; Truckenbrodt, H				Féry, C; Truckenbrodt, H			Sisterhood and tonal scaling	STUDIA LINGUISTICA				Article								This paper discusses central aspects of the effects of hierarchical structure on tonal scaling in intonation. The core results of a number of phonetic studies on this topic, by Ladd, by van den Berg, Gussenhoven and Rietveld, as well as experimental results of our own, are reviewed. We review the suggestions of this earlier work and argue for an addition to the theory. The principle 'The deeper the steeper' says that downstep among sister nodes is relatively larger if these sister-nodes are relatively more deeply embedded in the prosodic representation.												32	37											AUG-DEC	2005	59	2-3					223	243		10.1111/j.1467-9582.2005.00127.x	http://dx.doi.org/10.1111/j.1467-9582.2005.00127.x												2026-01-16	WOS:000232880300006
S	Schlaug, G; Marchina, S; Norton, A		DallaBella, S; Kraus, N; Overy, K; Pantev, C; Snyder, JS; Tervaniemi, M; Tillmann, B; Schlaug, G		Schlaug, Gottfried; Marchina, Sarah; Norton, Andrea			Evidence for Plasticity in White-Matter Tracts of Patients with Chronic Broca's Aphasia Undergoing Intense Intonation-based Speech Therapy	NEUROSCIENCES AND MUSIC III: DISORDERS AND PLASTICITY	Annals of the New York Academy of Sciences			Article; Proceedings Paper	Conference on the Neurosciences and Music III	JUN 25-28, 2008	McGill Univ, Montreal, CANADA		McGill Univ			Recovery from aphasia can be achieved through recruitment of either perilesional brain regions in the affected hemisphere or homologous language regions in the nonlesional hemisphere. For patients with large left-hemisphere lesions, recovery through the right hemisphere may be the only possible path. The right-hemisphere regions most likely to play a role in this recovery process are the superior temporal lobe (important for auditory feedback control), premotor regions/posterior inferior frontal gyrus (important for planning and sequencing of motor actions and for auditory-motor mapping), and the primary motor cortex (important for execution of vocal motor actions). These regions are connected reciprocally via a major fiber tract called the arcuate fasciculus (AF), however, this tract is not as well developed in the right hemisphere as it is in the dominant left. We tested whether an intonation-based speech therapy (i.e., melodic intonation therapy [MIT]), which is typically administered in an intense fashion with 75-80 daily therapy sessions, would lead to changes in white-matter tracts, particularly the AF Using diffusion tensor imaging (DTI), we found a significant increase in the number of AF fibers and AF volume comparing post- with pretreatment assessments in six patients that could not be attributed to scan-to-scan variability. This suggests that intense, long-term MIT leads to remodeling of the right AF and may provide an explanation for the sustained therapy effects that were seen in these six patients.												315	392												2009	1169						385	394		10.1111/j.1749-6632.2009.04587.x	http://dx.doi.org/10.1111/j.1749-6632.2009.04587.x												2026-01-16	WOS:000269652300059
J	Conwell, E; Barta, K				Conwell, Erin; Barta, Kellam			Phrase Position, but not Lexical Status, Affects the Prosody of Noun/Verb Homophones	FRONTIERS IN PSYCHOLOGY				Article								Words that can occur in more than one lexical category produce regions of ambiguity that could confound language learning and processing. However, previous findings suggest that pronunciation of noun/verb homophones may, in fact, differ as a function of category of use, potentially mitigating that ambiguity. Whether these differences are part of the lexical representation of such words or mere by-products of sentence-level prosodic processes remains an open question, the answer to which is critical to resolving questions about the structure of the lexicon. In three studies, adult native speakers of English read aloud passages containing noun/verb homophones or nonce words used in both noun and verb contexts. Acoustic measurements of the target words indicated that, while sentence position influences the acoustic properties of noun/verb homophones, including duration and pitch, there are not significant effects of lexical category when other factors are controlled. Furthermore, the lexical status of a word (real or nonce) does not produce consistent prosodic effects. These findings suggest that previously reported prosodic differences in noun/verb homophones may result from the syntactic positions in which those categories tend to occur.												0	0											SEP 25	2018	9								1785	10.3389/fpsyg.2018.01785	http://dx.doi.org/10.3389/fpsyg.2018.01785												2026-01-16	WOS:000445588700001
J	Plante, E; Creusere, M; Sabin, C				Plante, E; Creusere, M; Sabin, C			Dissociating sentential prosody from sentence processing: Activation interacts with task demands	NEUROIMAGE				Article								Sentence processing was contrasted with processing of syntactic prosody under two task conditions in order to examine the representation of these components of language and their interaction with working memory load. Twelve adults received fMRI scans while they listened to low-pass filtered and unfiltered sentences either passively, or during tasks that required subjects to remember and recognize information contained in the stimuli. Results indicated that temporal activation for prosodic stimuli differed compared to activation for sentence stimuli only during passive listening tasks. The inclusion of memory demands was associated with frontal activation, which was differentially lateralized for sentence and prosodic stimuli. The results demonstrate differential brain activation for prosodic vs sentential stimuli which interacts with the memory demands placed on the subjects. (C) 2002 Elsevier Science (USA).												57	62											SEP	2002	17	1					401	410		10.1006/nimg.2002.1182	http://dx.doi.org/10.1006/nimg.2002.1182												2026-01-16	WOS:000178102000030
J	Garrido-Vásquez, P; Pell, MD; Paulmann, S; Kotz, SA				Garrido-Vasquez, Patricia; Pell, Marc D.; Paulmann, Silke; Kotz, Sonja A.			Dynamic Facial Expressions Prime the Processing of Emotional Prosody	FRONTIERS IN HUMAN NEUROSCIENCE				Article								Evidence suggests that emotion is represented supramodally in the human brain. Emotional facial expressions, which often precede vocally expressed emotion in real life, can modulate event-related potentials (N100 and P200) during emotional prosody processing. To investigate these cross-modal emotional interactions, two lines of research have been put forward: cross-modal integration and cross-modal priming. In cross-modal integration studies, visual and auditory channels are temporally aligned, while in priming studies they are presented consecutively. Here we used cross-modal emotional priming to study the interaction of dynamic visual and auditory emotional information. Specifically, we presented dynamic facial expressions (angry, happy, neutral) as primes and emotionally-intoned pseudo-speech sentences (angry, happy) as targets. We were interested in how prime-target congruency would affect early auditory event-related potentials, i.e., N100 and P200, in order to shed more light on how dynamic facial information is used in cross-modal emotional prediction. Results showed enhanced N100 amplitudes for incongruently primed compared to congruently and neutrally primed emotional prosody, while the latter two conditions did not significantly differ. However, N100 peak latency was significantly delayed in the neutral condition compared to the other two conditions. Source reconstruction revealed that the right parahippocampal gyrus was activated in incongruent compared to congruent trials in the N100 time window. No significant ERP effects were observed in the P200 range. Our results indicate that dynamic facial expressions influence vocal emotion processing at an early point in time, and that an emotional mismatch between a facial expression and its ensuing vocal emotional signal induces additional processing costs in the brain, potentially because the cross-modal emotional prediction mechanism is violated in case of emotional prime-target incongruency.												23	27											JUN 12	2018	12								244	10.3389/fnhum.2018.00244	http://dx.doi.org/10.3389/fnhum.2018.00244												2026-01-16	WOS:000434993500001
J	FRANKISH, C				FRANKISH, C			INTONATION AND AUDITORY GROUPING IN IMMEDIATE SERIAL-RECALL	APPLIED COGNITIVE PSYCHOLOGY				Article								The concept of auditory buffer storage is supported by evidence from studies of dichotic memory and serial recall tasks. Previously reported studies of modality-specific grouping effects can also be accommodated within this theoretical framework, with the effects of stimulus grouping attributed to more effective utilization of the buffer. In this study, the representation of structured sequences in the auditory buffer was further explored in five experiments which investigated the extent to which this system can make use of prosodic cues. Experiment 1 demonstrated that the variations in pitch which constitute the intonation pattern of a natural utterance are extremely effective in enhancing memory performance. Experiment 2 demonstrated that the presence of a strong melodic contour is not a sufficient condition for improvement in recall, even when the melodic structure is both familiar and well-formed. The results of Experiments 3 and 4 suggested that improvements in recall are most likely to occur when abrupt changes in pitch at group boundaries are the most prominent features of the pitch contour. In Experiment 5 the natural pitch contour was simplified to produce a pattern in which the final item in each group was spoken with accented pitch. This structure was found to be as effective as grouping by pauses. These findings are related to perceptual studies of intonation, and implications for theoretical accounts of auditory memory are discussed.												43	48												1995	9				SI		S5	S22		10.1002/acp.2350090703	http://dx.doi.org/10.1002/acp.2350090703												2026-01-16	WOS:A1995QX53400002
J	Kojiri, T; Kaji, T				Kojiri, Tomoko; Kaji, Takaya			Effective Presentation Speech Support System for Representing Emphasis-Intention	SYSTEMS				Article								A research presentation integrates slides and speech. If these two aspects do not represent the same intention, the presentation will probably fail to effectively explain the presenter's intention. This paper focuses on the representation of the critical contents in a presentation. In an effective speech, the speaker adds more intonation and stress to emphasize the importance of the slide contents. Audiences recognize that important contents are those that are explained in a stronger voice or that are said after a short pause. However, in ineffective speeches, such voice effects do not always correspond to the important contents that are indicated by slides. On slides, the important contents are represented by levels of text indentation and size, color, and animation. This research develops a presentation speech support system that estimates important contents from slides and voices that might be recognized by audiences and extracts numerical differences. In addition, the system provides comments and feedback to improve speeches.												0	0											MAR	2016	4	1							1	10.3390/systems4010001	http://dx.doi.org/10.3390/systems4010001												2026-01-16	WOS:000373690200001
J	Patel, SP; Winston, M; Guilfoyle, J; Nicol, T; Martin, GE; Nayar, K; Kraus, N; Losh, M				Patel, Shivani P.; Winston, Molly; Guilfoyle, Janna; Nicol, Trent; Martin, Gary E.; Nayar, Kritika; Kraus, Nina; Losh, Molly			Neural Processing of Speech Sounds in ASD and First-Degree Relatives	JOURNAL OF AUTISM AND DEVELOPMENTAL DISORDERS				Article								Efficient neural encoding of sound plays a critical role in speech and language, and when impaired, may have reverberating effects on communication skills. This study investigated disruptions to neural processing of temporal and spectral properties of speech in individuals with ASD and their parents and found evidence of inefficient temporal encoding of speech sounds in both groups. The ASD group further demonstrated less robust neural representation of spectral properties of speech sounds. Associations between neural processing of speech sounds and language-related abilities were evident in both groups. Parent-child associations were also detected in neural pitch processing. Together, results suggest that atypical neural processing of speech sounds is a heritable ingredient contributing to the ASD language phenotype.												4	5											AUG	2023	53	8					3257	3271		10.1007/s10803-022-05562-7	http://dx.doi.org/10.1007/s10803-022-05562-7		JUN 2022										2026-01-16	WOS:000807363700001
J	Esipova, M				Esipova, Maria			Polar responses in Russian across modalities and across interfaces	JOURNAL OF SLAVIC LINGUISTICS				Article								This paper investigates gestures and prosody in polar responses in Russian as part of a larger research program of studying meaning as it is expressed through various channels and constrained at various levels of representation and their interfaces. Based on the data on head nods and a gestural-intonational duster used to question the rationale behind the antecedent speech act in Russian responses, it argues that gestures and intonational contours should be treated on a par with spoken words and their parts when it comes to fitting them into typologies of meaning-encoding expressions in spoken language. It also shows, based on the data on linear placement of gestural and spoken polarity markers in Russian as well as prosodic grouping in Russian (and English) polar responses, that studying gestural content and prosodic properties of utterances can help us reveal various interface constraints in natural language.												2	3												2021	29				SI				923057	10.1353/jsl.2021.a923057	http://dx.doi.org/10.1353/jsl.2021.a923057												2026-01-16	WOS:001280138900010
J	Hsu, B				Hsu, Brian			Exceptional prosodification effects revisited in Gradient Harmonic Grammar	PHONOLOGY				Article								This paper presents an analysis of exceptional prosodification effects, in which exceptional lexical items appear to follow a regular pattern that is found in a different prosodic context. These patterns have been analysed as cases of prosodic prespecification, where morphemes select a non-default prosodic representation. I argue that prespecification approaches should be reconsidered, and that such patterns are predicted without morpheme-specific prosody in Gradient Harmonic Grammar, a weighted constraint system with gradiently active symbols. Exceptional prosodification effects result from the interaction of two influences on constraint penalties: (i) scaling of constraint violations by prosodic context and (ii) contrastive activity values in underlying forms. This interaction is illustrated with the distribution of French nasal vowels and linking [n]. This approach reduces the amount of structure posited for URs, and provides new arguments for a more uniform syntax-prosody mapping.												6	6											MAY	2019	36	2					225	263		10.1017/S0952675719000125	http://dx.doi.org/10.1017/S0952675719000125												2026-01-16	WOS:000474880200002
J	Zhao, XM; Zhang, SQ; Lei, BC				Zhao, Xiaoming; Zhang, Shiqing; Lei, Bicheng			Robust emotion recognition in noisy speech via sparse representation	NEURAL COMPUTING & APPLICATIONS				Article								Emotion recognition in speech signals is currently a very active research topic and has attracted much attention within the engineering application area. This paper presents a new approach of robust emotion recognition in speech signals in noisy environment. By using a weighted sparse representation model based on the maximum likelihood estimation, an enhanced sparse representation classifier is proposed for robust emotion recognition in noisy speech. The effectiveness and robustness of the proposed method is investigated on clean and noisy emotional speech. The proposed method is compared with six typical classifiers, including linear discriminant classifier, K-nearest neighbor, C4.5 decision tree, radial basis function neural networks, support vector machines as well as sparse representation classifier. Experimental results on two publicly available emotional speech databases, that is, the Berlin database and the Polish database, demonstrate the promising performance of the proposed method on the task of robust emotion recognition in noisy speech, outperforming the other used methods.												31	37											JUN	2014	24	7-8					1539	1553		10.1007/s00521-013-1377-z	http://dx.doi.org/10.1007/s00521-013-1377-z												2026-01-16	WOS:000336371900007
J	Song, JN				Song, Jiannan			Representing state identity with journalistic attitudes: a corpus-assisted linguistic analysis of CGTN's trade dispute coverage	CIRCULO DE LINGUISTICA APLICADA A LA COMUNICACION				Article								This research explores the relationship between journalistic attitudes and the state identity of China Global Television Network (CGTN). It undertakes a corpus-assisted study of the linguistic representation of Affect, Judgment, and Appreciation in the trade dispute coverage of CGTN and the US media outlets at two levels: (1) prosody and social actors; (2) the preference for appraisal relations. It shows that CGTN manifests its state identity in attitudinal officialization and harmonization. Highlighting collectiveness in the choice of news agendas, actors, and prosody, CGTN prioritizes the appraiser's role of the group mind when expressing journalistic attitudes and is more inclined to draw on Judgment to stress the moral basis. A survey of journalistic attitudes in CGTN's trade dispute coverage enables us to elaborate on how the Chinese state media constructs its identity in news discourse.												0	0												2024		100					181	191		10.5209/clac.84450	http://dx.doi.org/10.5209/clac.84450												2026-01-16	WOS:001360298500014
J	Deniz, ND				Deniz, Nazik Dinctopal			Prosodic Disambiguation of Morphological Ambiguities in Turkish	JOURNAL OF PSYCHOLINGUISTIC RESEARCH				Article								This study investigates the production and processing of lexical prosody in morphological ambiguities in Turkish. Native speakers of Turkish took part in two read-aloud and two lexical decision experiments. The results showed that in speaking, for both genuine and pseudo words that contrasted in stress, participants changed the fundamental frequency (F0) and intensity to disambiguate; and they changed duration (but not F0 or intensity) to disambiguate words and pseudo-words that did not contrast in stress. In listening, the participants were sensitive to the prosodic (mis)match in stress-contrasting pairs, but not to durational (mis)match presumably because the durational differences between the comparison pairs were shorter than perceivable. The findings show that Turkish speakers use prosody to disambiguate morphologically ambiguous word pairs and that they are sensitive to prosodic cues (at least to those used in stress contrast) when they hear them. Their behavior for pseudo-words suggests that they do so not on the basis of individual word knowledge but productively. The comparison pairs in the current study were segmentally identical, allowing us to attribute the observed prosodic variation only to the morpho-syntactic structure of the ambiguous pairs.												0	2											DEC	2020	49	6					1083	1111		10.1007/s10936-020-09735-2	http://dx.doi.org/10.1007/s10936-020-09735-2		SEP 2020										2026-01-16	WOS:000572860800001
J	Lian, JC; Zhou, XR; Guo, CX; Ye, ZL; Ezzes, Z; Vonk, JMJ; Morin, B; Baquirin, D; Miller, Z; Gorno-Tempini, ML; Anumanchipalli, GK				Lian, Jiachen; Zhou, Xuanru; Guo, Chenxu; Ye, Zongli; Ezzes, Zoe; Vonk, Jet M. J.; Morin, Brittany; Baquirin, David; Miller, Zachary; Gorno-Tempini, Maria Luisa; Anumanchipalli, Gopala Krishna			Automatic Detection of Articulatory-Based Disfluencies in Primary Progressive Aphasia	IEEE JOURNAL OF SELECTED TOPICS IN SIGNAL PROCESSING				Article								Speech corpora are collections of textual data derived from human verbal output and speech signals that can be processed from a variety of perspectives, including formal or semantic content, to serve analyses of different levels of linguistic organisation (phonemic, morphosyntactic, lexico-semantic and content information, prosody and intonation) and to serve analyses of important phenomena such as speech fluency and errors (non-fluencies). We focus on transcribing speech along with non-fluencies or dysfluencies, the detection of which plays an important role in the diagnosis of primary progressive aphasia, where we specifically examine articulation-based dysfluencies in nfvPPA speech. In this work, we propose SSDM 2.0, which is built on top of the current state-of-the-art system of dysfluency detection [1] and tackles its shortcomings via four main contributions: (1) We propose a novel Neural Articulatory Flow for deriving highly scalable, dysfluency-aware speech representations. (2) We develop a full-stack connectionist subsequence aligner to capture all major dysfluency types. (3) We introduce a mispronunciation prompt pipeline and consistency learning into LLMs to enable in-context dysfluency learning. (4) We curate and open-source Libri-Co-Dys (Lian et al., 2024), the largest co-dysfluency corpus to date. (5) We also present SSDM-L, a modular, non-end-to-end, lightweight model designed for clinical deployment. In clinical experiments on pathological speech transcription, we tested SSDM 2.0 using nfvPPA corpus primarily characterized by articulatory dysfluencies. Overall, SSDM 2.0 outperforms SSDM and all other dysfluency transcription models by a large margin.												0	0											JUL	2025	19	5					810	826		10.1109/JSTSP.2025.3579972	http://dx.doi.org/10.1109/JSTSP.2025.3579972												2026-01-16	WOS:001630863500006
J	Meng, YX; Zhang, J				Meng, Yaxuan; Zhang, Juan			The dissociation of grammatical category from multiple levels in the neural representation of words: stress typicality effect among Chinese EFL learners	JOURNAL OF NEUROLINGUISTICS				Article								This study aimed to dissociate grammatical category from multiple levels during the processing of stress typicality, with a focus on understanding how class information is represented among Chinese speakers who learn English as a foreign language (EFL). Disyllabic English words were used as stimuli and three event-related potentials (ERPs) components, including P200, N400, and LPC (late positive component), were analyzed across two tasks that varied in their direct utilization of grammatical cue: lexical decision task in Experiment 1 and grammatical classification task in Experiment 2. Our findings indicate differences between words exhibiting distinct stress and grammatical patterns, suggesting that prosodic and grammatical cues are dissociated early around 200 ms, and continue to influence lexical access into later time windows. Additionally, the direct tapping of grammatical cues appears to impact how classes are processed, as differences between tasks were observed. In summary, our results reveal that grammatical class could be represented at the orthographic level and dissociated from prosody at an early stage. Furthermore, the representation of grammatical class among Chinese EFL learners may be independent of semantics.												0	0											AUG	2025	75								101265	10.1016/j.jneuroling.2025.101265	http://dx.doi.org/10.1016/j.jneuroling.2025.101265												2026-01-16	WOS:001509654700001
J	Xu, KY; Yan, JT; Ma, CL; Chang, XH; Chien, YF				Xu, Kunyu; Yan, Jinting; Ma, Chenlu; Chang, Xuhui; Chien, Yu-Fu			Atypical patterns of tone production in tone-language-speaking children with autism	FRONTIERS IN PSYCHOLOGY				Article								Speakers with autism spectrum disorder (ASD) are found to exhibit atypical pitch patterns in speech production. However, little is known about the production of lexical tones (T1, T2, T3, T4) as well as neutral tones (T1N, T2N, T3N, T4N) by tone-language speakers with ASD. Thus, this study investigated the height and shape of tones produced by Mandarin-speaking children with ASD and their age-matched typically developing (TD) peers. A pronunciation experiment was conducted in which the participants were asked to produce reduplicated nouns. The findings from the acoustic analyses showed that although ASD children generally produced both lexical tones and neutral tones with distinct tonal contours, there were significant differences between the ASD and TD groups for tone height and shape for T1/T1N, T3/T3N, and T4/T4N. However, we did not find any difference in T2/T2N. These data implied that the atypical acoustic pattern in the ASD group could be partially due to the suppression of the F0 range. Moreover, we found that ASD children tended to produce more errors for T2/T2N, T3/T3N than for T1/T1N, T4/T4N. The pattern of tone errors could be explained by the acquisition principle of pitch, similarities among different tones, and tone sandhi. We thus concluded that deficits in pitch processing could be responsible for the atypical tone pattern of ASD children, and speculated that the atypical tonal contours might also be due to imitation deficits. The present findings may eventually help enhance the comprehensive understanding of the representation of atypical pitch patterns in ASD across languages.												1	1											NOV 3	2022	13								1023205	10.3389/fpsyg.2022.1023205	http://dx.doi.org/10.3389/fpsyg.2022.1023205												2026-01-16	WOS:000886002800001
J	Voutilainen, E				Voutilainen, Eero			Written representation of spoken interaction in the official parliamentary transcripts of the Finnish Parliament	FRONTIERS IN COMMUNICATION				Article								In this article, I will analyze the written representation of spoken interaction in the official plenary session transcripts of the Finnish Parliament. The official parliamentary transcripts are not-and cannot be-identical copies of the original speech event. Instead, they are linguistically and textually edited in many ways. I will examine the different types of editorial changes that are made in the official Finnish parliamentary transcripts. These include phonological, morphological, and syntactic alterations, editing out of self-repairs, planning expressions, stuttering and slips-of-tongue, and finding written ways of expression for phenomena such as pauses, prosody, gestures, and non-verbal events. I will also discuss how the editorial changes affect the written representation of plenary session interaction.												4	4											JUL 24	2023	8								1047799	10.3389/fcomm.2023.1047799	http://dx.doi.org/10.3389/fcomm.2023.1047799												2026-01-16	WOS:001042280300001
S	Janata, P			Annals NY Acad Sci	Janata, Petr			Acuity of mental representations of pitch	NEUROSCIENCES AND MUSIC IV: LEARNING AND MEMORY	Annals of the New York Academy of Sciences			Article; Proceedings Paper	Conference on Neurosciences and Music-IV - Learning and Memory	JUN 09-12, 2011	Univ Edinburgh, Edinburgh, SCOTLAND		Univ Edinburgh			Singing in one's mind or forming expectations about upcoming notes both require that mental images of one or more pitches will be generated. As with other musical abilities, the acuity with which such images are formed might be expected to vary across individuals and may depend on musical training. Results from several behavioral tasks involving intonation judgments indicate that multiple memory systems contribute to the formation of accurate mental images for pitch, and that the functionality of each is affected by musical training. Electrophysiological measures indicate that the ability to form accurate mental images is associated with greater engagement of auditory areas and associated error-detection circuitry when listeners imagine ascending scales and make intonation judgments about target notes. A view of auditory mental images is espoused in which unified mental image representations are distributed across multiple brain areas. Each brain area helps shape the acuity of the unified representation based on current behavioral demands and past experience.												12	14												2012	1252						214	221		10.1111/j.1749-6632.2011.06441.x	http://dx.doi.org/10.1111/j.1749-6632.2011.06441.x												2026-01-16	WOS:000305518900029
J	LEFEVRE, JP; HILLER, SM; ROONEY, E; LAVER, J; DIBENEDETTO, MG				LEFEVRE, JP; HILLER, SM; ROONEY, E; LAVER, J; DIBENEDETTO, MG			MACRO AND MICRO FEATURES FOR AUTOMATED PRONUNCIATION IMPROVEMENT IN THE SPELL SYSTEM	SPEECH COMMUNICATION				Article								In this paper, the analysis of macro (prosodic) and micro (segmental) features is described for a workstation designed to improve the pronunciation of English, French and Italian by non-native speakers. The SPELL workstation is intended to be a teaching device aimed at intermediate ability foreign language learners. Audio and visual aids will be used to help students improve their general intelligibility within a basic teaching paradigm called DELTA (Demonstrate, Evaluate Listening, Teach and Assess). Prosodic analysis will apply to the features of intonation, stress and rhythm. A phonological approach is used for intonation which provides a well-structured system of contrasting units that correlate with discrete linguistic functions. A more limited approach to the prosodic phonology of stress and rhythm will be taught in the SPELL system by manipulating the relatively simple acoustic features of vowel quality and segmental duration. The micro feature analysis will focus on the segmental class of vowels. A distinctive feature approach is used to characterize non-native vowel pronunciation. Acoustic properties are sought which will be speaker-independent.												3	3											MAR	1992	11	1					31	44		10.1016/0167-6393(92)90061-B	http://dx.doi.org/10.1016/0167-6393(92)90061-B												2026-01-16	WOS:A1992HN10900003
J	Felici, M; Borgatti, M; Guerrieri, R				Felici, M; Borgatti, M; Guerrieri, R			Very low bit rate speech coding using a diphone-based recognition and synthesis approach	ELECTRONICS LETTERS				Article								High compression rates of speech signals may be achieved by coding schemes based on relevant linguistic segments. A system is described that relies on a diphone recogniser as the coder and on a speech synthesiser reproducing speech starting from a diphone codebook as the decoder. The spoken message is encoded in textual (phoneme labels) plus prosody representation. This speech coding technique may be used for voice mail or phone communication over low bit rate channels.												0	0											APR 30	1998	34	9					859	860		10.1049/el:19980573	http://dx.doi.org/10.1049/el:19980573												2026-01-16	WOS:000073847300025
J	Zhang, YJ; Zhang, C; Song, W; Zhang, ZC; Wu, YZ; He, XD				Zhang, Ya-Jie; Zhang, Chao; Song, Wei; Zhang, Zhengchen; Wu, Youzheng; He, Xiaodong			Prosody Modelling With Pre-Trained Cross-Utterance Representations for Improved Speech Synthesis	IEEE-ACM TRANSACTIONS ON AUDIO SPEECH AND LANGUAGE PROCESSING				Article								When humans speak multiple utterances in a continuous manner, the prosodic features generated in each utterance are related to those in its neighbouring utterances. Such cross-utterance (CU) dependencies are often ignored by the current neural text-to-speech (TTS) systems, which reduces the naturalness and expressiveness of the synthesized speeches. In this article, we propose to improve the prosody modelling ability of neural TTS systems using pre-trained CU acoustic and text representations. Such CU acoustic representations are derived using the Wav2Vec 2.0 model (W2V2) from the synthesized audios of the past utterances, while the CU text representations are extracted using the Bidirectional Encoder Representation from Transformers (BERT) model from the scripts of the future utterances. Experimental results on a Mandarin audiobook and an English audiobook showed the naturalness and expressiveness of the synthesized audios were significantly improved by incorporating such pre-trained W2V2 and BERT CU representations into the Fastspeech2 TTS framework.												6	7												2023	31						2812	2823		10.1109/TASLP.2023.3278184	http://dx.doi.org/10.1109/TASLP.2023.3278184												2026-01-16	WOS:001040051900003
J	Foxton, JM; Riviere, LD; Barone, P				Foxton, Jessica M.; Riviere, Louis-David; Barone, Pascal			Cross-modal facilitation in speech prosody	COGNITION				Article								Speech prosody has traditionally been considered solely in terms of its auditory features, yet correlated visual features exist, such as head and eyebrow movements. This study investigated the extent to which visual prosodic features are able to affect the perception of the auditory features. Participants were presented with videos of a speaker pronouncing two words, with visual features of emphasis on one of these words. For each trial, participants saw one video where the two words were identical in both pitch and amplitude, and another video where there was a difference in either pitch or amplitude that was congruent or incongruent with the visual changes. Participants were asked to decide which video contained the sound difference. Thresholds were obtained for the congruent and incongruent videos, and for an auditory-alone condition. It was found that the congruent thresholds were better than the incongruent thresholds for both pitch and amplitude changes. Interestingly, the congruent thresholds for amplitude were better than for the auditory-alone condition, which implies that the visual features improve sensitivity to loudness changes. These results demonstrate that visual stimuli can affect auditory thresholds for changes in pitch and amplitude, and furthermore support the view that visual prosodic features enhance speech processing. (C) 2009 Elsevier B.V. All rights reserved.												22	23											APR	2010	115	1					71	78		10.1016/j.cognition.2009.11.009	http://dx.doi.org/10.1016/j.cognition.2009.11.009												2026-01-16	WOS:000276126400007
J	Behar, D				Behar, Daniel			Forms of Hesitation: Tadhabdhub and Metrical Hybridity in Syrian taf'ila poetry, 1962-1975	MIDDLE EASTERN LITERATURES				Article; Early Access								This essay claims that shi'r al-taf'ila, modern poetry which adheres to one or more of the traditional prosodic feet, witnessed a second ideological turn in the moment leading up to the 1967 defeat. Around 1967, the mixing of meters asserts itself in attempt to grapple with the epistemic rupture in Arabist ideology as keyed to the taf'ila form. Hybrids emerge in Syria of the mid- to late-1960s, where modernistic nathr was cordoned off from poetic practice at the same time as social and political developments dictated a complex representation of interior struggles, paradoxes, and agonistic uncertainties. The readiness to experiment with metrical hybrids retrospectively highlights the silenced presence of metrical hybridity in Shi'r magazine (1956-1964), the carrier of the Arabic modernist project. The poets of Shi'r programmatically elided metrical thinking out of ideological considerations, and this paper wishes to rehabilitate prosody in the Arabic modernist legacy.												0	0											2024 DEC 19	2024										10.1080/1475262X.2024.2433809	http://dx.doi.org/10.1080/1475262X.2024.2433809		DEC 2024										2026-01-16	WOS:001379732600001
J	Meyer, S; Jungheim, M; Ptok, M				Meyer, S.; Jungheim, M.; Ptok, M.			Child-directed speech	HNO				Article								Infant- or child-directed speech (CDS) defines the code used to communicate with infants or children, which differs from standard adult speech in prosody, expressions, diction and word repetition etc. A selective literature search in PubMed was carried out for the purposes of this systematic review. Due to its specific advantages, child-directed speech facilitates the extraction and representation of relevant, meaningful sections from the continuous speech signal. Different speech communities use different variants of CDS. CDS is not only seen to be used by adults, but also by children communicating with younger children. However, there are speech communities that do not use CDS. Taking into consideration findings previously described in the literature, CDS appears to positively support language acquisition in children, but does not represent a necessary prerequisite. However, there are no findings in the literature to indicate that the linguistically reduced CDS hinders early language acquisition.												4	4											NOV	2011	59	11					1129	1134		10.1007/s00106-011-2333-9	http://dx.doi.org/10.1007/s00106-011-2333-9												2026-01-16	WOS:000296654600010
J	Jarmulowicz, L; Taran, VL				Jarmulowicz, Linda; Taran, Valentina L.			Lexical Morphology: Structure, Process, and Development	TOPICS IN LANGUAGE DISORDERS				Article								Recent work has demonstrated the importance of derivational morphology to later language development and has led to a consensus that derivation is a lexical process. In this review, derivational morphology is discussed in terms of lexical representation models from both linguistic and psycholinguistic perspectives. Input characteristics, including types of frequency (lexical, surface, affix, and relative) and transparency (semantic, phonological, and orthographic), are examined as key factors that affect processing and acquisition. We introduce the possibility that lexical prosody and syllabic characteristics are relevant to lexical representation and affix separability, and we propose that derivational morphemes can emerge to different degrees in a system that is sensitive to both sound and meaning. Finally, morphological development with a focus on children's sensitivity to input characteristics is briefly reviewed, and we conclude with a perspective of how lexical representation can be a framework for derived word study in therapeutic or educational settings.												15	22											JAN-MAR	2013	33	1					57	72		10.1097/TLD.0b013e318280f5c0	http://dx.doi.org/10.1097/TLD.0b013e318280f5c0												2026-01-16	WOS:000314804400006
J	Giorgi, A; Petrocchi, E				Giorgi, Alessandra; Petrocchi, Erika			ON THE SYNTACTIC REPRESENTATION OF CO-SPEECH GESTURES IN EXPRESSIVE LANGUAGE	LINGUE E LINGUAGGIO				Article								Language is assumed to be a multimodal system in which prosody, manual and non-manual gestures, and body positioning interact with syntactic structure in systematic ways. While gestures have often been analyzed from a semantic perspective, recent work has shown that they can be integrated into the syntactic architecture of the clause. We adopt this perspective and propose an analysis of co-speech gestures in expressive contexts, focusing on emotional meanings such as surprise and disapproval. Data from typologically diverse languages are considered. The discussion addresses three main questions: (i) What triggers the use of gesture in expressive utterances? (ii) Are these gestures language-specific or universal? (iii) What is their role within the grammar? We argue that a formal model integrating syntax, prosody, and gestures is required to account for the structural properties of expressive phenomena and to advance a theory of language as a fundamentally multimodal architecture.												1	1											JAN-JUN	2025	24	1					21	39															2026-01-16	WOS:001545637100003
J	Hoffmann, L				Hoffmann, Ludger			Narratives: A Functional-Pragmatic Perspective	LILI-ZEITSCHRIFT FUR LITERATURWISSENSCHAFT UND LINGUISTIK				Article								This paper investigates narratives from a functional pragmatic view. Telling a story is a complex pattern of discourse consisting of speech actions, procedures and linguistic means like temporal organization, personal deixis, representation of direct speech and intonation. The relation between self as teller and self as actor sheds light on the constitution of image by telling a story. The method of analysis is applied to a narrative of everyday life. The purpose of telling is to participate in the experience of others and to constitute a shared communicative world.												5	6											JUN	2018	48	2					203	224		10.1007/s41244-018-0090-x	http://dx.doi.org/10.1007/s41244-018-0090-x												2026-01-16	WOS:000440170100002
J	Mori, J				Mori, J.			The workings of the Japanese token hee in informing sequences - An analysis of sequential context, turn shape, and prosody	JOURNAL OF PRAGMATICS				Article								Employing the methodological framework of conversation analysis (cf. Sacks, Schegloff, and Jefferson, 1974), this study provides a detailed analysis of the ways in which the token hee is used in Japanese conversations. Hee has often been identified as a "news-receipt token," and indeed it frequently occurs in response to deliveries of news or other types of informing in the current data. However, close examination of the sequential context, turn shape, and prosody involved in each occurrence of hee demonstrates the varying contributions this token can make in the development of informing sequences. On some occasions, the token displays its producer's "assessment" (cf. Goodwin, 1986; Goodwin and Goodwin, 1987, 1992) of the news received, whereas on other occasions it serves as a "continuer" (cf. Schegloff, 1982), occurring in the midst of a projected, extended informing, and yet on other occasions it is treated as a "repair initiator" (cf. Schegloff, Jefferson, and Sacks, 1997). The results of the current microanalysis reveal potential pitfalls in classifying variants of a particular token into one category by virtue of its prescriptive orthographic representation and perceived core function. The concluding discussion considers implications for methodological issues involved in cross-linguistic, cross-cultural comparisons of interactional styles. (c) 2005 Elsevier B.V. All rights reserved.												35	53											AUG	2006	38	8					1175	1205		10.1016/j.pragma.2005.05.004	http://dx.doi.org/10.1016/j.pragma.2005.05.004												2026-01-16	WOS:000239377200003
J	Baart, M; Vroomen, J				Baart, Martijn; Vroomen, Jean			Recalibration of vocal affect by a dynamic face	EXPERIMENTAL BRAIN RESEARCH				Article								Perception of vocal affect is influenced by the concurrent sight of an emotional face. We demonstrate that the sight of an emotional face also can induce recalibration of vocal affect. Participants were exposed to videos of a 'happy' or 'fearful' face in combination with a slightly incongruous sentence with ambiguous prosody. After this exposure, ambiguous test sentences were rated as more 'happy' when the exposure phase contained 'happy' instead of 'fearful' faces. This auditory shift likely reflects recalibration that is induced by error minimization of the inter-sensory discrepancy. In line with this view, when the prosody of the exposure sentence was non-ambiguous and congruent with the face (without audiovisual discrepancy), aftereffects went in the opposite direction, likely reflecting adaptation. Our results demonstrate, for the first time, that perception of vocal affect is flexible and can be recalibrated by slightly discrepant visual information.												14	14											JUL	2018	236	7					1911	1918		10.1007/s00221-018-5270-y	http://dx.doi.org/10.1007/s00221-018-5270-y												2026-01-16	WOS:000435783300007
J	Lee, EK; Fraundorf, S				Lee, Eun-Kyung; Fraundorf, Scott			Effects of contrastive accents in memory for L2 discourse	BILINGUALISM-LANGUAGE AND COGNITION				Article								Contrastive pitch accents benefit native English speakers' memory for discourse by enhancing a representation of a specific relevant contrast item (Fraundorf et al., 2010). This study examines whether and how second language (L2) listeners differ in how contrastive accents affect their encoding and representation of a discourse, as compared to native speakers. Using the same materials as Fraundorf et al. (2010), we found that low and mid proficiency L2 learners showed no memory benefit from contrastive accents. High proficiency L2 learners revealed some sensitivity to contrastive accents, but failed to fully integrate information conveyed by contrastive accents into their discourse representation. The results suggest that L2 listeners' non-native performance in processing contrastive accents, observed in this and other prior studies, may be attributed at least in part to a difference in the depth of processing of the information conveyed by contrastive accents.												10	11											NOV	2017	20	5					1063	1079		10.1017/S1366728916000638	http://dx.doi.org/10.1017/S1366728916000638												2026-01-16	WOS:000418476900014
J	Thoret, E; Andrillon, T; Gauriau, C; Léger, D; Pressnitzer, D				Thoret, Etienne; Andrillon, Thomas; Gauriau, Caroline; Leger, Damien; Pressnitzer, Daniel			Sleep deprivation detected by voice analysis	PLOS COMPUTATIONAL BIOLOGY				Article								Sleep deprivation has an ever-increasing impact on individuals and societies. Yet, to date, there is no quick and objective test for sleep deprivation. Here, we used automated acoustic analyses of the voice to detect sleep deprivation. Building on current machine-learning approaches, we focused on interpretability by introducing two novel ideas: the use of a fully generic auditory representation as input feature space, combined with an interpretation technique based on reverse correlation. The auditory representation consisted of a spectro-temporal modulation analysis derived from neurophysiology. The interpretation method aimed to reveal the regions of the auditory representation that supported the classifiers' decisions. Results showed that generic auditory features could be used to detect sleep deprivation successfully, with an accuracy comparable to state-of-the-art speech features. Furthermore, the interpretation revealed two distinct effects of sleep deprivation on the voice: changes in slow temporal modulations related to prosody and changes in spectral features related to voice quality. Importantly, the relative balance of the two effects varied widely across individuals, even though the amount of sleep deprivation was controlled, thus confirming the need to characterize sleep deprivation at the individual level. Moreover, while the prosody factor correlated with subjective sleepiness reports, the voice quality factor did not, consistent with the presence of both explicit and implicit consequences of sleep deprivation. Overall, the findings show that individual effects of sleep deprivation may be observed in vocal biomarkers. Future investigations correlating such markers with objective physiological measures of sleep deprivation could enable "sleep stethoscopes" for the cost-effective diagnosis of the individual effects of sleep deprivation. Sleep deprivation has an ever-increasing impact on individuals and societies, from accidents to chronic conditions costing billions to health systems. Yet, to date, there is no quick and objective test for sleep deprivation. We show that sleep deprivation can be detected at the individual level with voice recordings. Importantly, we focused on interpretability, which allowed us to identify two independent effects of sleep deprivation on the voice: changes in prosody and changes in voice quality or timbre. The results also revealed a striking variability in individual reactions to the same deprivation, further confirming the need to consider the effects of sleep deprivation at the individual level. Vocal markers could be correlated to specific underlying physiological factors in future studies, outlining possible cost-effective and non-invasive "sleep stethoscopes".												3	5											FEB	2024	20	2							e1011849	10.1371/journal.pcbi.1011849	http://dx.doi.org/10.1371/journal.pcbi.1011849												2026-01-16	WOS:001157660200004
J	Prokopova, NL				Prokopova, Natalia L.			SPEECH CULTURE IN THE CONTEXT OF SOCIALIST REALISM	VESTNIK TOMSKOGO GOSUDARSTVENNOGO UNIVERSITETA FILOLOGIYA-TOMSK STATE UNIVERSITY JOURNAL OF PHILOLOGY				Article								The part of the Soviet speech culture which corresponds to the positions of socialist realism is studied. Value orientations and technological canons of speech culture caused by the method of socialist realism are discussed. The differentiated criteria intended for the development of the models of speech culture corresponding to the positions of socialist realism are formulated. A sample of the Soviet speech art is analyzed. The empirical material of the study is stage speech art of the official branch of Soviet culture. The author explains the urgency of the comprehension of the stage speech art of the Soviet period by the absence of a scientific reflection on this issue and by the timeliness of its reconsideration. The author' previously developed typology of public speech culture is used as the methodological support of this research. This typology proves that stage speech art of the official branch of Soviet culture is of the rhetorical type. The purpose of the article is to formulate the logic-stylistic and intonation-melodic canons of stage speech art of the official branch of Soviet culture. The principles of socialist realism and the value orientations of stage speech art are analyzed. The possibility of applying the value orientations of stage speech art as criteria for the identification of rhetorical type models is argued. The correspondence between the general principles of socialist realism, the value orientations of stage speech art and its technological canons is established in the publication. The author determines the meaning of the term "canon" in connection with speech culture and stage speech art, establishes and justifies the technological canons connected with the logic and style of stage speech art, argues the action of four canons: "the priority of text", "illustrative quality", "intonation-melodic simplicity", "intonation-melodic solemnity". The results of linguistic studies are used for the substantiation of the logic-stylistic and intonation-melodic canons of stage speech art. The connection of vocabulary and syntax of stage speech is emphasized. The article testifies to the early formation of the "priority of text" canon, explains the principle of its implementation in speech culture and in stage speech art. The author pays special attention to the argumentation of the "illustrative quality" canon. The technology of the illustrative approach use in the stage representation of the author's text is described in the article. The author proves the connection betwen using simple speech tasks in the work with the text and the illustrative style in stage speech art.												0	0											FEB	2016	39	1					35	49		10.17223/19986645/39/4	http://dx.doi.org/10.17223/19986645/39/4												2026-01-16	WOS:000407416200004
J	Ito, J; Mester, A				Ito, Junko; Mester, Armin			Prosodic subcategories in Japanese	LINGUA				Article								Research on Japanese prosody, especially on the pitch accent system of the language, has for a long time found that a single domain "phonological phrase" is not sufficient. Rather: two domains need to be distinguished, which go by various names (Minor vs. Major Phrase, Accentual vs. Intermediate Phrase). While empirically well-founded, these developments, together with similar findings in other languages, have resulted in a dissolution of the originally tightly organized universal prosodic hierarchy into a collection of many prosodic types, each instantiated here and there in different languages, but never simultaneously realized within a single language. Two strands of recent work, that of Selkirk (2009:205-219, 2011a), and of Ito and Mester (2007, 2009a, 2009b) converge on a common theme from different directions. On the one hand; Selkirk has developed a vastly simplified approach to the syntax prosody mapping which distinguishes only three levels (word, phrase, and clause) where syntactic constituents are systematically made to correspond to phonological domains ("Match Theory"). On the other hand, Ito and Mester have argued that the empirically necessary subcategories (such as Minor vs. Major Phrase) need to be understood not as additional categories existing in their own right, but rather as instances of recursively deployed basic categories. This paper carries forward this line of prosodic hierarchy research and shows that the recursion-based conception implemented within Match Theory allows for a conceptually and empirically cleaner understanding of the phonological facts and generalizations in Japanese as well as for an understanding of the respective roles of syntax and phonology in determining prosodic constituent structure organization, and the limitation in types of distinctions in prosodic category that are made in phonological representation. Finally, a formal constraint-based OT analysis is developed that provides an account of the varying tonal and accentual structures in syntactic collocations of varying sizes and structures. (C) 2012 Elsevier B.V. All rights reserved.												115	136											JAN	2013	124				SI		20	40		10.1016/j.lingua.2012.08.016	http://dx.doi.org/10.1016/j.lingua.2012.08.016												2026-01-16	WOS:000315065000003
J	Abesser, J; Frieler, K; Cano, E; Pfleiderer, M; Zaddach, WG				Abesser, Jakob; Frieler, Klaus; Cano, Estefania; Pfleiderer, Martin; Zaddach, Wolf-Georg			Score-Informed Analysis of Tuning, Intonation, Pitch Modulation, and Dynamics in Jazz Solos	IEEE-ACM TRANSACTIONS ON AUDIO SPEECH AND LANGUAGE PROCESSING				Article								Both the collection and analysis of large music repertoires constitute major challenges within musicological disciplines such as jazz research. Automatic methods of music analysis based on audio signal processing have the potential to assist researchers and to accelerate the transcription and analysis of music recordings significantly. In this paper, we propose a framework for analyzing improvised monophonic solos in multi-instrumental jazz recordings with special focus on reed and brass instruments. The analysis algorithms rely on prior score-information, which is taken from high quality manual solo transcriptions. Following an initial solo and accompaniment source separation, we propose algorithms for tone-wise extraction of fundamental frequency and intensity contours. Based on this fine-grained representation of recorded jazz solos, we perform several exploratory experiments motivated by questions relating to jazz research in order to analyze the use of expressive stylistic devices such as intonation, pitch modulation, and dynamics in jazz solos. The results show that a score-informed audio analysis of jazz recordings can provide valuable insights into the individual stylistic characteristics of jazz musicians.												6	11											JAN	2017	25	1					168	177		10.1109/TASLP.2016.2627186	http://dx.doi.org/10.1109/TASLP.2016.2627186												2026-01-16	WOS:000391491700013
J	Menuzzi, S; Mioto, C				Menuzzi, Sergio; Mioto, Carlos			Post-Verbal Monosyllabic Adverbs in Brazilian Portuguese: On the Relation between Syntax and Prosody	REVISTA DE ESTUDOS DA LINGUAGEM				Article								This article discusses the analysis proposed by Costa (1998) for the syntax of monosyllabic adverbs in European Portuguese (EP). Theoretically, the aim is to evaluate the analysis' underlying assumptions about the syntax-prosody interface. Under Costa's proposal, the order [Verb Complement Adverb] involves scrambling of the Complement to the left of the Adverb in EP. His main argument is based on an interaction of the phonological properties of monosyllabic adverbs with Cinque (1993)'s theory of the phrasal stress. Crucially, this theory assumes a very strong relation between syntactic constituents and the prosodic representation relevant for stress assignment. We will argue, however, that the distribution of monosyllabic adverbs, at least in BP, is best explained by autonomous rules of phonological phrase formation, as in Nespor & Vogel (1986)'s framework. Under this view, the relation between syntactic and prosodic constituents is indirect, and leads us to conclude that the distribution of monosyllabic adverbs does not support Complement scrambling in BP.												2	2											JUL-DEC	2006	14	2					211	243															2026-01-16	WOS:000215908000009
J	Chenausky, K; Norton, A; Tager-Flusberg, H; Schlaug, G				Chenausky, Karen; Norton, Andrea; Tager-Flusberg, Helen; Schlaug, Gottfried			Auditory-Motor Mapping Training: Comparing the Effects of a Novel Speech Treatment to a Control Treatment for Minimally Verbal Children with Autism	PLOS ONE				Article								This study compared Auditory-Motor Mapping Training (AMMT), an intonation-based treatment for facilitating spoken language in minimally verbal children with autism spectrum disorder (ASD), to a matched control treatment, Speech Repetition Therapy (SRT). 23 minimally verbal children with ASD (20 male, mean age 6; 5) received at least 25 sessions of AMMT. Seven (all male) were matched on age and verbal ability to seven participants (five male) who received SRT. Outcome measures were Percent Syllables Approximated, Percent Consonants Correct (of 86), and Percent Vowels Correct (of 61) produced on two sets of 15 bisyllabic stimuli. All subjects were assessed on these measures several times at baseline and after 10, 15, 20, and 25 sessions. The post-25 session assessment timepoint, common to all participants, was compared to Best Baseline performance. Overall, after 25 sessions, AMMT participants increased by 19.4% Syllables Approximated, 13.8% Consonants Correct, and19.1% Vowels Correct, compared to Best Baseline. In the matched AMMT-SRT group, after 25 sessions, AMMT participants produced 29.0% more Syllables Approximated (SRT 3.6%); 17.9% more Consonants Correct (SRT 0.5); and 17.6% more Vowels Correct (SRT 0.8%). Chi-square tests showed that significantly more AMMT than SRT participants in both the overall and matched groups improved significantly in number of Syllables Approximated per stimulus and number of Consonants Correct per stimulus. Pretreatment ability to imitate phonemes, but not chronological age or baseline performance on outcome measures, was significantly correlated with amount of improvement after 25 sessions. Intonation-based therapy may offer a promising new interventional approach for teaching spoken language to minimally verbal children with ASD.												45	56											NOV 9	2016	11	11							e0164930	10.1371/journal.pone.0164930	http://dx.doi.org/10.1371/journal.pone.0164930												2026-01-16	WOS:000387724300022
J	Anwar, MM; Anwar, MZ; Bhuiyan, MA				Anwar, Md. Musfique; Anwar, Mohammad Zabed; Bhuiyan, Md. Al-Amin			Syntax Analysis and Machine Translation of Bangla Sentences	INTERNATIONAL JOURNAL OF COMPUTER SCIENCE AND NETWORK SECURITY				Article								This paper addresses a method to analyze syntactically Bangla sentence using context-sensitive grammar rules which accept almost all types of Bangla sentences including simple, complex and compound sentences and then interpret the input Bangla sentence to English using the NLP conversion unit. The grammar rules employed for this system allow parsing five categories of sentences according to Bangla intonation. The system is based on analyzing an input sentence and converting into a structural representation (SR). Once the SR is created for a particular sentence it is then converted to corresponding English sentence by NLP conversion unit. For conversion, the NLP conversion unit takes help of the Corpus. The effectiveness of this method has been justified over the demonstration of different Bangla sentences with 28 decomposition rules and the success rates in all cases are over 90%.												10	11											AUG 30	2009	9	8					317	326															2026-01-16	WOS:000217226400044
J	Silva, CC; Barbosa, PA				Silva, Cristiane Conceicao; Barbosa, Plinio Almeida			The contribution of prosody to foreign accent: A study of Spanish as a foreign language	LOQUENS				Article								The aim of this study is to analyze the contribution of prosody on the perception of foreign accent by Brazilian learners of Spanish. The data were collected from 15 participants and a control group of 5 native Spanish speakers. A perceptual test was performed with two different speech styles (reading and storytelling) and with delexicalized and natural speech. The speech production was judged by 24 native Spanish subjects. First, they had to determine the nationality of the speaker by listening to the delexicalized excerpts in Spanish (storytelling). After that, the listeners used a continuous scale to rate the excerpts (reading and storytelling) for the degree of foreign accent in Spanish. The results suggest that it is possible to identify foreign accent only with the prosodic information provided in the delexicalized stimuli, i. e., f(0), duration, and overall intensity. In addition, the perceptual test allowed us to assess the degree of foreign accent of each subject while revealing the great variability of their production. Finally, concerning the external data, the following factors predicted foreign accent among the learners: gender, length of residence in Spain, formal language instruction in Brazil, age of arrival in Spain, and reported use of Brazilian Portuguese in Spain. These results confirm the crucial role of naturalistic learning of a foreign language, as shown by previous studies.												3	3											JUL	2017	4	2							e041	10.3989/loquens.2017.041	http://dx.doi.org/10.3989/loquens.2017.041												2026-01-16	WOS:000426438900001
J	Ivanova, EV; Kharin, MA				Ivanova, Ekaterina V.; Kharin, Maksim A.			A Vocal Cycle for Mezzo-Soprano, Bassoon and Piano "The Fragments" by Elisavieta Panchecko Set to Poems by Anna Akhmatova	PROBLEMY MUZYKALNOI NAUKI-MUSIC SCHOLARSHIP				Article								Elisavieta Panchenko's vocal cycle "The Fragments" set to poetry by Anna Akhmatova presents an example of a genuinely innovative contemporary manifestation of a specific kind of intonation of speech with its minutest emotional tints, as well as a non-standard type of interpretation of the solo instrumental timbre. Written for a vocal-instrumental trio (mezzo-soprano, bassoon, piano), this is, nonetheless, a vocal cycle one in the essence and nature of its musical thematicism. The features of through development in the cycle, the continuous renewal of musical material, the freedom of thematic development peculiar for the most part to instrumental compositions - all of these are directed for the most part towards heightened attention to micro-syntactic units of the poetic and musical texts. The musical content of the cycle is abundant with fine achievements in the domains of mode, harmony, texture and intonation, characteristic to the music of the present and previous centuries. The dialogue of the two equitable soloists - the two dramatic characters of the poem - is already being formed during the process of the representation. For the first time in vocal music the bassoon is interpreted as being endowed with a vocal timbre, albeit not possessing verbal characteristics of an unperceived character. The composer implements a counter-tendency to the picturesque content of the source hidden in the implication of the narrative: not only does the mother mourn the loss of her unjustly arrested son, but also the son when still alive bids his mother farewell, without hoping to see her again.												0	0												2017		1					121	127		10.17674/1997-0854.2017.1.121.127	http://dx.doi.org/10.17674/1997-0854.2017.1.121.127												2026-01-16	WOS:000461116900016
J	Matsuda, YT; Ueno, K; Waggoner, RA; Erickson, D; Shimura, Y; Tanaka, K; Cheng, K; Mazuka, R				Matsuda, Yoshi-Taka; Ueno, Kenichi; Waggoner, R. Allen; Erickson, Donna; Shimura, Yoko; Tanaka, Keiji; Cheng, Kang; Mazuka, Reiko			Processing of infant-directed speech by adults	NEUROIMAGE				Article								Adults typically address infants in a special speech mode called infant-directed speech (IDS). IDS is characterized by a special prosody (i.e., higher pitched, slower and hyperarticulated) and a special lexicon ("baby talk"). Here we investigated which areas of the adult brain are involved in processing IDS, which aspects of IDS (prosodic or lexical) are processed, to what extent the experience of being a parent affects the way adults process IDS, and the effects of gender and personality on IDS processing. Using functional magnetic resonance imaging, we found that mothers with preverbal infants showed enhanced activation in the auditory dorsal pathway of the language areas, regardless of whether they listened to the prosodic or lexical component of IDS. We also found that extroverted mothers showed higher cortical activation in speech-related motor areas than did mothers with lower extroverted personality scores. Increased cortical activation levels were not found for fathers, non-parents, or mothers with older children. (C) 2010 Elsevier Inc. All rights reserved.												12	14											JAN 1	2011	54	1					611	621		10.1016/j.neuroimage.2010.07.072	http://dx.doi.org/10.1016/j.neuroimage.2010.07.072												2026-01-16	WOS:000283825000063
J	Ye, KJ; Yin, BC; Wang, LC				Ye, Kejia; Yin, Baocai; Wang, Lichun			CSLML: a markup language for expressive Chinese sign language synthesis	COMPUTER ANIMATION AND VIRTUAL WORLDS				Article; Proceedings Paper	22nd International Conference on Computer Animation and Social Agents (CASA 2009)	JUN 17-19, 2009	Amsterdam, NETHERLANDS					This paper presents a Chinese Sign Language Markup Language (CSLML), which is developed for expressive Chinese sign language synthesis by introducing features and structure of sign language prosody. The tags of CSLML are divided into two levels: function level and phonetic level. Function level provides abstract information about signed content and prosody, so it facilitates text annotating for text-driven automatic synthetic system and adapts to diversified synthetic methods, such as motion capture animation or image-based synthesis, Which may not be good at processing lower-level information. Phonetic level provides detailed behavioral manners based on phonetics and phonology to interpret the meaning in function level. It facilitates creation and edit of any motions. The two levels co-exist in CSLML documents and high-level description can be mapped into corresponding low-level behavior to provide one-to-many variability and expression of synthesis. Therefore, We also introduce a framework for this mapping processing mid exhibit results of our animated prototype system based on this framework. Copyright (C) 2009 John Wiley & Sons, Ltd.												4	7											JUN	2009	20	2-3			SI		237	245		10.1002/cav.307	http://dx.doi.org/10.1002/cav.307												2026-01-16	WOS:000268110700017
J	Shattuck-Hufnagel, S				Shattuck-Hufnagel, Stefanie			Toward an (even) more comprehensive model of speech production planning	LANGUAGE COGNITION AND NEUROSCIENCE				Article								Since the publication of Speaking in 1989, with its extraordinary goal of modelling the entire process of human speech generation from message conceptualisation to articulation, encompassing results from a wide range of empirical studies, much new information has emerged about three aspects of speech production that were not clearly in focus at that time. This evidence has revealed 1) the systematic patterns of context-governed surface phonetic variation, and the active control of these patterns exercised by speakers and listeners, 2) the depth and pervasiveness of prosodic influences on those patterns, and 3) the close alignment of co-speech gestures with the prosodic structure of an utterance. This paper reviews some of that evidence, and suggests how its implications may constrain models of speech production planning, as those models become more comprehensive in their treatment of higher-level structures, and of aspects of the communicative act beyond the articulation of lexical and syntactic elements.												9	10											OCT 21	2019	34	9			SI		1202	1213		10.1080/23273798.2019.1650944	http://dx.doi.org/10.1080/23273798.2019.1650944		SEP 2019										2026-01-16	WOS:000485029100001
J	Haake, C; Kob, M; Willmes, K; Domahs, F				Haake, Caroline; Kob, Malte; Willmes, Klaus; Domahs, Frank			Word stress processing in specific language impairment: Auditory or representational deficits?	CLINICAL LINGUISTICS & PHONETICS				Article; Proceedings Paper	Workshop on Prosody in Typical and Atypical Populations	SEP, 2012	Univ Reading, Reading, ENGLAND		Univ Reading			Word stress processing has repeatedly been reported to be affected in specific language impairment (SLI) with potential consequences for various aspects of language development. However, it still remains unresolved whether word stress impairments in SLI are due to deficits in basic auditory processing or to a degraded phonological representation or both. We addressed this question examining an unselected sample of 10 children with SLI and 11 typically developing (TD) children, aged about 8 years, with respect to their basic auditory processing (duration and skewness discrimination) and phonological representation of prosodic (word stress) and segmental (consonant) contrasts. Our results show lower performance of the SLI group compared to the TD group in all tasks. Crucially, two subgroups of children with SLI emerged from our analyses: While one group was impaired in basic auditory perception, particularly affecting duration discrimination, the other showed no significant auditory processing deficits but a representational impairment.												10	10											AUG	2013	27	8					594	615		10.3109/02699206.2013.798034	http://dx.doi.org/10.3109/02699206.2013.798034												2026-01-16	WOS:000322338900004
J	Kentner, G				Kentner, Gerrit			Rhythmic parsing	LINGUISTIC REVIEW				Article								A controlled reading experiment reveals that stress-based linguistic rhythm impinges on syntactic ambiguity resolution in silent and oral reading. The results suggest that, at points of syntactic underspecification, the accruing prosodic representation may affect even the earliest stages of structure building, viz. the analysis of syntactic features of an ambiguous word. Such an effect remains inexplicable in the context of (psycho-) linguistic theories that assume a strictly unidirectional relationship between syntactic and phonological processes, the latter merely interpreting the conditions the syntactic component imposes on it. Here, a performance compatible grammar in the framework of Optimal Parsing is presented that is capable of capturing the reading data. The model integrates syntactic parsing and prosodification in reading and predicts that, at points of syntactic indetermination, weak prosodic constraints alone may guide syntactic structure assignment. This suggests a bidirectional relationship between syntax and phonology in grammar and processing while, at the same time, confirming a tight coupling of language production and comprehension.												6	7											FEB	2017	34	1					123	155		10.1515/tlr-2016-0005	http://dx.doi.org/10.1515/tlr-2016-0005												2026-01-16	WOS:000394238400004
J	Gronnum, N				Gronnum, Nina			A Danish phonetically annotated spontaneous speech corpus (DanPASS)	SPEECH COMMUNICATION				Article; Proceedings Paper	Seminar on Research Challenges in Speech Technology	OCT, 2005	Stockholm, SWEDEN					A corpus is described consisting of non-scripted monologues and dialogues, recorded by 27 speakers, comprising a total of 73,227 running words, corresponding to 9 h and 46 min of speech. The monologues were recorded as one-way communication with an unseen partner where the speaker performed three different tasks: (s)he described a network consisting of various geometrical shapes in various colours, (s)he guided the listener through four different routes in a virtual city map, and (s)he instructed the listener how to build a house from its individual pieces. The dialogues are replicas of the HCRC map tasks. Annotation is performed in Praat. The sound files are segmented into prosodic phrases, words, and syllables. The files are supplied, in separate interval tiers, with an orthographical representation, detailed part-of-speech tags, simplified part-of-speech tags, a phonemic notation, a semi-narrow phonetic notation, a symbolic representation of the pitch relation between each stressed and post-tonic syllable, and a symbolic representation of the phrasal intonation. (C) 2008 Elsevier B.V. All rights reserved.												17	17											JUL	2009	51	7			SI		594	603		10.1016/j.specom.2008.11.002	http://dx.doi.org/10.1016/j.specom.2008.11.002												2026-01-16	WOS:000267572800005
J	VALLDUVI, E				VALLDUVI, E			DETACHMENT IN CATALAN AND INFORMATION PACKAGING	JOURNAL OF PRAGMATICS				Article								The existing functional analyses of right-detachment constructions, the afterthought approach and the topic and topicality family of proposals, are inadequate to deal with right-detachment in Catalan. This paper argues that right-detachment in Catalan plays a specific role in the structural representation of information packaging. In particular, it encodes a tailful instruction in the sense of Vallduvi (1992). Right-detachment is contrasted with left-detachment and with pronominalization. Finally, it is pointed out that the association between a particular form and a particular function need not be constant across languages: the discourse function effected by right-detachment in Catalan can be expressed exclusively by prosodic means in English.												24	27											DEC	1994	22	6					573	601		10.1016/0378-2166(94)90031-0	http://dx.doi.org/10.1016/0378-2166(94)90031-0												2026-01-16	WOS:A1994PQ27900001
J	Lazzeretti, C				Lazzeretti, Cecilia			Communicating Sustainable Tourism in English and Italian: A Contrastive Analysis	LINGUAE &-RIVISTA DI LINGUE E CULTURE MODERNE				Article								Sustainable tourism has become a popular field of research over the last decades; yet, while acknowledging that sustainable tourism requires communication strategies different from those of mainstream tourism, scholars have paid little attention to this area of language. Based on two parallel corpora, this study explores the discursive representation of sustainable tourism in web communication in English and in Italian. The methodological framework adopted is that of Corpus Assisted Discourse Studies. The analysis suggests that the Italian representation of sustainable tourism is characterized by a distant stance towards readers and relies on a strong polarization between 'good' tourism and 'bad' tourism. Communication in English instead relies on proximal person deixis and on the creation of value around responsible tourism by means of factual information rather than on mere evaluation.												1	2												2020	19	2					133	154		10.7358/ling-2020-002-lazz	http://dx.doi.org/10.7358/ling-2020-002-lazz												2026-01-16	WOS:000634506400009
S	Wahlster, W		Gunter, A; Kruse, R; Neumann, B		Wahlster, W			Towards symmetric multimodality: Fusion and fission of speech, gesture, and facial expression	KI 2003: ADVANCES IN ARTIFICIAL INTELLIGENCE	Lecture Notes in Artificial Intelligence			Article; Proceedings Paper	26th Annual German Conference on Artificial Intelligence	SEP 15-18, 2003	HAMBURG, GERMANY					We introduce the notion of symmetric multimodality for dialogue systems in which all input modes (eg. speech, gesture, facial expression) are also available for output, and vice versa. A dialogue system with symmetric multimodality must not only understand and represent the user's multimodal input, but also its own multimodal output. We present the SmartKom system, that provides full symmetric multimodality in a mixed-initiative dialogue system with an embodied conversational agent. SmartKom represents a new generation of multimodal dialogue systems, that deal not only with simple modality integration and synchronization, but cover the full spectrum of dialogue phenomena that are associated with symmetric multimodality (including crossmodal references, one-anaphora, and backchannelling). We show that SmartKom's plug-an-play architecture supports multiple recognizers for a single modality, eg. the user's speech signal can be processed by three unimodal recognizers in parallel (speech recognition, emotional prosody, boundary,prosody). Finally, we detail SmartKom's three-tiered representation of multimodal discourse, consisting of a domain layer, a discourse layer, and a modality layer.												17	21												2003	2821						1	18															2026-01-16	WOS:000187009600001
J	Kachlicka, M; Tierney, A				Kachlicka, Magdalena; Tierney, Adam			Voice actors show enhanced neural tracking of pitch, prosody perception, and music perception	CORTEX				Article								Experiences with sound that make strong demands on the precision of perception, such as musical training and experience speaking a tone language, can enhance auditory neural encoding. Are high demands on the precision of perception necessary for training to drive auditory neural plasticity? Voice actors are an ideal subject population for answering this question. Voice acting requires exaggerating prosodic cues to convey emotion, character, and linguistic structure, drawing upon attention to sound, memory for sound features, and accurate sound production, but not fine perceptual precision. Here we assessed neural encoding of pitch using the frequency-following response (FFR), as well as prosody, music, and sound perception, in voice actors and a matched group of non-actors. We find that the consistency of neural sound encoding, prosody perception, and musical phrase perception are all enhanced in voice actors, suggesting that a range of neural and behavioural auditory processing enhancements can result from training which lacks fine perceptual precision. However, fine discrimination was not enhanced in voice actors but was linked to degree of musical experience, suggesting that low-level auditory processing can only be enhanced by demanding perceptual training. These findings suggest that training which taxes attention, memory, and production but is not perceptually taxing may be a way to boost neural encoding of sound and auditory pattern detection in individuals with poor auditory skills. (c) 2024 The Authors. Published by Elsevier Ltd. This is an open access article under the CC												2	2											SEP	2024	178									10.1016/j.cortex.2024.06.016	http://dx.doi.org/10.1016/j.cortex.2024.06.016		JUL 2024										2026-01-16	WOS:001274383400001
J	Diamond, E; Zhang, Y				Diamond, Erin; Zhang, Yang			Cortical processing of phonetic and emotional information in speech: A cross-modal priming study	NEUROPSYCHOLOGIA				Article								The current study employed behavioral and electrophysiological measures to investigate the timing, localization, and neural oscillation characteristics of cortical activities associated with phonetic and emotional information processing of speech. The experimental design used a cross-modal priming paradigm in which the normal adult participants were presented a visual prime followed by an auditory target. Primes were facial expressions that systematically varied in emotional content (happy or angry) and mouth shape (corresponding to /a/ or /i/ vowels). Targets were spoken words that varied by emotional prosody (happy or angry) and vowel (/a/ or /i/). In both the phonetic and prosodic conditions, participants were asked to judge congruency status of the visual prime and the auditory target. Behavioral results showed a congruency effect for both percent correct and reaction time. Two ERP responses, the N400 and late positive response (LPR), were identified in both conditions. Source localization and inter-trial phase coherence of the N400 and LPR components further revealed different cortical contributions and neural oscillation patterns for selective processing of phonetic and emotional information in speech. The results provide corroborating evidence for the necessity of differentiating brain mechanisms underlying the representation and processing of co-existing linguistic and paralinguistic information in spoken language, which has important implications for theoretical models of speech recognition as well as clinical studies on the neural bases of language and social communication deficits. (C) 2016 Elsevier Ltd. All rights reserved.												17	21											FEB	2016	82						110	122		10.1016/j.neuropsychologia.2016.01.019	http://dx.doi.org/10.1016/j.neuropsychologia.2016.01.019												2026-01-16	WOS:000370903800012
J	Nylén, F				Nylen, Fredrik			An acoustic model of speech dysprosody in patients with Parkinson's disease	FRONTIERS IN HUMAN NEUROSCIENCE				Article								Purpose: This study aimed to determine the acoustic properties most indicative of dysprosody severity in patients with Parkinson's disease using an automated acoustic assessment procedure. Method: A total of 108 read speech recordings of 68 speakers with PD (45 male, 23 female, aged 65.0 +/- 9.8 years) were made with active levodopa treatment. A total of 40 of the patients were additionally recorded without levodopa treatment to increase the range of dysprosody severity in the sample. Four human clinical experts independently assessed the patients' recordings in terms of dysprosody severity. Separately, a speech processing pipeline extracted the acoustic properties of prosodic relevance from automatically identified portions of speech used as utterance proxies. Five machine learning models were trained on 75% of speech portions and the perceptual evaluations of the speaker's dysprosody severity in a 10-fold cross-validation procedure. They were evaluated regarding their ability to predict the perceptual assessments of recordings excluded during training. The models' performances were assessed by their ability to accurately predict clinical experts' dysprosody severity assessments. Results: The acoustic predictors of importance spanned several acoustic domains of prosodic relevance, with the variability in f(o) change between intonational turning points and the average first Mel-frequency cepstral coefficient at these points being the two top predictors. While predominant in the literature, variability in utterance-wide f(o) was found to be only the fifth strongest predictor. Conclusion: Human expert raters' assessments of dysprosody can be approximated by the automated procedure, affording application in clinical settings where an experienced expert is unavailable. Variability in pitch does not adequately describe the level of dysprosody due to Parkinson's disease.												0	0											APR 28	2025	19								1566274	10.3389/fnhum.2025.1566274	http://dx.doi.org/10.3389/fnhum.2025.1566274												2026-01-16	WOS:001485339800001
J	MAZOYER, BM; TZOURIO, N; FRAK, V; SYROTA, A; MURAYAMA, N; LEVRIER, O; SALAMON, G; DEHAENE, S; COHEN, L; MEHLER, J				MAZOYER, BM; TZOURIO, N; FRAK, V; SYROTA, A; MURAYAMA, N; LEVRIER, O; SALAMON, G; DEHAENE, S; COHEN, L; MEHLER, J			THE CORTICAL REPRESENTATION OF SPEECH	JOURNAL OF COGNITIVE NEUROSCIENCE				Article								In this study, we compare regional cerebral blood flow (rCBF) while French monolingual subjects listen to continuous speech in an unknown language, to lists of French words, or to meaningful and distorted stories in French. Our results show that, in addition to regions devoted to single-word comprehension, processing of meaningful stories activates the left middle temporal gyrus, the left and right temporal poles, and a superior prefrontal area in the left frontal lobe. Among these regions, only the temporal poles remain activated whenever sentences with acceptable syntax and prosody are presented.												568	611											FAL	1993	5	4					467	479		10.1162/jocn.1993.5.4.467	http://dx.doi.org/10.1162/jocn.1993.5.4.467												2026-01-16	WOS:A1993ME01400006
J	Giugliano, M				Giugliano, Marcello			The representation of collective voices and social actors in the press through ethnonyms: the case of 'Catalans' and 'Spaniards'	CONFLUENZE-RIVISTA DI STUDI IBEROAMERICANI				Article								This study analyzes the use of the ethnonyms 'Catalan' and 'Spanish' in the Catalan and Spanish press before and after the October 1, 2017 referendum. Based on a journalistic corpus, it examines their role in identity construction, their semantic prosody, and discursive and ideological contexts. The findings show that these terms are not used in a stereotypical manner and that the notion of a 'collective voice' is a manipulable discursive construction, mediated by journalistic narratives that can exert forms of silencing.												0	0												2025	17	1					311	339		10.6092/issn.2036-0967/21828	http://dx.doi.org/10.6092/issn.2036-0967/21828												2026-01-16	WOS:001519150300013
J	Sridhar, VKR; Bangalore, S; Narayanan, S				Sridhar, Vivek Kumar Rangarajan; Bangalore, Srinivas; Narayanan, Shrikanth			Enriching machine-mediated speech-to-speech translation using contextual information	COMPUTER SPEECH AND LANGUAGE				Article								Conventional approaches to speech-to-speech (S2S) translation typically ignore key contextual information such as prosody, emphasis, discourse state in the translation process. Capturing and exploiting such contextual information is especially important in machine-mediated S2S translation as it can serve as a complementary knowledge source that can potentially aid the end users in improved understanding and disambiguation. In this work, we present a general framework for integrating rich contextual information in S2S translation. We present novel methodologies for integrating source side context in the form of dialog act (DA) tags, and target side context using prosodic word prominence. We demonstrate the integration of the DA tags in two different statistical translation frameworks, phrase-based translation and a bag-of-words lexical choice model. In addition to producing interpretable DA annotated target language translations, we also obtain significant improvements in terms of automatic evaluation metrics such as lexical selection accuracy and BLEU score. Our experiments also indicate that finer representation of dialog information such as yes no questions, wit-questions and open questions are the most useful in improving translation quality. For target side enrichment, we employ factored translation models to integrate the assignment and transfer of prosodic word prominence (pitch accents) during translation. The factored translation models provide significant improvement in assignment of correct pitch accents to the target words in comparison with a post-processing approach. Our framework is suitable for integrating any word or utterance level contextual information that can be reliably detected (recognized) from speech and/or text. (C) 2011 Elsevier Ltd. All rights reserved.												2	3											FEB	2013	27	2			SI		492	508		10.1016/j.csl.2011.08.001	http://dx.doi.org/10.1016/j.csl.2011.08.001												2026-01-16	WOS:000312471500007
J	Sun, H; Saito, K; Tierney, A				Sun, Hui; Saito, Kazuya; Tierney, Adam			A LONGITUDINAL INVESTIGATION OF EXPLICIT AND IMPLICIT AUDITORY PROCESSING IN L2 SEGMENTAL AND SUPRASEGMENTAL ACQUISITION	STUDIES IN SECOND LANGUAGE ACQUISITION				Article								Precise auditory perception at a subcortical level (neural representation and encoding of sound) has been suggested as a form of implicit L2 aptitude in naturalistic settings. Emerging evidence suggests that such implicit aptitude explains some variance in L2 speech perception and production among adult learners with different first language backgrounds and immersion experience. By examining 46 Chinese learners of English, the current study longitudinally investigated the extent to which explicit and implicit auditory processing ability could predict L2 segmental and prosody acquisition over a 5-month early immersion. According to the results, participants' L2 gains were associated with more explicit and integrative auditory processing ability (remembering and reproducing music sequences), while the role of implicit, preconscious perception appeared to be negligible at the initial stage of postpubertal L2 speech learning.												22	26											JUL	2021	43	3			SI		551	573	PII S0272263120000649	10.1017/S0272263120000649	http://dx.doi.org/10.1017/S0272263120000649												2026-01-16	WOS:000691976800006
J	Klasen, M; Kenworthy, CA; Mathiak, KA; Kircher, TTJ; Mathiak, K				Klasen, Martin; Kenworthy, Charles A.; Mathiak, Krystyna A.; Kircher, Tilo T. J.; Mathiak, Klaus			Supramodal Representation of Emotions	JOURNAL OF NEUROSCIENCE				Article								Supramodal representation of emotion and its neural substrates have recently attracted attention as a marker of social cognition. However, the question whether perceptual integration of facial and vocal emotions takes place in primary sensory areas, multimodal cortices, or in affective structures remains unanswered yet. Using novel computer-generated stimuli, we combined emotional faces and voices in congruent and incongruent ways and assessed functional brain data (fMRI) during an emotional classification task. Both congruent and incongruent audiovisual stimuli evoked larger responses in thalamus and superior temporal regions compared with unimodal conditions. Congruent emotions were characterized by activation in amygdala, insula, ventral posterior cingulate (vPCC), temporo-occipital, and auditory cortices; incongruent emotions activated a frontoparietal network and bilateral caudate nucleus, indicating a greater processing load in working memory and emotion-encoding areas. The vPCC alone exhibited differential reactions to congruency and incongruency for all emotion categories and can thus be considered a central structure for supramodal representation of complex emotional information. Moreover, the left amygdala reflected supramodal representation of happy stimuli. These findings document that emotional information does not merge at the perceptual audiovisual integration level in unimodal or multimodal areas, but in vPCC and amygdala.												94	103											SEP 21	2011	31	38					13635	13643		10.1523/JNEUROSCI.2833-11.2011	http://dx.doi.org/10.1523/JNEUROSCI.2833-11.2011												2026-01-16	WOS:000295083300027
J	Kim, JW; Chung, H; Jung, HY				Kim, June-Woo; Chung, Hoon; Jung, Ho-Young			Unsupervised Representation Learning with Task-Agnostic Feature Masking for Robust End-to-End Speech Recognition	MATHEMATICS				Article								Unsupervised learning-based approaches for training speech vector representations (SVR) have recently been widely applied. While pretrained SVR models excel in relatively clean automatic speech recognition (ASR) tasks, such as those recorded in laboratory environments, they are still insufficient for practical applications with various types of noise, intonation, and dialects. To cope with this problem, we present a novel unsupervised SVR learning method for practical end-to-end ASR models. Our approach involves designing a speech feature masking method to stabilize SVR model learning and improve the performance of the ASR model in a downstream task. By introducing a noise masking strategy into diverse combinations of the time and frequency regions of the spectrogram, the SVR model becomes a robust representation extractor for the ASR model in practical scenarios. In pretraining experiments, we train the SVR model using approximately 18,000 h of Korean speech datasets that included diverse speakers and were recorded in environments with various amounts of noise. The weights of the pretrained SVR extractor are then frozen, and the extracted speech representations are used for ASR model training in a downstream task. The experimental results show that the ASR model using our proposed SVR extractor significantly outperforms conventional methods.												2	2											FEB	2023	11	3							622	10.3390/math11030622	http://dx.doi.org/10.3390/math11030622												2026-01-16	WOS:000930445500001
J	Breen, M; Clifton, C				Breen, Mara; Clifton, Charles, Jr.			Stress matters: Effects of anticipated lexical stress on silent reading	JOURNAL OF MEMORY AND LANGUAGE				Article								This paper presents findings from two eye-tracking studies designed to investigate the role of metrical prosody in silent reading. In Experiment 1, participants read stress-alternating noun-verb or noun-adjective homographs (e.g. PREsent, preSENT) embedded in limericks, such that the lexical stress of the homograph, as determined by context, either matched or mismatched the metrical pattern of the limerick. The results demonstrated a reading cost when readers encountered a mismatch between the predicted and actual stress pattern of the word. Experiment 2 demonstrated a similar cost of a mismatch in stress patterns in a context where the metrical constraint was mediated by lexical category rather than by explicit meter. Both experiments demonstrated that readers are slower to read words when their stress pattern does not conform to expectations. The data from these two eye-tracking experiments provide some of the first on-line evidence that metrical information is part of the default representation of a word during silent reading. (C) 2010 Elsevier Inc. All rights reserved.												72	93											FEB	2011	64	2					153	170		10.1016/j.jml.2010.11.001	http://dx.doi.org/10.1016/j.jml.2010.11.001												2026-01-16	WOS:000287390000004
J	Wang, SM; Ai, Y; Chen, LP; Hu, YJ; Ling, ZH				Wang, Shiming; Ai, Yang; Chen, Liping; Hu, Yajun; Ling, Zhenhua			TEAR: A Cross-Modal Pre-Trained Text Encoder Enhanced by Acoustic Representations for Speech Synthesis	IEEE TRANSACTIONS ON AUDIO SPEECH AND LANGUAGE PROCESSING				Article								Text encoders play an important role in text-to-speech (TTS) by analyzing text input and converting it into linguistic representations. In order to generate expressive speech from text, pre-training text encoders on large amounts of data has recently become a solution to generate richer and more effective linguistic representations. However, existing pre-trained text encoders only use the self-supervised target on the text data, without considering the relationship between text and speech modalities during the pre-training stage. In this paper, we propose TEAR, a cross-modal pre-trained Text Encoder enhanced by Acoustic Representations for TTS. In addition to conventional text pre-training, TEAR incorporates speech pre-training to extract semantic and prosody-related acoustic representations from speech. Then, TEAR introduces a novel cross-modal pre-training task for the text encoder, termed acoustics-aware joint prediction. This task leverages the acoustic representations generated by the preceding speech pre-training, enabling the linguistic representation to perceive and comprehend prosody during the encoding process. In our implementation, TEAR was pre-trained on 130 million unlabeled Chinese and English sentences, as well as 740,000 Chinese text-speech pairs. The results of the downstream TTS experiments on three expressive TTS datasets indicate that the proposed TEAR can encode more effective and comprehensive linguistic representations compared to the text-only pre-trained encoders, leading to the generation of more natural speech.												0	0												2025	33						1117	1128		10.1109/TASLPRO.2025.3545274	http://dx.doi.org/10.1109/TASLPRO.2025.3545274												2026-01-16	WOS:001484963000007
J	Kitamura, C; Guellaï, B; Kim, J				Kitamura, Christine; Guellai, Bahia; Kim, Jeesun			Motherese by Eye and Ear: Infants Perceive Visual Prosody in Point-Line Displays of Talking Heads	PLOS ONE				Article								Infant-directed (ID) speech provides exaggerated auditory and visual prosodic cues. Here we investigated if infants were sensitive to the match between the auditory and visual correlates of ID speech prosody. We presented 8-month-old infants with two silent line-joined point-light displays of faces speaking different ID sentences, and a single vocal-only sentence matched to one of the displays. Infants looked longer to the matched than mismatched visual signal when full-spectrum speech was presented; and when the vocal signals contained speech low-pass filtered at 400 Hz. When the visual display was separated into rigid (head only) and non-rigid (face only) motion, the infants looked longer to the visual match in the rigid condition; and to the visual mismatch in the non-rigid condition. Overall, the results suggest 8-month-olds can extract information about the prosodic structure of speech from voice and head kinematics, and are sensitive to their match; and that they are less sensitive to the match between lip and voice information in connected speech.												24	27											OCT 29	2014	9	10							e111467	10.1371/journal.pone.0111467	http://dx.doi.org/10.1371/journal.pone.0111467												2026-01-16	WOS:000345204200083
J	Azarenkov, A				Azarenkov, Anton			Meeting with Infinity. Time, Memory and Return in The Book of Childhood by Elizaveta Mnatsakanova	NOVOE LITERATURNOE OBOZRENIE				Article								The article analyzes the poetics of The Book of Childhood by Elizaveta Mnatsakanova. The basis of The Book of Childhood is the phenomenon recollections of childhood. The first section of the article, "Words and Time" is devoted to the study of the verbal representation of the theme of time. The section "Plot and Time" discusses how the mechanisms of memory determine the plot structure of the book as a whole. Then in the section "Form and Time" we focus on some verse features of The Book of Childhood, which in our opinion correlate with the general semantic dynamics. Finally, the last section, "Idea and Time," reviews the author's concept of memory as a literary technique developed in Mnatsakanova's poems and essays.												0	0												2022		177					281	295		10.53953/08696365_2022_177_5_281	http://dx.doi.org/10.53953/08696365_2022_177_5_281												2026-01-16	WOS:000922636300017
J	Geelhand, P; Papastamou, F; Kissine, M				Geelhand, Philippine; Papastamou, Fanny; Kissine, Mikhail			How do autistic adults use syntactic and prosodic cues to manage spoken discourse?	CLINICAL LINGUISTICS & PHONETICS				Article								Discourse studies investigating differences in the socio-communicative profiles of autistic (ASD) and neurotypical (NT) individuals have mostly relied on orthographic transcriptions, without taking prosodic information into account. However, atypical prosody is ubiquitous in ASD and a more accurate representation of their discourse abilities should also include prosodic cues. This exploratory study addresses this gap by segmenting the spoken discourse of 12 ASD and NT adults using the framework of Basic Discourse Units (BDUs). BDUs result from the mapping of syntactic boundaries on prosodic units, which can coincide in different ways and are associated with different discourse strategies. We hypothesized that the discourse of ASD adults would display more atypical strategies than NT adults, reflecting a 'pedantic' style and more difficulties in managing ongoing discourse. While ASD adults did not produce more discourse units associated with didactic or pedantic strategies than NT adults, they did produce less units associated with strategies of interactional regulation. This study provides initial evidence that multidimensional linguistic units, such as BDUs can help differentiate speech delivery strategies of ASD adults from those of their NT peers, even based on simple prosodic cues like silent pauses.												7	7											DEC 2	2021	35	12					1184	1209		10.1080/02699206.2021.1878278	http://dx.doi.org/10.1080/02699206.2021.1878278		FEB 2021										2026-01-16	WOS:000614208000001
J	Giugliano, M				Giugliano, Marcello			Discourses about independence: A corpus-based analysis of discourse prosodies in Spanish and Catalan newspapers	DISCOURSE & COMMUNICATION				Article								The present study is a corpus-assisted analysis of discourses on the Catalan movement of independence in the Catalan and Spanish press. A referendum for Catalan independence was held on 1 October 2017 but was not approved by the central Spanish government and was declared illegal. Spanish and Catalan newspapers differed considerably in their treatment and representation of the conflict, which also drew the attention of the international press to Catalonia. My analysis interconnects theoretical perspectives from linguistic critical discourse studies, cognitive linguistics, and media studies. The methodology is based on the analysis of two comparable corpora of journalistic texts (in Catalan, Spanish). My aim is to identify and compare different features of the semantic prosody of words describing the event of geopolitical separation and the different narratives on this sociopolitical conflict that these prosodies contribute to producing. More specifically, I focus on a selection of keywords, like independence, secession, and sovereignty, that seem to be indicative of different discursive strategies consciously, and possibly unconsciously, chosen by a selection of national Catalan and Spanish newspapers. By carrying out a contrastive analysis of the two corpora, I am able to describe certain similarities, like the similar frequent use of the word independence, and differences, like the more frequent use of the word secession in the Spanish corpus, that indicate different framings of the same event and can be related to different ideological positionings against or in favor of Catalonia's independence from Spain.												2	2											OCT	2022	16	5					525	550		10.1177/17504813221099194	http://dx.doi.org/10.1177/17504813221099194		JUL 2022										2026-01-16	WOS:000824431300001
J	Kuriakose, LJ				Kuriakose, Liju Jacob			Translation as Strategic Foreignization: A Study of the Politics of Translation in Mother Forest: An Unfinished Autobiography	RUPKATHA JOURNAL ON INTERDISCIPLINARY STUDIES IN HUMANITIES				Article								The study draws upon Lawrence Venuti's concept of foreignization as a strategic tool employed in the translation of CK Janu's Mother Forest: An Unfinished Autobiography. The translation works to mould an ethnic autobiography and represent a subaltern subject through explicit signifiers of subalternity, masqueraded as an attempt to "retain the flavour of Janu's intonation and the sing-song nature of her speech in translation". As a mode of representation, this study identifies the text as catering to a transnational publishing industry and the global academic marketplace, transforming the cultural value of an ethnic subaltern text into what Graham Huggan describes as "tawdry ethnic goods" in the late capitalist supermarket.												0	0												2021	13	4								10.21659/rupkatha.v13n4.07	http://dx.doi.org/10.21659/rupkatha.v13n4.07												2026-01-16	WOS:000721116800001
J	Kamali, B; Krifka, M				Kamali, Beste; Krifka, Manfred			Focus and contrastive topic in questions and answers, with particular reference to Turkish	THEORETICAL LINGUISTICS				Article								Much recent research has recognized the importance of focus and contrastive topic in assertions for discourse coherence. However, with few exceptions, it has been neglected that focus and contrastive topic also occur in questions, and have a similar role in establishing coherence. We propose a framework of dynamic interpretation based on the notion of Commitment Spaces that show that a uniform interpretation of focus and contrastive topic is possible. The algebraic representation format is rich enough so that a separate introduction of discourse trees is not necessary. The paper discusses these phenomena for Turkish, a language with an explicit focus marker for polar and alternative questions, which distinguishes focus from contrastive topic.												12	15											JUN	2020	46	1-2					1	71		10.1515/tl-2020-0001	http://dx.doi.org/10.1515/tl-2020-0001												2026-01-16	WOS:000581119700001
J	Sandell, R; Gunkel, D				Sandell, Ryan; Gunkel, Dieter			On the representation and realization of the Ancient Greek acute Evidence from tone-tune mappings in Ancient Greek music	JOURNAL OF GREEK LINGUISTICS				Article								This study addresses the phonological representation and phonetic realization of pitch patterns found on or near prosodically prominent syllables in Ancient Greek, namely, the distinction between the so-called "acute" and "circumflex" accents. Empirically, we investigate in detail the correlation between tones and tunes in the Delphic hymns (DAGM 20 and 21) on syllables capable of bearing a circumflex accent (i.e., syllables containing a long vowel or diphthong = VV -syllables). This data supports two major findings. First, VV -syllables with circumflex accent are significantly more likely to be set to a melism than VV -syllables that are acute, grave, or unaccented, and, moreover, the proportion of melismatic settings among acute, unaccented, and grave VVsyllables does not significantly differ. Second, circumflex melisms consistently (always or nearly so) fall in pitch (on average, by three semitones), whereas acute and unaccented melisms may either rise or fall (on average, by 1.5-2.25 semitones in either direction). Taken together, this data conforms to the usual description of the circumflex as a falling pitch, [H L], but speaks against claims that the acute constitutes a rising pitch ([L H], or High alone aligned with the latter portion of a VV -syllable, [0 H]). We instead conclude that the acute represents a single High pitch target phonologically mapped to the entirety of a VV -syllable, and discuss the implications for the phonological analysis of the prosody of Ancient Greek in light of the typology of contour tones.												1	1											MAY	2024	24	1					78	183		10.1163/15699846-02401004	http://dx.doi.org/10.1163/15699846-02401004												2026-01-16	WOS:001246535300004
J	Estebas-Vilaplana, E; Blecua, B				Estebas-Vilaplana, Eva; Blecua, Beatriz			Phrasing and nuclear configurations in authentic English-accented Spanish	LOQUENS				Article								This paper examines the differences in the division of intonation phrases and in the tonal structure of the nuclear configuration (i.e., the last pitch accent and the following boundary tone) in imitated and in authentic English-accented Spanish. The same Spanish text was read by four native speakers of American English, who produced the text with a real English foreign accent in Spanish, and six native speakers of Spanish, who read the text twice: in L1 Spanish and in fake English-accented Spanish. An auditory analysis of the data was carried out along with an inspection of f(0) traces aligned with the spectrographic representation and the segmental string. The results showed that the Spanish speakers produce more intonation breaks when they imitate an English accent in Spanish than when they speak L1 Spanish. Furthermore, they adopt the typical tonal structure of Spanish final accents in their fake English-accented productions. The number of prosodic breaks in real and in imitated English-accented Spanish is similar. The nuclear configurations, on the other hand, present more variability and differ in the frequency of occurrence of some patterns. The high occurrence of the fall-rise pattern (L+H* LH%) and the presence of the high-fall contour (L+H* L%) in the English productions may help discriminate an authentic English-accented Spanish from a fake one.												0	0											JAN	2018	5	1							e050	10.3989/loquens.2018.050	http://dx.doi.org/10.3989/loquens.2018.050												2026-01-16	WOS:000446137200005
J	Hirose, Y; Mazuka, R				Hirose, Yuki; Mazuka, Reiko			Exploiting Pitch Accent Information in Compound Processing: A Comparison between Adults and 6- to 7-Year-Old Children	LANGUAGE LEARNING AND DEVELOPMENT				Article								A noun can be potentially ambiguous as to whether it is a head on its own, or is a modifier of a Noun + Noun compound waiting for its head. This study investigates whether young children can exploit the prosodic information on a modifier constituent preceding the head to facilitate resolution of such ambiguity in Japanese. Evidence from English suggests that young speakers are not sensitive to compound stress in distinguishing between compounds and syntactic phrases unless the compound is very familiar (Good, 2008; Vogel & Raimy, 2002). This study concerns whether children in general have such limited capability to use prosodic cues to promptly compute a compound representation without the lexical boost, or whether they might show greater sensitivity to more categorical compound prosody such as that associated with the Compound Accent Rule (CAR) in Japanese. A previous study (Hirose & Mazuka, 2015) demonstrated that adult Japanese speakers can predict the compound structure prior to the head if the prosodic information on the modifier unambiguously signals that the CAR is being applied. The present study conducted the same online experiment with children (6- to 7-year-olds) and compared the time course of the effects with that of adults using permutation-based analysis (Maris & Oosternveld, 2007). The results reveal that children are sensitive to pitch accent information that facilitates the quicker processing of the compound or the single head noun representation compared to when such prosodic signals are less apparent, depending on the type of the lexical accent of the noun in question.												4	4												2017	13	4					375	394		10.1080/15475441.2017.1292141	http://dx.doi.org/10.1080/15475441.2017.1292141												2026-01-16	WOS:000418529800002
J	Prové, V; Feyaerts, K				Prove, Valentijn; Feyaerts, Kurt			Pitch metaphors and the body in singing classes	COGNITEXTES				Article								This paper provides evidence that gesture promotes learning by schematizing a particular sensorimotor feeling associated with bodily action into a metaphorical representation. We analyze gestural depictions that are temporally aligned with musical performance in a video corpus of lyric singing classes conducted in Dutch (Flanders, Belgium) and that are specifically used by teachers to work on difficulties related to high and low pitch. The case of intonation is relevant because the vertical conception of 'ascending' and 'descending' interferes with good practices of singing and teachers often depict 'inverted' pitch contours to counteract this behavior. To motivate this conceptual inversion, teachers draw on the body as a local resource in the interactional context.												2	2												2022	22								2037	10.4000/cognitextes.2037	http://dx.doi.org/10.4000/cognitextes.2037												2026-01-16	WOS:000813926600001
S	Sayles, M; Stasiak, A; Winter, IM		VanDijk, P; Baskent, D; Gaudrain, E; DeKleine, E; Wagner, A; Lanting, C		Sayles, Mark; Stasiak, Arkadiusz; Winter, Ian M.			Neural Segregation of Concurrent Speech: Effects of Background Noise and Reverberation on Auditory Scene Analysis in the Ventral Cochlear Nucleus	PHYSIOLOGY, PSYCHOACOUSTICS AND COGNITION IN NORMAL AND IMPAIRED HEARING	Advances in Experimental Medicine and Biology			Article; Book Chapter								Concurrent complex sounds (e.g., two voices speaking at once) are perceptually disentangled into separate "auditory objects". This neural processing often occurs in the presence of acoustic-signal distortions from noise and reverberation (e.g., in a busy restaurant). A difference in periodicity between sounds is a strong segregation cue under quiet, anechoic conditions. However, noise and reverberation exert differential effects on speech intelligibility under "cocktail-party" listening conditions. Previous neurophysiological studies have concentrated on understanding auditory scene analysis under ideal listening conditions. Here, we examine the effects of noise and reverberation on periodicity-based neural segregation of concurrent vowels /a/ and /i/, in the responses of single units in the guinea-pig ventral cochlear nucleus (VCN): the first processing station of the auditory brain stem. In line with human psychoacoustic data, we find reverberation significantly impairs segregation when vowels have an intonated pitch contour, but not when they are spoken on a monotone. In contrast, noise impairs segregation independent of intonation pattern. These results are informative for models of speech processing under ecologically valid listening conditions, where noise and reverberation abound.												3	3												2016	894						389	397		10.1007/978-3-319-25474-6_41	http://dx.doi.org/10.1007/978-3-319-25474-6_41	10.1007/978-3-319-25474-6											2026-01-16	WOS:000385741400042
J	Gutiérrez-Serafín, B; Andreu-Perez, J; Pérez-Espinosa, H; Paulmann, S; Ding, WP				Gutierrez-Serafin, Benjamin; Andreu-Perez, Javier; Perez-Espinosa, Humberto; Paulmann, Silke; Ding, Weiping			Toward assessment of human voice biomarkers of brain lesions through explainable deep learning	BIOMEDICAL SIGNAL PROCESSING AND CONTROL				Article								Lesions in the brain resulting from traumatic injuries or strokes can evolve into speech dysfunction in undiagnosed patients. Employing ML-based tools to analyze the prosody or articulatory phonetics of human speech could be advantageous for early screening of undetected brain injuries. Additionally, explaining the model's decision-making process can support predictions and take appropriate measures to improve patient voice quality. However, traditional ML methods relying on low-level descriptors (LLDs) may sacrifice detailed temporal dynamics and other speech characteristics. Interpreting these descriptors can also be challenging, requiring significant effort to understand feature relationships and suitable ranges. To address these limitations, this research paper introduces xDMFCCs, a method that identifies interpretive discriminatory acoustic biomarkers from a single speech utterance, providing local and global interpretations of deep learning models in speech applications. To validate this approach, it was implemented to interpret a Convolutional Neural Network (CNN) trained on Mel-frequency Cepstral Coefficients (MFCC) for the binary classification task to differentiate between patients from control vocalizations. The ConvNet achieved promising results with a 75% f-score (75% recall, 76% precision), comparable to conventional machine learning baselines. What sets xDMFCCs apart is its explanation through a 2D time-frequency representation that preserves the complete speech signal. This representation offers a more transparent explanation for differentiating between patients and healthy controls, enhancing interpretability. This advancement enables more detailed and compelling studies in speech acoustic traits of brain lesions. Furthermore, the findings have significant implications for developing low-cost and rapid diagnostics of unnoticed brain lesions.												6	7											JAN	2024	87		B						105457	10.1016/j.bspc.2023.105457	http://dx.doi.org/10.1016/j.bspc.2023.105457		SEP 2023										2026-01-16	WOS:001081307300001
J	Selosse, G; Grandjean, D; Ceravolo, L				Selosse, Garance; Grandjean, Didier; Ceravolo, Leonardo			Neural correlates of embodied and vibratory mechanisms associated with emotional prosody production	SOCIAL COGNITIVE AND AFFECTIVE NEUROSCIENCE				Article								Despite a large body of literature on the psychological and brain mechanisms of vocal emotion perception, less is known about expression and production mechanisms, especially the vibrations originating in the vocal cords and their role in emotional voice production. In the present study, we aimed to fill this gap. Participants were asked to produce angry, happy, and neutral tone emotional vocalizations in different production conditions ('normal,' 'whisper,' and 'silent articulation'). An accelerometer recorded the vibrations on the throat, close to the vocal folds. The results highlight the crucial role of vocal tract vibrations in multisensory integration during emotional prosody production. Crucially, Production and its interaction with Emotion revealed significant effects in motor, somatosensory, insular, and inferior frontal cortices. Results also showed effects of the emotion with activations in the bilateral temporal voice areas, the inferior frontal gyri, as well as motor and supplementary motor areas. Exploratory analysis revealed that emotional vocal tract vibrations correlate with activations in multisensory integration regions (insula, inferior frontal cortex, and cerebellum). We propose that vocal tract vibrations could implicitly affect bodily self-consciousness and, therefore, the representation of one's own emotions related to emotional vocal production.												0	0												2025	20	1							nsaf084	10.1093/scan/nsaf084	http://dx.doi.org/10.1093/scan/nsaf084												2026-01-16	WOS:001586376900001
J	Elyasa, YM				Elyasa, Yasir M.			A Comparative Literary Study of the Prosodic Systems of English and Arabic Poetry	3L-LANGUAGE LINGUISTICS LITERATURE-THE SOUTHEAST ASIAN JOURNAL OF ENGLISH LANGUAGE STUDIES				Article								This study investigates the similarities and differences between the prosodic systems of English and Arabic poetry. It is qualitative research on the two systems, where the methods of representation are explained, compared, and contrasted, with examples of words and lines from both languages' poetry. It supposes that music, as a common ground for the poetry of both languages, has given them the essential elements of having to do with the beat and rhythm, though these terms are slightly different in music. This is added to the fact that both are rhythmic languages, affected by the factor of rhythm as a common feature between them. Furthermore, the study attempts to prove that it is possible to have some examples of Arabic poetry represented through the English prosodic system and vice versa. This showed that there is much similarity between the two systems in the practical sense of depending on the vowels as fundamental to the existence and representation of syllables. The differences between the two prosodic systems were found in the significance of the level of the beats and the representation of consonants and long vowels.												0	0												2025	31	4					362	374		10.17576/3L-2025-3104-23	http://dx.doi.org/10.17576/3L-2025-3104-23												2026-01-16	WOS:001643330200003
J	Large, EW				Large, EW			Periodicity, pattern formation, and metric structure	JOURNAL OF NEW MUSIC RESEARCH				Article								This article describes an approach to metrical structure focussing on its role as an active listening strategy. The theory postulates that metrical structure is a self-organized, dynamic structure composed of self-sustaining oscillations. The emergence of this structural representation is modeled as a pattern formation process whose the neural correlate is the formation of a spatiotemporal pattern of neural activity. The primary function of the dynamic structure is attentional. It enables anticipation of future events thus, targeting of perception, and coordination of action with exogenous events. Stability and flexibility properties arise through nonlinearities in the underlying pattern-forming dynamics. Furthermore, this dynamic representation functions in musical communication. Transient stimulus fluctuations observed in musical performance (e.g., rate changes, intonation) are not noise, but rather communicate structural information, intention, and affect. These communicative gestures are recognized as deviations from temporal expectations embodied in the metrical structure. Experiments are reviewed that investigate stimuli of varying complexity, from simple isochronous tone sequences to performed music, and the model's success at capturing these data is assessed.												16	21											JUN	2001	30	2			SI		173	185		10.1076/jnmr.30.2.173.7113	http://dx.doi.org/10.1076/jnmr.30.2.173.7113												2026-01-16	WOS:000174981100006
J	Kita, S				Kita, S			Two-dimensional semantic analysis of Japanese mimetics	LINGUISTICS				Article; Proceedings Paper	Workshop on Gesture Cross Linguistically	1995	ALBUQUERQUE, NM					This paper argues that two-dimensional semantic representation is necessary to account for the semantics of Japanese mimetics (giongo/gitaigo), following the insight of Diffloth (1972). One dimension is called the analytic dimension, the dimension of ''ordinary semantics,'' where meaning is represented as a hierarchical structure of decontextualized semantic primitives. The other is called the affecto-imagistic dimension, where meaning is represented in terms of affect and various kinds of imagery (auditory, visual, tactile, motoric, etc). It subsumes what is traditionally called the expressive function of language due to its affective character, but it has far greater referential capability. I will argue that the semantics of mimetics crucially involves the affecto-imagistic dimension. The evidence includes seeming redundancy of a mimetic in a clause, impossibility of logical negation, high association with expressive intonation and spontaneous iconic gestures, and iconism in the morphology of mimetics. Positing the two dimensions leads to an alternative to Jackendoff's (1983) conceptual structure hypothesis, which states that the analytic dimension is the only level of representation where language and other kinds of cognitive information are compatible.												163	191												1997	35	2					379	415		10.1515/ling.1997.35.2.379	http://dx.doi.org/10.1515/ling.1997.35.2.379												2026-01-16	WOS:A1997XC40000006
J	Luo, ZJ; Chen, JH; Takiguchi, T; Ariki, Y				Luo, Zhaojie; Chen, Jinhui; Takiguchi, Tetsuya; Ariki, Yasuo			Emotional voice conversion using neural networks with arbitrary scales F0 based on wavelet transform	EURASIP JOURNAL ON AUDIO SPEECH AND MUSIC PROCESSING				Article								An artificial neural network is an important model for training features of voice conversion (VC) tasks. Typically, neural networks (NNs) are very effective in processing nonlinear features, such as Mel Cepstral Coefficients (MCC), which represent the spectrum features. However, a simple representation of fundamental frequency (F0) is not enough for NNs to deal with emotional voice VC. This is because the time sequence of F0 for an emotional voice changes drastically. Therefore, in our previous method, we used the continuous wavelet transform (CWT) to decompose F0 into 30 discrete scales, each separated by one third of an octave, which can be trained by NNs for prosody modeling in emotional VC. In this study, we propose the arbitrary scales CWT (AS-CWT) method to systematically capture F0 features of different temporal scales, which can represent different prosodic levels ranging from micro-prosody to sentence levels. Meanwhile, the proposed method uses deep belief networks (DBNs) to pre-train the NNs that then convert spectral features. By utilizing these approaches, the proposed method can change the spectrum and the F0 for an emotional voice simultaneously as well as outperform other state-of-the-art methods in terms of emotional VC.												26	27											AUG 1	2017									18	10.1186/s13636-017-0116-2	http://dx.doi.org/10.1186/s13636-017-0116-2												2026-01-16	WOS:000410948600001
J	Alcock, KJ; Passingham, RE; Watkins, K; Vargha-Khadem, F				Alcock, KJ; Passingham, RE; Watkins, K; Vargha-Khadem, F			Pitch and timing abilities in inherited speech and language impairment	BRAIN AND LANGUAGE				Article								Members of the KE family who suffer from an inherited developmental speech-and-language disorder and normal, age-matched, controls were tested on musical abilities, including perception and production of pitch and rhythm. Affected family members were not deficient in either the perception or production of pitch, whether this involved either single notes or familiar melodies. However, they were deficient in both the perception and production of rhythm in both vocal and manual modalities. It is concluded that intonation abilities are not impaired in the affected family members, whereas their timing abilities are impaired. Neither their linguistic nor oral praxic deficits can be at the root of their impairment in timing; rather, the reverse may be true, (C) 2000 Academic Press.												85	95											OCT 15	2000	75	1					34	46		10.1006/brln.2000.2323	http://dx.doi.org/10.1006/brln.2000.2323												2026-01-16	WOS:000089952900003
J	Astésano, C; Bertrand, R				Astesano, Corine; Bertrand, Roxane			Stress and prosodic constituency in French: issues in phonology and speech processing	LANGUE FRANCAISE				Article								This article discusses the prosodic characteristics of French, in light of a metrical and perceptual analysis of various speaking styles. Our results lead us to propose the level of the prosodic word (pw) as the basic level of representation of French accentuation. This strong proposition, which has never been empirically attested to date, is based on two major results: listeners can perceive the final accent independently from intonation boundaries, at all levels of constituency; the processing of accentuation, particularly the initial accent, takes place at the lowest level of prosodic constituency (pw). The surface bipolar accentual demarcation of the lexical word invites us to reinterpret the status of accentuation in French and to question the notion of stress deafness in French.												3	3											SEP	2016		191					11	+															2026-01-16	WOS:000384960700002
J	Singh, P; Sahidullah, M; Saha, G				Singh, Premjeet; Sahidullah, Md; Saha, Goutam			Modulation spectral features for speech emotion recognition using deep neural networks	SPEECH COMMUNICATION				Article								This work explores the use of constant-Q transform based modulation spectral features (CQT-MSF) for speech emotion recognition (SER). The human perception and analysis of sound comprise of two important cognitive parts: early auditory analysis and cortex-based processing. The early auditory analysis considers spectrogram-based representation whereas cortex-based analysis includes extraction of temporal modulations from the spectrogram. This temporal modulation representation of spectrogram is called modulation spectral feature (MSF). As the constant-Q transform (CQT) provides higher resolution at emotion salient low -frequency regions of speech, we find that CQT-based spectrogram, together with its temporal modulations, provides a representation enriched with emotion-specific information. We argue that CQT-MSF when used with a 2-dimensional convolutional network can provide a time-shift invariant and deformation insensitive representation for SER. Our results show that CQT-MSF outperforms standard mel-scale based spectrogram and its modulation features on two popular SER databases, Berlin EmoDB and RAVDESS. We also show that our proposed feature outperforms the shift and deformation invariant scattering transform coefficients, hence, showing the importance of joint hand-crafted and self-learned feature extraction instead of reliance on complete hand-crafted features. Finally, we perform Grad-CAM analysis to visually inspect the contribution of constant-Q modulation features over SER.												42	47											JAN	2023	146						53	69		10.1016/j.specom.2022.11.005	http://dx.doi.org/10.1016/j.specom.2022.11.005		DEC 2022										2026-01-16	WOS:000899580800006
J	Fabianczyk, K				Fabianczyk, Karol			Decision making on ambiguous stimuli such as prosody by subjects suffering from paranoid schizophrenia, alcohol dependence, and without psychiatric diagnosis	BRITISH JOURNAL OF MATHEMATICAL & STATISTICAL PSYCHOLOGY				Article								The aim of this study is the empirical verification of the Bayesian approach applied to the description of the decision-making process with regard to prosodic stimuli in different psychopathological states. Using the Bayesian formalism, the interpretation of a disturbance in internal representation of the contextual information in schizophrenia was given. The results obtained satisfied the formula derived from Bayes' theorem in all tested except a schizophrenic group. Results were interpreted as reflecting cognitive flexibility, and discussed in the context of social adaptation. Although the investigation was based on psychopathological grounds, the results may be applied to the functioning of working memory in general.												0	0											FEB	2011	64	1					53	68		10.1348/000711010X492366	http://dx.doi.org/10.1348/000711010X492366												2026-01-16	WOS:000287345400004
J	LOOSEN, F				LOOSEN, F			INTONATION OF SOLO VIOLIN PERFORMANCE WITH REFERENCE TO EQUALLY TEMPERED, PYTHAGOREAN, AND JUST INTONATIONS	JOURNAL OF THE ACOUSTICAL SOCIETY OF AMERICA				Article								The purpose of this study was to deter-mine which musical scale best models the solo performances of violinists when they play diatonic scales of C major very slowly and without frequency vibrato as accurately as possible. Eight professional violinists played without stopping three adjacent scales in ascending order (from C4 to C7), followed immediately by an analogous return to the initial note C4 in descending order. Results show that when violin performances are analyzed taking into account the context of the scale in which they were played, Pythagorean and equally tempered scales are equally good models for the description of performances. Just intonation fits the data significantly less well. When the data analysis is limited to the intervals between separate pairs of notes, not taking into consideration the context of the scale in which they were played, observed interval sizes are almost identical to the arithmetic means of the corresponding interval sizes as defined in Pythagorean and equally tempered intonations. Octave intervals calculated by summing the sizes of performed adjacent major and minor seconds within octaves, show an average stretching of 3.9 cents. However, the arithmetic mean of computed interval sizes between two C's, deviates only 0.3 cents from the theoretical tonal extent of 1200 cents. Results suggest that when scales of C major are played, the tonic C is adopted as an absolute cognitive reference point.												22	35											JAN	1993	93	1					525	539		10.1121/1.405632	http://dx.doi.org/10.1121/1.405632												2026-01-16	WOS:A1993KG41500054
J	Dari, MW; Syahrani, A; Asfar, DA				Dari, Mika Wulan; Syahrani, Agus; Asfar, Dedy Ari			Collocations of Pria, Lelaki, and Jantan as Representations of Masculinity in Indonesia	GEMA ONLINE JOURNAL OF LANGUAGE STUDIES				Article								Language is one way to understand a society and its culture, including masculine norms. Exploring evolutionary masculinity through language is an intriguing concept to revisit. The research examines words synonymous with "men" in Indonesia and reviews their usage to depict current masculinity in the country. This research applied discourse analysis to corpora sourced from the Leipzig Corpora and CQPWeb. The data were analyzed using semantic preference to find meanings and semantic prosody to find connotations of pria, lelaki, and jantan. The findings reveal differences in the meanings and usage of the pria, lelaki, and jantan words. The difference in meaning is that pria is an adult male, whereas lelaki is a representation of men who are not limited in age, and jantan is interpreted as the genitals of animals or plants and men in the context of masculinity. According to usage, the word pria is frequently used in the public sphere, such as in the context of work and news discourse. Lelaki tends to be used more in the personal sphere, such as family, rather than in public settings. Jantan tends to be used in public discourse. The connotations of pria, lelaki, and jantan is neutral. This study successfully demonstrated the shift in Indonesian masculinity from traditional to new forms, indicating the impact of language studies on the analysis of masculinization in Indonesia.												1	1											NOV	2024	24	4					214	239		10.17576/gema-2024-2404-12	http://dx.doi.org/10.17576/gema-2024-2404-12												2026-01-16	WOS:001390728300012
J	Hert, R; Järvikivi, J; Arnhold, A				Hert, Regina; Jarvikivi, Juhani; Arnhold, Anja			The Importance of Linguistic Factors: He Likes Subject Referents	COGNITIVE SCIENCE				Article								We report the results of one visual-world eye-tracking experiment and two referent selection tasks in which we investigated the effects of information structure in the form of prosody and word order manipulation on the processing of subject pronouns er and der in German. Factors such as subject-hood, focus, and topicality, as well as order of mention have been linked to an increased probability of certain referents being selected as the pronoun's antecedent and described as increasing this referent's prominence, salience, or accessibility. The goal of this study was to find out whether pronoun processing is primarily guided by linguistic factors (e.g., grammatical role) or nonlinguistic factors (e.g., first-mention), and whether pronoun interpretation can be described in terms of referents' "prominence" / "accessibility" / "salience." The results showed an overall subject preference for er, whereas der was affected by the object role and focus marking. While focus increases the attentional load and enhances memory representation for the focused referent making the focused referent more available, ultimately it did not affect the final interpretation of er, suggesting that "prominence" or the related concepts do not explain referent selection preferences. Overall, the results suggest a primacy of linguistic factors in determining pronoun resolution.												4	4											APR 2	2024	48	4							e13436	10.1111/cogs.13436	http://dx.doi.org/10.1111/cogs.13436												2026-01-16	WOS:001195530200001
J	Wan, CY; Bazen, L; Baars, R; Libenson, A; Zipse, L; Zuk, J; Norton, A; Schlaug, G				Wan, Catherine Y.; Bazen, Loes; Baars, Rebecca; Libenson, Amanda; Zipse, Lauryn; Zuk, Jennifer; Norton, Andrea; Schlaug, Gottfried			Auditory-Motor Mapping Training as an Intervention to Facilitate Speech Output in Non-Verbal Children with Autism: A Proof of Concept Study	PLOS ONE				Article								Although up to 25% of children with autism are non-verbal, there are very few interventions that can reliably produce significant improvements in speech output. Recently, a novel intervention called Auditory-Motor Mapping Training (AMMT) has been developed, which aims to promote speech production directly by training he association between sounds and articulatory actions using intonation and bimanual motor activities. AMMT capitalizes on the inherent musical strengths of children with autism, and offers activities that they intrinsically enjoy. It also engages and potentially stimulates a network of brain regions that may be dysfunctional in autism. Here we report an initial efficacy study to provide 'proof of concept' for AMMT. Six non-verbal children with autism participated. Prior to treatment, the children had no intelligible words. They each received 40 individual sessions of AMMT 5 times per week, over an 8-week period. Probe assessments were conducted periodically during baseline, therapy, and follow-up sessions. After therapy, all children showed significant improvements in their ability to articulate words and phrases, with generalization to items that were not practiced during therapy sessions. Because these children had no or minimal vocal output prior to treatment, the acquisition of speech sounds and word approximations through AMMT represents a critical step in expressive language development in children with autism.												81	104											SEP 29	2011	6	9							e25505	10.1371/journal.pone.0025505	http://dx.doi.org/10.1371/journal.pone.0025505												2026-01-16	WOS:000295939600032
J	Türk, O; Calhoun, S				Tuerk, Olcay; Calhoun, Sasha			Multimodal cues to intonational categories: Gesture apex coordination with tonal events	LABORATORY PHONOLOGY				Article								This study argues for a multimodal view of the identification, representation, and implementation of intonational structure, with evidence from gesture apex-tone coordination in Turkish. Many studies have reported consistent synchronisation of atomic prominence markers across modalities (i.e., pitch accents and gesture apexes). This is prima facie evidence that gesture and prosody are implemented together, and therefore the former can play a role in the identification and perception of the latter through apex-tone synchronisation. However, only few studies considered the full intonational context when investigating synchronisation (e.g., potential alignment of apexes with boundary tones). This is particularly relevant for Turkish as there is disagreement in the literature about whether all words in Turkish bear a pitch accent. In this study, we test the synchronisation of apexes with all intonational events in Turkish natural speech data annotated for gesture and prosody, resulting in 820 gesture apex and 3697 tonal event annotations. The study uses syllable duration (160ms) to determine synchronisation between these anchors via equivalence tests while also integrating gestural and prosodic context as factors that can affect the temporal distance between these units through mixed-effects linear regression. The findings showed that apexes were chiefly synchronised with pitch accents (71%), indicating that prominence was the primary constraint for synchronisation. However, analysis of cases with no prosodic prominence provides the first evidence for a hierarchical constraint on synchronisation, since apexes were preferentially synchronised with the tones marking prosodic words (76%) and not with the markers of prosodic constituents higher in the hierarchy. This finding supports the claim that there may be accentless words in Turkish since the absence of prominence caused a systematic shift in the synchronisation behaviour of apexes. More generally, the study shows how multimodal evidence from gesture can be used in the identification of phonological categories, and that prosodic structure is likely to be expressed through multimodal cues as a composite signal.												4	4											APR 25	2023	14	1					1	50		10.16995/labphon.6432	http://dx.doi.org/10.16995/labphon.6432												2026-01-16	WOS:000982592900001
J	Lohmann, A; Conwell, E				Lohmann, Arne; Conwell, Erin			Phonetic effects of grammatical category: How category-specific prosodic phrasing and lexical frequency impact the duration of nouns and verbs	JOURNAL OF PHONETICS				Article								This paper is concerned with phonetic correlates of grammatical category, specifically the finding that nouns are pronounced with greater duration than verbs in discourse. Most previous research has attributed this difference to the sentence positions that the two grammatical categories occupy and concomitant prosodic effects. Based on previous findings, we test two further effects, namely a category-specific effect on prosodic phrasing, which leads to stronger prosodic boundaries after nouns than verbs even in maximally similar syntactic contexts, and a reductive effect of lexical frequency leading to shorter durations of the more frequent word. These effects are tested in a production study investigating durational differences of twelve noun verb homophone pairs in English in two clause-medial contexts. We find evidence for both effects: prosodic boundaries are stronger after nouns than verbs across all conditions, resulting in greater durations of nouns due to pre-boundary lengthening. Furthermore, differences in frequency result in a reduced duration of the homophone of the pair which has the greater frequency. We propose an explanation in which phonetic effects of grammatical category are caused by the interplay of sentence prosody, category-specific prosodic phrasing and lexical frequency. (C) 2019 Elsevier Ltd. All rights reserved.												7	9											JAN	2020	78								100939	10.1016/j.wocn.2019.100939	http://dx.doi.org/10.1016/j.wocn.2019.100939												2026-01-16	WOS:000510313500001
J	Kentner, G; Vasishth, S				Kentner, Gerrit; Vasishth, Shravan			Prosodic Focus Marking in Silent Reading: Effects of Discourse Context and Rhythm	FRONTIERS IN PSYCHOLOGY				Article								Understanding a sentence and integrating it into the discourse depends upon the identification of its focus, which, in spoken German, is marked by accentuation. In the case of written language, which lacks explicit cues to accent, readers have to draw on other kinds of information to determine the focus. We study the joint or interactive effects of two kinds of information that have no direct representation in print but have each been shown to be influential in the reader's text comprehension: (i) the (low-level) rhythmic-prosodic structure that is based on the distribution of lexically stressed syllables, and (ii) the (high-level) discourse context that is grounded in the memory of previous linguistic content. Systematically manipulating these factors, we examine the way readers resolve a syntactic ambiguity involving the scopally ambiguous focus operator auch (engl. "too") in both oral (Experiment 1) and silent reading (Experiment 2). The results of both experiments attest that discourse context and local linguistic rhythm conspire to guide the syntactic and, concomitantly, the focus-structural analysis of ambiguous sentences. We argue that reading comprehension requires the (implicit) assignment of accents according to the focus structure and that, by establishing a prominence profile, the implicit prosodic rhythm directly affects accent assignment.												21	26											MAR 8	2016	7								319	10.3389/fpsyg.2016.00319	http://dx.doi.org/10.3389/fpsyg.2016.00319												2026-01-16	WOS:000419621300001
J	SHAFFER, LH				SHAFFER, LH			TIMING IN MOTOR PROGRAMMING OF TYPING	QUARTERLY JOURNAL OF EXPERIMENTAL PSYCHOLOGY				Article								An abstract, structural representation in the motor programming of skilled performance may specify both a sequence of responses and expressive features of the sequence, such as timing, stress and intonation, which are mapped separately into the response output. In the case of typing, which does not require expressive features, it was previously assumed that response timing is governed more simply by a timekeeper providing a stochastically regular beat. Two sets of specially constructed texts were given to a fast typist and the results support the idea that skilled typing is paced by a regular beat. There were systematic rhythmic departures from the beat, which arose from contingencies of keyboard movement but were not the simple consequences of these; rather they may be regarded as structured anticipations of the contingencies, and as such are analogous to the expressive features of speech and playing music.												60	64												1978	30	MAY					333	345		10.1080/14640747808400680	http://dx.doi.org/10.1080/14640747808400680												2026-01-16	WOS:A1978FG98100012
J	Dehé, N; Samek-Lodovici, V				Dehe, Nicole; Samek-Lodovici, Vieri			On the prosody and syntax of DPs: evidence from Italian noun adjective sequences	NATURAL LANGUAGE & LINGUISTIC THEORY				Article; Proceedings Paper	Workshop on Nominatizations across Languages	NOV 29-DEC 01, 2007	Univ Stuttgart, Stuttgart, GERMANY		Univ Stuttgart			This study tests a syntactic property-namely the availability of N- vs. NP-raising in DPs-through prosodic means. The opposition between N- and NP-raising is central to the ongoing debate about the internal representation of DPs, yet it often eludes testing by syntactic means alone. As we show in this study, the two syntactic hypotheses are instead neatly distinguished by the distinct prosodic phrasing predicted by each operation. In this paper, we present the results of an empirical experiment designed to test the prosodic phrasing of N-A and A-N sequences in Italian and the corresponding syntactic implications. As prosodic cues, we use syllabic and word lengthening effects induced by phonological phrase boundaries. According to our results, A and N share the same phonological phrase in both orders. Regarding the syntactic implications of this finding, we show that under all current models of syntax-prosody mapping the underlying syntactic structure responsible for the attested prosodic phrasing must necessarily rely on N-raising. Finally, we propose an analysis of Italian DPs where the N-raising operation found necessary in light of the attested prosodic phrasing is reconciled with the evidence for DP-internal phrasal movement discussed in Cinque (2005 2006).												10	12											FEB	2009	27	1					45	75		10.1007/s11049-009-9063-7	http://dx.doi.org/10.1007/s11049-009-9063-7												2026-01-16	WOS:000263782600002
J	Hellbernd, N; Sammler, D				Hellbernd, Nele; Sammler, Daniela			Neural bases of social communicative intentions in speech	SOCIAL COGNITIVE AND AFFECTIVE NEUROSCIENCE				Article								Our ability to understand others' communicative intentions in speech is key to successful social interaction. Indeed, misunderstanding an 'excuse me' as apology, while meant as criticism, may have important consequences. Recent behavioural studies have provided evidence that prosody, that is, vocal tone, is an important indicator for speakers' intentions. Using a novel audio-morphing paradigm, the present functional magnetic resonance imaging study examined the neurocognitive mechanisms that allow listeners to 'read' speakers' intents from vocal prosodic patterns. Participants categorized prosodic expressions that gradually varied in their acoustics between criticism, doubt, and suggestion. Categorizing typical exemplars of the three intentions induced activations along the ventral auditory stream, complemented by amygdala and mentalizing system. These findings likely depict the stepwise conversion of external perceptual information into abstract prosodic categories and internal social semantic concepts, including the speaker's mental state. Ambiguous tokens, in turn, involved cingulo-opercular areas known to assist decision-making in case of conflicting cues. Auditory and decision-making processes were flexibly coupled with the amygdala, depending on prosodic typicality, indicating enhanced categorization efficiency of overtly relevant, meaningful prosodic signals. Altogether, the results point to a model in which auditory prosodic categorization and socio-inferential conceptualization cooperate to translate perceived vocal tone into a coherent representation of the speaker's intent.												34	36											JUN	2018	13	6					604	615		10.1093/scan/nsy034	http://dx.doi.org/10.1093/scan/nsy034												2026-01-16	WOS:000438330000005
J	Kreitewolf, J; Gaudrain, E; von Kriegstein, K				Kreitewolf, Jens; Gaudrain, Etienne; von Kriegstein, Katharina			A neural mechanism for recognizing speech spoken by different speakers	NEUROIMAGE				Article								Understanding speech from different speakers is a sophisticated process, particularly because the same acoustic parameters convey important information about both the speech message and the person speaking. How the human brain accomplishes speech recognition under such conditions is unknown. One view is that speaker information is discarded at early processing stages and not used for understanding the speech message. An alternative view is that speaker information is exploited to improve speech recognition. Consistent with the latter view, previous research identified functional interactions between the left- and the right-hemispheric superior temporal sulcus/gyrus, which process speech- and speaker-specific vocal tract parameters, respectively. Vocal tract parameters are one of the two major acoustic features that determine both speaker identity and speech message (phonemes). Here, using functional magnetic resonance imaging (fMRI), we show that a similar interaction exists for glottal fold parameters between the left and right Heschl's gyri. Glottal fold parameters are the other main acoustic feature that determines speaker identity and speech message (linguistic prosody). The findings suggest that interactions between left- and right-hemispheric areas are specific to the processing of different acoustic features of speech and speaker, and that they represent a general neural mechanism when understanding speech from different speakers. (C) 2014 Elsevier Inc. All rights reserved.												31	34											MAY 1	2014	91						375	385		10.1016/j.neuroimage.2014.01.005	http://dx.doi.org/10.1016/j.neuroimage.2014.01.005												2026-01-16	WOS:000338914100039
J	Lee, EH				Lee, EunHee			Aspectual and focus adverbs in English and Korean	NATURAL LANGUAGE & LINGUISTIC THEORY				Article								This article presents a comparative semantic analysis of the aspectual and focus adverbs already, still and STILL in English and imi/pelsse 'already' and acik/yothay 'still' in Korean based on their presuppositions and their focus interpretation. I argue that the two contrasting views of aspectual adverbs as logical duals (Lobner 1989, 1999) and as scalar (focus) particles (Michaelis 1993, 1996; Israel 1995) are both necessary in order to explain the English and Korean data. Aspect concerns the internal structure of events, relating a current state with the onset or the end of the state. These transitions are available for focusing, which triggers an explicit contrast between the asserted state and an alternative state with an opposite polarity. Korean is shown to lexicalize aspectual and focus adverbs differently from what is expressed in English by a single adverb with focus marked prosody. The meaning of aspectual and focus adverbs in both English and Korean is representated in Discourse Representation Theory (Kamp and Reyle 1993; van Eijck and Kamp 1997).												5	5											MAY	2008	26	2					339	358		10.1007/s11049-008-9035-3	http://dx.doi.org/10.1007/s11049-008-9035-3												2026-01-16	WOS:000258902400003
J	Borsos, Z; Marinier, R; Vincent, D; Kharitonov, E; Pietquin, O; Sharifi, M; Roblek, D; Teboul, O; Grangier, D; Tagliasacchi, M; Zeghidour, N				Borsos, Zalan; Marinier, Raphael; Vincent, Damien; Kharitonov, Eugene; Pietquin, Olivier; Sharifi, Matt; Roblek, Dominik; Teboul, Olivier; Grangier, David; Tagliasacchi, Marco; Zeghidour, Neil			AudioLM: A Language Modeling Approach to Audio Generation	IEEE-ACM TRANSACTIONS ON AUDIO SPEECH AND LANGUAGE PROCESSING				Article								We introduce AudioLM, a framework for high-quality audio generation with long-term consistency. AudioLM maps the input audio to a sequence of discrete tokens and casts audio generation as a language modeling task in this representation space. We show how existing audio tokenizers provide different trade-offs between reconstruction quality and long-term structure, and we propose a hybrid tokenization scheme to achieve both objectives. Namely, we leverage the discretized activations of a masked language model pre-trained on audio to capture long-term structure and the discrete codes produced by a neural audio codec to achieve high-quality synthesis. By training on large corpora of raw audio waveforms, AudioLM learns to generate natural and coherent continuations given short prompts. When trained on speech, and without any transcript or annotation, AudioLM generates syntactically and semantically plausible speech continuations while also maintaining speaker identity and prosody for unseen speakers. Furthermore, we demonstrate how our approach extends beyond speech by generating coherent piano music continuations, despite being trained without any symbolic representation of music.												232	247												2023	31						2523	2533		10.1109/TASLP.2023.3288409	http://dx.doi.org/10.1109/TASLP.2023.3288409										Y	N	2026-01-16	WOS:001025466100002
J	Duarte, AS; Padilha, SDJ				Duarte, Anderson Simao; Padilha, Simone de Jesus			RELATIONSHIP BETWEEN SIGN LANGUAGE AND PORTUGUESE LANGUAGE IN DIDACTIC MATERIALS: THE NOTATION BY THE SEMANTIC NUMBERS	REVISTA VIRTUAL DE ESTUDOS DA LINGUAGEM-REVEL				Article								This article intends to, in a way, present a short analysis of some national publications of books and educational material for the teaching of LIBRAS, focusing on the written representation of the Portuguese language for the teaching of sign language. On the other hand, this paper also shows a different proposal of notation that does not disregard the grammatical structure of the Portuguese language, which we call Semantic Numbers, present in the textbooks used for teaching LIBRAS to university students of Universidade Federal de Mato Grosso (UFMT). Solidifying this proposal, we will expose some concepts about language, themselves proposed by Russian thinker Mikhail Bakhtin and his Circle, among which we highlight the topics of language as interaction, utterance, intonation and theme.												3	4											AUG	2012	10	19					309	326															2026-01-16	WOS:000217778600016
J	Lewkowicz, DJ				Lewkowicz, DJ			Infants' response to the audible and visible properties of the human face .1. Role of lexical syntactic content, temporal synchrony, gender, and manner of speech	DEVELOPMENTAL PSYCHOLOGY				Article								Four-, 6-, and 8-month-old infants' perception of the multimodal features of the human face was investigated. First, infants were habituated to a visible and audible face of a person reciting a prepared script. Then they were tested by changing various features of just the audible, just the visible, or both components of the face. When features were changed, such as the lexical-syntactic content, the speaker's gender, or the synchrony relation between the audible and visible components, the infants discriminated their multimodal and visible representation but not the audible one. When the manner of speech was changed from adult- to infant-directed, the 2 older groups discriminated all 3 types of changes but the 4-month-old infants only discriminated its visible and multimodal representation. Results show that speech-related exaggerated prosody cues facilitate detection of the audible features of multimodally represented faces but not until 6 months of age.												46	51											MAR	1996	32	2					347	366		10.1037/0012-1649.32.2.347	http://dx.doi.org/10.1037/0012-1649.32.2.347												2026-01-16	WOS:A1996TZ43100015
J	Millotte, S; Morgan, J; Margules, S; Bernal, S; Dutat, M; Christophe, A				Millotte, Severine; Morgan, James; Margules, Sylvie; Bernal, Savita; Dutat, Michel; Christophe, Anne			Phrasal prosody constrains word segmentation in French 16-month-olds	JOURNAL OF PORTUGUESE LINGUISTICS				Article								Infants who are in the process of acquiring their mother tongue have to find a way of segmenting the continuous speech stream into word-sized units. We present an experiment showing that French 16-month-olds are able to exploit phonological phrase boundaries in order to constrain lexical access. Using the conditioned head-turning technique, we showed that infants trained to turn their head for a bisyllabic word responded more often to sentences that contained this word, than to sentences that contained both syllables of this word separated by a phonological phrase boundary. We compare these results with similar results obtained with English-speaking infants, and discuss their implication for lexical and syntactic acquisition.												4	6												2011	10	1					67	86		10.5334/jpl.101	http://dx.doi.org/10.5334/jpl.101												2026-01-16	WOS:000420493000004
S	Hoque, ME; Yeasin, M; Louwerse, MM		Gratch, J; Young, M; Aylett, R; Ballin, D; Olivier, P		Hoque, Mohammed E.; Yeasin, Mohammed; Louwerse, Max M.			Robust recognition of emotion from speech	INTELLIGENT VIRTUAL AGENTS, PROCEEDINGS	Lecture Notes in Artificial Intelligence			Article; Proceedings Paper	6th International Conference on Intelligent Virtual Agents	AUG 21-23, 2006	Marina del Rey, CA					This paper presents robust recognition of a subset of emotions by animated agents from salient spoken words. To develop and evaluate the model for each emotion from the chosen subset, both the prosodic and acoustic features were used to extract the intonational patterns and correlates of emotion from speech samples. The computed features were projected using a combination of linear projection techniques for compact and clustered representation of features. The projected features were used to build models of emotions using a set of classifiers organized in hierarchical fashion. The performances of the models were obtained using number of classifiers from the WEKA machine learning toolbox. Empirical analysis indicated that the lexical information computed from both the prosodic and acoustic features at word level yielded robust classification of emotions.												10	15												2006	4133						42	53															2026-01-16	WOS:000240268400004
J	Nikolsky, A				Nikolsky, Aleksey			Evolution of tonal organization in music mirrors symbolic representation of perceptual reality. Part-1: Prehistoric	FRONTIERS IN PSYCHOLOGY				Article								This paper reveals the way in which musical pitch works as a peculiar form of cognition that reflects upon the organization of the surrounding world as perceived by majority of music users within a socio-cultural formation. The evidence from music theory, ethnography, archeology, organology, anthropology, psychoacoustics, and evolutionary biology is plotted against experimental evidence. Much of the methodology for this investigation comes from studies conducted within the territory of the former USSR. To date, this methodology has remained solely confined to Russian speaking scholars. A brief overview of pitch-set theory demonstrates the need to distinguish between vertical and horizontal harmony, laying out the framework for virtual music space that operates according to the perceptual laws of tonal gravity. Brought to life by bifurcation of music and speech, tonal gravity passed through eleven discrete stages of development until the onset of tonality in the seventeenth century. Each stage presents its own method of integration of separate musical tones into an auditory-cognitive unity. The theory of "melodic intonation" is set forth as a counterpart to harmonic theory of chords. Notions of tonality, modality, key, diatonicity, chromaticism, alteration, and modulation are defined in terms of their perception, and categorized according to the way in which they have developed historically. Tonal organization in music, and perspective organization in fine arts are explained as products of the same underlying mental process. Music seems to act as a unique medium of symbolic representation of reality through the concept of pitch. Tonal organization of pitch reflects the culture of thinking, adopted as a standard within a community of music users. Tonal organization might be a naturally formed system of optimizing individual perception of reality within a social group and its immediate environment, setting conventional standards of intellectual and emotional intelligence.												14	15											OCT 16	2015	6								1405	10.3389/fpsyg.2015.01405	http://dx.doi.org/10.3389/fpsyg.2015.01405												2026-01-16	WOS:000363808400001
J	Gupta, C; Li, HZ; Goto, M				Gupta, Chitralekha; Li, Haizhou; Goto, Masataka			Deep Learning Approaches in Topics of Singing Information Processing	IEEE-ACM TRANSACTIONS ON AUDIO SPEECH AND LANGUAGE PROCESSING				Article								Singing, the vocal productionof musical tones, is one of the most important elements of music. Addressing the needs of real-world applications, the study of technologies related to singing voices has become an increasingly active area of research. In this paper, we provide a comprehensive overview of the recent developments in the field of singing information processing, specifically in the topics of singing skill evaluation, singing voice synthesis, singing voice separation, and lyrics synchronization and transcription. We will especially focus on deep learning approaches including modern representation learning techniques for singing voices. We will also provide an overview of contributions in public datasets for singing voice research.												10	12												2022	30						2422	2451		10.1109/TASLP.2022.3190732	http://dx.doi.org/10.1109/TASLP.2022.3190732												2026-01-16	WOS:000833754800007
J	DIEBOLD, G				DIEBOLD, G			IN PURSUIT OF THE OBJECT	PSYCHIATRIE DE L ENFANT				Article								The author proposes an extension of the transitional phenomenon concept. Begining with Winnicott's well known description, the author reviews the successive transformations of transitional space, first materialized and then increasingly (( intrapsychic )) and which persists in the individual all life long in various forms. Transformations go from the gross blanket to a more figurative little bear, then to play activities, creative drawing of the child, and finally to hypotheses and theories. This progressive hold on the object involves the mediation of transitional space-first found then created-and is instrumented through age-specific different means : concrete handling ; certain characteristics of baby-talk such as voice intonation, use of the past tense before playing and the conditional in playing ; redundancies, parentheses and abstractions. In the course of this paper, the author gives his personal view on the subtle differences between figuration and representation, and on the relationship between abstraction and aesthetical feeling.												0	0												1992	35	1					83	108															2026-01-16	WOS:A1992JF44100008
J	Nielsen, YA; Christiansen, MH				Nielsen, Yngwie A.; Christiansen, Morten H.			Context, not grammar, is key to structural priming	TRENDS IN COGNITIVE SCIENCES				Article								Structural priming - a change in processing after repeated exposure to a syntac-tic structure - has been put forward as evidence for the psychological reality of constituent structures derived from grammar. However, converging evidence from memory research, large language models (LLMs), and structural priming it-self challenges the validity of mapping structural representations onto grammat-ical constituents and demonstrates structural priming in the absence of such structure. Instead of autonomous representations specified by grammar, we pro-pose that contextual representations emerging from multiple constraints (e.g., words, prosody, gesture) underlie structural priming. This perspective ac-counts for existing anomalous findings, is supported by the strong dependence on lexical cues observed in structural priming, and suggests that future research should prioritize studying linguistic representations in more naturalistic contexts.												1	1											AUG	2025	29	8					703	714		10.1016/j.tics.2025.05.016	http://dx.doi.org/10.1016/j.tics.2025.05.016		AUG 2025										2026-01-16	WOS:001550617400006
J	Pérez-Gil, M; Tejada, J; Morant, R; De Martos, APG				Perez-Gil, Manuel; Tejada, Jesus; Morant, Remigi; Perez-Gonzalez De Martos, A.			Cantus: Construction and evaluation of a software solution for real-time vocal music training and musical intonation assessment	JOURNAL OF MUSIC TECHNOLOGY & EDUCATION				Article								The development of the ability to sing or play in tune is one of the most critical tasks in music training. In music education, melodic patterns are usually learned by imitative processes (modelling). Once modelled, pitch sounds are then associated to a representation according to a syllabic system such as the Guidonian system - or an arbitrary single syllable - or western graphic notation system symbols. From a didactic standpoint, few advances have been made in this area besides the use of audio-supported guides and existing software, which use a microphone to analyse the input and estimate the pitch or fundamental frequency of the given tone. However, these programmes lack the necessary analytical algorithm to provide the student with precise feedback on their execution; and also they do not provide adequate noise-robust solutions to minimize the student assessment error rate. The ongoing research discussed in this article focuses on Cantus, a new software solution expressly designed as an assessment and diagnosis tool for online training and assessment of vocal musical intonation at the initial stages of music education. Cantus software embodies the latest research on real-time analysis of audio stream, which permits the teacher to customize music training by means of recording patterns and embedding them into the programme. The study presented in this article includes the design, implementation and assessment of Cantus by music teachers. The pilot study for the software assessment includes a sample of 21 music teachers working at thirteen music schools in Valencia, Spain. These teachers worked with the software at their own pace for a week in order to evaluate it. Subsequently, a two-part questionnaire was filled in with (1) questions related to demographics, professional experience and the use of ITC; and (2) questions related to the software's technical and didactic aspects. The questionnaire also included three open questions related to Cantus, namely advantages, issues and suggestions. The results show an excellent reception by teachers, who consider this software as a highly adequate music training tool at the initial stages of music education.												20	26											JUL 1	2016	9	2					125	144		10.1386/jmte.9.2.125_1	http://dx.doi.org/10.1386/jmte.9.2.125_1												2026-01-16	WOS:000409307400002
J	Tsai, FS; Chang, WW; Lee, CC				Tsai, Fu-Sheng; Chang, Wei-Wen; Lee, Chi-Chun			A Social Condition-Enhanced Network for Recognizing Power Distance Using Expressive Prosody and Intrinsic Brain Connectivity	IEEE TRANSACTIONS ON MULTIMEDIA				Article								Culture is the social norm that often dictates a person's thoughts, decision-making, and social behaviors during interaction at an individual level. In this study, we present a computational framework that automatically assesses an individual culture attribute of power distance (PDI), i.e., the measure to describe one's acceptance of social status, power and authority in organizations through multimodal modeling of a participant's expressive prosodic structures and brain connectivity using a social condition-enhanced network. In specific, we propose a joint learning approach of center-loss embedding network architecture that learns to "centerize" the embedding space given a particular social interaction condition to enhance the PDI discriminability of the representation. Our proposed method achieves 88.5% and 73.1% in binary classification task of recognizing low versus high power distance on prosodic and fMRI modality separately. After performing multimodal fusion, it improves to 96.2% of 2-class recognition rate (7.7% relative improvement). Further analyses reveal that average and standard deviation of speech energy are significantly correlated with power distance index; the right middle cingulate cortex (MCC) of brain region achieves the best recognition accuracy demonstrating its role in processing a person's belief about power distance.												2	2												2022	24						2046	2057		10.1109/TMM.2021.3075091	http://dx.doi.org/10.1109/TMM.2021.3075091												2026-01-16	WOS:000778959200021
J	Norris, D; Cutler, A; McQueen, JM; Butterfield, S				Norris, Dennis; Cutler, Anne; McQueen, James M.; Butterfield, Sally			Phonological and conceptual activation in speech comprehension	COGNITIVE PSYCHOLOGY				Article								We propose that speech comprehension involves the activation of token representations of the phonological forms of current lexical hypotheses, separately from the ongoing construction of a conceptual interpretation of the current utterance. In a series of cross-modal priming experiments, facilitation of lexical decision responses to visual target words (e.g., time) was found for targets that were semantic associates of auditory prime words (e.g., date) when the primes were isolated words, but not when the same primes appeared in sentence contexts. Identity priming (e.g., faster lexical decisions to visual date after spoken date than after an unrelated prime) appeared, however, both with isolated primes and with primes in prosodically neutral sentences. Associative priming in sentence contexts only emerged when sentence prosody involved contrastive accents, or when sentences were terminated immediately after the prime. Associative priming is therefore not an automatic consequence of speech processing. In no experiment was there associative priming from embedded words (e.g., sedate-time), but there was inhibitory identity priming (e.g., sedate-date) from embedded primes in sentence contexts. Speech comprehension therefore appears to involve separate distinct activation both of token phonological word representations and of conceptual word representations. Furthermore, both of these types of representation are distinct from the long-term memory representations of word form and meaning. (c) 2006 Elsevier Inc. All rights reserved.												68	82											SEP	2006	53	2					146	193		10.1016/j.cogpsych.2006.03.001	http://dx.doi.org/10.1016/j.cogpsych.2006.03.001												2026-01-16	WOS:000240666500002
J	Grygiel, M				Grygiel, Marcin			Affirmation as a type of modality: evidence from Serbian and English	ZEITSCHRIFT FUR SLAWISTIK				Article								The aim of the paper is to present modes of grammatical representation of affirmation in Serbian and English. I will explore the hypothesis that affirmation is a type of modality and its expression involves syntactic and morphological markers. The formal expression of strong types of affirmation modality is characterized by the preference for long, full and stressed variants of modal auxiliaries Alternatively, affirmative verb forms may be intensified by additional suprasegmental elements, such as intonation, or even paralinguistic tools, gestures and non-verbal ways of reinforcing a statement. This seems to confirm the general function-form isomorphism requiring the more complex mental events to be represented by more complex structures. I will argue that this requirement may initiate the process of auxiliation, perceived as a search to find a more adequate means for expressing affirmation modality.												0	0												2013	58	2					143	168		10.1524/slaw.2013.0014	http://dx.doi.org/10.1524/slaw.2013.0014												2026-01-16	WOS:000322047900002
J	Marques, C; Moreno, S; Castro, SL; Besson, M				Marques, Carlos; Moreno, Sylvain; Castro, Sio Luis; Besson, Mireille			Musicians detect pitch violation in a foreign language better than nonmusicians: Behavioral and electrophysiological evidence	JOURNAL OF COGNITIVE NEUROSCIENCE				Article								The aim of this study was to determine whether musical expertise influences the detection of pitch variations in a foreign language that participants did not understand. To this end, French adults, musicians and nonmusicians, were presented with sentences spoken in Portuguese. The final words of the sentences were prosodically congruous (spoken at normal pitch height) or incongruous (pitch was increased by 35% or 120%). Results showed that when the pitch deviations were small and difficult to detect (35%: weak prosodic incongruities), the level of performance was higher for musicians than for nonmusicians. Moreover, analysis of the time course of pitch processing, as revealed by the event-related brain potentials to the prosodically congruous and incongruous sentence-final words, showed that musicians were, on average, 300 msec faster than nonmusicians to categorize prosodically congruous and incongruous endings. These results are in line with previous ones showing that musical expertise, by increasing discrimination of pitch-a basic acoustic parameter equally important for music and speech prosody-does facilitate the processing of pitch variations not only in music but also in language. Finally, comparison with previous results [Schon, D., Magne, C., & Besson, M. The music of speech: Music training facilitates pitch processing in both music and language. Psychophysiolog, 41, 341-349, 2004] points to the influence of semantics on the perception of acoustic prosodic cues.												200	238											SEP	2007	19	9					1453	1463		10.1162/jocn.2007.19.9.1453	http://dx.doi.org/10.1162/jocn.2007.19.9.1453												2026-01-16	WOS:000249251100003
J	Pataca, CD; Costa, PDP				Pataca, Calua de Lacerda; Costa, Paula Dornhofer Paro			Hidden Bawls, Whispers, and Yelps: Can Text Convey the Sound of Speech, Beyond Words?	IEEE TRANSACTIONS ON AFFECTIVE COMPUTING				Article								Whether a word was bawled, whispered, or yelped, captions will typically represent it in the same way. If they are your only way to access what is being said, subjective nuances expressed in the voice will be lost. Since so much of communication is carried by these nuances, we posit that if captions are to be used as an accurate representation of speech, embedding visual representations of paralinguistic qualities into captions could help readers use them to better understand speech beyond its mere textual content. This paper presents a model for processing vocal prosody (its loudness, pitch, and duration) and mapping it into visual dimensions of typography (respectively, font-weight, baseline shift, and letter-spacing), creating a visual representation of these lost vocal subtleties that can be embedded directly into the typographical form of text. An evaluation was carried out where participants were exposed to this speech-modulated typography and asked to match it to its originating audio, presented between similar alternatives. Participants (n=117) were able to correctly identify the original audios with an average accuracy of 65%, with no significant difference when showing them modulations as animated or static text. Additionally, participants' comments showed their mental models of speech-modulated typography varied widely.												9	9											JAN 1	2023	14	1					6	16		10.1109/TAFFC.2022.3174721	http://dx.doi.org/10.1109/TAFFC.2022.3174721												2026-01-16	WOS:000966036500001
J	Büring, D				Buering, Daniel			A theory of second occurrence focus	LANGUAGE COGNITION AND NEUROSCIENCE				Article								This paper proposes to analyse second occurrence foci as foci whose domain is properly contained in the background of another focus domain, and linearly follows the last focus of that domain. It is shown that general assumptions about the representation and prosodic realisation of focus predict that foci with these properties will be realised by stress, but not pitch accent, i.e. as second occurrence foci. Furthermore, whether a focus domain is subordinated in this sense follows from general principles of focus assignment and interpretation. No assumptions specific to second occurrence foci are required to explain the phenomenon. The analysis relies on, and thus indirectly supports, the assumptions that focus/background, rather than new/given are the relevant concepts in stress and accent assignment, and that focus realisation is mediated by prosodic, particularly metrical, structure.												9	11											FEB 7	2015	30	1-2			SI		73	87		10.1080/01690965.2013.835433	http://dx.doi.org/10.1080/01690965.2013.835433												2026-01-16	WOS:000350338900005
J	FERREIRA, F				FERREIRA, F			CREATION OF PROSODY DURING SENTENCE PRODUCTION	PSYCHOLOGICAL REVIEW				Article								Phrase-final words tend to be lengthened and followed by a pause. The dominant view of prosodic production is that word lengthening and pausing reflect the syntax of a sentence. The author demonstrates that, instead, lengthening and pausing reflect a distinctly prosodic representation, in which phonological constituents are arranged in a hierarchical, nonrecursive structure. Prosodic structure is created without knowledge of words' phonemic content. As a result, within a single sentential position, greater word lengthening necessitates shorter pauses, but across positions, word and pause durations show a positive correlation. The author presents a model of prosodic production that describes the process of prosodic encoding and provides a quantitative specification of the relation between word lengthening and pausing. This model has implications for studies of language production, comprehension, and development.												177	215											APR	1993	100	2					233	253		10.1037/0033-295X.100.2.233	http://dx.doi.org/10.1037/0033-295X.100.2.233												2026-01-16	WOS:A1993KZ79600004
J	Shymko, V				Shymko, Vitalii			Personality Profiling Through Language: Assessment Techniques for Big Five Traits in Psycholinguistic Perspective	PSYCHOLINGUISTICS				Article								Purpose. The present paper aims to systematically examine contemporary approaches to personality assessment based on linguistic and paralinguistic indicators, with a specific focus on the Big Five trait model. The study addresses a growing interdisciplinary demand for theoretically grounded, empirically validated, and practically applicable methodologies in the domain of indirect personality profiling. The central objective is to map the modalities, feature types, computational methods, and personality traits targeted in empirical research published between 2017 and 2025. Methods. A systematic search was conducted using the Scopus database, yielding an initial set of publications screened according to defined inclusion criteria: empirical design, and direct relevance to Big Five trait recognition using linguistic or paralinguistic data. The final sample comprised 20 studies. Each entry was coded along four analytic dimensions: (1) modality (text, speech, or multimodal); (2) indicator type (linguistic, paralinguistic, or both); (3) trait representation (explicit Big Five or inferred); and (4) computational methodology (psychometrics, statistical modeling, machine learning, deep learning). Descriptive and thematic synthesis procedures were applied. Results. The analysis revealed a dominance of linguistic indicators, particularly lexical and syntactic features extracted from text-based data such as social media posts or self-descriptions. Paralinguistic indicators-such as prosody, intonation, and speech rhythm-were significantly underrepresented, despite evidence of their predictive value. Only a small subset of studies employed multimodal models. Deep learning architectures were used in a limited number of cases but showed promising accuracy and interpretability when combined with trait-specific embeddings. Extraversion and neuroticism were the most frequently assessed traits, with agreeableness and conscientiousness comparatively neglected. A trend toward integrating AI-generated linguistic items into psychometric scale construction was also observed. Conclusions. Current research on psycholinguistic personality profiling reflects significant methodological innovation but also conceptual and technical fragmentation. The field would benefit from standardized assessment protocols, shared benchmarking datasets, and increased attention to underrepresented traits and modalities. In particular, future studies should explore multimodal modeling, trait-specific feature calibration, and ethically robust implementation frameworks. The review highlights substantial translational potential for these methods in forensic psychology, human-computer interaction, organizational diagnostics, and digital mental health.												0	0												2025	38	1								10.31470/2309-1797-2025-38-1-175-192	http://dx.doi.org/10.31470/2309-1797-2025-38-1-175-192												2026-01-16	WOS:001638166300007
J	Terao, Y; Ugawa, Y; Yamamoto, T; Sakurai, Y; Masumoto, T; Abe, O; Masutani, Y; Aoki, S; Tsuji, S				Terao, Yasuo; Ugawa, Yoshikazu; Yamamoto, Tomotaka; Sakurai, Yasuhisa; Masumoto, Tomohiko; Abe, Osamu; Masutani, Yoshitaka; Aoki, Shigeki; Tsuji, Shoji			Primary face motor area as the motor representation of articulation	JOURNAL OF NEUROLOGY				Article								No clinical data have yet been presented to show that a lesion localized to the primary motor area (M1) can cause severe transient impairment of articulation, although a motor representation for articulation has been suggested to exist within M1. Here We describe three cases of patients who developed severe dysarthria, temporarily mimicking speech arrest or aphemia, due to a localized brain lesion near the left face representation of the human primary motor cortex (face-M1). Speech was slow, effortful, lacking normal prosody, and more affected than expected from the degree of facial or tongue palsy. There was a mild deficit in tongue movements in the sagittal plane that impaired palatolingual contact and rapid tongue movements. The speech disturbance was limited to verbal output, without aphasia or orofacial apraxia. Overlay of magnetic resonance images revealed a localized cortical region near face-M1, which displayed high intensity on diffusion weighted images, while the main portion of the corticobulbar fibers arising from the lower third of the motor cortex was preserved. The cases suggest the existence of a localized brain region specialized for articulation near face-M1. Cortico-cortical fibers connecting face-M1 with the lower premotor areas including Broca's area may also be important for articulatory control.												24	25											APR	2007	254	4					442	447		10.1007/s00415-006-0385-7	http://dx.doi.org/10.1007/s00415-006-0385-7												2026-01-16	WOS:000246303800005
J	Syrett, K; Kawahara, S				Syrett, Kristen; Kawahara, Shigeto			Production and perception of listener-oriented clear speech in child language	JOURNAL OF CHILD LANGUAGE				Article								In this paper, we ask whether children are sensitive to the needs of their interlocutor, and, if so, whether they - like adults - modify acoustic characteristics of their speech as part of a communicative goal. In a production task, preschoolers participated in a word learning task that favored the use of clear speech. Children produced vowels that were longer, more intense, more dispersed in the vowel space, and had a more expanded F. range than normal speech. Two perception studies with adults showed that these acoustic differences were perceptible and were used to distinguish normal and clear speech styles. We conclude that preschoolers are sensitive to aspects of the speaker-hearer relationship calling upon them to modify their speech in ways that benefit their listener.												13	14											NOV	2014	41	6					1373	1389		10.1017/S0305000913000482	http://dx.doi.org/10.1017/S0305000913000482												2026-01-16	WOS:000342918600008
J	Isel, F; Gunter, TC; Friederici, AD				Isel, F; Gunter, TC; Friederici, AD			Prosody-assisted head-driven access to spoken German compounds	JOURNAL OF EXPERIMENTAL PSYCHOLOGY-LEARNING MEMORY AND COGNITION				Article								Auditory processing of German 2-noun compound words was investigated with 328 participants in 4 experiments by monitoring semantic priming effects of the left constituents of the compound words. The authors demonstrated that there is no primacy of the left constituents in accessing auditorily presented German compound words in the mental lexicon. A clear priming effect of left constituents occurred only for compound words with a transparent right constituent that is the head of compound words in Germanic languages. The data suggest that the access to German compounds in the auditory domain involves 2 temporally overlapping routes: direct and decompositional. The prosodic structure (i.e., the duration) of the first morphemes of compound words appears to be a determining factor for activation of the decompositional route.												47	54											MAR	2003	29	2					277	288		10.1037/0278-7393.29.2.277	http://dx.doi.org/10.1037/0278-7393.29.2.277												2026-01-16	WOS:000181875500009
J	Begicheva, OV; Kazantseva, LP				Begicheva, Olga, V; Kazantseva, Liudmila P.			The National-Historical Ballad in the Musical Art of Romanticism: Towards Posing the Problem	PROBLEMY MUZYKALNOI NAUKI-MUSIC SCHOLARSHIP				Article								As the result of systematic analysis of the romantic of the two branches ballad genre, the taboo and the national-historical ones, their affinity (their narrative qualities, dramatic substance and incorporation of the fantastic element) and the individual signs of the national-historical genre model are distinguished. Examination is made of its genre-related phenomenological markers: the genre code "The Human Being and the Historical Tragedy of the People"; the general intonation of the Nordic sublime genre of; the protagonists are - the hero, his beloved and the narrator. Carrying out the search for the archetypal regular laws in the storylines, the motive complexes the genre-related semantic lines of character of the heroes in the archetypal construction of the genre on the level of composition and dramaturgy, the authors arrive at the conclusion that the national-historical ballad, while preserving its logical-structural content, converts the "general intonation" of the genre, supplanting the category of irrational fear. The heroes of the ballad receive a "reversing": the infernal newcomer is replaced by the warrior, the narrator - by the singer-prophet, and the self-sacrificing beloved - by the heroic maiden. On the basis of analysis of works by John Blackwood McEwen, Arnold Bax, Horatio Parker, Gerard Bunk and Franz Poenitz the methods of musical representation of the mentioned heroes are examined. It is noted that in the mature formation of the genre each hero becomes attributed with a stable lexical-intonational sphere. The battle, panegyric and heroic-dramatic style present the distinctive features of the warrior, the female lamentation and Nordic landscape comprise the musical portrait of the maid of the North, whereas the musical "emblem" of the bard is taken on by the odic and song-narrative style.												0	0												2019		4					205	215		10.17674/1997-0854.2019.4.205-215	http://dx.doi.org/10.17674/1997-0854.2019.4.205-215												2026-01-16	WOS:000504041400021
J	Lemarié, J; Eyrolle, H; Cellier, JM				Lemarié, J; Eyrolle, H; Cellier, JM			Visual signals in text comprehension:: How to restore them when oralizing a text via a speech synthesis?	COMPUTERS IN HUMAN BEHAVIOR				Article								It has been assumed theoretically and established empirically that text signals exert an influence on text memorization and comprehension. The study investigates whether the restoration of the text visual signals improve text memorization and comprehension when automatically converting a text into speech. Participants listened to a restaurant menu oralized by a text-to-speech synthesis. The visual signals used in the menu were restored either with discursive segments, with prosodic cues, or with a picture of text, displayed before or during the listening. Participants had to perform tasks assessing their text memorization and comprehension. The restoration of text visual signals exerts an influence on the participants' recall but these effects vary according to the restoration mean used and to the task. When visual signals are not restored, individuals construct an erroneous representation of the situation described in the text leading to a misinterpretation of the text meaning, whereas the discursive and prosodic restorations involve the construction of an adequate representation. (c) 2006 Elsevier Ltd. All rights reserved.												10	11											NOV	2006	22	6					1096	1115		10.1016/j.chb.2006.02.013	http://dx.doi.org/10.1016/j.chb.2006.02.013												2026-01-16	WOS:000238733100014
J	Karimullah, K				Karimullah, Kamran			Sketching women: a corpus-based approach to representations of women's agency in political Internet corpora in Arabic and English	CORPORA				Article								In this paper, I use methods from corpus linguistics to examine patterns pertaining to the representation of women in online Arabic- and English-language political corpora. I highlight the discursive differences and similarities that characterise the two corpora. Using word sketches, I identify representational categories in each corpus that are indexed by patterns of collocation. Analysis of semantic preference and prosody in each corpus reveals the ways in which women are represented. An exploration of the representations of women and gendered agency in both corpora reveals incongruities between the message of women's empowerment that the outlets promote and the implicit discursive representations of gender and gendered agency.												17	19											APR	2020	15	1					21	53		10.3366/cor.2020.0184	http://dx.doi.org/10.3366/cor.2020.0184												2026-01-16	WOS:000583426400002
J	Kim, SS				Kim, Sung-Suk			Automatic Recognition of Pitch Accent Using Distributed Time-Delay Recursive Neural Network	JOURNAL OF THE ACOUSTICAL SOCIETY OF KOREA				Article								This paper presents a method for the automatic recognition of pitch accents over syllables. The method that we propose is based on the time-delay recursive neural network (TDRNN), which is a neural network classifier with two different representation of dynamic context: the delayed input nodes allow the representation of an explicit trajectory FO (t) along time, while the recursive nodes provide long-term context information that reflects the characteristics of pitch accentuation in spoken English. We apply the TDRNN to pitch accent recognition in two forms: in the normal TDRNN, all of the prosodic features (pitch, energy, duration) are used as an entire set in a single TDRNN, while in the distributed TDRNN, the network consists of several TDRNNs each taking a single prosodic feature as the input. The final output of the distributed TDRNN is weighted sum of the output of individual TDRNN. We used the Boston Radio News Corpus (BRNC) for the experiments on the speaker-independent pitch accent recognition. The experimental results show that the distributed TDRNN exhibits an average recognition accuracy of 83.64% over both pitch events and non-events.												0	0											AUG	2006	25	6					277	281															2026-01-16	WOS:000409872700003
J	Hathaway, Y				Hathaway, Yulia			"They Made us into a Race. We Made Ourselves into a People": A Corpus Study of Contemporary Black American Group Identity in the Non-Fictional Writings of Ta-Nehisi Coates	CORPUS PRAGMATICS				Article								This article examines representations of contemporary Black American identity in the non-fictional writings of Ta-Nehisi Coates. The dataset is a self-compiled specialized corpus of Coates's non-fictional writings from 1996 until 2018 (350 texts; 468,899 words). The study utilizes an interdisciplinary approach combining corpus linguistics and corpus pragmatics. Frequencies of five identity-related terms in the corpus (African(-)Americans, blacks, black people, black America/Americans and black community/communities) are compared diachronically; then the pragmatic prosody of the terms is analyzed via the notion of control. The findings suggest that Coates's representation of Black American group identity has shifted over time. Specifically, the terms African Americans and black America are replaced by the terms blacks and black people. The study's empirical findings, considered through the theoretical framework on Black solidarity, suggest a shift in representation of group identity in Coates's writings from an identity based on cultural and ethnic commonalities to an identity based on the shared experiences of anti-Black racism.												2	5											SEP	2021	5	3					313	334		10.1007/s41701-021-00101-8	http://dx.doi.org/10.1007/s41701-021-00101-8												2026-01-16	WOS:000687608500001
J	Gotzner, N; Spalek, K				Gotzner, Nicole; Spalek, Katharina			The life and times of focus alternatives: Tracing the activation of alternatives to a focused constituent in language comprehension	LANGUAGE AND LINGUISTICS COMPASS				Article								The function of focus is to activate a set of alternatives, providing the locus for focus-sensitive particles like only. In the past decade, psycholinguistic research has shown that listeners entertain a set of alternatives in online language comprehension, similar to the algorithm stipulated by Alternative Semantics. The purpose of the present review is to gain a comprehensive picture of the role of focus alternatives in utterance comprehension and interpretation. Specifically, we focus on how the processing of focus particles interacts with alternatives activated by focus. We show that focus marking activates a network of related concepts, but over time, only those that can be considered as focus alternatives in the relevant context of the utterance are retained in the mental representation of the discourse. Focus particles, in turn, increase the competition between the focused element and its alternatives during the initial stages of comprehension, helping contextual restriction of the set of alternatives. Overall, the studies presented in this review show that focus does not only guide a listener in determining which alternatives are relevant for the purpose of conversation, it also plays a fundamental role in the memory representation of a discourse.												17	20											FEB	2019	13	2							e12310	10.1111/lnc3.12310	http://dx.doi.org/10.1111/lnc3.12310												2026-01-16	WOS:000459515300001
J	Moneta, ME; Penna, M; Loyola, H; Buchheim, A; Kächele, H				Moneta, Maria E.; Penna, Mario; Loyola, Hugo; Buchheim, Anna; Kaechele, Horst			Measuring emotion in the voice during psychotherapy interventions: A pilot study	BIOLOGICAL RESEARCH				Article								The voice as a representation of the psychic world of patients in psychotherapeutic interventions has not been studied thoroughly, To explore speech prosody in relation to the emotional content of words, voices recorded during a semi-structured interview were analyzed. The subjects had been classified according to their childhood emotional experiences with caregivers and their different attachment representations. In this pilot study, voice quality as spectral parameters extracted from vowels of the key word "mother" (German: "Mutter") were analyzed. The amplitude of the second harmonic was large relative to the amplitude of the third harmonic for the vowel "u" in the secure group as compared to the preoccupied group. Such differences might be related to the subjects' emotional involvement during an interview eliciting reconstructed childhood memories.												4	7												2008	41	4					389	395															2026-01-16	WOS:000264574400004
J	Menn, L; Duffield, CJ				Menn, Lise; Duffield, Cecily Jill			Aphasias and theories of linguistic representation: representing frequency, hierarchy, constructions, and sequential structure	WILEY INTERDISCIPLINARY REVIEWS-COGNITIVE SCIENCE				Article								Error and preservation patterns in aphasic speech show that the brain makes use of the frequencies of words, constructions, and collocations, as well as category membership and hierarchical structure, during language processing. Frequency effects are evident along two quasi-independent axes: syntagmatic (the sequential context, e.g., deploying correct functors, categories, and utterance-level intonation) and paradigmatic (the choice at any given linguistic level, e.g., selecting content words and modifying structures). Frequency along the syntagmatic axis is shown to play a role in errors involving idioms, constructions, and collocations that cross major phrasal boundaries. Along the paradigmatic axis, frequency affects errors involving lexical selection, competing functors and inflected forms (e.g., using plural where singular is required). An account of language representation and processing that encompasses frequency as well as categorization and structure is compatible with what we know about how the brain works: increased experience with a linguistic structure results in increased activationand strengtheningof the neural networks involved in processing that structure. These claims are supported by the literature on experimental work in normal speakers. Parsimony, plus the unexamined assumption that mental representation is like a written record (entries either present or absent, structure displayable in two dimensions), has been a misleading guide to modeling language representation. The substantial redundancy in representations and processing that is introduced by incorporating both frequency-based and hierarchy-based information is in fact appropriate for the brain as a fast, reliable, massively parallel error-correcting network with very large storage capacity and gradient representation strength. (C) 2013 John Wiley & Sons, Ltd. WIREs Cogn Sci 2013, 4:651-663. doi: 10.1002/wcs.1257 Conflict of interest: The authors have declared no conflicts of interest for this article. For further resources related to this article, please visit the WIREs website.												10	10											NOV	2013	4	6					651	663		10.1002/wcs.1257	http://dx.doi.org/10.1002/wcs.1257												2026-01-16	WOS:000325623200006
J	Prieto, P; D'Imperio, M; Fivela, BG				Prieto, Pilar; D'Imperio, Mariapaola; Fivela, Barbara Gili			Pitch accent alignment in romance: Primary and secondary associations with metrical structure	LANGUAGE AND SPEECH				Article; Proceedings Paper	Workshop on Typology of Tone and Intonation	APR 01-03, 2004	Cascais, PORTUGAL					The article describes the contrastive possibilities of alignment of high accents in three Romance varieties, namely, Central Catalan, Neapolitan Italian, and Pisa Italian. The Romance languages analyzed in this article provide crucial evidence that small differences in alignment in rising accents should be encoded phonologically. To account for such facts within the AM model, the "phonological anchoring'' as an extension of article develops the notion of the concept of secondary association originally proposed by Pierrehumbert and Beckman (1988), and later adopted by Grice (1995), Grice, Ladd, and Arvaniti (2000), and others to explain the behavior of edge tones. The Romance data represent evidence that not only peripheral edge tones seek secondary associations. We claim that the phonological representation of pitch accents should include two independent mechanisms to encode alignment properties with metrical structure: (1) encoding of the primary phonological association (or affiliation) between the tone and its tone-bearing unit; and (2), for some specific cases, encoding of the secondary phonological anchoring of tones to prosodic edges (moras, syllables, and prosodic words). The Romance data described in the article provide crucial evidence of mora-edge, syllable-edge, and word-edge H tonal associations.												67	81												2005	48		4		SI		359	396		10.1177/00238309050480040301	http://dx.doi.org/10.1177/00238309050480040301												2026-01-16	WOS:000237621300003
J	Lester, NA; Katsika, A				Lester, Nicholas A.; Katsika, Argyro			The Syntactic Pasts of Nouns Shape Their Prosodic Future: Lexico-Syntactic Effects on Position and Duration	LANGUAGE AND SPEECH				Article								Phrasal prosody is often viewed as a level of linguistic representation at which the phonetic profile of an utterance varies independently of the lexical items it contains. For example, the same word, when produced at the edges of prosodic phrases, will take longer to produce than when it is produced within the edges of a phrase. Lengthening effects have also been found for words when placed in different syntactic or lexical contexts. Recent evidence suggests that lexico-syntactic information-for example, the global syntactic distributions of words-affects phonetic duration in production, irrespective of other factors. The present study asks whether these lexico-syntactic effects on duration interact with prosodic position within the phrase. Specifically, we ask whether (a) the lexico-syntactic information of a word determines its prosodic position, and (b) whether, beyond any categorical effects on positioning, lexico-syntactic factors affect duration within prosodic positions. We address these questions using the Santa Barbara Corpus of Spoken American English. We operationalize syntactic information as the diversity and the typicality of the syntactic distributions of nouns based on a dependency parse of the British National Corpus. We find that earlier positions in the prosodic phrase generally prefer words with higher syntactic diversity. In addition, diversity and typicality modulate duration more reliably in nonfinal positions. Together, our results point to an early influence of lexico-syntactic considerations on prosodic planning.												0	0											SEP	2024	67	3					639	675		10.1177/00238309231177884	http://dx.doi.org/10.1177/00238309231177884		JUL 2023										2026-01-16	WOS:001022326900001
J	Mattavelli, G; Pisoni, A; Casarotti, A; Comi, A; Sera, G; Riva, M; Bizzi, A; Rossi, M; Bello, L; Papagno, C				Mattavelli, Giulia; Pisoni, Alberto; Casarotti, Alessandra; Comi, Alessandro; Sera, Giada; Riva, Marco; Bizzi, Alberto; Rossi, Marco; Bello, Lorenzo; Papagno, Costanza			Consequences of brain tumour resection on emotion recognition	JOURNAL OF NEUROPSYCHOLOGY				Article								Emotion processing impairments are common in patients undergoing brain surgery for fronto-temporal tumour resection, with potential consequences on social interactions. However, evidence is controversial concerning side and site of lesions causing such deficits. This study investigates visual and auditory emotion recognition in brain tumour patients with the aim of clarifying which lesion sites are related to impairments in emotion processing from different modalities. Thirty-four patients were evaluated, before and after surgery, on facial expression and emotional prosody recognition; voxel-based lesion-symptom mapping (VLSM) analyses were performed on patients' post-surgery MRI images. Results showed that patients' performance decreased after surgery in both visual and auditory modalities, but, in general, recovered 3 months after surgery. In facial expression recognition, left brain-damaged patients showed greater post-surgery deterioration than right brain-damaged ones, whose performance specifically decreased for sadness and fear. VLSM analysis revealed two segregated areas in the left hemisphere accounting for post-surgery scores for happy (fronto-temporo-insular region) and surprised (middle frontal gyrus and inferior fronto-occipital fasciculus) facial expressions. Our findings demonstrate that surgical removal of tumours in the fronto-temporal region produces impairment in facial emotion recognition with an overall recovery at 3 months, suggesting a partially different representation of positive and negative emotions in the left and right hemispheres for visually - but not auditory - presented emotions; moreover, we show that deficits in specific expression recognition are associated with discrete lesion locations.												35	37											MAR	2019	13	1					1	21		10.1111/jnp.12130	http://dx.doi.org/10.1111/jnp.12130												2026-01-16	WOS:000460194700001
J	Liu, SY; Samuel, AG				Liu, Siyun; Samuel, Arthur G.			The role of Mandarin lexical tones in lexical access under different contextual conditions	LANGUAGE AND COGNITIVE PROCESSES				Article								The current study pursues Ye & Connine's (1999) suggestion that tonal information is Much more important when words are presented in context, than in isolation. Disyllabic Mandarin words were either presented normally, or with changes in their segmental and/or tonal structure. Critically, these items were presented in isolation, in sentence context, and in idioms; previous studies have not examined these issues in sentential context. In Experiment 1, native Mandarin speakers made lexical decisions about these items. In Experiment 2, the critical stimuli were presented in white noise, and the listeners' task was to detect the vowels and the tones of the stimuli. The results supported a more important role for tonal Cites when the stimulus is presented in context than when it is in isolation; this pattern depended on the task conditions, as suggested by Soto-Faraco et al. (2001), and Mattys et al. (2005).												39	46											JUN	2007	22	4					566	594		10.1080/01690960600989600	http://dx.doi.org/10.1080/01690960600989600												2026-01-16	WOS:000247730000004
J	Bestelmeyer, PEG; Maurage, P; Rouger, J; Latinus, M; Belin, P				Bestelmeyer, Patricia E. G.; Maurage, Pierre; Rouger, Julien; Latinus, Marianne; Belin, Pascal			Adaptation to Vocal Expressions Reveals Multistep Perception of Auditory Emotion	JOURNAL OF NEUROSCIENCE				Article								The human voice carries speech as well as important nonlinguistic signals that influence our social interactions. Among these cues that impact our behavior and communication with other people is the perceived emotional state of the speaker. A theoretical framework for the neural processing stages of emotional prosody has suggested that auditory emotion is perceived in multiple steps (Schirmer and Kotz, 2006) involving low-level auditory analysis and integration of the acoustic information followed by higher-level cognition. Empirical evidence for this multistep processing chain, however, is still sparse. We examined this question using functional magnetic resonance imaging and a continuous carry-over design (Aguirre, 2007) to measure brain activity while volunteers listened to non-speech-affective vocalizations morphed on a continuum between anger and fear. Analyses dissociated neuronal adaptation effects induced by similarity in perceived emotional content between consecutive stimuli from those induced by their acoustic similarity. We found that bilateral voice-sensitive auditory regions as well as right amygdala coded the physical difference between consecutive stimuli. In contrast, activity in bilateral anterior insulae, medial superior frontal cortex, precuneus, and subcortical regions such as bilateral hippocampi depended predominantly on the perceptual difference between morphs. Our results suggest that the processing of vocal affect recognition is a multistep process involving largely distinct neural networks. Amygdala and auditory areas predominantly code emotion-related acoustic information while more anterior insular and prefrontal regions respond to the abstract, cognitive representation of vocal affect.												74	86											JUN 11	2014	34	24					8098	8105		10.1523/JNEUROSCI.4820-13.2014	http://dx.doi.org/10.1523/JNEUROSCI.4820-13.2014												2026-01-16	WOS:000338338700005
J	Cercy, SP; Kuluva, JE				Cercy, Steven P.; Kuluva, Joshua E.			Gelastic epilepsy and dysprosodia in a case of late-onset right frontal seizures	EPILEPSY & BEHAVIOR				Article								Gelastic epilepsy (GE) is an uncommon type of seizure disorder characterized by stereotyped, unprovoked, inappropriate ictal laughter. GE is most frequently associated with hypothalamic hamartoma, with onset almost invariably occurring during childhood. GE also occurs occasionally with temporal and frontal cortical seizure foci. We describe an unusual case of senescent-onset GE with a right frontal seizure focus. In addition to laughter, dysprosodia was a clinical feature. Clinical and electroencephalographic evidence of seizure activity ceased on levetiracetam, and the patient showed concurrent improvement in cognitive function. We review the evidence for the cerebral representation of laughter and prosody, and discuss issues bearing on the differential diagnosis and management of GE. Published by Elsevier Inc.												11	17											OCT	2009	16	2					360	365		10.1016/j.yebeh.2009.08.007	http://dx.doi.org/10.1016/j.yebeh.2009.08.007												2026-01-16	WOS:000271083800029
J	Soto-Almela, J; Alcaraz-Mármol, G				Soto-Almela, Jorge; Alcaraz-Marmol, Gema			Victims or non-humans: Exploring the semantic preference of refugees in Spanish news articles	LANGUAGE & COMMUNICATION				Article								This paper explores the discursive representation of refugees in a 1.8-million-word corpus of Spanish news articles collected from the digital libraries of El Mundo and El Pais. Through a corpus-assisted methodology, synchronic and diachronic analyses have been conducted in order to examine the semantic preference of the lemma refugiado over the 2010-16 period. The results show a semantic preference of refugiado for two major semantic sets, namely victimization and dehumanization. Indeed, the preference tends to fluctuate between these two extremes over the years analyzed: either they are victims and their human condition is highlighted or they are dehumanized. Both sets of collocates represent about 50 percent of the total semantic preference of refugiado. (C) 2019 Elsevier Ltd. All rights reserved.												4	4											NOV	2019	69						11	25		10.1016/j.langcom.2019.05.001	http://dx.doi.org/10.1016/j.langcom.2019.05.001												2026-01-16	WOS:000501402300002
J	Busso, C; Deng, ZG; Neumann, U				Busso, C; Deng, ZG; Neumann, U			Natural head motion synthesis driven by acoustic prosodic features	COMPUTER ANIMATION AND VIRTUAL WORLDS				Article; Proceedings Paper	18th International Conference on Computer Animation and Social Agents (CASA 2005)	OCT 17-19, 2005	Hong Kong, PEOPLES R CHINA					Natural head motion is important to realistic facial animation and engaging human-computer interactions. In this paper, we present a novel data-driven approach to synthesize appropriate head motion by sampling from trained hidden markov models (HMMs). First, while an actress recited a corpus specifically designed to elicit various emotions, her 3D head motion was captured and further processed to construct a head motion database that included synchronized speech information. Then, an HMM for each discrete head motion representation (derived directly from data using vector quantization) was created by using acoustic prosodic features derived from speech. Finally, first-order Markov models and interpolation techniques were used to smooth the synthesized sequence. Our comparison experiments and novel synthesis results show that synthesized head motions follow the temporal dynamic behavior of real human subjects. Copyright (c) 2005 John Wiley & Sons, Ltd.												55	65											JUL	2005	16	3-4					283	290		10.1002/cav.80	http://dx.doi.org/10.1002/cav.80												2026-01-16	WOS:000232568000014
S	Zervas, P; Xydas, G; Fakotakis, N; Kokkinakis, G; Kouroupetroglou, G		Matousek, V; Mautner, P; Pavelka, T		Zervas, P; Xydas, G; Fakotakis, N; Kokkinakis, G; Kouroupetroglou, G			Experimental evaluation of tree-based algorithms for intonational breaks representation	TEXT, SPEECH AND DIALOGUE, PROCEEDINGS	Lecture Notes in Artificial Intelligence			Article; Proceedings Paper	8th International Conference on Text, Speech and Dialogue	SEP 12-15, 2005	Karlovy Vary, CZECH REPUBLIC					The prosodic specification of an utterance to be spoken by a Text-to-Speech synthesis system can be devised in break indices, pitch accents and boundary tones. In particular, the identification of break indices formulates the intonational phrase breaks that affect all the forthcoming prosody-related procedures. In the present paper we use tree-structured predictors, and specifically the commonly used in similar tasks CART and the introduced C4.5 one, to cope with the task of break placement in the presence of shallow textual features. We have utilized two 500-utterance prosodic corpora offered by two Greek universities in order to compare the machine learning approaches and to argue on the robustness they offer for Greek break modeling. The evaluation of the resulted models revealed that both approaches were positively compared with similar works published for other languages, while the C4.5 method accuracy scaled from 1% to 2,7% better than CART.												2	2												2005	3658						334	341															2026-01-16	WOS:000232264700043
J	Staib, M; Abivardi, A; Bach, DR				Staib, Matthias; Abivardi, Aslan; Bach, Dominik R.			Primary auditory cortex representation of fear-conditioned musical sounds	HUMAN BRAIN MAPPING				Article								Auditory cortex is required for discriminative fear conditioning beyond the classical amygdala microcircuit, but its precise role is unknown. It has previously been suggested that Heschl's gyrus, which includes primary auditory cortex (A1), but also other auditory areas, encodes threat predictions during presentation of conditioned stimuli (CS) consisting of monophones, or frequency sweeps. The latter resemble natural prosody and contain discriminative spectro-temporal information. Here, we use functional magnetic resonance imaging (fMRI) in humans to address CS encoding in A1 for stimuli that contain only spectral but no temporal discriminative information. Two musical chords (complex) or two monophone tones (simple) were presented in a signaled reinforcement context (reinforced CS+ and nonreinforced CS-), or in a different context without reinforcement (neutral sounds, NS1 and NS2), with an incidental sound detection task. CS/US association encoding was quantified by the increased discriminability of BOLD patterns evoked by CS+/CS-, compared to NS pairs with similar physical stimulus differences and task demands. A1 was defined on a single-participant level and based on individual anatomy. We find that in A1, discriminability of CS+/CS- was higher than for NS1/NS2. This representation of unconditioned stimulus (US) prediction was of comparable magnitude for both types of sounds. We did not observe such encoding outside A1. Different from frequency sweeps investigated previously, musical chords did not share representations of US prediction with monophone sounds. To summarize, our findings suggest decodable representation of US predictions in A1, for various types of CS, including musical chords that contain no temporal discriminative information.												14	17											MAR	2020	41	4					882	891		10.1002/hbm.24846	http://dx.doi.org/10.1002/hbm.24846		OCT 2019										2026-01-16	WOS:000493159400001
J	Lee, SH; Choi, HY; Kim, SB; Lee, SW				Lee, Sang-Hoon; Choi, Ha-Yeong; Kim, Seung-Bin; Lee, Seong-Whan			HierSpeech plus plus : Bridging the Gap Between Semantic and Acoustic Representation of Speech by Hierarchical Variational Inference for Zero-Shot Speech Synthesis	IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS				Article								Large language model (LLM)-based speech synthesis has been widely adopted in zero-shot speech synthesis. However, they require a large-scale data and possess the same limitations as previous autoregressive speech models, including slow inference speed and lack of robustness. This article proposes HierSpeech++, a fast and strong zero-shot speech synthesizer for text-to-speech (TTS) and voice conversion (VC). We verified that hierarchical speech synthesis frameworks could significantly improve the robustness and expressiveness of the synthetic speech. Furthermore, we significantly improve the naturalness and speaker similarity of synthetic speech even in zero-shot speech synthesis scenarios. For TTS, we adopt the text-to-vec (TTV) framework, which generates a self-supervised speech representation and an F0 representation based on text representations and prosody prompts. Then, HierSpeech++ generates speech from the generated vector, F0, and voice prompt. We further introduce a high-efficient speech super-resolution (SpeechSR) framework from 16 to 48 kHz. The experimental results demonstrated that the hierarchical variational autoencoder could be a strong zero-shot speech synthesizer given that it outperforms LLM-based and diffusion-based models. Moreover, we achieved the first human-level quality zero-shot speech synthesis. Audio samples and source code are available at https://github.com/hierspeechpp/code												0	0											OCT	2025	36	10					18422	18436		10.1109/TNNLS.2025.3584944	http://dx.doi.org/10.1109/TNNLS.2025.3584944		JUL 2025										2026-01-16	WOS:001527315200001
J	Gussenhoven, C				Gussenhoven, Carlos			DOES PHONOLOGICAL PROMINENCE EXIST?	LINGUE E LINGUAGGIO				Article								There is no motivation for collapsing the prosodic structure of words and the prosodic structure of sentences of English into a single representation that expresses degrees of stress or prominence. Word stress is represented as foot structure, while sentence prosody is represented in terms of phonological phrasing and the distribution of pitch accents. The reason why native speakers can perform rating tasks for prominence on syllables is that their grammar dictates that focus-marking pitch accents be located in stressed syllables and that emphatic speech implies a hyper-articulation of pitch accents in the emphasized text. As a result, any factor, phonetic or otherwise, that affects the listener's impression of the emphasis with which the speaker expresses his message will affect the prominence rating of accentable syllables in the text. Speakers of languages with different prosodic grammars may not be able to perform such tasks.												7	9											JAN-JUN	2015	14	1			SI		7	24		10.1418/80751	http://dx.doi.org/10.1418/80751												2026-01-16	WOS:000436878700002
J	EDWARDS, J; BECKMAN, ME				EDWARDS, J; BECKMAN, ME			ARTICULATORY TIMING AND THE PROSODIC INTERPRETATION OF SYLLABLE DURATION	PHONETICA				Article								A number of different prosodic effects (e.g. intonation-phrase-final position, the presence of stress or accent) increase syllable duration, as conventionally measured by the spacing of abrupt energy transitions in the acoustic signal. However, different prosodic contrasts may have different influences on syllable-internal articulatory organization. The present study examined the time course of vowel-related opening and closing mandibular gestures in four different prosodic contexts. For some prosodic effects, such as intonationphrase-final lengthening, longer acoustic durations were associated with a disproportionate lengthening of the latter part of the vocalic gesture. By contrast, the presence of nuclear stress was associated with a more even distribution of lengthening throughout the syllable. These results suggest that the rhythmic effects of different prosodic contrasts cannot be adequately modelled in terms of millisecond values of durational ratios for acoustic segments. It is proposed that a suitable phonological representation of the rhythms of stress and phrasing might describe them as the time course of a syllable''s phonetic sonority.												43	48												1988	45	2-4					156	174		10.1159/000261824	http://dx.doi.org/10.1159/000261824												2026-01-16	WOS:A1988AH58100006
J	Thirumuru, R; Gurugubelli, K; Vuppala, AK				Thirumuru, Ramakrishna; Gurugubelli, Krishna; Vuppala, Anil Kumar			Novel feature representation using single frequency filtering and nonlinear energy operator for speech emotion recognition	DIGITAL SIGNAL PROCESSING				Article								In this paper, the intrinsic characteristics of speech modulations are estimated to propose the instant modulation spectral features for efficient emotion recognition. This feature representation is based on single frequency filtering (SFF) technique and higher order nonlinear energy operator. The speech signal is decomposed into frequency sub-bands using SFF, and associated nonlinear energies are estimated with higher order nonlinear energy operator. Then, the feature vector is realized using cepstral analysis. The high-resolution property of SFF technique is exploited to extract the amplitude envelope of the speech signal at a selected frequency with good time-frequency resolution. The fourth order nonlinear energy operator provides noise robustness in estimating the modulation components. The proposed feature set is tested for the emotion recognition task using the i-vector model with the probabilistic linear discriminant scoring scheme, support vector machine and random forest classifiers. The results demonstrate that the performance of this feature representation is better than the widely used spectral and prosody features, achieving detection accuracy of 85.75%, 59.88%, and 65.78% on three emotional databases, EMODB, FAUAIBO, and IEMOCAP, respectively. Further, the proposed features are found to be robust in the presence of additive white Gaussian and vehicular noises. (C) 2021 Elsevier Inc. All rights reserved.												19	23											JAN	2022	120								103293	10.1016/j.dsp.2021.103293	http://dx.doi.org/10.1016/j.dsp.2021.103293		NOV 2021										2026-01-16	WOS:000723629500002
J	Athanaselis, T; Bakamidis, S; Dologlou, I; Cowie, R; Douglas-Cowie, E; Cox, C				Athanaselis, T; Bakamidis, S; Dologlou, I; Cowie, R; Douglas-Cowie, E; Cox, C			ASR emotional speech: Clarifying the issues and enhancing performance	NEURAL NETWORKS				Article								There are multiple reasons to expect that recognising the verbal content of emotional speech will be a difficult problem, and recognition rates reported in the literature are in fact low. Including information about prosody improves recognition rate for emotions simulated by actors, but its relevance to the freer patterns of spontaneous speech is unproven. This paper shows that recognition rate for spontaneous emotionally coloured speech can be improved by using a language model based on increased representation of emotional utterances. The models are derived by adapting an already existing corpus, the British National Corpus (BNC). An emotional lexicon is used to identify emotionally coloured words, and sentences containing these words are recombined with the BNC to form a corpus with a raised proportion of emotional material. Using a language model based on that technique improves recognition rate by about 20%. (c) 2005 Elsevier Ltd. All rights reserved.												55	61											MAY	2005	18	4					437	444		10.1016/j.neunet.2005.03.008	http://dx.doi.org/10.1016/j.neunet.2005.03.008												2026-01-16	WOS:000230710900008
J	Fram, NR				Fram, Noah R. R.			Genredynamics: a perceptual calculus of genre	JOURNAL OF MATHEMATICS AND MUSIC				Article								Prevailing theories of genre, derived primarily from literary and musical scholarship, differ in characteristics they ascribe to genre itself. Here, the temporally dynamic and culturally contingent nature of genre informs a computational framework that is reducible to extant theories of genre and connected to psychological theories of perceptual categorization. This framework, called genredynamics, interprets genres as perceptual categories in a space defined by aesthetic and sociocultural variables, and characterizes the behaviour and structure of genres using concepts from differential topology. Its existence demonstrates that disparate theoretical approaches to genre can be unified and implies that genre is best understood as both a psychological and musicological phenomenon. Classifications' temporal fluidity and incorporating sociocultural variables alongside sensory ones are necessary for this framework to be generalizable. Together, these theoretical results have broad implications for potential applications of genre theory, including the study of mental representations, social and cultural psychology, and cognition.												0	0											SEP 2	2023	17	3					351	370		10.1080/17459737.2022.2149869	http://dx.doi.org/10.1080/17459737.2022.2149869		JAN 2023										2026-01-16	WOS:000910908400001
J	Alarcón, IEG; Daoussi, S				Alarcon, Isabel Esther Gonzalez; Daoussi, Syrine			Theatre in the FLE Classroom: Annie Ernaux through her Characters. for Dramatisation	THELEME-REVISTA COMPLUTENSE DE ESTUDIOS FRANCESES				Article								This article presents a series of workshops focused on the study and theatrical analysis of Annie Ernaux's L'& Eacute;v & eacute;nement (2000) and Le Jeune homme (2022), with the aim of their subsequent dramatization and theatrical representation. The activity was carried out with students from the French III course of the English Studies degree program at the University of Almeria, who possess a B2 level in FLE, during the 2022-2023 academic year. Due to the success and excellent results achieved-both in terms of language learning and the knowledge transfer involved-it was decided to include this theatrical adaptation, along with its premiere and staging, in the summer course En torno a la figura y la obra de Annie Ernaux, Premio Nobel de Literatura 2022, held at the University of Almeria.												0	0												2024	39	2					223	231		10.5209/thel.94845	http://dx.doi.org/10.5209/thel.94845												2026-01-16	WOS:001385587000009
J	Dolatian, H				Dolatian, Hossep			An apparent case of outwardly-sensitive allomorphy in the Armenian definite	GLOSSA-A JOURNAL OF GENERAL LINGUISTICS				Article								Cross-linguistically, it is rare to find cases of phonologically-conditioned allomorphy where the trigger morpheme lies external or outside the target morpheme. At first sight, the Armenian definite suffix seems to be such a case. The definite suffix uses various surface forms. The choice of surface form is conditioned by the preceding segment, the following clitic, and/or the following word. However, we argue that this outward sensitivity is epiphenomenal and not actual allomorphy. We derive the surface forms by using an abstract underlying representation that uses floating segments or ghost segments. These segments go through rigid cycles of spell-out and phonological strata. Constraint re-rankings of autosegmental docking, phrasal resyllabification, and cluster avoidance explain a range of dialectal variation. In sum, the Armenian definite suffix is one apparent case of outwardly-sensitive allomorphy that is reducible to latent segments.												4	5											MAY 10	2022	7	1								10.16995/glossa.6406	http://dx.doi.org/10.16995/glossa.6406												2026-01-16	WOS:000805328900001
J	Morency, LP; de Kok, I; Gratch, J				Morency, Louis-Philippe; de Kok, Iwan; Gratch, Jonathan			A probabilistic multimodal approach for predicting listener backchannels	AUTONOMOUS AGENTS AND MULTI-AGENT SYSTEMS				Article								During face-to-face interactions, listeners use backchannel feedback such as head nods as a signal to the speaker that the communication is working and that they should continue speaking. Predicting these backchannel opportunities is an important milestone for building engaging and natural virtual humans. In this paper we show how sequential probabilistic models ( e. g., Hidden Markov Model or Conditional Random Fields) can automatically learn from a database of human-to-human interactions to predict listener backchannels using the speaker multimodal output features ( e. g., prosody, spoken words and eye gaze). The main challenges addressed in this paper are automatic selection of the relevant features and optimal feature representation for probabilistic models. For prediction of visual backchannel cues (i.e., head nods), our prediction model shows a statistically significant improvement over a previously published approach based on hand-crafted rules.												108	119											JAN	2010	20	1			SI		70	84		10.1007/s10458-009-9092-y	http://dx.doi.org/10.1007/s10458-009-9092-y												2026-01-16	WOS:000273806500006
J	Sugahara, M; Turk, A				Sugahara, Mariko; Turk, Alice			Durational correlates of English sublexical constituent structure	PHONOLOGY				Article								This study investigates whether differences (a) in word-internal morphological structure and (b) in lexical stress patterns are reflected in prosodic Constituent structure, by examining duration measurements in Scottish English. In Experiments 1 and 2, at a slow speech rate, stem-final rhymes followed by Level II suffixes were on average 4-6% longer than corresponding strings in monomorphemic words, and 7-8% longer than stem-final rhymes followed by Level I suffixes. These results are consistent with the view that stems preceding Level II suffixes are mapped onto prosodic words in the prosodic representation. Experiment 3 obtained no reliable durational differences, even at a slow, speech rate, between the initial syllable rhymes of SS words and SW words, which does not provide evidence for the hypothesis that these different stress patterns are represented as differences in foot structure.												32	39												2009	26	3					477	524		10.1017/S0952675709990248	http://dx.doi.org/10.1017/S0952675709990248												2026-01-16	WOS:000272766000004
J	El Ayadi, M; Kamel, MS; Karray, F				El Ayadi, Moataz; Kamel, Mohamed S.; Karray, Fakhri			Survey on speech emotion recognition: Features, classification schemes, and databases	PATTERN RECOGNITION				Article								Recently, increasing attention has been directed to the study of the emotional content of speech signals, and hence, many systems have been proposed to identify the emotional content of a spoken utterance. This paper is a survey of speech emotion classification addressing three important aspects of the design of a speech emotion recognition system. The first one is the choice of suitable features for speech representation. The second issue is the design of an appropriate classification scheme and the third issue is the proper preparation of an emotional speech database for evaluating system performance. Conclusions about the performance and limitations of current speech emotion recognition systems are discussed in the last section of this survey. This section also suggests possible ways of improving speech emotion recognition systems. (C) 2010 Elsevier Ltd. All rights reserved.												1350	1496											MAR	2011	44	3					572	587		10.1016/j.patcog.2010.09.020	http://dx.doi.org/10.1016/j.patcog.2010.09.020												2026-01-16	WOS:000285233300007
J	Shintel, H; Nusbaum, HC				Shintel, Hadas; Nusbaum, Howard C.			The sound of motion in spoken language: Visual information conveyed by acoustic properties of speech	COGNITION				Article								Language is generally viewed as conveying information through symbols whose form is arbitrarily related to their meaning. This arbitrary relation is often assumed to also characterize the mental representations underlying language comprehension. We explore the idea that visuo-spatial information can be analogically conveyed through acoustic properties of speech and that such information is integrated into an analog perceptual representation as a natural part of comprehension. Listeners heard sentences describing objects, spoken at varying speaking rates. After each sentence, participants saw a picture of an object and judged whether it had been mentioned in the sentence. Participants were faster to recognize the object when motion implied by speaking rate matched the motion implied by the picture. Results suggest that visuo-spatial referential information can be analogically conveyed and represented. (c) 2006 Elsevier B.V. All rights reserved.												31	39											DEC	2007	105	3					681	690		10.1016/j.cognition.2006.11.005	http://dx.doi.org/10.1016/j.cognition.2006.11.005												2026-01-16	WOS:000250666400011
J	Spalek, K; Oganian, Y				Spalek, Katharina; Oganian, Yulia			The neurocognitive signature of focus alternatives	BRAIN AND LANGUAGE				Article								Focus alternatives are words/phrases that can substitute for the focused constituent of an utterance. In "Carsten has picked [CHERRIES](F) from the tree.", (marked by pitch focus on cherries), the speaker wants to not only convey the fact that Carsten has picked cherries, but also to contrast cherries with other fruit that could have been picked, such as plums. Although focus alternatives are key to understanding the implicit aspects of an utterance, nothing is known about their neural representation. We directly contrasted neural representations of lexicosemantic similarity and focus alternative status using fMRI. Semantic relatedness was reflected in decreased activation in the bilateral superior temporal gyri. By contrast, processing of focus alternatives induced increased activations in the precuneus and the fronto-median wall, two regions previously implicated in discourse processing. These results suggest that focus alternative status is processed separately from semantic relatedness, at the level of discourse integration.												6	6											JUL	2019	194						98	108		10.1016/j.bandl.2019.04.007	http://dx.doi.org/10.1016/j.bandl.2019.04.007												2026-01-16	WOS:000471735900011
J	Agmon, G; Jaeger, M; Magen, E; Pinto, D; Perelmuter, Y; Golumbic, EZ; Bleichner, MG				Agmon, Galit; Jaeger, Manuela; Magen, Ella; Pinto, Danna; Perelmuter, Yuval; Zion Golumbic, Elana; Bleichner, Martin G.			Challenges and Methods in Annotating Natural Speech for Neurolinguistic Research	NEUROBIOLOGY OF LANGUAGE				Article								Spoken language is central to human communication, influencing cognition, learning, and social interactions. Despite its spontaneous nature, characterized by disfluencies, fillers, self-corrections and irregular syntax, it effectively serves its communicative purpose. Understanding how the brain processes natural language offers valuable insights into the neurobiology of language. Recent neuroscience advancements allow us to study neural processes in response to ongoing speech, requiring detailed, time-locked descriptions of speech material to capture the nuances of spoken language. While there are many speech-to-text tools available, obtaining a time-locked true verbatim transcript, reflecting everything that was uttered, requires additional effort to achieve an accurate representation. We demonstrate the challenges involved in the process of obtaining time-resolved annotation of spontaneous speech, by presenting two semi-automatic pipelines, developed for German and Hebrew but adaptable to other languages. The outputs of these pipelines enable analyses of the neural representation and processing of key linguistic features. We discuss the methodological challenges and opportunities posed by current state-of-the-art pipelines, and advocate for new lines of natural language processing research aimed at advancing our understanding of how the brain processes everyday language.												2	2											SEP 5	2025	6								nola12	10.1162/nol.a.12	http://dx.doi.org/10.1162/nol.a.12												2026-01-16	WOS:001571556000001
J	Varga, E; Herold, R; Tényil, T; Endre, S; Fekete, J; Bugya, T				Varga, Eszter; Herold, Robert; Tenyil, Tamas; Endre, Szilvia; Fekete, Judit; Bugya, Titusz			Social Cognition Analyzer Application-A New Method for the Analysis of Social Cognition in Patients Diagnosed With Schizophrenia	FRONTIERS IN PSYCHIATRY				Article								Introduction: Because of the importance of the assessment of social cognitive impairments in schizophrenia in clinical settings, a new computer application called SCAN (Social Cognition Analyzer applicatioN) was developed. Our first aim was to examine if patients diagnosed with schizophrenia could be differentiated from healthy individuals based on the results of SCAN, taking into consideration both response rates and response times. Our second aim was to create Scanalizer, as part of SCAN, to produce social cognitive profiles of individual patients. Materials and Methods: 86 patients (SG) and 101 healthy participants (CG) were examined with SCAN. The domains were: ToM, irony, metaphor, emotion perception from prosody and social perception. SCAN displayed the tasks, recorded the answers and the response times. For the differentiation of the two groups a two-dimensional scatter plot was used. For the graphical presentation of the social cognitive profile of patients, the calculation of the distributions of CG's results was made with Kolmogorov-Smirnov Goodness-of-fit Test and with the sum of squared residuals (SSR). Results: We found that the SG's response rates were significantly lower and the SG's response times were significantly slower compared to the CG in every condition. With the two-dimensional comparison of the summary response rates and the summary response times of the participants, the SG could be differentiated from the CG and this differentiation worked irrespective of age and education. For the graphical representation of social cognitive functions of patients, distributions of the results of the CG were calculated. We found normal distributions in the response times of all conditions and in the response rates of the ToM condition. In the low-end tail of the irony condition, and in the metaphor, social perception and emotional prosody conditions, power-law distributions were found. We also found that the summary response rates of the lowest performing 10% of the CG was in the same range as the summary response rates of all examined patients. Discussion: Scanalizer enables clinicians to measure and analyse social cognitive profiles of patients diagnosed with schizophrenia. Moreover, SCAN could also be used to detect social cognitive disabilities of vulnerable individuals.												5	6											DEC 20	2019	10								912	10.3389/fpsyt.2019.00912	http://dx.doi.org/10.3389/fpsyt.2019.00912												2026-01-16	WOS:000505492300001
J	Dingemanse, M; Akita, K				Dingemanse, Mark; Akita, Kimi			An inverse relation between expressiveness and grammatical integration: On the morphosyntactic typology of ideophones, with special reference to Japanese	JOURNAL OF LINGUISTICS				Article								Words and phrases may differ in the extent to which they are susceptible to prosodic foregrounding and expressive morphology: their expressiveness. They may also differ in the degree to which they are integrated in the morphosyntactic structure of the utterance: their grammatical integration. We describe an inverse relation that holds across widely varied languages, such that more expressiveness goes together with less grammatical integration, and vice versa. We review typological evidence for this inverse relation in ten spoken languages, then quantify and explain it using Japanese corpus data. We do this by tracking ideophones - vivid sensory words also known as mimetics or expressives - across different morphosyntactic contexts and measuring their expressiveness in terms of intonation, phonation and expressive morphology. We find that as expressiveness increases, grammatical integration decreases. Using gesture as a measure independent of the speech signal, we find that the most expressive ideophones are most likely to come together with iconic gestures. We argue that the ultimate cause is the encounter of two distinct and partly incommensurable modes of representation: the gradient, iconic, depictive system represented by ideophones and iconic gestures, and the discrete, arbitrary, descriptive system represented by ordinary words. The study shows how people combine modes of representation in speech and demonstrates the value of integrating description and depiction into the scientific vision of language.												75	83											AUG	2017	53	3					501	532		10.1017/S002222671600030X	http://dx.doi.org/10.1017/S002222671600030X												2026-01-16	WOS:000405196600002
J	Marmel, F; Tillmann, B				Marmel, Frederic; Tillmann, Barbara			TONAL PRIMING BEYOND TONICS	MUSIC PERCEPTION				Article								THE MUSICAL PRIMING PARADIGM ALLOWS FOR INVESTIGATION of listeners' expectations based on their implicit knowledge of tonal stability. To date, priming data are limited to reports of facilitated processing for tonic over nontonic events. The special status of the tonic as a cognitive reference point brings into question the subtlety of listeners' tonal knowledge: Is the facilitated processing observed in priming studies limited to tonic events, or is tone processing influenced by subtler tonal contrasts? The present study investigated tonal priming for mediants (the third scale degree) over leading tones (the seventh scale degree) presented in melodic contexts. Experiment 1 used a timbre discrimination task and Experiment 2 an intonation task. Facilitated processing was observed for the more tonally stable mediants over the less stable leading tones, thus showing that priming effects are not limited to pairs of tonal degrees including the tonic. This finding emphasizes the subtlety of nonexpert listeners' tonal knowledge.												22	33											FEB	2009	26	3					211	221		10.1525/MP.2009.26.3.211	http://dx.doi.org/10.1525/MP.2009.26.3.211												2026-01-16	WOS:000262861800005
J	Charnavel, I				Charnavel, Isabelle			Steps Toward a Universal Grammar of Dance: Local Grouping Structure in Basic Human Movement Perception	FRONTIERS IN PSYCHOLOGY				Article								The general goal of this paper is to investigate the structure of our unconscious mental representation of dance: we do not perceive dance as an unanalyzed flow of movement, but we unconsciously create a mental representation regulated by structural principles. Specifically, this article examines local grouping principles in dance perception inspired by Lerdahl and Jackendoff's (1983) approach to musical grouping. I spell out the basic perceptual dimensions at work in basic human movement perception, and on that basis, I propose six principles of change that determine group boundaries in dance (change of body part, orientation, level, direction, speed, quality). I experimentally test the relevance and interaction of these principles, and find that they are organized on a scale of relative strength. This experiment thus supports the hypothesis that grouping is a general cognitive capacity applying across domains and modalities, and shows how specific grouping principles are stated in relation to modality-specific and domain-specific dimensions. More generally, it takes a step toward the development of a generative theory of dance that should help extend the research avenue of comparing complex temporal cognitive activities across modalities (visual, auditory) and purposes (referential, non-referential), which so far involves spoken language, signed language and music.												25	28											JUN 18	2019	10								1364	10.3389/fpsyg.2019.01364	http://dx.doi.org/10.3389/fpsyg.2019.01364												2026-01-16	WOS:000472143400001
J	Lefter, I; Burghouts, GJ; Rothkrantz, LJM				Lefter, Iulia; Burghouts, Gertjan J.; Rothkrantz, Leon J. M.			Recognizing Stress Using Semantics and Modulation of Speech and Gestures	IEEE TRANSACTIONS ON AFFECTIVE COMPUTING				Article								This paper investigates how speech and gestures convey stress, and how they can be used for automatic stress recognition. As a first step, we look into how humans use speech and gestures to convey stress. In particular, for both speech and gestures, we distinguish between stress conveyed by the intended semantic message (e.g. spoken words for speech, symbolic meaning for gestures), and stress conveyed by the modulation of either speech and gestures (e.g. intonation for speech, speed and rhythm for gestures). As a second step, we use this decomposition of stress as an approach for automatic stress prediction. The considered components provide an intermediate representation with intrinsic meaning, which helps bridging the semantic gap between the low level sensor representation and the high level context sensitive interpretation of behavior. Our experiments are run on an audiovisual dataset with service-desk interactions. The final goal is having a surveillance system that would notify when the stress level is high and extra assistance is needed. We find that speech modulation is the best performing intermediate level variable for automatic stress prediction. Using gestures increases the performance and is mostly beneficial when speech is lacking. The two-stage approach with intermediate variables performs better than baseline feature level or decision level fusion.												38	43											APR-JUN	2016	7	2					162	175		10.1109/TAFFC.2015.2451622	http://dx.doi.org/10.1109/TAFFC.2015.2451622												2026-01-16	WOS:000383995300005
J	Hauser, DJ; Schwarz, N				Hauser, David J.; Schwarz, Norbert			Implicit Bias Reflects the Company That Words Keep	FRONTIERS IN PSYCHOLOGY				Article								In everyday language, concepts appear alongside (i.e., collocate with) related concepts. Societal biases often emerge in these collocations; e.g., female (vs. male) names collocate with art- (vs. science-) related concepts, and African American (vs. White American) names collocate with negative (vs. positive) concepts. It is unknown whether such collocations merely reflect societal biases or contribute to them. Concepts that are themselves neutral in valence but nevertheless collocate with valenced concepts provide a unique opportunity to address this question. For example, when asked, most people evaluate the concept "cause" as neutral, but "cause" is frequently followed by negative concepts (e.g., death, pain, and trouble). We use such semantically prosodic concepts to test the influence of collocation on the emergence of implicit bias: do neutral concepts that frequently collocate with valenced concepts have corresponding implicit bias? In evaluative priming tasks, participants evaluated positive/negative nouns (Study 1) or pictures (Study 2) after seeing verb primes that were (a) strongly valenced (e.g., hate and comfort), (b) neutral in valence but collocated with valenced concepts in corpora (e.g., ease and gain), or (c) neutral in valence and not collocated with valenced concepts in corpora (e.g., reply and describe). Throughout, neutral primes with positive (negative) collocates facilitated the evaluation of positive (negative) targets much like strongly valenced primes, whereas neutral primes without valenced collocates did not. That neutral concepts with valenced collocates parallel the influence of valenced concepts suggests that their collocations in natural language may be sufficient for fostering implicit bias. Societal implications of the causal embedding hypothesis are discussed.												7	7											JUN 13	2022	13								871221	10.3389/fpsyg.2022.871221	http://dx.doi.org/10.3389/fpsyg.2022.871221												2026-01-16	WOS:000816253900001
J	Levshina, N; Koptjevskaja-Tamm, M; Östling, R				Levshina, Natalia; Koptjevskaja-Tamm, Maria; Ostling, Robert			Revered and reviled: a sentiment analysis of female and male referents in three languages	FRONTIERS IN COMMUNICATION				Article								Our study contributes to the less explored domain of lexical typology, focusing on semantic prosody and connotation. Semantic derogation, or pejoration of nouns referring to women, whereby such words acquire connotations and further denotations of social pejoration, immorality and/or loose sexuality, has been a very prominent question in studies on gender and language (change). It has been argued that pejoration emerges due to the general derogatory attitudes toward female referents. However, the evidence for systematic differences in connotations of female- vs. male-related words is fragmentary and often fairly impressionistic; moreover, many researchers argue that expressed sentiments toward women (as well as men) often are ambivalent. One should also expect gender differences in connotations to have decreased in the recent years, thanks to the advances of feminism and social progress. We test these ideas in a study of positive and negative connotations of feminine and masculine term pairs such as woman - man, girl - boy, wife - husband, etc. Sentences containing these words were sampled from diachronic corpora of English, Chinese and Russian, and sentiment scores for every word were obtained using two systems for Aspect-Based Sentiment Analysis: PyABSA, and OpenAI's large language model GPT-3.5. The Generalized Linear Mixed Models of our data provide no indications of significantly more negative sentiment toward female referents in comparison with their male counterparts. However, some of the models suggest that female referents are more infrequently associated with neutral sentiment than male ones. Neither do our data support the hypothesis of the diachronic convergence between the genders. In sum, results suggest that pejoration is unlikely to be explained simply by negative attitudes to female referents in general.												0	0											MAR 28	2024	9								1266407	10.3389/fcomm.2024.1266407	http://dx.doi.org/10.3389/fcomm.2024.1266407												2026-01-16	WOS:001199813900001
J	Luo, ZJ; Chen, JH; Takiguchi, T; Ariki, Y				Luo, Zhaojie; Chen, Jinhui; Takiguchi, Tetsuya; Ariki, Yasuo			Emotional Voice Conversion Using Dual Supervised Adversarial Networks With Continuous Wavelet Transform F0 Features	IEEE-ACM TRANSACTIONS ON AUDIO SPEECH AND LANGUAGE PROCESSING				Article								In emotional voice conversion (VC) tasks, it is difficult to deal with a simple representation of fundamental frequency (F0), which is the most important feature in emotional voice representation. In order to address this issue, we propose the adaptive scales continuous wavelet transform (ADS-CWT) method to systematically capture F0 features of different temporal levels, which can represent different prosodic aspects, ranging from micro-prosody to sentences. Moreover, in an emotional VC task, each dataset is paired with the labeled emotional voice and neutral voice, which can be regarded as a dual task. Owing to, first, dual supervised learning's ability to improve the training performances by using the leveraging probabilistic connection between the dual tasks to enhance the learning from labeled data and, second, generative adversarial networks' (GANs') ability to mitigate the over-smoothing problem caused in the low-level data space when converting the acoustic features, we further present a novel training framework for emotional VC using GANs combined with dual supervised learning, named as dual supervised adversarial networks. In emotional VC experiments, we confirmed the high similarity performance of our method when using limited labeled data for emotional VC. Our method achieves good and consistent performance, in both objective and subjective evaluations.												19	23											OCT	2019	27	10					1535	1548		10.1109/TASLP.2019.2923951	http://dx.doi.org/10.1109/TASLP.2019.2923951												2026-01-16	WOS:000473621000004
J	Hesling, I; Clément, S; Bordessoules, M; Allard, M				Hesling, I; Clément, S; Bordessoules, M; Allard, M			Cerebral mechanisms of prosodic integration: evidence from connected speech	NEUROIMAGE				Article								Using functional Magnetic Resonance Imaging (fMRI) and long connected speech stimuli, we addressed the question of neuronal networks involved in prosodic integration by comparing (1) differences in brain activity when hearing connected speech stimuli with high and low degrees of prosodic expression; (2) differences in brain activity in two different diotic listening conditions (normal speech delivery to both ears, i.e., NN; and low-pass-filtered speech delivery to both ears, i.e., FF); and (3) effects of high and low degrees of prosodic information in the NN and FIT conditions. Twelve right-handed French men listened passively to the stimuli. Each stimulus induced a specific cerebral network, the flat one weakening activations, which were mainly reduced to the bilateral STG for both listening conditions. High degrees of prosodic information were found to trigger right specific activations in a wider neuronal network involved in speech integration (such as BA44, BA21-22 and BA39-40) than low degrees of prosodic information did. More precisely, the right BA44 was found to be specifically involved in the process of F-0 modulations, which are the main acoustic correlate of prosody. Not only do the results achieved in the present experiment using 30-s-long connected speech stimuli show the involvement of a bilateral neuronal network but they also strongly suggest that high degrees of prosodic information elicit activations in a wider neuronal network involved in speech perception than low degrees of prosodic information do. (C) 2004 Elsevier Inc. All rights reserved.												74	80											FEB 15	2005	24	4					937	947		10.1016/j.neuroimage.2004.11.003	http://dx.doi.org/10.1016/j.neuroimage.2004.11.003												2026-01-16	WOS:000226788100001
J	Clement, T; Tcheng, D; Auvil, L; Capitanu, B; Monroe, M				Clement, Tanya; Tcheng, David; Auvil, Loretta; Capitanu, Boris; Monroe, Megan			Sounding for Meaning: Using Theories of Knowledge Representation to Analyze Aural Patterns in Texts	DIGITAL HUMANITIES QUARTERLY				Article								Computational literary analytics that include frequency trends and collocation, topic modeling, and network analysis have relied on rapid and large-scale analysis of the word or strings of words. This essay shows that there are many other features of literary texts by which humanists make meaning other than the word, such as prosody and sound, and how computational methods allow us to do what has historically been a more difficult method of analysis - trying to understand how literary texts make meaning with these features. This paper will discuss a case study that uses theories of knowledge representation and research on phonetic and prosodic symbolism to develop analytics and visualizations that help readers discover aural and prosodic patterns in literary texts. To this end, this paper has two parts: (I) We describe the theories of knowledge representation and research into phonetic and prosodic symbolism that underpin the logics and ontologies of aurality incorporated in our project. This basic theory of aurality is reflected in our use of OpenMary, a text-to-speech application tool for extracting aural features; in the "flow" we coordinated to pre-process texts in SEASR's Meandre, a data flow environment; in the instance-based predictive modeling procedure that we developed for the project; and in ProseVis, the reader interface that we created to allow readers to discover aural features across literary texts. And (II), we discuss readings of several works by Gertrude Stein (the portraits "Matisse" and "Picasso" and the prose poem Tender Buttons) that were facilitated by this work.												9	12												2013	7	1			SI																		2026-01-16	WOS:000218260500015
J	Hamed, M; Missaoui, I; Lachiri, Z				Hamed, Mohamed; Missaoui, Ibrahim; Lachiri, Zied			RFGETT-TTS: Robust Fine-Grained Expressivity Transfer With Transformer for Text-to-Speech Synthesis	IEEE ACCESS				Article								Neural text-to-speech (TTS) research has advanced significantly, yielding various approaches that generate speech with enhanced naturalness. Despite these strides, synthesizing expressive speech remains a significant challenge due to the complex and variable nature of explicit human prosody. In this paper, we presented an effective TTS approach that transfers expressivity from a reference speech to a target spoken text. The proposed approach, Robust Fine-Grained Expressivity Transfer with Transformer, RFGETT-TTS, extends and enhances the Transformer-based text-to-speech architecture to enable transfer of expressivity from a reference utterance to synthesized speech. Key components of RFGETT-TTS include: 1) a prosody extraction module that aligns prosodic features with phoneme inputs, providing stable prosodic representations to the NTTS system, 2) an expressivity aggregation module that encodes and fuses expressive characteristics into a single expressive vector using convolutional layers and normalization, 3) a Multi-Head Cross-Attention mechanism that aligns and integrates linguistic inputs with expressivity features derived from the reference utterance, and 4) the speaker module that encodes speaker identity representation. The Transformer encoder's output is then fused with speaker embeddings and used to condition the Transformer decoder. Extensive evaluations on ESD and EmoV-DB datasets demonstrate that RFGETT-TTS outperforms four TTS models in expressivity transfer while maintaining high-quality of synthesized speech, validated by both objective and subjective evaluation metrics. Objective metric like Mel Cepstral Distortion shows that RFGETT-TTS achieves better than four models with a gap up to 0.18, while statistical subjective results on Expressivity Mean Opinion Score show significant difference (p-value < 0.05) than four models.												0	0												2025	13						218238	218253		10.1109/ACCESS.2025.3648672	http://dx.doi.org/10.1109/ACCESS.2025.3648672												2026-01-16	WOS:001652569800022
J	Stefanics, G; Háden, GP; Sziller, I; Balázs, L; Beke, A; Winkler, I				Stefanics, Gabor; Haden, Gabor P.; Sziller, Istvan; Balazs, Laszlo; Beke, Anna; Winkler, Istvan			Newborn infants process pitch intervals	CLINICAL NEUROPHYSIOLOGY				Article								Objective: We investigated whether the auditory system of newborn babies extracts the constancy of a pitch interval from exemplars varying in absolute pitch. Methods: Event-related brain potentials (ERP) were recorded from healthy newborn infants in an oddball paradigm consisting of frequent standard and infrequent deviant tone pairs. Tone pairs varied in absolute frequency. Standard and deviant pairs differed in the amount of pitch difference within the pairs, but not in the direction of pitch change. Results: Deviant tone pairs elicited a discriminative ERP response. Conclusions: This result suggests that the neonate auditory system represents pitch intervals similarly to adults. Significance: Adult-like processing of pitch intervals allows newborn infants to learn music, speech prosody, and to process various important auditory cues based on spectral acoustic features. (C) 2008 International Federation of Clinical Neurophysiology. Published by Elsevier Ireland Ltd. All rights reserved.												80	87											FEB	2009	120	2					304	308		10.1016/j.clinph.2008.11.020	http://dx.doi.org/10.1016/j.clinph.2008.11.020												2026-01-16	WOS:000264040100011
J	Brechmann, A; Scheich, H				Brechmann, A; Scheich, H			Hemispheric shifts of sound representation in auditory cortex with conceptual listening	CEREBRAL CORTEX				Article								The weak field specificity and the heterogeneity of neuronal filters found in any given auditory cortex field does not substantiate the view that such fields are merely descriptive maps of sound features. But field mechanisms were previously shown to support behaviourally relevant classification of sounds. Here the prediction was tested in human auditory cortex (AC) that classification-tasks rather than the stimulus class per se determine which auditory cortex area is recruited. By presenting the same set of frequency-modulations we found that categorization of their pitch direction (rising versus falling) increased functional magnetic resonance imaging activation in right posterior AC compared with stimulus exposure and in contrast to left posterior AC dominance during categorization of their duration (short versus long). Thus, top-down influences appear to select not only auditory cortex areas but also the hemisphere for specific processing.												132	143											MAY	2005	15	5					578	587		10.1093/cercor/bhh159	http://dx.doi.org/10.1093/cercor/bhh159												2026-01-16	WOS:000228636000011
J	Fuks, O				Fuks, Orit			Intensifier actions in Israeli Sign Language (ISL) discourse	GESTURE				Article								The study describes certain structural modifications employed on the citation forms of ISL during signing for intensification purposes. In Signed Languages, citation forms are considered relatively immune to modifications. Nine signers signed several scenarios describing some intense quality. The signers used conventional adverbs existing in ISL for intensification purposes. Yet, they also employed idiosyncratic modifications on the formational components of adjectives simultaneously to form realization. These optional modifications enriched the messages conveyed merely by the conventional forms. They show that signers can incorporate gradient modes of expressions directly into the production of the lexical items to communicate more diverse and explicit messages in context. Using a comparative semiotic approach allowed us to describe the synergetic cooperation manifested at the stage of utterance construction between formational elements which were more suited to convey gradient and analog meanings in context and those that were less suited and thus not modified.												5	6												2016	15	2					192	223		10.1075/gest.15.2.03fuk	http://dx.doi.org/10.1075/gest.15.2.03fuk												2026-01-16	WOS:000380174700003
J	Roll, M; Lindgren, M; Alter, K; Horne, M				Roll, Mikael; Lindgren, Magnus; Alter, Kai; Horne, Merle			Time-driven effects on parsing during reading	BRAIN AND LANGUAGE				Article								The phonological trace of perceived words starts fading away in short-term memory after a few seconds. Spoken utterances are usually 2-3 s long, possibly to allow the listener to parse the words into coherent prosodic phrases while they still have a clear representation. Results from this brain potential study suggest that even during silent reading, words are organized into 2-3 s long 'implicit' prosodic phrases. Participants read the same sentences word by word at different presentation rates. Clause-final words occurring at multiples of 2-3 s from sentence onset yielded increased positivity, irrespective of presentation rate. The effect was interpreted as a closure positive shift (CPS), reflecting insertion of implicit prosodic phrase boundaries every 2-3 s. Additionally, in participants with low working memory span, clauses over 3 s long produced a negativity, possibly indicating increased working memory load. (C) 2012 Elsevier Inc. All rights reserved.												20	24											JUN	2012	121	3					267	272		10.1016/j.bandl.2012.03.002	http://dx.doi.org/10.1016/j.bandl.2012.03.002												2026-01-16	WOS:000304339700010
J	Chung, S				Chung, S			The syntax and prosody of weak pronouns in Chamorro	LINGUISTIC INQUIRY				Article; Proceedings Paper	Conference of the Texas-Linguistic-Society	2001	UNIV TEXAS, AUSTIN, TX		UNIV TEXAS			In the modular linguistic theory assumed by many generative linguists, phonology and syntax are interconnected but fundamentally independent components of grammar. The effects of syntax on phonology are mediated by prosodic structure, a representation of prosodic constituents calculated from syntactic structure but not isomorphic to it. Within this overall architecture, I investigate the placement of weak pronouns in the Austronesian language Chamorro. Certain Chamorro pronominals can be realized as prosodically deficient weak pronouns that typically occur right after the predicate. I show that these pronouns are second-position clitics whose placement is determined not syntactically, but prosodically: they occur after the leftmost phonological phrase of their intonational phrase. My analysis of these clitics assumes that lexical insertion is late and can affect and be affected by prosodic phrase formation-assumptions consistent with the view that the mutual interaction of phonology and syntax is confined to the postsyntactic operations that translate syntactic structure into prosodic structure.												24	30											FAL	2003	34	4					547	599		10.1162/002438903322520151	http://dx.doi.org/10.1162/002438903322520151												2026-01-16	WOS:000186390100002
J	Kentner, G; Féry, C				Kentner, Gerrit; Fery, Caroline			A new approach to prosodic grouping	LINGUISTIC REVIEW				Article								This paper reports on two experiments concerning the prosodic realization and perception of various sentences with three or four coordinated names in German. The expression of prosodic boundaries, as evidenced by pitch and duration, is shown to signal the depth of syntactic embedding of the conjuncts and also the branching direction of the co-ordination structure. The results of the production experiment inspire a model of syntax-prosody mapping, which assumes that the strength of a prosodic boundary after a given constituent is a function of a) the syntactic relation to the following constituent and b) the depth of its syntactic embedding. Comparison reveals that the proposed model provides better predictions than other current approaches to prosodic boundary strength. The perception experiment indicates that listeners recognize recursively embedded coordination structures on the basis of the prosodic form of the sentence. We argue for a recursive representation of prosodic constituent structure at the level of the phonological phrase and above.												35	38												2013	30	2					277	311		10.1515/tlr-2013-0009	http://dx.doi.org/10.1515/tlr-2013-0009												2026-01-16	WOS:000322554600004
J	Vallejo, G				Vallejo, Gloria			NON-VERBAL COMMUNICATION MODELS IN SPORTS AND BALLET	FORMA Y FUNCION				Article								This study analyzes the communication model generated among professional soccer trainers, artistic gymnastics trainers, and folkloric ballet instructors, on the basis of the dynamic body language typical of specialized communication among sportspeople and dancers, which includes a high percentage of non-verbal language. Non-verbal language was observed in both psychomotor and socio-motor practices in order to identify and characterize relations between different concepts and their corresponding gestural representation. This made it possible to generate a communication model that takes into account the non-verbal aspects of specialized communicative contexts. The results indicate that the non-verbal language of trainers and instructors occasionally replaces verbal language when the latter is insufficient or inappropriate to describe an action or movement of great precision, due to circumstances of distance or acoustic interferences. With regard to ballet instructors, it was found that there was a generalized form of guiding rehearsals, through the use of rhythmic counts with hands or feet. In addition, the paralinguistic components of the different speech acts are emphasized, especially concerning intonation, duration and intensity.												0	0											JUL-DEC	2010	23	2					147	156															2026-01-16	WOS:000434544400006
J	Reilly, J; Kean, J				Reilly, Jamie; Kean, Jacob			Formal distinctiveness of high- and low-imageability nouns: Analyses and theoretical implications	COGNITIVE SCIENCE				Article								Words associated with perceptually salient, highly imageable concepts are learned earlier in life, more accurately recalled, and more rapidly named than abstract words (R. W. Brown, 1976; Walker & Hulme, 1999). Theories accounting for this concreteness effect have focused exclusively on semantic properties of word referents. A novel possibility is that word structure may also contribute to the effect. We report a corpus-based analysis of the phonological and morphological structures of a large set of nouns with imageability ratings (N = 2,023). High- and low-imageability nouns differed by length, etymology, prosody, affixation, phonological neighborhood density, and rates of consonant clustering. On average, nouns denoting abstract concepts were longer, more derivationally complex, and emerged in English from a different distribution of languages than did concrete nouns. We address implications for interactivity of word form and meaning as pertain to theories of word concreteness, lexical acquisition, and word processing.												98	109											JAN-FEB	2007	31	1					157	168		10.1080/03640210709336988	http://dx.doi.org/10.1080/03640210709336988												2026-01-16	WOS:000245224200006
J	Huron, D; Davis, MJ				Huron, David; Davis, Matthew J.			The Harmonic Minor Scale Provides an Optimum Way of Reducing Average Melodic Interval Size, Consistent with Sad Affect Cues	EMPIRICAL MUSICOLOGY REVIEW				Article								Small pitch movement is known to characterize sadness in speech prosody. Small melodic interval sizes have also been observed in nominally sad music-at least in the case of Western music. Starting with melodies in the major mode, a study is reported which examines the effect of different scale modifications on the average interval size. Compared with all other possible scale modifications, lowering the third and sixth scale tones from the major scale is shown to provide an optimum or near optimum way of reducing the average melodic interval size for a large diverse sample of major-mode melodies. The results are consistent with the view that Western melodic organization and the major-minor polarity are co-adapted, and that the structure of the minor mode contributes to the evoking, expressing or representation of sadness for listeners enculturated to the major scale.												11	18												2012	7	3-4					103	117															2026-01-16	WOS:000214272200002
J	Anderson, AJ; Davis, C; Lalor, EC				Anderson, Andrew J.; Davis, Chris; Lalor, Edmund C.			Deep-learning models reveal how context and listener attention shape electrophysiological correlates of speech-to-language transformation	PLOS COMPUTATIONAL BIOLOGY				Article								To transform continuous speech into words, the human brain must resolve variability across utterances in intonation, speech rate, volume, accents and so on. A promising approach to explaining this process has been to model electroencephalogram (EEG) recordings of brain responses to speech. Contemporary models typically invoke context invariant speech categories (e.g. phonemes) as an intermediary representational stage between sounds and words. However, such models may not capture the complete picture because they do not model the brain mechanism that categorizes sounds and consequently may overlook associated neural representations. By providing end-to-end accounts of speech-to-text transformation, new deep-learning systems could enable more complete brain models. We model EEG recordings of audiobook comprehension with the deep-learning speech recognition system Whisper. We find that (1) Whisper provides a self-contained EEG model of an intermediary representational stage that reflects elements of prelexical and lexical representation and prediction; (2) EEG modeling is more accurate when informed by 5-10s of speech context, which traditional context invariant categorical models do not encode; (3) Deep Whisper layers encoding linguistic structure were more accurate EEG models of selectively attended speech in two-speaker "cocktail party" listening conditions than early layers encoding acoustics. No such layer depth advantage was observed for unattended speech, consistent with a more superficial level of linguistic processing in the brain.												0	0											NOV	2024	20	11							e1012537	10.1371/journal.pcbi.1012537	http://dx.doi.org/10.1371/journal.pcbi.1012537												2026-01-16	WOS:001352298800009
J	Poeppel, D				Poeppel, D			The analysis of speech in different temporal integration windows: cerebral lateralization as 'asymmetric sampling in time'	SPEECH COMMUNICATION				Article								The 'asymmetric sampling in time' (AST) hypothesis developed here provides a framework for understanding a range of psychophysical and neuropsychological data on speech perception in the context of a revised cortical functional anatomic model. The AST model is motivated by observations from psychophysics and cognitive neuroscience that speak to the fractionation of auditory processing, in general, and speech perception, in particular. Building on the observations (1) that the speech signal contains more than one time scale relevant to auditory cognition (e.g. time scales commensurate with processing formant transitions versus scales commensurate with syllabicity and intonation contours), and (2) that speech perception is mediated by both left and right auditory cortices, AST suggests a time-based perspective that maintains anatomic symmetry while permitting functional asymmetry. AST proposes that the input speech signal has a neural representation that is bilaterally symmetric at an early representational level. Beyond the initial representation, however, the signal is elaborated asymmetrically in the time domain: left auditory areas preferentially extract information from short (similar to20-40 ms) temporal integration windows. The right hemisphere homologues preferentially extract information from long (similar to150-250 ms) integration windows. It is suggested that temporal integration is reflected as oscillatory neuronal activity in different frequency bands (gamma, theta). (C) 2002 Elsevier Science B.V. All rights reserved.												951	1068											AUG	2003	41	1					245	255		10.1016/S0167-6393(02)00107-3	http://dx.doi.org/10.1016/S0167-6393(02)00107-3												2026-01-16	WOS:000183840900020
J	Martin, S				Martin, Scott			Supplemental update	SEMANTICS & PRAGMATICS				Article								Supplements have often been characterized as inert with respect to other content. But under closer scrutiny, the data shows that supplements can take scope and participate in anaphoric links, undermining multidimensional accounts of them. I argue that the core empirical facts pertaining to supplements, including projection, can in many cases be accounted for by more general, independently motivated factors such as anaphora resolution in discourse and quantifier scope preferences. Importantly, supplement projection is decoupled from at-issueness, with projection arising instead as an epiphenomenon of various external influences. The account is formalized in a dynamic, compositional, and unidimensional semantics that allows anaphoric links to and from supplement content. Since supplements are modeled as a kind of quantifier phrase modifier, scope interactions with semantic operators are captured without further stipulation. When a supplement takes widest scope, it constitutes a separate at-issue proposal, enabling both supplement projection and (non)deniability. The formal machinery requires no additional rules or representation layers except for the dynamic meaning of the comma intonation, which demarcates a supplement from its surrounding content.												0	1												2016	9									10.3765/sp.9.5	http://dx.doi.org/10.3765/sp.9.5												2026-01-16	WOS:000388836800006
J	Pellerin, N; Lecours, S				Pellerin, Nathalie; Lecours, Serge			SENSITIZATION TO EMOTIONS AND REPRESENTATION FORMATION THROUGH SOCIAL BIOFEEDBACK: Is Markedness a Necessary Mechanism?	PSYCHOANALYTIC PSYCHOLOGY				Article								This study reviews Gergely and Watson's (1996) social biofeedback theory of parental affect-mirroring, furthered by Fonagy, Gergely, Jurist, and Target (2002), especially the "markedness" hypothesis. These authors hypothesize that a salient facial expression and the singsong prosody of markedness called "motherese" are necessary for successful emotion sensitization and symbolization. The revision investigates whether this is accomplished through "internalization" mechanisms requiring markedness of the mirroring, or solely through social biofeedback processes. The article argues that the infant contingency-detection mechanism (similar to that of adult biofeedback training) mediates the functions of sensitization, representation, and symbolization of emotions through its processes of covariance-invariance detection, maximization, and contingent control of the parental mirroring, whether the mirroring is marked or not. The review argues that a caregiver producing a covariant-invariant mirroring can help bring the infant's emotional somatosensations to consciousness along with its implicit dispositional content without using motherese. It considers the clinical implications of the new model and speculates about parental difficulties centered on sharing troubling emotions. Finally, it discusses how the model may be a mediating mechanism in the change process in the therapy of adults through the promotion of sensitive emotions, their awareness, and symbolization.												1	3											JAN	2015	32	1					61	93		10.1037/a0038024	http://dx.doi.org/10.1037/a0038024												2026-01-16	WOS:000347730600004
J	de Simone, J; Cevasco, J				de Simone, Julieta; Cevasco, Jazmin			The Role of the Establishment of Causal Connections and the Modality of Presentation of Discourse in the Generation of Emotion Inferences by Argentine College Students	READING PSYCHOLOGY				Article								The purpose of this study was to examine the role of the causal connectivity of the statements (their total number of causal connections) and the modality of presentation of discourse (oral-written) in the generation of emotion inferences by Spanish-speaking students. With this aim, we asked a group of Argentine college students to either listen to or read an excerpt of a radio interview (on the topic 'Argentine radio presenters' relationship with the audience'), and to perform an emotions recall task. Results indicated that statements that promoted the generation of emotion inferences and had a high number of causal connections were more often included in the recall protocols than those that promoted the generation of these inferences and had a low number of them. They also indicated that participants who were presented with the spoken version of the materials included a higher number of statements in this task than those that were presented with the written version. These findings suggest that the establishment of meaningful discourse connections has a role in the generation of emotion inferences, and that there appear to be differences in the representation that listeners and readers construct of speakers' emotions.												6	7												2021	42	1					22	41		10.1080/02702711.2020.1837314	http://dx.doi.org/10.1080/02702711.2020.1837314												2026-01-16	WOS:000629745200002
J	Tang, KV; Shaw, JA				Tang, Kevin; Shaw, Jason A.			Prosody leaks into the memories of words	COGNITION				Article								The average predictability (aka informativity) of a word in context has been shown to condition word duration (Seyfarth, 2014). All else being equal, words that tend to occur in more predictable environments are shorter than words that tend to occur in less predictable environments. One account of the informativity effect on duration is that the acoustic details of probabilistic reduction are stored as part of a word's mental representation. Other research has argued that predictability effects are tied to prosodic structure in integral ways. With the aim of assessing a potential prosodic basis for informativity effects in speech production, this study extends past work in two directions; it investigated informativity effects in another large language, Mandarin Chinese, and broadened the study beyond word duration to additional acoustic dimensions, pitch and intensity, known to index prosodic prominence. The acoustic information of content words was extracted from a large telephone conversation speech corpus with over 400,000 tokens and 6000 word types spoken by 1655 individuals and analyzed for the effect of informativity using frequency statistics estimated from a 431 million word subtitle corpus. Results indicated that words with low informativity have shorter durations, replicating the effect found in English. In addition, informativity had significant effects on maximum pitch and intensity, two phonetic dimensions related to prosodic prominence. Extending this interpretation, these results suggest that predictability is closely linked to prosodic prominence, and that the lexical representation of a word includes phonetic details associated with its average prosodic prominence in discourse. In other words, the lexicon absorbs prosodic influences on speech production.												22	24											MAY	2021	210								104601	10.1016/j.cognition.2021.104601	http://dx.doi.org/10.1016/j.cognition.2021.104601		JAN 2021										2026-01-16	WOS:000635450600010
J	Le Goffic, P				Le Goffic, Pierre			Sentence and textual integration	LANGUE FRANCAISE				Article								The article sets up a twofold modelling of verbal communication: i.e. syntactic computing, and textual computing. Syntactic computing consists in producing/interpreting the elementary units which give the message its basic structure. Contrary to commonly received ideas, it is argued that those elementary units follow the 'sentence' pattern, assuming that a sentence may include not only the core (propositional structure) but also some peripheric elements. Both speaker and hearer try (successfully or not) to build (/reconstruct) well-formed sentences, in a step by step ('sequence' by 'sequence') process. Textual computing deals with the immediate integration of processed sequences (which lose their previous autonomy) into a higher level of textual representation. The analysis of the oral text (interview of Anita Musso) shows that the sentence level is easily recognisable (through unequivocal cores, and peripheric elements identifiable as such) and clearly plays a basic structuring role, which no alternative unit is likely to play. Textual units of a higher level than the sentence level are much more difficult to determine and to describe, for at least three reasons: (a) sequences may provide heterogeneous materials; (b) embedding sequences in order to build a higher representation is a continuous process, which leads to complex hierarchical structures; (c) speakers often follow a non-consistent expository path (as is the case in the text under study). Intonation has been deliberately left aside: the aim was to extend a purely segmental analysis as far as possible towards a complete account of the text.												0	0											JUN	2011		170					11	+															2026-01-16	WOS:000295188300002
J	GERKEN, L; JUSCZYK, PW; MANDEL, DR				GERKEN, L; JUSCZYK, PW; MANDEL, DR			WHEN PROSODY FAILS TO CUE SYNTACTIC STRUCTURE - 9-MONTH-OLDS SENSITIVITY TO PHONOLOGICAL VERSUS SYNTACTIC PHRASES	COGNITION				Article								According to prosodic bootstrapping accounts of syntax acquisition, language learners use the correlation between syntactic boundaries and prosodic changes (e.g., pausing, vowel lengthening, large increases or decreases in fundamental frequency) to cue the presence and arrangement of syntactic constituents. However, recent linguistic accounts suggest that prosody does not directly reflect syntactic structure but rather is governed by independent prosodic units such as phonological phrases. To examine the implications of this view for the prosodic bootstrapping hypothesis, infants in Experiment 1 were presented with sentences in which pauses were inserted either between the subject noun phrase (NP) and verb or after the verb. Half of the infants heard sentences with lexical NP subjects, in which prosodic structure is consistent with syntactic structure. The other half heard sentences with pronoun subjects, in which prosodic structure does not mirror syntactic structure. In a preferential listening paradigm, infants in the lexical NP condition listened longer to materials containing pauses between the subject an verb, the main syntactic constituents. However, in the pronoun NP condition, infants showed no difference in listening times for the two pause locations. To determine if other sentence types containing pronoun subjects potentially provide information about the syntactic constituency of these elements, infants in Experiment 2 heard yes-no questions with pronoun subjects, in which the prosodic structure reflects the constituency of the subject, Infants listened longer when pauses were inserted between the subject and verb than after the verb. Taken together, our results suggest that the prosodic information in an individual sentence is not always sufficient to assign a syntactic structure. Rather, learners must engage in active inferential processes, using cross-sentence comparisons and other types of information to arrive at the correct syntactic representation.												111	125											MAR	1994	51	3					237	265		10.1016/0010-0277(94)90055-8	http://dx.doi.org/10.1016/0010-0277(94)90055-8												2026-01-16	WOS:A1994NB45600002
J	Jiang, XM; Pell, MD				Jiang, Xiaoming; Pell, Marc D.			Neural responses towards a speaker's feeling of (un)knowing	NEUROPSYCHOLOGIA				Article								During interpersonal communication, listeners must rapidly evaluate verbal and vocal cues to arrive at an integrated meaning about the utterance and about the speaker, including a representation of the speaker's 'feeling of knowing' (i.e., how confident they are in relation to the utterance). In this study, we investigated the time course and neural responses underlying a listener's ability to evaluate speaker confidence from combined verbal and vocal cues. We recorded real-time brain responses as listeners judged statements conveying three levels of confidence with the speaker's voice (confident, close-to-confident, unconfident), which were preceded by meaning-congruent lexical phrases (e.g. I am positive, Most likely, Perhaps). Event-related potentials to utterances with combined lexical and vocal cues about speaker confidence were compared to responses elicited by utterances without the verbal phrase in a previous study (Jiang and Pell, 2015). Utterances with combined cues about speaker confidence elicited reduced, N1, P2 and N400 responses when compared to corresponding utterances without the phrase. When compared to confident statements, close-to-confident and unconfident expressions elicited reduced N1 and P2 responses and a late positivity from 900 to 1250 ms; unconfident and close-to-confident expressions were differentiated later in the 1250-1600 ms time window. The effect of lexical phrases on confidence processing differed for male and female participants, with evidence that female listeners incorporated information from the verbal and vocal channels in a distinct manner. Individual differences in trait empathy and trait anxiety also moderated neural responses during confidence processing. Our findings showcase the cognitive processing mechanisms and individual factors governing how we infer a speaker's mental (knowledge) state from the speech signal. (C) 2015 Elsevier Ltd. All rights reserved.												38	40											JAN 29	2016	81						79	93		10.1016/j.neuropsychologia.2015.12.008	http://dx.doi.org/10.1016/j.neuropsychologia.2015.12.008												2026-01-16	WOS:000370459400008
J	Bednarek, M				Bednarek, Monika			Invisible or high-risk: Computer-assisted discourse analysis of references to Aboriginal and Torres Strait Islander people(s) and issues in a newspaper corpus about diabetes	PLOS ONE				Article								This article employs computer-assisted methods to analyse references to Aboriginal and Torres Strait Islander people(s) and issues in a newspaper corpus about diabetes. The objectives are to identify both the frequency and quality of social representation. The dataset consisted of 694 items from 12 Australian newspapers in a five-year period (2013-2017). The quantitative analysis focused on frequency (raw/normalised) and range (number/percentage of texts). The qualitative analysis focused on the identification of semantic prosody (co-occurrence with negative/positive words and phrases) and on selective social actor analysis. The qualitative analysis also compared choices made by the press to language practices recommended in relevant reporting guidelines. Key results include that references to Aboriginal and Torres Strait Islander people(s) or matters appear to be extremely rare. In addition, newspapers' language choices only partially align with guidelines. References that do occur can be classified into four categories: a) references to [groups of] people and other references to identity; b) names of services, institutions, professions, roles etc; c) non-human nouns related to health; d) non-human nouns related to culture. Qualitative analysis of the word COMMUNITY suggests that newspapers for the most part do recognise the existence of different communities at a national level. However, analysis of all references to [groups of] people shows that the vast majority occur in contexts to do with negativity, therefore having a negative semantic prosody. More specifically, there is a strong association with mentions of a higher risk, likelihood, or incidence of having or developing diabetes (or complications/effects). In sum, Aboriginal and Torres Strait Islander people(s) and issues lack in visibility in Australian diabetes coverage, and are associated with deficit framing, which can be disempowering. To change the discourse would require both an increased visibility as well as changing the deficit lens.												7	8											JUN 11	2020	15	6							e0234486	10.1371/journal.pone.0234486	http://dx.doi.org/10.1371/journal.pone.0234486												2026-01-16	WOS:000542036800049
J	Zou, T; Caspers, J; Chen, YY				Zou, Ting; Caspers, Johanneke; Chen, Yiya			Perception of Different Tone Contrasts at Sub-Lexical and Lexical Levels by Dutch Learners of Mandarin Chinese	FRONTIERS IN PSYCHOLOGY				Article								This study explores the difficulties in distinguishing different lexical tone contrasts at both sub-lexical and lexical levels for beginning and advanced Dutch learners of Mandarin, using a sequence-recall task and an auditory lexical decision task. In both tasks, the Tone 2-Tone 3 contrast is most prone to errors for both groups of learners. A significant improvement in the advanced group was found for this tone contrast in the sub-lexical sequence recall task, but not in the lexical decision task. This is taken as evidence that utilizing tones in on-line spoken word recognition is more complex and demanding for L2 learners than in a memory-based task. The results of the lexical decision task also revealed that advanced learners have developed a stronger sensitivity to Tone 1 compared to the other three tones, with Tone 4 showing the least sensitivity. These findings suggest different levels of robustness and distinctiveness for the representation of different lexical tones in L2 learners' lexicon and consequently different levels of proficiency in integrating tones for lexical processing. The observed patterns of difficulty are potentially related to the acoustic characteristics of different lexical tone contrasts as well as to the interference of the suprasegmental features of learner's native language (i.e., the tonal contrasts of Dutch intonation) on the acquisition of the Mandarin lexical tone contrasts.												3	3											JUN 6	2022	13								891756	10.3389/fpsyg.2022.891756	http://dx.doi.org/10.3389/fpsyg.2022.891756												2026-01-16	WOS:000813299300001
J	Berg, T				Berg, Thomas			The modification of compound nouns by three adjectives	FUNCTIONS OF LANGUAGE				Article								This paper is the final instalment in a series of studies investigating the modification patterns in complex noun phrases (NPs) in English. It particularly focuses on the modification of two-noun compounds by three attributive adjectives. An analysis of all such NPs from the BNC reveals a strong preference for head modification over modifier modification, similar rates of convergent and divergent modification and the non-occurrence of crossed modification. The single most important factor influencing the modification patterns is functional status. The larger the number of adjectives modifying the head of the compound, the higher the frequency of the modification type (modulo a proximity effect). The absence of crossed modification is expected under the no-crossing constraint, which is understood here not as a formal but as a functional principle ensuring successful communication. The various factors can be tied together under the rubric of accessibility. The probability of selecting a particular modification target is argued to be a function of the accessibility of the nouns in an NP.												0	0												2017	24	2					139	165		10.1075/fol.24.2.01ber	http://dx.doi.org/10.1075/fol.24.2.01ber												2026-01-16	WOS:000418438700001
J	Hirose, Y; Mazuka, R				Hirose, Yuki; Mazuka, Reiko			Predictive processing of novel compounds: Evidence from Japanese	COGNITION				Article								Our study argues that pre-head anticipatory processing operates at a level below the level of the sentence. A visual-world eye-tracking study demonstrated that, in processing of Japanese novel compounds, the compound structure can be constructed prior to the head if the prosodic information on the preceding modifier constituent signals that the Compound Accent Rule (CAR) is being applied. This prosodic cue rules out the single head analysis of the modifier noun, which would otherwise be a natural and economical choice. Once the structural representation for the head is computed in advance, the parser becomes faster in identifying the compound meaning. This poses a challenge to models maintaining that structural integration and word recognition are separate processes. At the same time, our results, together with previous findings, suggest the possibility that there is some degree of staging during the processing of different sources of information during the comprehension of compound nouns. (C) 2014 Elsevier B.V. All rights reserved.												10	10											MAR	2015	136						350	358		10.1016/j.cognition.2014.11.033	http://dx.doi.org/10.1016/j.cognition.2014.11.033												2026-01-16	WOS:000349882600030
J	Breen, M; Clifton, C				Breen, Mara; Clifton, Charles, Jr.			Stress matters revisited: A boundary change experiment	QUARTERLY JOURNAL OF EXPERIMENTAL PSYCHOLOGY				Article								Breen and Clifton (Stress matters: Effects of anticipated lexical stress on silent reading. Journal of Memory and Language, 2011, 64, 153-170) argued that readers' eye movements during silent reading are influenced by the stress patterns of words. This claim was supported by the observation that syntactic reanalysis that required concurrent metrical reanalysis (e.g., a change from the noun form of abstract to the verb form) resulted in longer reading times than syntactic reanalysis that did not require metrical reanalysis (e.g., a change from the noun form of report to the verb form). However, the data contained a puzzle: The disruption appeared on the critical word (abstract, report) itself, although the material that forced the part of speech change did not appear until the next region. Breen and Clifton argued that parafoveal preview of the disambiguating material triggered the revision and that the eyes did not move on until a fully specified lexical representation of the critical word was achieved. The present experiment used a boundary change paradigm in which parafoveal preview of the disambiguating region was prevented. Once again, an interaction was observed: Syntactic reanalysis resulted in particularly long reading times when it also required metrical reanalysis. However, now the interaction did not appear on the critical word, but only following the disambiguating region. This pattern of results supports Breen and Clifton's claim that readers form an implicit metrical representation of text during silent reading.												32	36											OCT 1	2013	66	10					1896	1909		10.1080/17470218.2013.766899	http://dx.doi.org/10.1080/17470218.2013.766899												2026-01-16	WOS:000327186700003
J	Bordbar, A; Memari, M; Asadi, B				Bordbar, Anahita; Memari, Mehran; Asadi, Bita			Introspective Study of Emotion Icon in Public Chat as a Gesture of Texting	JOURNAL OF RESEARCH IN APPLIED LINGUISTICS				Article								An emotion icon, better known as emoticon is a metacommunicative pictorial representation of a facial expression that, in the absence of body language and prosody, serves to draw a receiver's attention to the tenor or temper of a sender's nominal verbal communication, changing and improving its interpretation. The present study investigates the use of these nonverbal cues in whatsapp public chat. The analysis focuses on the multifunctionality of emoticons, their role in online relational work, and possible connections between emoticon use and language proficiency and thus contributes to a more complete understanding of emotive communication online. Its ultimate goal is to help clarify the role of emoticons within a larger conceptual framework of emotive and relational meaning. To this end, this study takes a micro-analytic approach to show how English as foreign language learners use emoticons in text chat. The analysis shows that emoticons are highly context-sensitive and can display affect or serve as contextual cues to signal illocutionary force or humor.												0	0											WIN-SPR	2017	8				SI		176	182		10.22055/rals.2017.12922	http://dx.doi.org/10.22055/rals.2017.12922												2026-01-16	WOS:000432170000019
J	BECKMAN, ME; DEJONG, K; JUN, SA; LEE, SH				BECKMAN, ME; DEJONG, K; JUN, SA; LEE, SH			THE INTERACTION OF COARTICULATION AND PROSODY IN SOUND CHANGE	LANGUAGE AND SPEECH				Article								Ohala (1974, 1981a) has proposed that sound changes can originate in hearers' misinterpretations of synchronic phonetic patterns. This paper applies this idea to sound changes that are conditioned by the prosodic environment, such as the voicing of voiceless fricatives in unstressed syllables in Proto-Germanic. Browman and Goldstein's (1989, 1990) "gestural score" suggests a representation of synchronic patterns in which extreme overlap between gestures of neighboring phoneme segments in casual speech can produce the appearance of a feature change or a segment deletion. Many of the sound changes that are conditioned by prosodic environment can be viewed as a diachronic reinterpretation of just such synchronic fast-speech processes. For example, vowel reduction in unstressed syllables can be viewed as a reinterpretation of undershoot that occurs when the vowel is overlapped to a great extent by the oral gestures for neighboring consonants. Phonetic data are reviewed that support analogous accounts of stop spirantization, voiceless obstruent voicing, and even the insertion of an intrusive stop in clusters such as /ns/ in some prosodic environments.												25	28											JAN-JUN	1992	35		1-2				45	58		10.1177/002383099203500205	http://dx.doi.org/10.1177/002383099203500205												2026-01-16	WOS:A1992JR38200004
J	Schön, D; Magne, C; Besson, M				Schön, D; Magne, C; Besson, M			The music of speech: Music training facilitates pitch processing in both music and language	PSYCHOPHYSIOLOGY				Article								The main aim of the present experiment was to determine whether extensive musical training facilitates pitch contour processing not only in music but also in language. We used a parametric manipulation of final notes or words' fundamental frequency (F0), and we recorded behavioral and electrophysiological data to examine the precise time Course of pitch processing. We compared professional musicians and nonmusicians. Results revealed that within both domains, musicians detected weak F0 manipulations better than nonmusicians. Moreover, F0 manipulations within both music and language elicited similar variations in brain electrical potentials, with overall shorter onset latency for musicians than for nonmusicians. Finally, the scalp distribution of an early negativity in the linguistic task varied with musical expertise, being largest over temporal sites bilaterally for musicians and largest centrally and over left temporal sites for nonmusicians. These results are taken as evidence that extensive musical training influences the perception of pitch contour in spoken language.												410	507											MAY	2004	41	3					341	349		10.1111/1469-8986.00172.x	http://dx.doi.org/10.1111/1469-8986.00172.x												2026-01-16	WOS:000221485900001
J	Snefjella, B; Kuperman, V				Snefjella, Bryor; Kuperman, Victor			It's all in the delivery: Effects of context valence, arousal, and concreteness on visual word processing	COGNITION				Article								Prior research has examined how distributional properties of contexts (number of unique contexts or their informativeness) influence the effort of word recognition. These properties do not directly interrogate the semantic properties of contexts. We evaluated the influence of average concreteness, valence (positivity) and arousal of the contexts in which a word occurs on response times in the lexical decision task, age of acquisition of the word, and word recognition memory performance. Using large corpora and norming mega-studies we quantified semantics of contexts for thousands of words and demonstrated that contextual factors were predictive of lexical representation and processing above and beyond the influence shown by concreteness, valence and arousal of the word itself. Our findings indicate that lexical representations are influenced not only by how diverse the word's contexts are, but also by the embodied experiences they elicit. (C) 2016 Elsevier B.V. All rights reserved.												36	40											NOV	2016	156						135	146		10.1016/j.cognition.2016.07.010	http://dx.doi.org/10.1016/j.cognition.2016.07.010												2026-01-16	WOS:000383939500013
J	Xu, YS; Gandour, J; Talavage, T; Wong, D; Dzemidzic, M; Tong, YX; Li, XJ; Lowe, M				Xu, YS; Gandour, J; Talavage, T; Wong, D; Dzemidzic, M; Tong, YX; Li, XJ; Lowe, M			Activation of the left planum temporale in pitch processing is shaped by language experience	HUMAN BRAIN MAPPING				Article								Implicit, abstract knowledge acquired through language experience can alter cortical processing of complex auditory signals. To isolate prelexical processing of linguistic tones (i.e., pitch variations that convey part of word meaning), a novel design was used in which hybrid stimuli were created by superimposing Thai tones onto Chinese syllables (tonal chimeras) and Chinese tones onto the same syllables (Chinese words). Native speakers of tone languages (Chinese, Thai) underwent fMRI scans as they judged tones from both stimulus sets. In a comparison of native vs. non-native tones, overlapping activity was identified in the left planum temporale (PT). In this area a double dissociation between language experience and neural representation of pitch occurred such that stronger activity was elicited in response to native as compared to non-native tones. This finding suggests that cortical processing of pitch information can be shaped by language experience and, moreover, that lateratized PT activation can be driven by top-down cognitive processing.												68	82											FEB	2006	27	2					173	183		10.1002/hbm.20176	http://dx.doi.org/10.1002/hbm.20176												2026-01-16	WOS:000235054400008
J	Hinnell, J				Hinnell, Jennifer			The multimodal marking of aspect: The case of five periphrastic auxiliary constructions in North American English	COGNITIVE LINGUISTICS				Article								Cognitive linguistics (CL) has, in recent years, seen an increase in appeals to include multiple modalities in language analyses. While individual studies have incorporated gesture, gaze, facial expression, and prosody, among other modalities, CL has yet to completely embrace the systematic analysis of face-to-face interaction. Here, I present an investigation of five aspect-marking periphrastic constructions in North American English. Using naturalistic inter-actional data (n = 250) from the Red Hen archive, this study establishes a multimodal profile for auxiliary constructions headed by one of five highly aspectualized verbs: CONTINUE, KEEP, START, STOP, and QUIT, as in The jackpot continued to grow and He quit smoking. Results show that gesture timing, the structure of the gesture stroke, and gesture movement type, are variables that iconically and differentially represent distinctive aspectual conceptualizations. This study enhances our understanding of aspectual representation in co-speech gesture and informs the ongoing debate within CL and construction grammar circles of what constitutes conventionalization, or what constitutes a construction (mono- or multimodal).												24	27											NOV	2018	29	4					773	806		10.1515/cog-2017-0009	http://dx.doi.org/10.1515/cog-2017-0009												2026-01-16	WOS:000450073900005
J	Sisman, B; Yamagishi, J; King, S; Li, HZ				Sisman, Berrak; Yamagishi, Junichi; King, Simon; Li, Haizhou			An Overview of Voice Conversion and Its Challenges: From Statistical Modeling to Deep Learning	IEEE-ACM TRANSACTIONS ON AUDIO SPEECH AND LANGUAGE PROCESSING				Article								Speaker identity is one of the important characteristics of human speech. In voice conversion, we change the speaker identity from one to another, while keeping the linguistic content unchanged. Voice conversion involves multiple speech processing techniques, such as speech analysis, spectral conversion, prosody conversion, speaker characterization, and vocoding. With the recent advances in theory and practice, we are now able to produce human-like voice quality with high speaker similarity. In this article, we provide a comprehensive overview of the state-of-the-art of voice conversion techniques and their performance evaluation methods from the statistical approaches to deep learning, and discuss their promise and limitations. We will also report the recent Voice Conversion Challenges (VCC), the performance of the current state of technology, and provide a summary of the available resources for voice conversion research.												248	277												2021	29						132	157		10.1109/TASLP.2020.3038524	http://dx.doi.org/10.1109/TASLP.2020.3038524												2026-01-16	WOS:000597160600011
J	Silva, CC; Almiñana, JMG				Silva, Cristiane Conceicao; Garrido Alminana, Juan Maria			Perceptual validation of two pitch representation procedures applied to Spanish, Brazilian Portuguese and Spanish as a foreign language	ONOMAZEIN				Article								There are many procedures to describe F0 contours in acoustic-phonetic terms. Garrido's (1996, 2001, 2010) and z-score normalization systems have the advantage that they are automatic procedures. Therefore, this paper aims at analyzing both systems in order to determine the possible future application for the analysis of Spanish as a Foreign Language spoken by Brazilians (SFL). To do so, we analyze the melodic curves in declaratives, yes-no questions and wh-questions in Madrid Spanish, in Brazilian Portuguese (BP) spoken in the city of Sao Paulo and finally, in SFL. The validity of both systems was tested through a perception test with 10 Brazilian and 10 Spanish listeners. Listeners rated the degree of similarity between the signals with original intonation and signals with stylized F0 contours. The results showed that Garrido's automatic stylization method is really able to perceptually create representations equivalent to the original ones in Spanish, BP and SFL and also better than those obtained with the procedure based on z-score normalization.												1	1											DEC	2016		34					242	260		10.7764/onomazein.34.15	http://dx.doi.org/10.7764/onomazein.34.15												2026-01-16	WOS:000393208600016
J	Tremblay, A				Tremblay, Annie			Is second language lexical access prosodically constrained? Processing of word stress by French Canadian second language learners of English	APPLIED PSYCHOLINGUISTICS				Article								The objectives of this study are (a) to determine if native speakers of Canadian French at different English proficiencies can use primary stress for recognizing English words and (b) to specify how the second language (L2) learners' (surface-level) knowledge of L2 stress placement influences their use of primary stress in L2 word recognition. Two experiments were conducted: a cross-modal word-identification task investigating (a) and a vocabulary production task investigating (b). The results show that several L2 learners can use primary stress for recognizing English words, but only the L2 learners with targetlike knowledge of stress placement can do so. The results also indicate that knowing where primary stress falls in English words is not sufficient for L2 learners to be able to use stress for L2 lexical access. This suggests that the problem that L2 word stress poses for many native speakers of (Canadian) French is at the level of lexical processing.												39	48											OCT	2008	29	4					553	584		10.1017/S0142716408080247	http://dx.doi.org/10.1017/S0142716408080247												2026-01-16	WOS:000259828500002
J	Pearce, M				Pearce, M			The marketization of discourse about education in UK general election manifestos	TEXT				Article								After 1945, a broad 'post-war consensus' developed in the West. There was general agreement that the state had an important role to play in such areas as macroeconomic management, environmental protection, and social provision for health, education, and welfare. But since the late 1970s, as part of the neo-liberal project to extend the market into every aspect of social life, there has been a backlash against 'inefficient, 'bureaucratic', 'unwieldy', and 'inflexible' state provision. In this article, I examine the discursive dimension of one facet of the 'new capitalism': the marketization of education in the UK. Using frameworks derived from critical discourse analysis, I analyze texts from three election manifestos: the Labour and Conservative manifestos from the 1987 election (a turning point in UK education policy), and the Labour 1997 manifesto. I show how aspects of textual organization, such as patterns of transitivity, the representation of social actors, semantic prosody, and coherence, have a central role to play in the construction of 'comprehensive' and 'market' conceptualizations of the domain.												14	15												2004	24	2					245	265		10.1515/text.2004.009	http://dx.doi.org/10.1515/text.2004.009												2026-01-16	WOS:000226635300004
J	Chrusciel, P				Chrusciel, Patrycja			Typography in the Construction of Social Meaning	ACADEMIC JOURNAL OF MODERN PHILOLOGY				Article								The paper describes typography as one of the mechanisms contributing to the construction of social meanings. According to the French discourse analysis, we assume that social meaning results from the nomination activity, which involves multiple and diverse naming of one element of the real world. Obtaining social meaning is possible by recreating the so-called designational paradigm, i.e. establishing a list of regular reformulations of the initial word introduced by metalanguage (definitional sentences), coordination, diaphors and typography. This work mainly focuses on the latter. The subsequent parts of the article discuss the impact of the comma, colon, parentheses, double dash and quotation marks on meaning construction. The description of each of them is complemented by examples derived from the study on the social meaning of the proper name Pologne (Poland), created and disseminated by the French press. It turns out that the typographic symbols are not a simple visual representation of pauses or intonation. They also have a semantic and pragmatic role. Typography signals the reformulations (comma, colon, parenthesis, dash), introduces the secondary predicates (comma, dash) and allows a journalist to distance him/herself from the created meanings (quotation marks).												0	0												2020	9				SI		39	50															2026-01-16	WOS:000627851700004
J	Zhu, YH				Zhu, Yuhong			Variable f0 of toneless moras in Suzhou Chinese: a computational analysis	GLOSSA-A JOURNAL OF GENERAL LINGUISTICS				Article								Toneless Tone Bearing Units (TBUs) as an analytical device have been widely used in tone and intonation studies, but there is a lack of consensus on how toneless TBUs realize in f0. This study investigates the variable f0 realization of phonologically toneless moras in Suzhou Chinese (Northern Wu) using Naive Bayes classification models. By embedding the toneless moras in different contexts (e.g., between two H tones, preceded by H and followed by L), I have found both intra- and inter-speaker variation across the tonal contexts. Speakers of Suzhou Chinese realized toneless moras in three main ways: insertion of a 'Default L' tone, linear pitch interpolation between the left and right tonal contexts, and spreading of the left tonal context. In addition, I found insufficient evidence for the proposal that toneless TBUs as weak elements in speech realize as a stable target in the mid pitch range (Y. Chen & Xu 2006). The categorical pitch variation of toneless moras is indicative of a phonological model of variable/optional processes, where a single phonological representation (here, the absence of tone) can be mapped to distinctive surface forms (Coetzee & Pater 2011; Coetzee & Kawahara 2013).												0	0											NOV 7	2024	9	1							15487	10.16995/glossa.15487	http://dx.doi.org/10.16995/glossa.15487												2026-01-16	WOS:001380650700003
J	Yang, S; Lu, H; Kang, SY; Xue, LM; Xiao, J; Su, D; Xie, L; Yu, D				Yang, Shan; Lu, Heng; Kang, Shiyin; Xue, Liumeng; Xiao, Jinba; Su, Dan; Xie, Lei; Yu, Dong			On the localness modeling for the self-attention based end-to-end speech synthesis	NEURAL NETWORKS				Article								Attention based end-to-end speech synthesis achieves better performance in both prosody and quality compared to the conventional "front-end"-"back-end" structure. But training such end-to-end framework is usually time-consuming because of the use of recurrent neural networks. To enable parallel calculation and long-range dependency modeling, a solely self-attention based framework named Transformer is proposed recently in the end-to-end family. However, it lacks position information in sequential modeling, so that the extra position representation is crucial to achieve good performance. Besides, the weighted sum form of self-attention is conducted over the whole input sequence when computing latent representation, which may disperse the attention to the whole input sequence other than focusing on the more important neighboring input states, resulting in generation errors. In this paper, we introduce two localness modeling methods to enhance the self-attention based representation for speech synthesis, which maintain the abilities of parallel computation and global-range dependency modeling in self-attention while improving the generation stability. We systematically analyze the solely self-attention based end-to-end speech synthesis framework, and unveil the importance of local context. Then we add the proposed relative-position-aware method to enhance local edges and experiment with different architectures to examine the effectiveness of localness modeling. In order to achieve query-specific window and discard the hyper-parameter of the relative-position-aware approach, we further conduct Gaussian-based bias to enhance localness. Experimental results indicate that the two proposed localness enhanced methods can both improve the performance of the self-attention model, especially when applied to the encoder part. And the query-specific window of Gaussian bias approach is more robust compared with the fixed relative edges. (c) 2020 Elsevier Ltd. All rights reserved.												33	37											MAY	2020	125						121	130		10.1016/j.neunet.2020.01.034	http://dx.doi.org/10.1016/j.neunet.2020.01.034												2026-01-16	WOS:000523306100011
J	Suleymanova, OA; Vodianitskaya, AA; Fomina, MA				Suleymanova, Olga A.; Vodianitskaya, Albina A.; Fomina, Marina A.			Categorization and its linguistic representation	VESTNIK SANKT-PETERBURGSKOGO UNIVERSITETA-YAZYK I LITERATURA				Article								The cognitive science approached categorization from merely linguistic perspectives - the researchers focus on categorization, linguistic means of its representation (articles, pronouns, verbs, word order, intonation), while the process and the results of categorization are verbalized and language means employed in this cognitive operation are still not well studied. We aim to build the categorization frame, reveal the principles of profiling and language means of verbalization employed while describing the process. The research starts with gathering the lexical units from the Russian-Russian Dictionary by Sergey Ozhegov that describe the process of categorization. Then the authors build a categorization frame - first, the objects are classified, second, the speaker rationalizes his/her decision, then, the categorizing per segoes - the objects are referred to some class, the speaker expresses the extent of his confidence of the decision, the extent to which the object is assigned to the class, or correlates the object with the members of the class without 'establishing the membership'. The research resulted in the typology of items that describe categorization, profiling operations with the focus on the way of acquiring knowledge (oboznachat', vyglyadet'), circumstances, aspects of the decision making process - hesitating (vsyo-taki), doubting the decision (vrode, kak budto), estimating the degree to which the object meets the requirements to the members of the category (identichnyj, pohozhij, nastoyashchij), while other language units establish similarities between objects of different classes (pohozhij), emphasize the result of such a cognitive operation as likening (mnimyj, lozhnyj, shozhij), or a weak correspondence between the object and those properties that allow it to be assigned to a particular class (the "worst" representative of the class: zauryadnyj, zahudalyj, nikudyshnij).												0	1												2020	17	2					309	322		10.21638/spbu09.2020.209	http://dx.doi.org/10.21638/spbu09.2020.209												2026-01-16	WOS:000561756100008
J	Smietanka, L; Maka, T				Smietanka, Lukasz; Maka, Tomasz			Enhancing Embedded Space with Low-Level Features for Speech Emotion Recognition	APPLIED SCIENCES-BASEL				Article								This work proposes an approach that uses a feature space by combining the representation obtained in the unsupervised learning process and manually selected features defining the prosody of the utterances. In the experiments, we used two time-frequency representations (Mel and CQT spectrograms) and EmoDB and RAVDESS databases. As the results show, the proposed system improved the classification accuracy of both representations: 1.29% for CQT and 3.75% for Mel spectrogram compared to the typical CNN architecture for the EmoDB dataset and 3.02% for CQT and 0.63% for Mel spectrogram in the case of RAVDESS. Additionally, the results present a significant increase of around 14% in classification performance in the case of happiness and disgust emotions using Mel spectrograms and around 20% in happiness and disgust emotions for CQT in the case of best models trained on EmoDB. On the other hand, in the case of models that achieved the highest result for the RAVDESS database, the most significant improvement was observed in the classification of a neutral state, around 16%, using the Mel spectrogram. For CQT representation, the most significant improvement occurred for fear and surprise, around 9%. Additionally, the average results for all prepared models showed the positive impact of the method used on the quality of classification of most emotional states. For the EmoDB database, the highest average improvement was observed for happiness-14.6%. For other emotions, it ranged from 1.2% to 8.7%. The only exception was the emotion of sadness, for which the classification quality was average decreased by 1% when using the Mel spectrogram. In turn, for the RAVDESS database, the most significant improvement also occurred for happiness-7.5%, while for other emotions ranged from 0.2% to 7.1%, except disgust and calm, the classification of which deteriorated for the Mel spectrogram and the CQT representation, respectively.												3	3											MAR	2025	15	5							2598	10.3390/app15052598	http://dx.doi.org/10.3390/app15052598												2026-01-16	WOS:001442410600001
J	Liu, YH; Zhang, LJ; Yang, L				Liu, Yanhong; Zhang, Lawrence Jun; Yang, Li			A Corpus Linguistics Approach to the Representation of Western Religious Beliefs in Ten Series of Chinese University English Language Teaching Textbooks	FRONTIERS IN PSYCHOLOGY				Article								The early Sino-Western contact was through the way in which religion and language interact to produce language contact. However, research on this contact is relatively limited to date, particularly in the realm of English language materials. In fact, there is a paucity of research on Western religions in English Language Teaching (ELT) textbooks. By applying corpus linguistics as a tool and the Critical Discourse Analysis as the theoretical framework, this manuscript critically investigates the significant semantic domains in ten English language textbook series that are officially approved and are widely used in Chinese universities. The findings suggest that various Western religious beliefs, which are the highly unusual topics in previous Chinese ELT textbooks, are represented in the textbook corpus. The results also show that when presenting the views and attitudes toward Western religious beliefs, these textbooks have adopted an eclectic approach to the material selection. Surprisingly, positive semantic prosody surrounding the concept of religion is evident and no consistent negative authorial stance toward religion is captured. Atheism has been assumed to be in the center of Chinese intellectual traditions and the essence of the Constitution of the Chinese Communist Party. Interestingly, the findings from this study provide a new understanding of Chinese foreign language textbooks in the new era, and its addition to the literature on the study of ELT textbooks, as well as its development worldwide.												6	6											JAN 20	2022	12								789660	10.3389/fpsyg.2021.789660	http://dx.doi.org/10.3389/fpsyg.2021.789660												2026-01-16	WOS:000752676600001
J	ECHOLS, CH				ECHOLS, CH			A PERCEPTUALLY-BASED MODEL OF CHILDRENS EARLIEST PRODUCTIONS	COGNITION				Article								A model is proposed to account for processes underlying the initial extraction and representation of words. The model incorporates perceptual salience into a framework provided by autosegmental phonology. In one study, predictions of the model were tested in a corpus of utterances obtained from three children in the one-word speech period. Analyses of the corpus supported the predictions, suggesting that salience of elements such as stressed and final syllables may contribute to the form of early productions and, specifically, to the form of utterances containing filler syllables and full or partial reduplications. Because the data for this study were children's productions, and the model concerns children's representations, a second study was carried out to investigate representations somewhat more directly. That study also explored the possible influence of an additional prosodic factor on the form of early words. A word-learning task with 2-year-olds, 3-year-olds and adults assessed whether children would attend to stress pattern or segmental sequence in identifying the referent for a word. As expected, children did rely on prosody in their word choices far more frequently than did adults, suggesting that one prosodic component, stress pattern, may in some cases be prominent in a child's representation for a word. The results of the two studies provide support for the utility of the autosegmental framework, as well as additional evidence for the perceptual salience of stressed and final syllables and of stress pattern.												83	90											MAR	1993	46	3					245	296		10.1016/0010-0277(93)90012-K	http://dx.doi.org/10.1016/0010-0277(93)90012-K												2026-01-16	WOS:A1993KT30500003
J	Saeedi, NE; Blamey, PJ; Burkitt, AN; Grayden, DB				Saeedi, Nafise Erfanian; Blamey, Peter J.; Burkitt, Anthony N.; Grayden, David B.			Learning Pitch with STDP: A Computational Model of Place and Temporal Pitch Perception Using Spiking Neural Networks	PLOS COMPUTATIONAL BIOLOGY				Article								Pitch perception is important for understanding speech prosody, music perception, recognizing tones in tonal languages, and perceiving speech in noisy environments. The two principal pitch perception theories consider the place of maximum neural excitation along the auditory nerve and the temporal pattern of the auditory neurons' action potentials (spikes) as pitch cues. This paper describes a biophysical mechanism by which fine-structure temporal information can be extracted from the spikes generated at the auditory periphery. Deriving meaningful pitch-related information from spike times requires neural structures specialized in capturing synchronous or correlated activity from amongst neural events. The emergence of such pitch-processing neural mechanisms is described through a computational model of auditory processing. Simulation results show that a correlation-based, unsupervised, spike-based form of Hebbian learning can explain the development of neural structures required for recognizing the pitch of simple and complex tones, with or without the fundamental frequency. The temporal code is robust to variations in the spectral shape of the signal and thus can explain the phenomenon of pitch constancy.												6	8											APR	2016	12	4							e1004860	10.1371/journal.pcbi.1004860	http://dx.doi.org/10.1371/journal.pcbi.1004860												2026-01-16	WOS:000376584400031
J	Yao, B; Belin, P; Scheepers, C				Yao, Bo; Belin, Pascal; Scheepers, Christoph			Silent Reading of Direct versus Indirect Speech Activates Voice-selective Areas in the Auditory Cortex	JOURNAL OF COGNITIVE NEUROSCIENCE				Article								In human communication, direct speech (e. g., Mary said: "I'm hungry") is perceived to be more vivid than indirect speech (e. g., Mary said [that] she was hungry). However, for silent reading, the representational consequences of this distinction are still unclear. Although many of us share the intuition of an "inner voice," particularly during silent reading of direct speech statements in text, there has been little direct empirical confirmation of this experience so far. Combining fMRI with eye tracking in human volunteers, we show that silent reading of direct versus indirect speech engenders differential brain activation in voice-selective areas of the auditory cortex. This suggests that readers are indeed more likely to engage in perceptual simulations (or spontaneous imagery) of the reported speaker's voice when reading direct speech as opposed to meaning-equivalent indirect speech statements as part of a more vivid representation of the former. Our results may be interpreted in line with embodied cognition and form a starting point for more sophisticated interdisciplinary research on the nature of auditory mental simulation during reading.												93	107											OCT	2011	23	10					3146	3152		10.1162/jocn_a_00022	http://dx.doi.org/10.1162/jocn_a_00022												2026-01-16	WOS:000294055600040
J	Kim, M; Jeong, M; Choi, BJ; Kim, S; Lee, JY; Kim, NS				Kim, Minchan; Jeong, Myeonghun; Choi, Byoung Jin; Kim, Semin; Lee, Joun Yeop; Kim, Nam Soo			Utilizing Neural Transducers for Two-Stage Text-to-Speech via Semantic Token Prediction	IEEE TRANSACTIONS ON AUDIO SPEECH AND LANGUAGE PROCESSING				Article								We propose a novel text-to-speech (TTS) framework centered around a neural transducer. Our approach divides the whole TTS pipeline into semantic-level sequence-to-sequence (seq2seq) modeling and fine-grained acoustic modeling stages, utilizing discrete semantic tokens obtained from wav2vec2.0 embeddings. For a robust and efficient alignment modeling, we employ a neural transducer named token transducer for the semantic token prediction, benefiting from its hard monotonic alignment constraints. Subsequently, a non-autoregressive (NAR) speech generator efficiently synthesizes waveforms from these semantic tokens. Additionally, a reference speech controls temporal dynamics and acoustic conditions at each stage. This decoupled framework reduces the training complexity of TTS while allowing each stage to focus on semantic and acoustic modeling. Our experimental results on zero-shot adaptive TTS demonstrate that our model surpasses the baseline in terms of speech quality and speaker similarity, both objectively and subjectively. We also delve into the inference speed and prosody control capabilities of our approach, highlighting the potential of neural transducers in TTS frameworks.												0	0												2025	33						1922	1932		10.1109/TASLPRO.2025.3566247	http://dx.doi.org/10.1109/TASLPRO.2025.3566247												2026-01-16	WOS:001487988400005
J	Power, AJ; Colling, LJ; Mead, N; Barnes, L; Goswami, U				Power, Alan J.; Colling, Lincoln J.; Mead, Natasha; Barnes, Lisa; Goswami, Usha			Neural encoding of the speech envelope by children with developmental dyslexia	BRAIN AND LANGUAGE				Article								Developmental dyslexia is consistently associated with difficulties in processing phonology (linguistic sound structure) across languages. One view is that dyslexia is characterised by a cognitive impairment in the "phonological representation" of word forms, which arises long before the child presents with a reading problem. Here we investigate a possible neural basis for developmental phonological impairments. We assess the neural quality of speech encoding in children with dyslexia by measuring the accuracy of low-frequency speech envelope encoding using EEG. We tested children with dyslexia and chronological age-matched (CA) and reading-level matched (RL) younger children. Participants listened to semantically-unpredictable sentences in a word report task. The sentences were noise-vocoded to increase reliance on envelope cues. Envelope reconstruction for envelopes between 0 and 10 Hz showed that the children with dyslexia had significantly poorer speech encoding in the 0-2 Hz band compared to both CA and RL controls. These data suggest that impaired neural encoding of low frequency speech envelopes, related to speech prosody, may underpin the phonological deficit that causes dyslexia across languages. (C) 2016 The Authors. Published by Elsevier Inc.												124	138											SEP	2016	160						1	10		10.1016/j.bandl.2016.06.006	http://dx.doi.org/10.1016/j.bandl.2016.06.006												2026-01-16	WOS:000382796400001
J	Stine-Morrow, EAL; Payne, BR				Stine-Morrow, Elizabeth A. L.; Payne, Brennan R.			AGE DIFFERENCES IN LANGUAGE SEGMENTATION	EXPERIMENTAL AGING RESEARCH				Article								Reading bears the evolutionary footprint of spoken communication. Prosodic contour in speech helps listeners parse sentences and establish semantic focus. Readers' regulation of input mirrors the segmentation patterns of prosody, such that reading times are longer for words at the ends of syntactic constituents. As reflected in these micropauses, older readers are often found to segment text into smaller chunks. The mechanisms underlying these micropauses are unclear, with some arguing that they derive from the mental simulation of prosodic contour and others arguing they reflect higher-level language comprehension mechanisms (e.g., conceptual integration, consolidation with existing knowledge, ambiguity resolution) that are common across modality and support the consolidation of the memory representation. The authors review evidence based on reading time and comprehension performance to suggest that (a) age differences in segmentation derive both from age-related declines in working memory, as well as from crystallized ability and knowledge, which have the potential to grow in adulthood, and that (b) shifts in segmentation patterns may be a pathway through which language comprehension is preserved in late life.												13	15											JAN 1	2016	42	1			SI		107	125		10.1080/0361073X.2016.1108751	http://dx.doi.org/10.1080/0361073X.2016.1108751												2026-01-16	WOS:000366810500007
J	Li, YN; Tang, C; Lu, JF; Wu, JS; Chang, EF				Li, Yuanning; Tang, Claire; Lu, Junfeng; Wu, Jinsong; Chang, Edward F.			Human cortical encoding of pitch in tonal and non-tonal languages	NATURE COMMUNICATIONS				Article								Languages can use a common repertoire of vocal sounds to signify distinct meanings. In tonal languages, such as Mandarin Chinese, pitch contours of syllables distinguish one word from another, whereas in non-tonal languages, such as English, pitch is used to convey intonation. The neural computations underlying language specialization in speech perception are unknown. Here, we use a cross-linguistic approach to address this. Native Mandarin- and English- speaking participants each listened to both Mandarin and English speech, while neural activity was directly recorded from the non-primary auditory cortex. Both groups show language-general coding of speaker-invariant pitch at the single electrode level. At the electrode population level, we find language-specific distribution of cortical tuning parameters in Mandarin speakers only, with enhanced sensitivity to Mandarin tone categories. Our results show that speech perception relies upon a shared cortical auditory feature processing mechanism, which may be tuned to the statistics of a given language. Different languages rely on different vocal sounds to convey meaning. Here the authors show that language-general coding of pitch occurs in the non-primary auditory cortex for both tonal (Mandarin Chinese) and non-tonal (English) languages, with some language specificity on the population level.												51	59											FEB 19	2021	12	1							1161	10.1038/s41467-021-21430-x	http://dx.doi.org/10.1038/s41467-021-21430-x												2026-01-16	WOS:000621489800003
J	Olthoff, A; Baudewig, J; Kruse, E; Dechent, P				Olthoff, Arno; Baudewig, Juergen; Kruse, Eberhard; Dechent, Peter			Cortical Sensorimotor Control in Vocalization: A Functional Magnetic Resonance Imaging Study	LARYNGOSCOPE				Article; Proceedings Paper	22nd Scientific Meeting of the German-Society-of-Phoniatrics-and-Pedaudiology	SEP 16-18, 2005	Berlin, GERMANY					Background: Verbal communication is a human feature and volitional vocalization is its basis. However, little is known regarding the cortical areas involved in human vocalization. Methods: Therefore, functional magnetic resonance imaging at 3 Tesla was performed in 16 healthy adults to evaluate brain activations related to voice production. The main experiments included tasks involving motor control of laryngeal muscles with and without intonation. In addition, reference mappings of the sensorimotor hand area and the auditory cortices were performed. Results: Related to vocalization, in addition to activation of the most lateral aspect of the primary sensorimotor cortex close to the Sylvian fissure (M1c), we found activations medially (M1a) and laterally (M1b) of the well-known sensorimotor hand area. Moreover, the supplementary motor area and the anterior cingulate cortex were activated. Conclusions: Although M1a could be ascribed to motor control of breathing, M1b has been associated with laryngeal motor control. Consequently, even though M1c represents a laryngeal sensorimotor area, its exclusiveness as suggested previously could not be confirmed. Activations in the supplementary motor area and anterior cingulate cortex were ascribed to "vocal-motor planning." The present data provide the basis for further functional magnetic resonance imaging studies in patients with neurological laryngeal disorders.												38	44											NOV	2008	118	11					2091	2096		10.1097/MLG.0b013e31817fd40f	http://dx.doi.org/10.1097/MLG.0b013e31817fd40f												2026-01-16	WOS:000260874700035
J	Snape, N; Kupisch, T				Snape, Neal; Kupisch, Tanja			Ultimate attainment of second language articles: A case study of an endstate second language Turkish-English speaker	SECOND LANGUAGE RESEARCH				Article								An area of considerable interest in second language (L2) acquisition is the difficulties learners face with the acquisition of articles. This article examines the role of prosody in the acquisition of articles by an endstate L2 English speaker focusing on the free morphemes the and a. In order to analyse the articles produced by a Turkish speaker named SD, we used the Praat (Boersma and Weenink, 2006) phonetic analysis software to determine the prosodic shape of each article in article + noun configurations and article + adjective + noun configurations. The aim of the analysis is to see whether a more detailed analysis of the data would be fully consistent with the strong or weak interpretation of the Prosodic Transfer Hypothesis. The findings of our analysis show that SD produces a large percentage of stressed articles, which are non target-like. We discuss the implications of our analysis for the interlanguage representation of articles by SD as well as the Prosodic Transfer Hypothesis.												3	6											OCT	2010	26	4					527	548		10.1177/0267658310377102	http://dx.doi.org/10.1177/0267658310377102												2026-01-16	WOS:000282125300004
J	COPPENS, P; ROBEY, RR				COPPENS, P; ROBEY, RR			CROSSED APHASIA - NEW PERSPECTIVES	APHASIOLOGY				Article								Crossed aphasia reflects an unusual lateralization pattern characterized by a dissociation between manual and language hemispheric dominance in a right-handed individual. In order to circumscribe the syndrome of crossed aphasia, authors have developed stringent exclusion criteria to define that syndrome. We believe that such an approach artificially created a homogeneous syndrome. As an alternative to the rigorous exclusion criteria approach, we propose to broaden the definition of crossed aphasia to accommodate the various demonstrated aphasic symptoms. The interest in crossed aphasia can then shift from the search for a universal symptom complex to different subgroups of patients. Indeed, there now appears to be overwhelming evidence (including Wada experiments) to indicate that crossed aphasia can either be the mirror image of uncrossed aphasia or indicate a bilateral language representation pattern. Two patients are presented and their symptoms arc discussed in the light of the literature. One of our patients is the only one to our knowledge to evidence affective prosody impairments. We argue that this latter symptom be added to the list of associated signs to be assessed as part of a crossed aphasia battery.												14	14											NOV-DEC	1992	6	6					585	596		10.1080/02687039208249493	http://dx.doi.org/10.1080/02687039208249493												2026-01-16	WOS:A1992JX49300005
J	Awal, A				Awal, Abdul			Ecolinguistics in Bangladeshi Secondary-Level English Textbooks: A Corpus Analysis	COLOMBIAN APPLIED LINGUISTICS JOURNAL				Article								Ecolinguistics has developed over the past five decades in response to ecological crises and the growing demand for an ecological perspective within linguistics (Zhou, 2021). This study examines the integration of environmental content in 'English for Today Classes Nine-Ten', a secondary-level textbook used in Bangladesh, a country facing a range of environmental challenges. Employing both qualitative and quantitative methods, including the use of AntConc and semantic prosody analysis, the study assessed the frequency, context, and presentation of ecological themes such as sustainability, conservation, and environmental awareness. The findings revealed that ecological terms are included in the textbook inconsistently and with limited diversity, which may hinder students' development of environmental awareness. The research aimed to influence curriculum development and educational policies, underlining the need to incorporate varied and recent environmental issues into educational materials. Therefore, this study emphasizes the need for a more comprehensive inclusion of ecological elements to promote ecolinguistic awareness among students. It contributes to ecolinguistics by recommending improvements in environmental representation in English curricula. Additionally, it offers valuable insights for educators and policymakers to enhance students' environmental literacy and promote sustainable development.												0	0											JAN-JUN	2025	27	1					18	32		10.14483/22487085.21698	http://dx.doi.org/10.14483/22487085.21698												2026-01-16	WOS:001496162900002
J	Liu, J; Song, H; Chen, DP; Wang, B; Zhang, ZW				Liu, Jia; Song, Hong; Chen, Dapeng; Wang, Bin; Zhang, Zengwei			A Multimodal Sentiment Analysis Model Enhanced with Non-verbal Information and Contrastive Learning	JOURNAL OF ELECTRONICS & INFORMATION TECHNOLOGY				Article								Deep learning methods have gained popularity in multimodal sentiment analysis due to their impressive representation and fusion capabilities in recent years. Existing studies often analyze the emotions of individuals using multimodal information such as text, facial expressions, and speech intonation, primarily employing complex fusion methods. However, existing models inadequately consider the dynamic changes in emotions over long time sequences, resulting in suboptimal performance in sentiment analysis. In response to this issue, a Multimodal Sentiment Analysis Model Enhanced with Non-verbal Information and Contrastive Learning is proposed in this paper. Firstly, the paper employs long-term textual information to enable the model to learn dynamic changes in audio and video across extended time sequences. Subsequently, a gating mechanism is employed to eliminate redundant information and semantic ambiguity between modalities. Finally, contrastive learning is applied to strengthen the interaction between modalities, enhancing the model's generalization. Experimental results demonstrate that on the CMU-MOSI dataset, the model improves the Pearson Correlation coefficient (Corr) and F1 score by 3.7% and 2.1%, respectively. On the CMU-MOSEI dataset, the model increases "Corr" and "F1 score" by 1.4% and 1.1%, respectively. Therefore, the proposed model effectively utilizes intermodal interaction information while eliminating information redundancy.												1	2											AUG	2024	46	8					3372	3381		10.11999/JEIT231274	http://dx.doi.org/10.11999/JEIT231274												2026-01-16	WOS:001491586400008
J	Huffman, MK				Huffman, MK			Segmental and prosodic effects on coda glottalization	JOURNAL OF PHONETICS				Article								This paper examines effects of segmental context and prosodic phrasing on the occurrence of coda glottalization in American English. On the basis of acoustic data from six female speakers, it is argued that the main effect of following segmental context on the occurrence of coda glottalization is due to anticipatory coarticulation, with anticipation of following sonorant consonant articulations favoring the aerodynamic conditions for glottalized voicing. The cross-dialect propensity to have high coda glottalization rates before sonorant consonants can then be understood to arise as a phonetically natural consequence of normal coarticulation processes. This coarticulatory account is supported by the fact that when an intonation phrase (IP) boundary intervenes between the coda consonant and a following sonorant, the contextual effect on glottalization rates is weakened. Our data also suggest that, all else being equal, presence of an IP boundary favors the occurrence of glottalization. These patterns are compatible with an account in which a glottal constriction goal on the coda consonant is optional in the linguistic representation. The optionality of this goal is somewhat problematic for many models of phonetic knowledge, but the coarticulatory explanation of the sonorancy effect helps to insightfully simplify any account of the distribution of glottalization. (c) 2005 Elsevier Ltd. All rights reserved.												41	53											JUL	2005	33	3					335	362		10.1016/j.wocn.2005.02.004	http://dx.doi.org/10.1016/j.wocn.2005.02.004												2026-01-16	WOS:000231740700004
J	Yue, JX; Bastiaanse, R; Howard, D; Alter, K				Yue, Jinxing; Bastiaanse, Roelien; Howard, David; Alter, Kai			Representational level matters for tone-word recognition: Evidence from form priming	QUARTERLY JOURNAL OF EXPERIMENTAL PSYCHOLOGY				Article								In a form priming experiment with a lexical decision task, we investigated whether the representational structure of lexical tone in lexical memory impacts spoken-word recognition in Mandarin. Target monosyllabic words were preceded by five types of primes: (1) the same real words (/lun4/-/lun4/), (2) real words with only tone contrasts (/lun2/-/lun4/), (3) unrelated real words (/pie3/-/lun4/), (4) pseudowords with only tone contrasts (*/lun3/-/lun4/), and (5) unrelated pseudowords (*/tai3/-/lun4/). We found a facilitation effect in target words with pseudoword primes that share the segmental syllable but contrast in tones (*/lun3/-/lun4/). Moreover, no evident form priming effect was observed in target words primed by real words with only tone contrasts (/lun2/-/lun4/). These results suggest that the recognition of a tone word is influenced by the representational level of tone accessed by the prime word. The distinctive priming patterns between real-word and pseudoword primes are best explained by the connectionist models of tone-word recognition, which assume a hierarchical representation of lexical tone.												1	1											MAY	2024	77	5					1125	1135		10.1177/17470218231203615	http://dx.doi.org/10.1177/17470218231203615		OCT 2023										2026-01-16	WOS:001087883000001
J	Alam, F; Danieli, M; Riccardi, G				Alam, Firoj; Danieli, Morena; Riccardi, Giuseppe			Annotating and modeling empathy in spoken conversations	COMPUTER SPEECH AND LANGUAGE				Article								Empathy, as defined in behavioral sciences, expresses the ability of human beings to recognize, understand and react to emotions, attitudes and beliefs of others. In this paper, we address two related problems in automatic affective behavior analysis: the design of the annotation protocol and the automatic recognition of empathy from human human dyadic spoken conversations. We propose and evaluate an annotation scheme for empathy inspired by the modal model of emotions. The annotation scheme was evaluated on a corpus of real-life, dyadic spoken conversations. In the context of behavioral analysis, we designed an automatic segmentation and classification system for empathy. Given the different speech and language levels of representation where empathy may be communicated, we investigated features derived from the lexical and acoustic spaces. The feature development process was designed to support both the fusion and automatic selection of relevant features from a high dimensional space. The automatic classification system was evaluated on call center conversations where it showed significantly better performance than the baseline. (C) 2017 Elsevier Ltd. All rights reserved.												48	60											JUL	2018	50						40	61		10.1016/j.csl.2017.12.003	http://dx.doi.org/10.1016/j.csl.2017.12.003												2026-01-16	WOS:000427479600003
J	Sun, XE; Han, X; Yao, F; Xu, JW				Sun, Xueer; Han, Xiao; Yao, Fei; Xu, Jiawei			Emotion-aware cross-modal music generation based on multimodal emotion recognition	ALEXANDRIA ENGINEERING JOURNAL				Article								This study presents a Multimodal Emotion-guided Music Generation Model (MEMGM) that directly translates multimodal affective states into instrumental music. Unlike prior approaches relying on textual intermediaries or discrete categories, MEMGM integrates facial expressions, speech prosody, and ECG-derived heart signals into a continuous valence-arousal-dominance (VAD) space for fine-grained emotion representation. A new MIDI-based dataset with continuous VAD annotations is constructed, enabling controllable manipulation of musical elements and nuanced mapping of emotional dynamics. The framework combines a cross-modal Transformer, multimodal BiLSTM, and gating block for robust affective recognition, followed by a plug-and-play generation module enhanced with supervised contrastive learning to ensure intra- and inter-modal consistency. Experimental results demonstrate superior performance in both emotion recognition and music generation compared to state-of-theart baselines. Subjective evaluations confirm that the generated music aligns closely with users' perceived emotions. The main contributions are: (1) an end-to-end pathway from multimodal signals to music without textual intermediaries, (2) a VAD-annotated MIDI dataset for expressive generation, and (3) a contrastive learning strategy that enhances affective alignment across modalities.												0	0											DEC	2025	133						254	270		10.1016/j.aej.2025.11.020	http://dx.doi.org/10.1016/j.aej.2025.11.020												2026-01-16	WOS:001628070500001
J	Dilley, LC				Dilley, Laura C.			Pitch Range Variation in English Tonal Contrasts: Continuous or Categorical?	PHONETICA				Article								The importance of pitch range variation for intonational meaning and theory is well known; however, whether pitch range is a phonetic dimension which is treated categorically in English remains unclear. To test this possibility, three intonation continua varying in pitch range were constructed which had endpoints with contrastive representations under autosegmental-metrical (AM) theory: H* vs. L+H*, H* with 'peak delay' vs. L*+H, and %H L* vs. L*. The prediction derived from AM theory was that the reproduction of continuous pitch range variation should show a discrete pattern reflecting a change in the phonological representation of tonal sequences and in the number of tonal targets across each continuum. Participants' reproductions of each stimulus set showed continuous variation in pitch range, suggesting that pitch range is a gradient phonetic dimension in English conveying semantic contrast, similar to the formant space for vowels. Moreover, the gradience observed in productions across all parts of the pitch range suggests that contours within each series had the same number of tonal targets. The results support a version of AM theory in which rises and falls are usually comprised of two tonal targets, with strictly monotonic f(0) interpolation between them. Copyright (C) 2010 S. Karger AG, Basel												24	34												2010	67	1-2					63	81		10.1159/000319379	http://dx.doi.org/10.1159/000319379												2026-01-16	WOS:000281277800004
J	Joshy, AA; Rajan, R				Joshy, Amlu Anna; Rajan, Rajeev			Automated Dysarthria Severity Classification: A Study on Acoustic Features and Deep Learning Techniques	IEEE TRANSACTIONS ON NEURAL SYSTEMS AND REHABILITATION ENGINEERING				Article								Assessing the severity level of dysarthria can provide an insight into the patient's improvement, assist pathologists to plan therapy, and aid automatic dysarthric speech recognition systems. In this article, we present a comparative study on the classification of dysarthria severity levels using different deep learning techniques and acoustic features. First, we evaluate the basic architectural choices such as deep neural network (DNN), convolutional neural network, gated recurrent units and long short-term memory network using the basic speech features, namely, Mel-frequency cepstral coefficients (MFCCs) and constant-Q cepstral coefficients. Next, speech-disorder specific features computed from prosody, articulation, phonation and glottal functioning are evaluated on DNN models. Finally, we explore the utility of low-dimensional feature representation using subspace modeling to give i-vectors, which are then classified using DNN models. Evaluation is done using the standard UA-Speech and TORGO databases. By giving an accuracy of 93.97% under the speaker-dependent scenario and 49.22% under the speaker-independent scenario for the UA-Speech database, the DNN classifier using MFCC-based i-vectors outperforms other systems.												53	60												2022	30						1147	1157		10.1109/TNSRE.2022.3169814	http://dx.doi.org/10.1109/TNSRE.2022.3169814												2026-01-16	WOS:000790812300009
J	Trevarthen, C				Trevarthen, Colwin			Apres-propos Anthony DeCasper, explorer of a new psychology of intimate intentions in understanding	ENFANCE				Article								Forty years ago, Tony DeCasper developed a new psychology of childhood, which would transform scientific understanding of motives we share. By adapting an operant method to study the initiative of the infant seeking experience, he clarified how human actions are generated in measures of time in the mind. His method offered the newborn the opportunity to direct the sensations of their sucking movements to select experiences. He proved the fetus could learn the mother's voice and appreciate the rhythms and melodies of her movements. With colleagues in the University of Carolina and in Paris he explored for the musical dynamics and emotions of narratives in shared life that animate learning of speech and language, and other cultural skills. With French colleagues, he recorded changes in heartbeat to detect the emotions of a fetus, and to show their enjoyment of songs and rhymes recited by the mother. Inspired by the courage and imagination of Tony's life in science, we believe that the aesthetic and moral evaluations of human experience are an essential part of our autopoeitic nature, not only products of acquired reasoning and symbolic representation.												0	0											JUL-SEP	2017		3					387	401															2026-01-16	WOS:000461203600008
J	Bocci, G; Bianchi, V; Cruschina, S				Bocci, Giuliano; Bianchi, Valentina; Cruschina, Silvio			Focus inwh-questions Evidence from Italian	NATURAL LANGUAGE & LINGUISTIC THEORY				Article								This paper addresses two long-standing issues concerning focus: first, the question of whether the focal interpretation is directly read off the prosodic structure of a sentence, or it is rather mediated by a [focus] feature encoded in the syntactic representation; second, whether interrogativewh-phrases are inherently endowed with a [focus] feature. We provide evidence from two prosodic experiments on directwh-questions in Italian, showing that the Nuclear Pitch Accent (NPA) and main stress fall on the lexical verb, without a concomitant focal interpretation of the latter. Furthermore, we show that NPA assignment is sensitive to the derivational history of thewh-phrase under short-distance vs. long-distance extraction. We account for the observed NPA distribution in terms of a [focus] feature which is bundled with the [wh] in direct questions, and is specified on each phase head that hosts in its edge one link of thewh-chain. Thus, v degrees is specified for the feature bundle {wh, focus} and attracts the assignment of the NPA, which is then realized on the lexical verb. Our findings, thus, cast doubt on the direct association between prosodic prominence and a focal interpretation.												12	13											MAY	2021	39	2					405	455		10.1007/s11049-020-09483-x	http://dx.doi.org/10.1007/s11049-020-09483-x		JUL 2020										2026-01-16	WOS:000552811100002
J	Kim, JH; Yang, HS; Ju, YC; Kim, I; Kim, BY; Chung, JS				Kim, Ji-Hoon; Yang, Hong-Sun; Ju, Yoon-Cheol; Kim, Il-Hwan; Kim, Byeong-Yeol; Chung, Joon Son			CrossSpeech plus plus : Cross-Lingual Speech Synthesis With Decoupled Language and Speaker Generation	IEEE TRANSACTIONS ON AUDIO SPEECH AND LANGUAGE PROCESSING				Article								The goal of this work is to generate natural speech in multiple languages while maintaining the same speaker identity, a task known as cross-lingual speech synthesis. A key challenge of cross-lingual speech synthesis is the language-speaker entanglement problem, which causes the quality of cross-lingual systems to lag behind that of intra-lingual systems. In this paper, we propose CrossSpeech++, which effectively disentangles language and speaker information and significantly improves the quality of cross-lingual speech synthesis. To this end, we break the complex speech generation pipeline into two simple components: language-dependent and speaker-dependent generators. The language-dependent generator produces linguistic variations that are not biased by specific speaker attributes. The speaker-dependent generator models acoustic variations that characterize speaker identity. By handling each type of information in separate modules, our method can effectively disentangle language and speaker representation. We conduct extensive experiments using various metrics, and demonstrate that CrossSpeech++ achieves significant improvements in cross-lingual speech synthesis, outperforming existing methods by a large margin.												0	0												2025	33						1364	1374		10.1109/TASLPRO.2025.3547231	http://dx.doi.org/10.1109/TASLPRO.2025.3547231												2026-01-16	WOS:001478168200002
J	Protopapas, A; Panagaki, E; Andrikopoulou, A; Palma, NG; Arvaniti, A				Protopapas, Athanassios; Panagaki, Eleonora; Andrikopoulou, Angeliki; Palma, Nicolas Gutierrez; Arvaniti, Amalia			Priming Stress Patterns in Word Recognition	JOURNAL OF EXPERIMENTAL PSYCHOLOGY-HUMAN PERCEPTION AND PERFORMANCE				Article								This study addresses the lexical representation of stress in a series of 5 intramodal and cross-modal priming experiments in the Greek language using lexical decision tasks with auditory and visual targets. Three-syllable primes and targets were matched in first syllable segments, length, and other variables, and differed segmentally in the second and third syllable. Primes matched or mismatched targets in stress, which was placed on the penultimate or antepenultimate syllable. There was no evidence for stress priming in either accuracy or latency of responses to either words or pseudowords in any of these experiments, either intramodally or cross-modally. In contrast, a control fragment priming experiment using only the first 2 syllables of the primes produced a significant effect of stress congruence for words but not for pseudowords. The results are interpreted in the context of previous findings in the literature as arising from lexical activation rather than from matching stress patterns. Overall, findings are consistent with lexical representations including stress information that is inseparable from segmental specification, rather than with abstract representations of metrical templates.												13	16											NOV	2016	42	11					1739	1760		10.1037/xhp0000259	http://dx.doi.org/10.1037/xhp0000259												2026-01-16	WOS:000387150100006
J	Banissy, MJ; Sauter, DA; Ward, J; Warren, JE; Walsh, V; Scott, SK				Banissy, Michael J.; Sauter, Disa Anna; Ward, Jamie; Warren, Jane E.; Walsh, Vincent; Scott, Sophie K.			Suppressing Sensorimotor Activity Modulates the Discrimination of Auditory Emotions But Not Speaker Identity	JOURNAL OF NEUROSCIENCE				Article								Our ability to recognize the emotions of others is a crucial feature of human social cognition. Functional neuroimaging studies indicate that activity in sensorimotor cortices is evoked during the perception of emotion. In the visual domain, right somatosensory cortex activity has been shown to be critical for facial emotion recognition. However, the importance of sensorimotor representations in modalities outside of vision remains unknown. Here we use continuous theta-burst transcranial magnetic stimulation (cTBS) to investigate whether neural activity in the right postcentral gyrus (rPoG) and right lateral premotor cortex (rPM) is involved in nonverbal auditory emotion recognition. Three groups of participants completed same-different tasks on auditory stimuli, discriminating between the emotion expressed and the speakers' identities, before and following cTBS targeted at rPoG, rPM, or the vertex (control site). A task-selective deficit in auditory emotion discrimination was observed. Stimulation to rPoG and rPM resulted in a disruption of participants' abilities to discriminate emotion, but not identity, from vocal signals. These findings suggest that sensorimotor activity may be a modality-independent mechanism which aids emotion discrimination.												55	64											OCT 13	2010	30	41					13552	13557		10.1523/JNEUROSCI.0786-10.2010	http://dx.doi.org/10.1523/JNEUROSCI.0786-10.2010												2026-01-16	WOS:000282874600002
J	Spalek, K; Zeldes, A				Spalek, Katharina; Zeldes, Amir			Converging evidence for the relevance of alternative sets: data from NPs with focus sensitive particles in German	LANGUAGE AND COGNITION				Article								Recent psycholinguistic studies on the reality of alternative sets in processing focus NPs have shown that focus particles like 'only' play a special role in activating the mental representation of alternatives to focused nouns. In this paper we present a new corpus study which provides converging evidence to support psycholinguistic findings and suggests that alternatives preceded by a focus particle are not only more activated in experimental contexts, but are also more likely to be discussed in the subsequent context. To this end we develop and evaluate inter-annotator agreement on two novel annotation tasks in naturally occurring German corpus data: recognition of nominal alternatives in general without any context, and recognition of alternatives in the context of sentence pairs. We show that while annotators agree poorly on the first, they agree strongly on the second. We also develop a concept of 'alternative density', the number of alternatives realized in a sentence following a target NP, and present a mixed-eff ects model showing a very significant rise in density after the presence of German nur 'only' independently of other factors.												9	9											MAR	2017	9	1					24	51		10.1017/langcog.2015.12	http://dx.doi.org/10.1017/langcog.2015.12												2026-01-16	WOS:000395074000002
J	Kuhn, LK; Wydell, T; Lavan, N; McGettigan, C; Garrido, L				Kuhn, Lisa Katharina; Wydell, Taeko; Lavan, Nadine; McGettigan, Carolyn; Garrido, Lucia			Similar Representations of Emotions Across Faces and Voices	EMOTION				Article								Emotions are a vital component of social communication, carried across a range of modalities and via different perceptual signals such as specific muscle contractions in the face and in the upper respiratory system. Previous studies have found that emotion recognition impairments after brain damage depend on the modality of presentation: recognition from faces may be impaired whereas recognition from voices remains preserved, and vice versa. On the other hand, there is also evidence for shared neural activation during emotion processing in both modalities. In a behavioral study, we investigated whether there are shared representations in the recognition of emotions from faces and voices. We used a within-subjects design in which participants rated the intensity of facial expressions and nonverbal vocalizations for each of the 6 basic emotion labels. For each participant and each modality, we then computed a representation matrix with the intensity ratings of each emotion. These matrices allowed us to examine the patterns of confusions between emotions and to characterize the representations of emotions within each modality. We then compared the representations across modalities by computing the correlations of the representation matrices across faces and voices. We found highly correlated matrices across modalities, which suggest similar representations of emotions across faces and voices. We also showed that these results could not be explained by commonalities between low-level visual and acoustic properties of the stimuli. We thus propose that there are similar or shared coding mechanisms for emotions which may act independently of modality, despite their distinct perceptual inputs.												19	24											SEP	2017	17	6					912	937		10.1037/emo0000282	http://dx.doi.org/10.1037/emo0000282												2026-01-16	WOS:000423033700004
J	Kawashima, H; Funayama, M; Inaba, Y; Baba, M				Kawashima, Hiroaki; Funayama, Michitaka; Inaba, Yoshie; Baba, Mikoto			Articulatory-based Phonemic Paraphasia in Conduction Aphasia: A Dysfunction in Phoneme-to-Articulation Conversion Uncovered Through Crossed Aphasia	COGNITIVE AND BEHAVIORAL NEUROLOGY				Article								Phonemic paraphasia, a common characteristic of conduction aphasia, has traditionally been attributed to phonological representation dysfunction. An alternative hypothesis posits that phonemic paraphasia arises from difficulty converting phonemes into their corresponding articulatory maneuvers. However, detailed case studies supporting this theory have been lacking. In this report, we present the case of a 61-year-old right-handed man with right temporo-parietal infarction who exhibited crossed aphasia characterized by typical conduction aphasia symptoms (eg, relatively fluent speech with intact comprehension, frequent phonemic paraphasia, and pronounced difficulties in oral repetition) in the absence of distorted articulation, syllable segmentation, and prosody impairment. Despite the frequent occurrence of phonemic paraphasia and articulatory challenges, our patient's phonological representations remained relatively intact. His phonemic paraphasia was often self-corrected to produce correct responses, a feature known as conduit d'approche. During the oral repetition of individual mora (ie, the smallest unit of speech in Japanese), we observed that the patient consistently traced the corresponding Hiragana phonetic symbol accurately, despite his difficulties in articulation. We substantiated this phenomenon through objective assessment and posit that it resulted from an unusual separation of language functions in crossed aphasia-specifically, a disconnection between phonological representations in the right temporo-parietal cortex and speech articulation engrams in the left hemisphere. In this case of conduction aphasia, articulatory-based phonemic paraphasia may be viewed as an inability to convert phonemes into the appropriate articulatory maneuvers rather than as phonological representation dysfunction or apraxia of speech.												1	1											SEP	2024	37	3					165	179		10.1097/WNN.0000000000000371	http://dx.doi.org/10.1097/WNN.0000000000000371												2026-01-16	WOS:001304164200005
J	Alharbi, A; Albawardi, A				Alharbi, Amal; Albawardi, Areej			The social representation of 'women' on X platform before and after the launch of Saudi vision 2030	APPLIED CORPUS LINGUISTICS				Article								This study investigates how Saudi males and females represent "women" on X (formerly Twitter), focusing on two distinct timeframes: 2015 (before Vision 2030) and 2022 (after Vision 2030). By integrating applied Corpus Linguistics (CL) and Critical Discourse Analysis (CDA), the research examines a corpus of 10,000 Arabic tweets (equally divided between male and female authors), thereby illuminating how broader social reforms correspond with shifts in online discourse. Specifically, we apply frequency counts, collocation analysis, and semantic prosody techniques in order to compare lexical choice, thematic focus, and evaluative stands in relation to Saudi women during both phases. The findings reveal a discernible positive shift in attitudes after the official publication of Vision 2030. In 2015, the discourse was more likely to be about "spinsterhood," boycotts, and guardianship, reflecting predominantly negative or restrictive portrayals of women. By 2022, tweets became more likely to be about empowerment, achievements, and national pride, suggesting changing social attitudes that increasingly legitimize women's roles in workplaces, education, and public life. Although pockets of negativity persist-particularly in certain domains such as sports-these pockets of resistance are outnumbered by the overall trend towards more inclusive and celebratory discourses. These results highlight how top-down reforms, such as the lifting of the driving ban and the promotion of women's employment, have reshaped Saudi women's discourse. Beyond its sociolinguistic and critical discourse studies contribution, this research highlights the power of large-scale policy changes in achieving shifts in everyday language and attitudes in conservative societies.												0	0											DEC	2025	5	3							100140	10.1016/j.acorp.2025.100140	http://dx.doi.org/10.1016/j.acorp.2025.100140		AUG 2025										2026-01-16	WOS:001546509000001
J	Deutsch, D; Henthorn, T				Deutsch, D; Henthorn, T			Absolute pitch, speech, and tone language: Some experiments and a proposed framework	MUSIC PERCEPTION				Article								Absolute pitch is generally considered to reflect a rare musical endowment; however, its characteristics are puzzling and its genesis is unclear. We describe two experiments in which native speakers of tone languages-Mandarin and Vietnamese-were found to display a remarkably precise and stable form of absolute pitch in enunciating words. We further describe a third experiment in which speakers of English displayed less stability on an analogous task. Based on these findings, and considering the related literatures on critical periods in speech development, and the neurological underpinnings of lexical tone, we propose a framework for the genesis of absolute pitch. The framework assumes that absolute pitch originally evolved as a feature of speech, analogous to other features such as vowel quality, and that speakers of tone language naturally acquire this feature during the critical period for speech acquisition. We further propose that the acquisition of absolute pitch by rare individuals who speak an intonation language may be associated with a critical period of unusually long duration, so that it encompasses the age at which the child can take music lessons. We conclude that the potential to acquire absolute pitch is universally present at birth, and that it can be realized by enabling the infant to associate pitches with verbal labels during the critical period for speech acquisition.												115	148											SPR	2004	21	3					339	356		10.1525/mp.2004.21.3.339	http://dx.doi.org/10.1525/mp.2004.21.3.339												2026-01-16	WOS:000220273000005
J	Brun, D				Brun, D			Information structure and the status of NP in Russian	THEORETICAL LINGUISTICS				Article								This paper investigates the role of the information structure in the interpretation of nominal elements in Russian. More specifically, it concentrates on the correlations between the position an NP occupies within a sentence and its reading with respect to (in)definiteness. To this end, different ways of indicating (in)definiteness in this language are discussed. Russian, as a language lacking articles, has an option of denoting this feature overtly (lexically or morphosyntactically); alternatively, an NP may remain unspecified. It is proposed that, in the latter case, the interpretation depends on the role the NP has in the discourse (or information) structure. The paper further examines the information packaging of Russian clauses. It is concluded that the appropriate representation of a sentence in this language consists of three parts: optional Topic (s) and Neutral Information and obligatory New Information Focus in a neutral intonation sentence of Contrastive Focus (1992) and King (1995), is contrasted the traditional two-way division into Topic and Focus or Theme and Rheme. Finally, the paper looks at the possible types of NPs representing various functions of information structure. It is shown that neither definiteness nor the related feature of specificity may provide a one-to-one correspondence. It is then demonstrated that the feature underlying the dependence between the interpretation of NP and its role in the information structure is D(iscourse)-linking (Pesetsky 1787).												17	18												2001	27	2-3					109	135		10.1515/thli.2001.27.2-3.109	http://dx.doi.org/10.1515/thli.2001.27.2-3.109												2026-01-16	WOS:000178004900002
J	Chuprina, N				Chuprina, Nataliia			Works by Maria Shimanovskaya in the Reflection of Slavic Style Line of Biedermeier	TARIH KULTUR VE SANAT ARASTIRMALARI DERGISI-JOURNAL OF HISTORY CULTURE AND ART RESEARCH				Article								The aim of the work is the analysis of features of Biedermeier in the legacy of M. Shimanovskaya based on the detailed investigation of Mazurkas and Nocturnes which reflect the main characteristics of the "high Biedermeier", distinguished by religious and spiritual traits. The methodological base of the given research is the intonation system of the comparative school of B. Asafiev, representation of the results of contribution of authors which were aimed at the development of problems of Slavic Biedermeier by the means of various types of studies. Scientific novelty lies in the predominant accentuation of the Biedermeier style line in the heritage of M. Shimanovskaya. On the whole, M. Shimanovskaya does not cross the limits of abilities of "easy piano", giving preference to expression achievement through the eclectic stylistic combinations, while demonstrating an emphasized miniaturization of national or the expansion of culturally dominant quality of the genre. The mentioned eclecticism does not tough upon the demonic opposition of romanticism in any perceptible way, apart from the "review" of the latter in the structure of Nocturne. This is the key point of the Biedermeier logic of the "great in small", which also emphasizes the romantic principles in the expressiveness of M. Shimanovskaya`s works and performing art.												0	0											DEC	2019	8	4					158	165		10.7596/taksad.v8i4.2278	http://dx.doi.org/10.7596/taksad.v8i4.2278												2026-01-16	WOS:000504899600013
J	Wesolowski, BC				Wesolowski, Brian C.			Predicting Operational Rater-Type Classifications Using Rasch Measurement Theory and Random Forests: A Music Performance Assessment Perspective	JOURNAL OF EDUCATIONAL MEASUREMENT				Article								The purpose of this study was to build a Random Forest supervised machine learning model in order to predict musical rater-type classifications based upon a Rasch analysis of raters' differential severity/leniency related to item use. Raw scores (N = 1,704) from 142 raters across nine high school solo and ensemble festivals (grades 9-12) were collected using a 29-item Likert-type rating scale embedded within five domains (tone/intonation, n = 6; balance, n = 5; interpretation, n = 6; rhythm, n = 6; and technical accuracy, n = 6). Data were analyzed using a Many Facets Rasch Partial Credit Model. An a priori k-means cluster analysis of 29 differential rater functioning indices produced a discrete feature vector that classified raters into one of three distinct rater-types: (a) syntactical rater-type, (b) expressive rater-type, or (c) mental representation rater-type. Results of the initial Random Forest model resulted in an out-of-bag error rate of 5.05%, indicating that approximately 95% of the raters were correctly classified. After tuning a set of three hyperparameters (n(tree), m(try), and node size), the optimized model demonstrated an improved out-of-bag error rate of 2.02%. Implications for improvements in assessment, research, and rater training in the field of music education are discussed.												5	8											SEP	2019	56	3			SI		610	625		10.1111/jedm.12227	http://dx.doi.org/10.1111/jedm.12227												2026-01-16	WOS:000485286100007
J	Izen, SC; Lapp, HE; Harris, DA; Hunter, RG; Ciaramitaro, VM				Izen, Sarah C.; Lapp, Hannah E.; Harris, Daniel A.; Hunter, Richard G.; Ciaramitaro, Vivian M.			Seeing a Face in a Crowd of Emotional Voices: Changes in Perception and Cortisol in Response to Emotional Information across the Senses	BRAIN SCIENCES				Article								One source of information we glean from everyday experience, which guides social interaction, is assessing the emotional state of others. Emotional state can be expressed through several modalities: body posture or movements, body odor, touch, facial expression, or the intonation in a voice. Much research has examined emotional processing within one sensory modality or the transfer of emotional processing from one modality to another. Yet, less is known regarding interactions across different modalities when perceiving emotions, despite our common experience of seeing emotion in a face while hearing the corresponding emotion in a voice. Our study examined if visual and auditory emotions of matched valence (congruent) conferred stronger perceptual and physiological effects compared to visual and auditory emotions of unmatched valence (incongruent). We quantified how exposure to emotional faces and/or voices altered perception using psychophysics and how it altered a physiological proxy for stress or arousal using salivary cortisol. While we found no significant advantage of congruent over incongruent emotions, we found that changes in cortisol were associated with perceptual changes. Following exposure to negative emotional content, larger decreases in cortisol, indicative of less stress, correlated with more positive perceptual after-effects, indicative of stronger biases to see neutral faces as happier.												3	5											AUG	2019	9	8							176	10.3390/brainsci9080176	http://dx.doi.org/10.3390/brainsci9080176												2026-01-16	WOS:000482974100025
J	Ran, YX; Zhao, MD				Ran, Yangxia; Zhao, Mengdan			A corpus-driven critical discourse analysis of news reports on disabled women	COGENT ARTS & HUMANITIES				Article								Words engender consciousness, and news reporting, as an important medium for the dissemination of discourse, shapes public cognition imperceptibly. As a marginalized group in patriarchal societies, disabled women have received relatively little attention. Therefore, using a corpus-driven critical discourse analysis, this study investigates the overall media representation of disabled women in Chinese news reports (2013-2023), along with the underlying cognitive and social factors. It reveals that Chinese news reporting prefers the social model of disability, which tends to narrate from the perspective of society and caregivers. This is also evidenced by the use of different personal pronouns. Second, in the view of semantic preference, it is apparent that expressions associated with disabled women often carry derogatory and negative emotional connotations, such as 'left-behind' and 'poor'. However, the overall semantic prosody presented in the news is primarily positive, advocating for societal attention and assistance towards this group. Finally, through the analysis of thematic words and high-frequency collocations, Chinese reports touch upon topics related to sexuality and marriage in the news descriptions of intellectually disabled women, potentially hinting at the discourse rights of this segment of the population.												0	0											DEC 31	2025	12	1							2465027	10.1080/23311983.2025.2465027	http://dx.doi.org/10.1080/23311983.2025.2465027												2026-01-16	WOS:001426695200001
J	Bielova, O				Bielova, Olena			Speech of Six-year-old Children with Logopathology: Features and State of Development	PSYCHOLINGUISTICS				Article								Purpose. The purpose of the article is to describe the state of speech development of six-year-old children with logopathology.Research methods and techniques. Research methods and techniques. During the experimental research, theoretical methods aimed at analysing the research results and forming conclusions were used. Empirical methods included analysis, comparison, data processing, as well as observation and interviews with children during the use of various types of tasks aimed at studying the state of formation of phonemic processes (phonemic perception, phonemic analysis, phonemic representation), lexical (passive, active dictionaries), grammatical (composing stories on various topics, using pronouns, agreement of words in gender, number, case), prosodic levels (loudness, tempo, intonation, diction) competences. Results. The results of the conducted research give a clear idea that there are significant differences between the groups of studied children with logopathology and those with normotypical psychophysical development regarding the formation of their speech and language competences. Children of older preschool age (six years old) who had low indicators had persistent violations of phonemic competence (perception, analysis and representation); insufficiently formed lexical competence (misunderstanding of words, difficulties in composing a story, problems with classification of concepts and definition of words with the opposite meaning); the grammatical competence is not formed (agrammatism, distortion of the sound structure of words, perseveration, paraphasia, inability to use pronouns, agree words and number, gender, case); undeveloped prosodic skills (unregulated voice strength, pace of speech, vague utterances, diction abilities are limited due to persistent phonological disorders).Conclusions. Six-year-old children with logopathology have insufficiently developed phonetic, lexical, grammatical and prosodic competences, as compared to the results of their peers with normotypical psychophysical development. The lack of speech and language competences will affect children's mastery of writing and reading skills during learning the curriculum at school.												0	4												2023	34	1					50	84		10.31470/2309-1797-2023-34-1-50-84	http://dx.doi.org/10.31470/2309-1797-2023-34-1-50-84												2026-01-16	WOS:001131259600005
J	Giugliano, M; Keith, VA				Giugliano, Marcello; Alsina Keith, Victoria			Repetition and variation in the Catalan translation of Virginia Woolf's The years: a corpus-based approach	PERSPECTIVES-STUDIES IN TRANSLATION THEORY AND PRACTICE				Article								The present study is a corpus-based contrastive analysis of the use of repetitive patterns in Virginia Woolf's novel The Years (1937) and its Catalan translation (1988) by Maria-Antonia Oliver. For our study, we build a parallel corpus in which both the source text and the translation are aligned, and then focus on three kinds of repetition: (a) The question Where am I?; (b) the phrase hum in time to + N, and (c) the construction 'verb indicating stillness (sit, stay horizontal ellipsis ) + for a moment + verb of perception.' All these patterns are stylistic devices that Woolf uses for the representation of time in its diverse and overlapping manifestations: as an external measurable dimension and as an internal continuous stream. The use of a parallel corpus allows us to study how all occurrences of these repetitions have been translated into Catalan and to identify the semantic prosody surrounding the three expressions in both English and Catalan. Finally, our corpus-based approach provides evidence for a description of Oliver's translation method, which we define as intentionally literal, though mindful of the numerous stylistic and lyrical effects that can characterize Woolf's prose.												0	0											MAR 4	2022	30	2					242	257		10.1080/0907676X.2021.1905673	http://dx.doi.org/10.1080/0907676X.2021.1905673		APR 2021										2026-01-16	WOS:000641517700001
J	Bestelmeyer, PEG; Latinus, M; Bruckert, L; Rouger, J; Crabbe, F; Belin, P				Bestelmeyer, Patricia E. G.; Latinus, Marianne; Bruckert, Laetitia; Rouger, Julien; Crabbe, Frances; Belin, Pascal			Implicitly Perceived Vocal Attractiveness Modulates Prefrontal Cortex Activity	CEREBRAL CORTEX				Article								Social interactions involve more than "just" language. As important is a more primitive nonlinguistic mode of communication acting in parallel with linguistic processes and driving our decisions to a much higher degree than is generally suspected. Amongst the "honest signals" that influence our behavior is perceived vocal attractiveness. Not only does vocal attractiveness reflect important biological characteristics of the speaker, it also influences our social perceptions according to the "what sounds beautiful is good" phenomenon. Despite the widespread influence of vocal attractiveness on social interactions revealed by behavioral studies, its neural underpinnings are yet unknown. We measured brain activity while participants listened to a series of vocal sounds ("ah") and performed an unrelated task. We found that voice-sensitive auditory and inferior frontal regions were strongly correlated with implicitly perceived vocal attractiveness. While the involvement of auditory areas reflected the processing of acoustic contributors to vocal attractiveness ("distance to mean" and spectrotemporal regularity), activity in inferior prefrontal regions (traditionally involved in speech processes) reflected the overall perceived attractiveness of the voices despite their lack of linguistic content. These results suggest the strong influence of hidden nonlinguistic aspects of communication signals on cerebral activity and provide an objective measure of this influence.												41	43											JUN	2012	22	6					1263	1270		10.1093/cercor/bhr204	http://dx.doi.org/10.1093/cercor/bhr204												2026-01-16	WOS:000304539700005
J	Luo, ZJ; Lin, SF; Liu, R; Baba, J; Yoshikawa, Y; Ishiguro, H				Luo, Zhaojie; Lin, Shoufeng; Liu, Rui; Baba, Jun; Yoshikawa, Yuichiro; Ishiguro, Hiroshi			Decoupling Speaker-Independent Emotions for Voice Conversion via Source-Filter Networks	IEEE-ACM TRANSACTIONS ON AUDIO SPEECH AND LANGUAGE PROCESSING				Article								Emotional voice conversion (VC) aims to convert a neutral voice to an emotional one while retaining the linguistic information and speaker identity. We note that the decoupling of emotional features from other speech information (such as content, speaker identity, etc.) is the key to achieving promising performance. Some recent attempts of speech representation decoupling on the neutral speech cannot work well on the emotional speech, due to the more complex entanglement of acoustic properties in the latter. To address this problem, here we propose a novel Source-Filter-based Emotional VC model (SFEVC) to achieve proper filtering of speaker-independent emotion cues from both the timbre and pitch features. Our SFEVC model consists of multi-channel encoders, emotion separate encoders, pre-trained speaker-dependent encoders, and the corresponding decoder. Note that all encoder modules adopt a designed information bottleneck auto-encoder. Additionally, to further improve the conversion quality for various emotions, a novel training strategy based on the 2D Valence-Arousal (VA) space is proposed. Experimental results show that the proposed SFEVC along with a VA training strategy outperforms all baselines and achieves the state-of-the-art performance in speaker-independent emotional VC with nonparallel data.												11	12												2023	31						11	24		10.1109/TASLP.2022.3190715	http://dx.doi.org/10.1109/TASLP.2022.3190715												2026-01-16	WOS:000923960000002
J	Peña, M; Langus, A; Gutiérrez, C; Huepe-Artigas, D; Nespor, M				Pena, Marcela; Langus, Alan; Gutierrez, Cesar; Huepe-Artigas, Daniela; Nespor, Marina			Rhythm on Your Lips	FRONTIERS IN PSYCHOLOGY				Article								The Iambic-Trochaic Law (ITL) accounts for speech rhythm, grouping of sounds as either lambs-if alternating in duration-or Trochees-if alternating in pitch and/or intensity. The two different rhythms signal word order, one of the basic syntactic properties of language. We investigated the extent to which Iambic and Trochaic phrases could be auditorily and visually recognized, when visual stimuli engage lip reading. Our results show both rhythmic patterns were recognized from both, auditory and visual stimuli, suggesting that speech rhythm has a multimodal representation. We further explored whether participants could match Iambic and Trochaic phrases across the two modalities. We found that participants auditorily familiarized with Trochees, but not with lambs, were more accurate in recognizing visual targets, while participants visually familiarized with lambs, but not with Trochees, were more accurate in recognizing auditory targets. The latter results suggest an asymmetric processing of speech rhythm: in auditory domain, the changes in either pitch or intensity are better perceived and represented than changes in duration, while in the visual domain the changes in duration are better processed and represented than changes in pitch, raising important questions about domain general and specialized mechanisms for speech rhythm processing.												4	4											NOV 8	2016	7								1708	10.3389/fpsyg.2016.01708	http://dx.doi.org/10.3389/fpsyg.2016.01708												2026-01-16	WOS:000387513600001
J	Shen, J; Wright, R; Souza, PE				Shen, Jing; Wright, Richard; Souza, Pamela E.			On Older Listeners' Ability to Perceive Dynamic Pitch	JOURNAL OF SPEECH LANGUAGE AND HEARING RESEARCH				Article								Purpose: Natural speech comes with variation in pitch, which serves as an important cue for speech recognition. The present study investigated older listeners' dynamic pitch perception with a focus on interindividual variability. In particular, we asked whether some of the older listeners' inability to perceive dynamic pitch stems from the higher susceptibility to the interference from formant changes. Method: A total of 22 older listeners and 21 younger controls with at least near-typical hearing were tested on dynamic pitch identification and discrimination tasks using synthetic monophthong and diphthong vowels. Results: The older listeners' ability to detect changes in pitch varied substantially, even when musical and linguistic experiences were controlled. The influence of formant patterns on dynamic pitch perception was evident in both groups of listeners. Overall, strong pitch contours (i.e., more dynamic) were perceived better than weak pitch contours (i.e., more monotonic), particularly with rising pitch patterns. Conclusions: The findings are in accordance with the literature demonstrating some older individuals' difficulty perceiving dynamic pitch cues in speech. Moreover, they suggest that this problem may be prominent when the dynamic pitch is carried by natural speech and when the pitch contour is not strong.												15	16											JUN	2016	59	3					572	582		10.1044/2015_JSLHR-H-15-0228	http://dx.doi.org/10.1044/2015_JSLHR-H-15-0228												2026-01-16	WOS:000386781500014
J	Arioli, M; Ricciardi, E; Cattaneo, Z				Arioli, Maria; Ricciardi, Emiliano; Cattaneo, Zaira			Social cognition in the blind brain: A coordinate-based meta-analysis	HUMAN BRAIN MAPPING				Article								Social cognition skills are typically acquired on the basis of visual information (e.g., the observation of gaze, facial expressions, gestures). In light of this, a critical issue is whether and how the lack of visual experience affects neurocognitive mechanisms underlying social skills. This issue has been largely neglected in the literature on blindness, despite difficulties in social interactions may be particular salient in the life of blind individuals (especially children). Here we provide a meta-analysis of neuroimaging studies reporting brain activations associated to the representation of self and others' in early blind individuals and in sighted controls. Our results indicate that early blindness does not critically impact on the development of the "social brain," with social tasks performed on the basis of auditory or tactile information driving consistent activations in nodes of the action observation network, typically active during actual observation of others in sighted individuals. Interestingly though, activations along this network appeared more left-lateralized in the blind than in sighted participants. These results may have important implications for the development of specific training programs to improve social skills in blind children and young adults.												15	15											APR 1	2021	42	5					1243	1256		10.1002/hbm.25289	http://dx.doi.org/10.1002/hbm.25289		DEC 2020										2026-01-16	WOS:000598626500001
J	Falk, TH; Chan, WY; Shein, F				Falk, Tiago H.; Chan, Wai-Yip; Shein, Fraser			Characterization of atypical vocal source excitation, temporal dynamics and prosody for objective measurement of dysarthric word intelligibility	SPEECH COMMUNICATION				Article								Objective measurement of dysarthric speech intelligibility can assist clinicians in the diagnosis of speech disorder severity as well as in the evaluation of dysarthria treatments. In this paper, several objective measures are proposed and tested as correlates of subjective intelligibility. More specifically, the kurtosis of the linear prediction residual is proposed as a measure of vocal source excitation oddity. Additionally, temporal perturbations resultant from imprecise articulation and atypical speech rates are characterized by short- and long-term temporal dynamics measures, which in turn, are based on log-energy dynamics and on an auditory-inspired modulation spectral signal representation, respectively. Motivated by recent insights in the communication disorders literature, a composite measure is developed based on linearly combining a salient subset of the proposed measures with conventional prosodic parameters. Experiments with the publicly-available 'Universal Access' database of spastic dysarthric speech (10 patient speakers; 300 words spoken in isolation, per speaker) show that the proposed composite measure can achieve correlation with subjective intelligibility ratings as high as 0.97; thus the measure can serve as an accurate indicator of dysarthric speech intelligibility. (C) 2011 Elsevier B.V. All rights reserved.												76	82											JUN	2012	54	5			SI		622	631		10.1016/j.specom.2011.03.007	http://dx.doi.org/10.1016/j.specom.2011.03.007												2026-01-16	WOS:000302756600004
J	Cardona, MD				Cardona, Margrete Dyvik			More than just an immigrant: The semantic patterns of (im)migrant/predicate-pairings in news stories about Mexican and Central American (im)migrants to the USA. A corpus-assisted discourse study	DISCOURSE & COMMUNICATION				Article								In this paper we explore how some of the largest US-newspapers linguistically frame immigrants to the USA in articles about Mexican and Central American immigrants. Specifically, it is a corpus-assisted discourse study which examines the frequency of different semantic predicate-types with (im)migrant subjects and (im)migrant by-agents in the quest for underlying positive or negative biases. We wish to ascertain what activities (im)migrants are presented as taking part in, principally as agents. The analysis shows that more than half of the (im)migrant/predicate-pairings reflect the dictionary definitions of (im)migrant. However, immigrants are described as illegal 66% of the times that their location is mentioned with an immigrant/predicate-pairing. The non-definition-confirming pairings also show evidence of a negative framing of immigrants, but not of migrants. Furthermore, immigrants are more often than migrants cast as agents of activities that do not simply reiterate their status as (im)migrants. Finally, we found evidence of the Negation Bias in the immigrant/predicate-pairings.												1	1											JUN	2022	16	3					285	304	17504813221101821	10.1177/17504813221101821	http://dx.doi.org/10.1177/17504813221101821		JUN 2022										2026-01-16	WOS:000811801000001
J	Zaghbani, S; Boujneh, N; Bouhlel, MS				Zaghbani, Soumaya; Boujneh, Noureddine; Bouhlel, Med Salim			Age estimation using deep learning	COMPUTERS & ELECTRICAL ENGINEERING				Article								Age has always been an important attribute of identity. It also has been an important factor in social interaction. The posture, vocabulary, facial wrinkles and the intonation are all elements that facilitate the prediction of the user's age. Age estimation from the face by numerical analysis finds many potential applications such as the development of intelligent human-machine interfaces and improvement of safety and protection in various sectors such as transport, security and medicine. In many works, researchers are particularly interested in the face's features to regress the age. Recent advances in Artificial Intelligence (AI) and particulary Deep Learning (DL) techniques increase motivations to use this methods to estimate age. In this work, we present a novel method for age estimation from a facial images based on autoencoders. Autoencoder is an artificial neural network used for unsupervised learning of efficient coding. Its aim is to learn a representation for a set of data. The purpose of this work is to exploit the performance of autoencoders to learn features in a supervised manner to estimate user's age. We use MORPH, FG-NET datasets to test the performance of our proposed method. Experimental results show the robustness and effectiveness of the proposed method through the MAE (Men Average Error) rate showing a value of 3.34% for MORPH dataset and 3.75% for FG-NET.												29	33											MAY	2018	68						337	347		10.1016/j.compeleceng.2018.04.012	http://dx.doi.org/10.1016/j.compeleceng.2018.04.012												2026-01-16	WOS:000437999300026
J	Milian, P				Milian, Patrick			Art/Artifact Semiotics of Music, Language, and Sound in Different Trains	PACIFIC COAST PHILOLOGY				Article								Steve Reich's minimalist composition Different Trains (1988) for string quartet and tape uses the speech prosody of recorded testimony as its fundamental melodic material. This article adapts Peircean semiotics to explore how Reich's co-constituting treatments of recorded voices-as testimonial evidence and as musical melody-create two co-constituting operations that make possible Different Trains' meaning-making capacity. First, the taped voices' isolation and reproduction complicate the function of language as a set of stipulated symbols by refiguring the speech fragments as material and indexical traces of testimony, not the testimony itself. Second, the transformation of these prosodic fragments into gestural melodies makes the voice's intonational curve an iconic gesture requiring an attentive, even participatory, listening practice. The two operations work in conjunction toward a representation not of history itself, but of history's recurring and highly mediated experience within the present. The intermedial network of sign systems in Different Trains is made possible through Reich's implementation of sound technology in composition and performance. Careful attention to the work reveals the extent to which word and music studies are complicated when the material conditions and acoustic interventions of aural media are taken into account.												0	1												2019	54	1					38	55															2026-01-16	WOS:000502365600004
J	Gauvreau, J				Gauvreau, Joseph			FROM THE TIBER TO THE THAMES: THOMAS WATSON'S ITALIAN MADRIGALLS ENGLISHED AND THE NATURALISATION OF MARENZIO'S PASTORAL MADRIGAL	EARLY MUSIC HISTORY				Article								One of the five Elizabethan anthologies of 'Englished' Italian songs, Thomas Watson's 1590 Italian Madrigalls Englished (IME) presents itself as a selection of madrigals - almost all by Marenzio - with texts that do not strictly translate the original lyrics yet remain equally suitable to the music they underlay. Contrary to earlier studies of the IME, this article argues that Watson's contrafacta, while indeed far from faithful translations, in fact remain deeply invested in the appropriation and subversion of the madrigals' original verse. Most crucially, the IME carefully naturalises Marenzio's pastoral landscapes - originally meant to evoke the Roman milieu of the composer's patron - by repopulating this Arcadia with prominent Elizabethans and recognisable characters drawn from Watson's own poetry. His contrafacta equally engage with the madrigals' representation of characteristic formal elements of Italian verse, to prove not only the English language's capacity to assimilate foreign prosody but also the Italian madrigal's capacity to accommodate native English rhythms. Ultimately, the IME seeks to prove that English verse is equally suitable to being sung to the period's most prestigious secular compositions, that the madrigal is equally capable of evoking a musical Arcadia in Elizabethan England.												0	0											OCT	2023	42						175	233		10.1017/S0261127925000014	http://dx.doi.org/10.1017/S0261127925000014												2026-01-16	WOS:001520463700006
J	Petrenko, DA; Likhachev, EV; Chernyshova, MV				Petrenko, Daniil A.; Likhachev, Eduard, V; Chernyshova, Marina, V			LINGUISTIC MEANS IN IMAGE OF COVID-19 (GERMAN POLITICAL DISCOURSE IN MEDIA)	NAUCHNYI DIALOG				Article								The article is focused on the role of lexical and prosodic means of expression in the coverage of the COVID-19 pandemic in German political media discourse. As a research task, the authors identified an attempt to assess the dynamics of the image of the coronavirus phenomenon in the media and to identify the conditionality of the use of linguistic units at certain stages of the pandemic. The material for the study was transcripts and audio recordings of plots from leading German news channels in the first half of 2020. Particular attention is paid to the analysis of the frequency of the use of lexical units and the correlation of lexical and prosodic means of expression. In the course of linguo-stylistic analysis, the main stylistic means are established, depicting the course of the pandemic and the fight against the virus. The prosodic features of the informants' speech, which are determined in the course of the electroacoustic analysis of statements, are brought into consideration. The impact of COVID-19 on all spheres of public life in Germany and its maximum representation in the media determine the relevance of this study. The novelty of the study is seen in the application of a comprehensive methodology for analyzing expressive means in the speech of informants in the period from January to May 2020.												1	3												2020		7					194	209		10.24224/2227-1295-2020-7-194-209	http://dx.doi.org/10.24224/2227-1295-2020-7-194-209												2026-01-16	WOS:000568419600012
J	Oh, HS; Lee, SH; Cho, DH; Lee, SW				Oh, Hyung-Seok; Lee, Sang-Hoon; Cho, Deok-Hyeon; Lee, Seong-Whan			DurFlex-EVC: Duration-Flexible Emotional Voice Conversion Leveraging Discrete Representations Without Text Alignment	IEEE TRANSACTIONS ON AFFECTIVE COMPUTING				Article								Emotional voice conversion (EVC) involves modifying various acoustic characteristics, such as pitch and spectral envelope, to match a desired emotional state while preserving the speaker's identity. Existing EVC methods often rely on text transcriptions or time-alignment information and struggle to handle varying speech durations effectively. In this paper, we propose DurFlex-EVC, a duration-flexible EVC framework that operates without the need for text or alignment information. We introduce a unit aligner that models contextual information by aligning speech with discrete units representing content, eliminating the need for text or speech-text alignment. Additionally, we design a style autoencoder that effectively disentangles content and emotional style, allowing precise manipulation of the emotional characteristics of the speech. We further enhance emotional expressiveness through a hierarchical stylize encoder that applies the target emotional style at multiple hierarchical levels, refining the stylization process to improve the naturalness and expressiveness of the converted speech. Experimental results from subjective and objective evaluations demonstrate that our approach outperforms baseline models, effectively handling duration variability and enhancing emotional expressiveness in the converted speech.												2	2											JUL-SEP	2025	16	3					1660	1674		10.1109/TAFFC.2025.3530920	http://dx.doi.org/10.1109/TAFFC.2025.3530920												2026-01-16	WOS:001566948500040
J	Adam-Darque, A; Pittet, MP; Grouiller, F; Rihs, TA; Leuchter, RHV; Lazeyras, F; Michel, CM; Hüppi, PS				Adam-Darque, Alexandra; Pittet, Marie P.; Grouiller, Frederic; Rihs, Tonia A.; Leuchter, Russia Ha-Vinh; Lazeyras, Francois; Michel, Christoph M.; Huppi, Petra S.			Neural Correlates of Voice Perception in Newborns and the Influence of Preterm Birth	CEREBRAL CORTEX				Article								Maternal voice is a highly relevant stimulus for newborns. Adult voice processing occurs in specific brain regions. Voice-specific brain areas in newborns and the relevance of an early vocal exposure on these networks have not been defined. This study investigates voice perception in newborns and the impact of prematurity on the cerebral processes. Functional magnetic resonance imaging (fMRI) and high-density electroencephalography (EEG) were used to explore the brain responses to maternal and stranger female voices in full-term newborns and preterm infants at term-equivalent age (TEA). fMRI results and the EEG oddball paradigm showed enhanced processing for voices in preterms at TEA than in full-term infants. Preterm infants showed additional cortical regions involved in voice processing in fMRI and a late mismatch response for maternal voice, considered as a first trace of a recognition process based on memory representation. Full-term newborns showed increased cerebral activity to the stranger voice. Results from fMRI, oddball, and standard auditory EEG paradigms highlighted important change detection responses to novelty after birth. These findings suggest that the main components of the adult voice-processing networks emerge early in development. Moreover, an early postnatal exposure to voices in premature infants might enhance their capacity to process voices.												19	21											NOV	2020	30	11					5717	5730		10.1093/cercor/bhaa144	http://dx.doi.org/10.1093/cercor/bhaa144												2026-01-16	WOS:000582709400008
J	Vassolo, N; Ocampo, PJ; Acevedo, BE; Bosch, S; Bendersky, M; Alba-Ferrara, L				Vassolo, Nicolas; Ocampo, Pablo Joaquin; Acevedo, Bautista Elizalde; Bosch, Sofia; Bendersky, Mariana; Alba-Ferrara, Lucia			Understanding Sarcasm's Neural Correlates Through a Novel fMRI Spanish Paradigm	BRAIN TOPOGRAPHY				Article								There is growing interest in the neural network of pragmatic language and its potential overlap with the Theory of Mind (ToM) network. However, no Spanish-adapted fMRI tasks were used for studying sarcasm, the subtype of pragmatic language most related to ToM. Furthermore, stimuli used in prior studies often impose high cognitive demands, confounding its sarcasm brain representation with the executive network. We investigate the neural correlates of sarcasm in Spanish using a novel experimental paradigm designed to minimize cognitive load and enhance ecological validity. Eighteen healthy, right-handed participants underwent a 3T fMRI session with a sarcasm comprehension task. Brain activations analysed with SPM12 were calculated for sarcasm vs. literal contrast. Sarcasm activated the left temporo-parietal junction, Medial Prefrontal Cortex (BA 10), Left Inferior Frontal Gyrus (BA 45), Left Medial and Superior Temporal Gyrus (BA 21 & 22), and Left Temporal Pole (BA 38). Sarcasm comprehension involves an extensive fronto-temporal-parietal network, with prominent activation of ToM-related areas. These findings suggest an overlap between sarcasm and ToM networks, emphasizing the role of the medial prefrontal cortex in pragmatic language, the left inferior frontal gyrus in semantic integration, and the role of a left-lateralized frontotemporal network for sarcasm processing.												1	1											JUL	2025	38	4							46	10.1007/s10548-025-01118-x	http://dx.doi.org/10.1007/s10548-025-01118-x												2026-01-16	WOS:001499224800001
J	Zhang, Y; Sares, A; Delage, A; Lehmann, A; Deroche, M				Zhang, Yue; Sares, Anastasia; Delage, Arthur; Lehmann, Alexandre; Deroche, Mickael			Pupillometry reveals effects of pitch manipulation within and across words on listening effort and short-term memory	SCIENTIFIC REPORTS				Article								For individuals with hearing loss, even successful speech communication comes at a cost. Cochlear implants transmit degraded information, specifically for voice pitch, which demands extra and sustained listening effort. The current study hypothesized that abnormal pitch patterns contribute to the additional listening effort, even in non-tonal language native speaking normally hearing listeners. We manipulated the fundamental frequency (F0) within and across words, while participants listen and repeat (simple intelligibility task), or listen, repeat, and later recall (concurrent encoding task) the words. In both experiments, the F0 manipulations resulted in small changes in intelligibility but no difference in free recall or subjective effort ratings. Pupillary metrics were yet sensitive to these manipulations: pupil dilations were larger when words were monotonized (flat contour) or inverted (the natural contour flipped upside-down), and larger when successive words were organized into a melodic pattern. The most likely interpretation is that the natural or expected F0 contour of a word contributes to its identity and facilitate its matching and retrieval from the phonological representation stored in long-term memory. Consequently, degrading words' F0 contour can result in extra listening effort. Our results call for solutions to improve pitch saliency and naturalness in future development of cochlear implants' signal processing strategies, even for non-tonal languages.												2	2											SEP 30	2024	14	1							22595	10.1038/s41598-024-73320-z	http://dx.doi.org/10.1038/s41598-024-73320-z												2026-01-16	WOS:001326080400028
J	Tucker, BV; Ernestus, M				Tucker, Benjamin V.; Ernestus, Mirjam			Why we need to investigate casual speech to truly understand language production, processing and the mental lexicon	MENTAL LEXICON				Article								The majority of studies addressing psycholinguistic questions focus on speech produced and processed in a careful, laboratory speech style. This 'careful' speech is very different from the speech that listeners encounter in casual conversations. This article argues that research on casual speech is necessary to show the validity of conclusions based on careful speech. Moreover, research on casual speech produces new insights and questions on the processes underlying communication and on the mental lexicon that cannot be revealed by research using careful speech. This article first places research on casual speech in its historic perspective. It then provides many examples of how casual speech differs from careful speech and shows that these differences may have important implications for psycholinguistic theories. Subsequently, the article discusses the challenges that research on casual speech faces, which stem from the high variability of this speech style, its necessary casual context, and that casual speech is connected speech. We also present opportunities for research on casual speech, mostly in the form of new experimental methods that facilitate research on connected speech. However, real progress can only be made if these new methods are combined with advanced (still to be developed) statistical techniques.												29	33												2016	11	3					375	400		10.1075/ml.11.3.03tuc	http://dx.doi.org/10.1075/ml.11.3.03tuc												2026-01-16	WOS:000391222400003
J	Creemers, A; Embick, D				Creemers, Ava; Embick, David			The Role of Semantic Transparency in the Processing of Spoken Compound Words	JOURNAL OF EXPERIMENTAL PSYCHOLOGY-LEARNING MEMORY AND COGNITION				Article								The question of whether lexical decomposition is driven by semantic transparency in the lexical processing of morphologically complex words, such as compounds, remains controversial. Prior research on compound processing has predominantly examined visual processing. Focusing instead on spoken word word recognition, the present study examined the processing of auditorily presented English compounds that were semantically transparent (e.g., farmyard) or partially opaque with an opaque head (e.g., airline) or opaque modifier (e.g., pothole). Three auditory primed lexical decision experiments were run to examine to what extent constituent priming effects are affected by the semantic transparency of a compound and whether semantic transparency affects the processing of heads and modifiers equally. The results showed priming effects for both modifiers and heads regardless of their semantic transparency, indicating that individual constituents are accessed in transparent as well as opaque compounds. In addition, the results showed smaller priming effects for semantically opaque heads compared with matched transparent compounds with the same head. These findings suggest that semantically opaque heads induce an increased processing cost, which may result from the need to suppress the meaning of the head in favor of the meaning of the opaque compound.												6	10											MAY	2022	48	5					734	751		10.1037/xlm0001132	http://dx.doi.org/10.1037/xlm0001132		APR 2022										2026-01-16	WOS:000778682100001
J	Jiménez-Bravo, M; Marrero-Aguiar, V				Jimenez-Bravo, Miguel; Marrero-Aguiar, Victoria			Multimodal perception of prominence in spontaneous speech: A methodological proposal using mixed models and AIC	SPEECH COMMUNICATION				Article								Research on prominence perception has made use of animated agents and controlled speech in experimental settings, but these methodologies have disregarded some aspects of the acoustic and visual correlates of prom-inence. To overcome these limitations we propose a new methodological approach using spontaneous speech data. For this, we created a small database with extracts from a television talent show and neutralised the prominence-lending properties of the acoustic cues of prominence in the speech signal. In our pilot study twelve naive listeners marked words for binary prominence (prominent vs. non-prominent) in two modalities, i.e. audio only and audiovisual, under three conditions involving neutralisation of (a) fundamental frequency, (b) intensity, and (c) both fundamental frequency and intensity. Additionally, the marks of two trained listeners served as control condition. Different generalised linear mixed models were estimated and compared using the Akaike Information Criterion (AIC). The most parsimonious model was then examined using traditional null-hypothesis testing in order to provisionally establish the effects of our independent variables on prominence marking. We argue that spontaneous speech can be successfully applied to the study of the multimodal perception of prominence.												5	6											NOV	2020	124						28	45		10.1016/j.specom.2020.07.006	http://dx.doi.org/10.1016/j.specom.2020.07.006												2026-01-16	WOS:000591505000004
J	Zsiga, E; Zec, D				Zsiga, Elizabeth; Zec, Draga			Contextual Evidence for the Representation of Pitch Accents in Standard Serbian	LANGUAGE AND SPEECH				Article								This paper reports the results of an experiment that elicits contextual effects on Rising and Falling accents in Standard Serbian, with the goal of determining their acoustic correlates and their phonological representation. Materials systematically vary the distance between pitch accents, inducing "tone crowding," in order to identify the phonetic dimensions that consistently distinguish the two pitch accent types, to examine the association between accents and the segmental string, as well as the timing relationship between accent minima and maxima, and to investigate the interaction between lexical accents and boundary tones. On the basis of the phonetic findings, a unified analysis of the phonological distribution and phonetic realization of Falling and Rising accents in Standard Serbian is proposed. It is proposed that both Rising and Falling accents consist of a single lexical High (H). The restricted distribution of the two accents emerges from the interaction of stress and tone: Falling accents are monosyllabic, such that stress and pitch prominence coincide; Rising accents are bisyllabic, such that the stressed syllable precedes the pitch-accented syllable. The phonetic differences between the Falling and Rising accents follow from the place of lexically designated H, the location of stress, and the effects of boundary tones. The larger issue we address concerns the phonological characterization of tone/stress interactions. Given the two general types of interactions, one in which the place of stress is predictable from the place of tone, and the other with the reversed direction of influence, we analyze Standard Serbian as belonging to the former type. While both types can be characterized in systems of tonal phonology, which allow free interaction of tone and stress, the type exemplified by Standard Serbian, with contrastive tonal specifications governing the distribution of stress, cannot be captured in an Autosegmental-Metrical (AM) framework, in which stress serves as anchor for tonal melodies.												14	16											MAR	2013	56	1					69	104		10.1177/0023830912440792	http://dx.doi.org/10.1177/0023830912440792												2026-01-16	WOS:000330288600005
J	Fernández-Prieto, I; Caprile, C; Tinoco-González, D; Ristol-Orriols, B; López-Sala, A; Póo-Argüelles, P; Pons, F; Navarra, J				Fernandez-Prieto, I.; Caprile, C.; Tinoco-Gonzalez, D.; Ristol-Orriols, B.; Lopez-Sala, A.; Poo-Arguelles, P.; Pons, F.; Navarra, J.			Pitch perception deficits in nonverbal learning disability	RESEARCH IN DEVELOPMENTAL DISABILITIES				Article								The nonverbal learning disability (NLD) is a neurological dysfunction that affects cognitive functions predominantly related to the right hemisphere such as spatial and abstract reasoning. Previous evidence in healthy adults suggests that acoustic pitch (i.e., the relative difference in frequency between sounds) is, under certain conditions, encoded in specific areas of the right hemisphere that also encode the spatial elevation of external objects (e.g., high vs. low position). Taking this evidence into account, we explored the perception of pitch in preadolescents and adolescents with NLD and in a group of healthy participants matched by age, gender, musical knowledge and handedness. Participants performed four speeded tests: a stimulus detection test and three perceptual categorization tests based on colour, spatial position and pitch. Results revealed that both groups were equally fast at detecting visual targets and categorizing visual stimuli according to their colour. In contrast, the NLD group showed slower responses than the control group when categorizing space (direction of a visual object) and pitch (direction of a change in sound frequency). This pattern of results suggests the presence of a subtle deficit at judging pitch in NLD along with the traditionally-described difficulties in spatial processing. (C) 2016 Published by Elsevier Ltd.												3	4											DEC	2016	59						378	386		10.1016/j.ridd.2016.09.011	http://dx.doi.org/10.1016/j.ridd.2016.09.011												2026-01-16	WOS:000387632300035
J	Kuehnast, M				Kuehnast, Milena			PROCESSING CLITIC PRONOUNS IN BULGARIAN - EVIDENCE FROM NORMAL AND AGRAMMATIC COMPREHENSION	POZNAN STUDIES IN CONTEMPORARY LINGUISTICS				Article								Clitic clusters display a complicated interaction of prosodic and syntactic properties which determines their word order and stress patterns. In Bulgarian, short pronouns appear as unstressed verbal enclitics in positive utterances. Proclitic negation attracts the pronouns and forms with them a prosodic unit stressed on the second syllable, the pronoun. Theoretical linguistics characterizes the behaviour of object clitics in terms of "non-trivial chains" (Boskovic 2001) containing copies. The overt realisation of a higher or lower copy depends on phonological constraints like enclitisation requirements. In line with the slow-syntax-hypothesis (Burkhardt et al. 2008) and with the assumption that prosody-related processes may also compete for the same limited processing resources of Broca's aphasics (Avrutin et al. 1999), we test sensitivity to the phono-syntactic constraints negation imposes on the word order of personal and reflexive clitics. Results suggest that the pattern of agrammatic processing of clitic clusters resembles normal comprehension but proceeds in a protracted manner. Employing a self-paced reading task and an experimental design which reduces discourse-related interpretation processes, we also show that the syntactic functions of personal object clitics as syntactic object agreement markers in Bulgarian are relatively preserved in the aphasic group.												3	4											DEC	2009	45	4					487	507		10.2478/v10010-009-0029-z	http://dx.doi.org/10.2478/v10010-009-0029-z												2026-01-16	WOS:000274330500002
J	Duffield, N				Duffield, Nigel			On polarity emphasis, assertion and mood in Vietnamese and English	LINGUA				Article								The paper presents data from several languages chiefly, Vietnamese and English in support of two empirical claims concerning the syntax of polarity elements, assertion and mood (illocutionary force). The proposal draws on and develops Klein's (1998) arguments for a decomposition of Finiteness: whereas Klein originally proposed that finiteness should be understood as involving at least two independent components tense and assertion (validity) this is elaborated to three in the present analysis, with polarity added as a distinct projection intermediate between the other two projections, to the left of Outer Aspect. Contrastive intonation polarity emphasis is argued to be able to target either polarity or assertion, by default the former; cf. Battlori and Hernanz (2011). With regard to assertion itself, it is shown that these features are projected rather low in Vietnamese phrase-structure, immediately to the left of the predicate-phrase. It is further claimed on the basis of evidence from imperative, interrogative and modal constructions that this low structural position hosts many other illocutionary features in Vietnamese (notwithstanding the evidence of Romance and Germanic languages, which seem to support a much higher position for such features on the left periphery of the clause). The paper considers the theoretical implications of this apparently parametric contrast in the context of current Minimalist theorizing. (C) 2013 Elsevier B.V. All rights reserved.												13	14											DEC	2013	137						248	270		10.1016/j.lingua.2013.09.007	http://dx.doi.org/10.1016/j.lingua.2013.09.007												2026-01-16	WOS:000328302800014
J	Stamp, R; Cohen, D; Hel-Or, H; Sandler, W				Stamp, Rose; Cohen, David; Hel-Or, Hagit; Sandler, Wendy			Kinect-ing the Dots: Using Motion-Capture Technology to Distinguish Sign Language Linguistic From Gestural Expressions	LANGUAGE AND SPEECH				Article								Just as vocalization proceeds in a continuous stream in speech, so too do movements of the hands, face, and body in sign languages. Here, we use motion-capture technology to distinguish lexical signs in sign language from other common types of expression in the signing stream. One type of expression is constructed action, the enactment of (aspects of) referents and events by (parts of) the body. Another is classifier constructions, the manual representation of analogue and gradient motions and locations simultaneously with specified referent morphemes. The term signing is commonly used for all of these, but we show that not all visual signals in sign languages are of the same type. In this study of Israeli Sign Language, we use motion capture to show that the motion of lexical signs differs significantly along several kinematic parameters from that of the two other modes of expression: constructed action and the classifier forms. In so doing, we show how motion-capture technology can help to define the universal linguistic category "word," and to distinguish it from the expressive gestural elements that are commonly found across sign languages.												6	7											MAR	2024	67	1					255	276		10.1177/00238309231169502	http://dx.doi.org/10.1177/00238309231169502		JUN 2023										2026-01-16	WOS:001005297200001
J	Guo, N; Si, XP; Zhang, Y; Ding, Y; Zhou, WJ; Zhang, D; Hong, B				Guo, Ning; Si, Xiaopeng; Zhang, Yang; Ding, Yue; Zhou, Wenjing; Zhang, Dan; Hong, Bo			Speech frequency-following response in human auditory cortex is more than a simple tracking	NEUROIMAGE				Article								The human auditory cortex is recently found to contribute to the frequency following response (FFR) and the cortical component has been shown to be more relevant to speech perception. However, it is not clear how cortical FFR may contribute to the processing of speech fundamental frequency (F0) and the dynamic pitch. Using intracranial EEG recordings, we observed a significant FFR at the fundamental frequency (F0) for both speech and speech-like harmonic complex stimuli in the human auditory cortex, even in the missing fundamental condition. Both the spectral amplitude and phase coherence of the cortical FFR showed a significant harmonic preference, and attenuated from the primary auditory cortex to the surrounding associative auditory cortex. The phase coherence of the speech FFR was found significantly higher than that of the harmonic complex stimuli, especially in the left hemisphere, showing a high timing fidelity of the cortical FFR in tracking dynamic F0 in speech. Spectrally, the frequency band of the cortical FFR was largely overlapped with the range of the human vocal pitch. Taken together, our study parsed the intrinsic properties of the cortical FFR and reveals a preference for speech-like sounds, supporting its potential role in processing speech intonation and lexical tones.												11	12											FEB 1	2021	226								117545	10.1016/j.neuroimage.2020.117545	http://dx.doi.org/10.1016/j.neuroimage.2020.117545												2026-01-16	WOS:000608035900024
J	Whiteside, SP; Grobler, S; Windsor, F; Varley, R				Whiteside, Sandra P.; Grobler, Simon; Windsor, Fay; Varley, Rosemary			An acoustic study of vowels and coarticulation as a function of utterance type: A case of acquired apraxia of speech	JOURNAL OF NEUROLINGUISTICS				Article								This case study examines vowel production and coarticulation patterns in AOS as a function of utterance type. A female speaker with AOS, and a sex-matched control participant repeated target vowels in three conditions: isolated Word statement frames and, question frames. The first two formant frequencies (F1 and F2) of the target vowels were measured at their onset and temporal midpoints. The vowel spaces of both speakers were examined using a two-dimensional vowel chart; temporal midpoint formant frequency values of the first formant (171) were plotted against the difference between F2 and F1 (F2-F1) as a representation of the constricted versus open (F-I) and fronted versus backed (F2-F1) quality of vowels. The speaker with AOS produced vowels that deviated to a posterior/backed distribution within the vowel space. Coarticulation patterns were also examined using F2 locus equations. The speaker with AOS exhibited reduced coarticulation patterns in all three conditions, when compared to the control speaker. Furthermore, these effects were amplified with increasing motoric complexity. The data elucidate the nature of the compromised speech control system in a speaker with AOS. (C) 2009 Elsevier Ltd. All rights reserved												11	12											MAR	2010	23	2					145	161		10.1016/j.jneuroling.2009.12.002	http://dx.doi.org/10.1016/j.jneuroling.2009.12.002												2026-01-16	WOS:000275130500004
J	Frühholz, S; van der Zwaag, W; Saenz, M; Belin, P; Schobert, AK; Vuilleumier, P; Grandjean, D				Fruhholz, Sascha; van der Zwaag, Wietske; Saenz, Melissa; Belin, Pascal; Schobert, Anne-Kathrin; Vuilleumier, Patrik; Grandjean, Didier			Neural decoding of discriminative auditory object features depends on their socio-affective valence	SOCIAL COGNITIVE AND AFFECTIVE NEUROSCIENCE				Article								Human voices consist of specific patterns of acoustic features that are considerably enhanced during affective vocalizations. These acoustic features are presumably used by listeners to accurately discriminate between acoustically or emotionally similar vocalizations. Here we used high-field 7T functional magnetic resonance imaging in human listeners together with a so-called experimental 'feature elimination approach' to investigate neural decoding of three important voice features of two affective valence categories (i.e. aggressive and joyful vocalizations). We found a valence-dependent sensitivity to vocal pitch (f0) dynamics and to spectral high-frequency cues already at the level of the auditory thalamus. Furthermore, pitch dynamics and harmonics-to-noise ratio (HNR) showed overlapping, but again valence-dependent sensitivity in tonotopic cortical fields during the neural decoding of aggressive and joyful vocalizations, respectively. For joyful vocalizations we also revealed sensitivity in the inferior frontal cortex (IFC) to the HNR and pitch dynamics. The data thus indicate that several auditory regions were sensitive to multiple, rather than single, discriminative voice features. Furthermore, some regions partly showed a valence-dependent hypersensitivity to certain features, such as pitch dynamic sensitivity in core auditory regions and in the IFC for aggressive vocalizations, and sensitivity to high-frequency cues in auditory belt and parabelt regions for joyful vocalizations.												20	22											OCT	2016	11	10					1638	1649		10.1093/scan/nsw066	http://dx.doi.org/10.1093/scan/nsw066												2026-01-16	WOS:000388939700014
J	Magne, C; Schön, D; Besson, M				Magne, C; Schön, D; Besson, M			Musician children detect pitch violations in both music and language better than nonmusician children: Behavioral and electrophysiological approaches	JOURNAL OF COGNITIVE NEUROSCIENCE				Article								The idea that extensive musical training can influence processing in cognitive domains other than music has received considerable attention from the educational system and the media. Here we analyzed behavioral data and recorded event-related brain potentials ( ERPs) from 8-year-old children to test the hypothesis that musical training facilitates pitch processing not only in music but also in language. We used a parametric manipulation of pitch so that the final notes or words of musical phrases or sentences were congruous, weakly incongruous, or strongly incongruous. Musician children outperformed nonmusician children in the detection of the weak incongruity in both music and language. Moreover, the greatest differences in the ERPs of musician and nonmusician children were also found for the weak incongruity: whereas for musician children, early negative components developed in music and late positive components in language, no such components were found for nonmusician children. Finally, comparison of these results with previous ones from adults suggests that some aspects of pitch processing are in effect earlier in music than in language. Thus, the present results reveal positive transfer effects between cognitive domains and shed light on the time course and neural basis of the development of prosodic and melodic processing.												281	348											FEB	2006	18	2					199	211		10.1162/jocn.2006.18.2.199	http://dx.doi.org/10.1162/jocn.2006.18.2.199												2026-01-16	WOS:000235368300005
J	Bunton, K				Bunton, Kate			Fundamental frequency as a perceptual cue for vowel identification in speakers with Parkinson's disease	FOLIA PHONIATRICA ET LOGOPAEDICA				Article								This study investigates the importance of fundamental frequency (F0) as a perceptual cue for identification of vowel targets produced by speakers with Parkinson's disease (PD). It has been suggested in the literature that F0 is a redundant cue for vowel identification in highly intelligible speech. For speakers with dysarthria who are having difficulty with segmental and suprasegmental aspects of production which result in ambiguous or conflicting cues in the acoustic signal, F0 may have increased perceptual importance for accurate identification of vowel targets. In the present study, F0 contours for single-word targets produced in sentence level material by 20 speakers with PD and 20 control speakers were synthetically modified in several different ways (i.e.,. attened and enhanced). Listener identification of vowel targets across the F0 conditions was recorded. The accuracy of vowel identification for the control group was not affected by the flattening of the F0 contour. For the speakers with PD, however, modi. cation of the F0 contour (flattening or enhancing) affected the accuracy with which listeners identified certain vowels. Differences in vowel identification were found primarily for the front vowels/I, epsilon, ae / along a high-low continuum. Copyright (c) 2006 S. Karger AG, Basel.												26	32												2006	58	5					323	339		10.1159/000094567	http://dx.doi.org/10.1159/000094567												2026-01-16	WOS:000242165800002
J	Goswami, U; Barnes, L; Mead, N; Power, AJ; Leong, V				Goswami, Usha; Barnes, Lisa; Mead, Natasha; Power, Alan James; Leong, Victoria			Prosodic Similarity Effects in Short-Term Memory in Developmental Dyslexia	DYSLEXIA				Article								Children with developmental dyslexia are characterized by phonological difficulties across languages. Classically, this phonological deficit' in dyslexia has been investigated with tasks using single-syllable words. Recently, however, several studies have demonstrated difficulties in prosodic awareness in dyslexia. Potential prosodic effects in short-term memory have not yet been investigated. Here we create a new instrument based on three-syllable words that vary in stress patterns, to investigate whether prosodic similarity (the same prosodic pattern of stressed and unstressed syllables) exerts systematic effects on short-term memory. We study participants with dyslexia and age-matched and younger reading-level-matched typically developing controls. We find that all participants, including dyslexic participants, show prosodic similarity effects in short-term memory. All participants exhibited better retention of words that differed in prosodic structure, although participants with dyslexia recalled fewer words accurately overall compared to age-matched controls. Individual differences in prosodic memory were predicted by earlier vocabulary abilities, by earlier sensitivity to syllable stress and by earlier phonological awareness. To our knowledge, this is the first demonstration of prosodic similarity effects in short-term memory. The implications of a prosodic similarity effect for theories of lexical representation and of dyslexia are discussed. (c) 2016 The Authors. Dyslexia published by John Wiley & Sons Ltd.												11	14											NOV	2016	22	4					287	304		10.1002/dys.1535	http://dx.doi.org/10.1002/dys.1535												2026-01-16	WOS:000387141300001
J	Hedger, SC; Nusbaum, HC; Hoeckner, B				Hedger, Stephen C.; Nusbaum, Howard C.; Hoeckner, Berthold			Conveying Movement in Music and Prosody	PLOS ONE				Article								We investigated whether acoustic variation of musical properties can analogically convey descriptive information about an object. Specifically, we tested whether information from the temporal structure in music interacts with perception of a visual image to form an analog perceptual representation as a natural part of music perception. In Experiment 1, listeners heard music with an accelerating or decelerating temporal pattern, and then saw a picture of a still or moving object and decided whether it was animate or inanimate - a task unrelated to the patterning of the music. Object classification was faster when musical motion matched visually depicted motion. In Experiment 2, participants heard spoken sentences that were accompanied by accelerating or decelerating music, and then were presented with a picture of a still or moving object. When motion information in the music matched motion information in the picture, participants were similarly faster to respond. Fast and slow temporal patterns without acceleration and deceleration, however, did not make participants faster when they saw a picture depicting congruent motion information (Experiment 3), suggesting that understanding temporal structure information in music may depend on specific metaphors about motion in music. Taken together, these results suggest that visuo-spatial referential information can be analogically conveyed and represented by music and can be integrated with speech or influence the understanding of speech.												3	4											OCT 16	2013	8	10							e76744	10.1371/journal.pone.0076744	http://dx.doi.org/10.1371/journal.pone.0076744												2026-01-16	WOS:000326019400085
J	Pérez, MJM; Almela, A				Marin Perez, Maria Jose; Almela, Angela			The representation of migrants in Spanish judicial decisions: using corpus data to refute hate speech	CORPORA				Article								The phenomenon of immigration and its depiction in media texts have been examined profusely within the field of corpus-based discourse analysis (Gabrielatos and Baker, 2008; Baker et al., 2013; and Blinder and Allen, 2016). This research seeks to present it as reflected in a corpus of 600 judicial decisions issued by Spanish courts in the years 2016 and 2017. This analysis was motivated by the rise of extreme right-wing parties in Europe in recent years. Such parties dehumanise immigrants and portray them as a threat to the welfare state. On first examination, the results appear to dissociate immigration and crime since a considerable percentage of the keywords obtained (about 20 percent) revolves around three major topoi (namely, `family', `territory/access' and `legal punishment') and there is no evidence of any major offences or crimes amongst the top-ranking lexicon. The study of the collocate networks of the keywords within the category `legal punishment' confirms our initial perception; in fact, out of twentyone collocates, only the word delito (`crime') itself collocates with terms referring to typified crimes such as violencia (`violence'). In parallel, the data were triangulated using the text-classification software UMUTextStats (Garcia-Diaz et al., 2018). The results of this second analysis also confirm our initial observations.												0	0												2022	17	2					167	196		10.3366/cor.2022.0253	http://dx.doi.org/10.3366/cor.2022.0253												2026-01-16	WOS:000879752500001
J	Bejani, M; Gharavian, D; Charkari, NM				Bejani, Mahdi; Gharavian, Davood; Charkari, Nasrollah Moghaddam			Audiovisual emotion recognition using ANOVA feature selection method and multi-classifier neural networks	NEURAL COMPUTING & APPLICATIONS				Article								To make human-computer interaction more naturally and friendly, computers must enjoy the ability to understand human's affective states the same way as human does. There are many modals such as face, body gesture and speech that people use to express their feelings. In this study, we simulate human perception of emotion through combining emotion-related information using facial expression and speech. Speech emotion recognition system is based on prosody features, mel-frequency cepstral coefficients (a representation of the short-term power spectrum of a sound) and facial expression recognition based on integrated time motion image and quantized image matrix, which can be seen as an extension to temporal templates. Experimental results showed that using the hybrid features and decision-level fusion improves the outcome of unimodal systems. This method can improve the recognition rate by about 15 % with respect to the speech unimodal system and by about 30 % with respect to the facial expression system. By using the proposed multi-classifier system that is an improved hybrid system, recognition rate would increase up to 7.5 % over the hybrid features and decision-level fusion with RBF, up to 22.7 % over the speech-based system and up to 38 % over the facial expression-based system.												47	56											FEB	2014	24	2					399	412		10.1007/s00521-012-1228-3	http://dx.doi.org/10.1007/s00521-012-1228-3												2026-01-16	WOS:000330318500016
J	Caridakis, G; Karpouzis, K; Wallace, M; Kessous, L; Amir, N				Caridakis, George; Karpouzis, Kostas; Wallace, Manolis; Kessous, Loic; Amir, Noam			Multimodal user's affective state analysis in naturalistic interaction	JOURNAL ON MULTIMODAL USER INTERFACES				Article								Affective and human-centered computing have attracted an abundance of attention during the past years, mainly due to the abundance of environments and applications able to exploit and adapt to multimodal input from the users. The combination of facial expressions with prosody information allows us to capture the users' emotional state in an unintrusive manner, relying on the best performing modality in cases where one modality suffers from noise or bad sensing conditions. In this paper, we describe a multi-cue, dynamic approach to detect emotion in naturalistic video sequences, where input is taken from nearly real world situations, contrary to controlled recording conditions of audiovisual material. Recognition is performed via a recurrent neural network, whose short term memory and approximation capabilities cater for modeling dynamic events in facial and prosodic expressivity. This approach also differs from existing work in that it models user expressivity using a dimensional representation, instead of detecting discrete 'universal emotions', which are scarce in everyday human-machine interaction. The algorithm is deployed on an audiovisual database which was recorded simulating human-human discourse and, therefore, contains less extreme expressivity and subtle variations of a number of emotion labels. Results show that in turns lasting more than a few frames, recognition rates rise to 98%.												21	22											MAR	2010	3	1-2			SI		49	66		10.1007/s12193-009-0030	http://dx.doi.org/10.1007/s12193-009-0030												2026-01-16	WOS:000208480100005
J	Cutler, A; Otake, T				Cutler, A; Otake, T			Pitch accent in spoken-word recognition in Japanese	JOURNAL OF THE ACOUSTICAL SOCIETY OF AMERICA				Article; Proceedings Paper	134th Meeting of the Acoustical-Society-of-America	DEC 01-05, 1997	SAN DIEGO, CALIFORNIA					Three experiments addressed the question of whether pitch-accent information may be exploited in the process of recognizing spoken words in Tokyo Japanese. In a two-choice classification task, listeners judged from which of two words, differing in accentual structure, isolated syllables had been extracted (e.g., ka from baka HL or gaka LH); most judgments were correct, and listeners' decisions were correlated with the fundamental frequency characteristics of the syllables. In a gating experiment, listeners heard initial fragments of words and guessed what the words were; their guesses overwhelmingly had the same initial accent structure as the gated word even when only the beginning CV of the stimulus (e.g., na- from nagasa HLL or nagashi LHH) was presented. In addition, listeners were more confident in guesses with the same initial accent structure as the stimulus than in guesses with different accent. In a lexical decision experiment, responses to spoken words (e.g., ame HL) were speeded by previous presentation of the same word (e.g., ame HL) but not by previous presentation of a word differing only in accent (e.g., ame LH). Together these findings provide strong evidence that accentual information constrains the activation and selection of candidates for spoken-word recognition. (C) 1999 Acoustical Society of America. [S0001-4966(99)03003-9].												90	108											MAR	1999	105	3					1877	1888		10.1121/1.426724	http://dx.doi.org/10.1121/1.426724												2026-01-16	WOS:000079078500045
J	O'Regan, V; O'Regan, P; Killian, S; Lynch, R				O'Regan, Veronica; O'Regan, Philip; Killian, Sheila; Lynch, Ruth			MEDIA DISCOURSE AROUND TAXATION IN IRELAND AND THE UK IN THE WAKE OF FINANCIAL CRISIS	JOURNAL OF TAX ADMINISTRATION				Article								Media representation of tax practices is important because of the impact of public opinion on tax policy. Traditionally viewed as a technical subject and the preserve of professionals, taxation has recently become the focus of widespread and more informed public attention, as a result of, inter alia, tax scandals and the financial crisis. These events, together with wider international tax reform initiatives, provide researchers with an opportunity to explore the impact of tax reform on discourse by the public, as well as by tax experts and professionals. To this end, we analyse the changing treatment of tax-related issues in the mainstream and professional media in Ireland and the United Kingdom (UK) in order to capture expert voices, as well as public discourse. We do so in the immediate and medium-term aftermath of the financial crisis. Our analysis of tax discourse in general, and of the public framing of the term "tax avoidance" in particular, in both Ireland and the UK, reveals that a marked change has occurred in the public discourse in Ireland, a country struggling in the aftermath of a severe financial crisis. In contrast, our research finds that there is greater consistency in the UK's mainstream and professional media. Our findings also indicate that expert voices may lag behind public opinion.												0	0											SEP	2025	10	1																					2026-01-16	WOS:001577325200005
J	Zhang, XF; Li, BY; Qi, GB				Zhang, Xiufeng; Li, Bingyi; Qi, Guobin			A novel multimodal depression diagnosis approach utilizing a new hybrid fusion method	BIOMEDICAL SIGNAL PROCESSING AND CONTROL				Article								In recent years, research has found that the impact of depression status primarily lies in patients' language expression and facial expressions. Furthermore, facial expressions and intonation in speech exhibit a natural coexistence, making facial and vocal information core recognition indicators in depression identification. It is imperative to explore the effective use of deep learning methods for multimodal depression detection. We have proposed a novel trilateral bimodal encoding model (MEN), attentional decision fusion (ADF), and feature extraction fusion strategy. We employed a hybrid fusion approach that combines early intra-modality fusion with late inter-modality fusion, for multimodal depression diagnosis. In the feature extraction fusion component, we combine different representations of the same modality before inputting them into the network for training, enhancing features relevant to depression in the data. Through our multimodal encoding network, we extract frame-level information using Convolutional Neural Networks (CNN) while considering long-term context information and dependencies with Bidirectional Long Short-Term Memory (BiLSTM). Finally, the three streams of information were effectively integrated through attention fusion representation in our Attention Decision Fusion module (ADF), for depression score regression prediction. Extensive experiments were conducted on two public datasets, AVEC2013 and AVEC2014. The average absolute error/ root mean squared error (MAE/RMSE) scores for predicting depression scores were 6.48/8.91 and 7.01/9.38, respectively. This demonstrated that our hybrid fusion method outperforms traditional early or late fusion methods in terms of performance.												14	14											OCT	2024	96		A						106552	10.1016/j.bspc.2024.106552	http://dx.doi.org/10.1016/j.bspc.2024.106552		JUN 2024										2026-01-16	WOS:001253614900001
J	Malekroodi, HS; Madusanka, N; Lee, BI; Yi, M				Malekroodi, Hadi Sedigh; Madusanka, Nuwan; Lee, Byeong-il; Yi, Myunggi			Multi-Channel Spectro-Temporal Representations for Speech-Based Parkinson's Disease Detection	JOURNAL OF IMAGING				Article								Early, non-invasive detection of Parkinson's Disease (PD) using speech analysis offers promise for scalable screening. In this work, we propose a multi-channel spectro-temporal deep-learning approach for PD detection from sentence-level speech, a clinically relevant yet underexplored modality. We extract and fuse three complementary time-frequency representations-mel spectrogram, constant-Q transform (CQT), and gammatone spectrogram-into a three-channel input analogous to an RGB image. This fused representation is evaluated across CNNs (ResNet, DenseNet, and EfficientNet) and Vision Transformer using the PC-GITA dataset, under 10-fold subject-independent cross-validation for robust assessment. Results showed that fusion consistently improves performance over single representations across architectures. EfficientNet-B2 achieves the highest accuracy (84.39% +/- 5.19%) and F1-score (84.35% +/- 5.52%), outperforming recent methods using handcrafted features or pretrained models (e.g., Wav2Vec2.0, HuBERT) on the same task and dataset. Performance varies with sentence type, with emotionally salient and prosodically emphasized utterances yielding higher AUC, suggesting that richer prosody enhances discriminability. Our findings indicate that multi-channel fusion enhances sensitivity to subtle speech impairments in PD by integrating complementary spectral information. Our approach implies that multi-channel fusion could enhance the detection of discriminative acoustic biomarkers, potentially offering a more robust and effective framework for speech-based PD screening, though further validation is needed before clinical application.												0	0											OCT 1	2025	11	10							341	10.3390/jimaging11100341	http://dx.doi.org/10.3390/jimaging11100341												2026-01-16	WOS:001601744600001
J	Martínez-García, MT				Martinez-Garcia, Maria Teresa			Using Eye-Movements to Track Bilingual Activation	LANGUAGES				Article								Recent research found that the languages of bilingual listeners are active and interact, such that both lexical representations are activated by the spoken input with which they are compatible. However, the time course of bilingual activation and whether suprasegmental information further modulates this cross-language competition are still not well understood. This study investigates the effect of stress placement on the processing of English-Spanish cognates by beginner-to-intermediate Spanish-speaking second-language (L2) learners of English and intermediate-to-advanced English-speaking L2 learners of Spanish using the visual-world eye-tracking paradigm. In each trial, participants saw a target (asado, 'roast'), one of two competitors (stress match: asados, 'roast (pl)'; stress mismatch: asador, 'rotisserie'), and two unrelated distracters, while hearing the target word. The experiment included a non-cognate condition (asado-asados-asador) and a cognate condition, where the stress pattern of the English word corresponding to the Spanish competitor in the stress-mismatch condition (inventor) instead matched that of the Spanish target (invento, 'invent'). Growth-curve analyses revealed cognate-status and stress-mismatch effects for Spanish-speaking L2 learners of English, and cognate-status and stress-mismatch effects, and an interaction for English-speaking L2 learners of Spanish. This suggests that both groups use stress for word recognition, but the English stress pattern only affects the processing of Spanish words in the English-speaking L2 learners of Spanish.												1	2											SEP	2019	4	3							59	10.3390/languages4030059	http://dx.doi.org/10.3390/languages4030059												2026-01-16	WOS:000682799700014
J	Schirmer, A; Escoffier, N				Schirmer, Annett; Escoffier, Nicolas			Emotional MMN: Anxiety and heart rate correlate with the ERP signature for auditory change detection	CLINICAL NEUROPHYSIOLOGY				Article								Objective: Previous work established the mismatch negativity (MMN) as a correlate of pre-attentive auditory change detection. The present study aimed at investigating the relationship between the MMN and emotional processes associated with the detection of change. Methods: To this end, we assessed state anxiety with a questionnaire and subsequently recorded the electroencephalogram (EEG) and heart rate while participants watched a silent movie and listened to a task-irrelevant auditory oddball sequence. The oddball sequence comprised meaningless syllables of which some were deviants spoken with an angry or neutral voice. Results: The MMN to angry voice deviants was larger than that to neutral deviants and correlated positively with ensuing heart rate acceleration. Additionally, both the MMN and heart rate acceleration to angry voice deviants were increased with increasing state anxiety. A similar effect for neutral voice deviants was non-significant. Conclusion: Taken together, these results suggest that the pre-attentive processing of threat, as reflected by the MMN, is linked to an activation of the sympathetic nervous system. Moreover, this link is more strongly activated in individuals with high state anxiety. Significance: Thus, the MMN may be used as a marker for an individual's state dependent sensitivity to unattended, emotionally relevant change. (C) 2009 International Federation of Clinical Neurophysiology. Published by Elsevier Ireland Ltd. All rights reserved.												50	60											JAN	2010	121	1					53	59		10.1016/j.clinph.2009.09.029	http://dx.doi.org/10.1016/j.clinph.2009.09.029												2026-01-16	WOS:000274557500009
J	Alcaraz-Mármol, G; Soto-Almela, J				Alcaraz-Marmol, Gema; Soto-Almela, Jorge			Refugees' dehumanization in the Spanish media: A corpus-assisted study within the semantic preference framework	APPLIED LINGUISTICS REVIEW				Article								The dehumanization of migrants and refugees in the media has been the object of numerous critical discourse analyses and metaphor-based studies which have primarily dealt with English written news articles. This paper, however, addresses the dehumanizing language which is used to refer to refugees in a 1.8-million-word corpus of Spanish news articles collected from the digital libraries of El Mundo and El Pais, the two most widely read Spanish newspapers. Our research particularly aims to explore how the dehumanization of the lemma refugiado is constructed through the identification of semantic preferences. It is concerned with synchronic and diachronic aspects, offering results on the evolution of refugees' dehumanization from 2010 to 2016. The dehumanizing collocates are determined via a corpus-based analysis, followed by a detailed manual analysis conducted in order to label the different collocates of refugiado semantically and classify them into more specific semantic subsets. The results show that the lemma refugiado usually collocates with dehumanizing words that express, by frequency order, quantification, out-of-control phenomenon, objectification, and economic burden. The analysis also demonstrates that the collocates corresponding to these four semantic subsets are unusually frequent in the 2015-16 period, giving rise to seasonal collocates strongly related to the Syrian civil war and other Middle-East armed conflicts.												4	8											SEP 27	2022	13	5					791	817		10.1515/applirev-2019-0069	http://dx.doi.org/10.1515/applirev-2019-0069												2026-01-16	WOS:000852114300004
J	Cho, T; McQueen, JM				Cho, Taehong; McQueen, James M.			Perceptual Recovery from Consonant-Cluster Simplification in Korean Using Language-Specific Phonological Knowledge	JOURNAL OF PSYCHOLINGUISTIC RESEARCH				Article								Two experiments examined whether perceptual recovery from Korean consonant-cluster simplification is based on language-specific phonological knowledge. In tri-consonantal C1C2C3 sequences such as /lkt/ and /lpt/ in Seoul Korean, either C1 or C2 can be completely deleted. Seoul Koreans monitored for C2 targets (/p/ or /k/, deleted or preserved) in the second word of a two-word phrase with an underlying /l/-C2-/t/ sequence. In Experiment 1 the target-bearing words had contextual lexical-semantic support. Listeners recovered deleted targets as fast and as accurately as preserved targets with both Word and Intonational Phrase (IP) boundaries between the two words. In Experiment 2, contexts were low-pass filtered. Listeners were still able to recover deleted targets as well as preserved targets in IP-boundary contexts, but better with physically-present targets than with deleted targets in Word-boundary contexts. This suggests that the benefit of having target acoustic-phonetic information emerges only when higher-order (contextual and phrase-boundary) information is not available. The strikingly efficient recovery of deleted phonemes with neither acoustic-phonetic cues nor contextual support demonstrates that language-specific phonological knowledge, rather than language-universal perceptual processes which rely on fine-grained phonetic details, is employed when the listener perceives the results of a continuous-speech process in which reduction is phonetically complete.												2	2											AUG	2011	40	4					253	274		10.1007/s10936-011-9168-0	http://dx.doi.org/10.1007/s10936-011-9168-0												2026-01-16	WOS:000300174300002
J	Halle, PA; DeBoyssonBardies, B				Halle, PA; DeBoyssonBardies, B			The format of representation of recognized words in infants' early receptive lexicon	INFANT BEHAVIOR & DEVELOPMENT				Article								Eleven-month-olds can recognize a few auditorily presented familiar words in experimental situations where no hints are given by the intonation, the situation, or the presence of possible visual referents. That is, infants of this age (and possibly somewhat younger) can recognize words based on sound patterns alone. The issue addressed in this article is what is the type of mental representations infants use to code words they recognize. The results of a series of experiments with French-learning infants indicate that word representations in 11-month-olds are segmentally underspecified and suggest that they are all the more underspecified when infants engage in recognizing words rather than merely attending to meaningless speech sounds. But underspecification has limits, which were explored here with respect to word-initial consonants. The last two experiments show the way to investigating further these limits for word-initial consonants as well as for segments in other word positions. In French, infants' word representations are flexible enough to allow for structural changes in the voicing or even in the manner of articulation of word-initial consonants. Word-initial consonants must be present, however, for words to be recognized. In conclusion, a parallel is proposed between the emerging capacities to ignore variations that are irrelevant for word recognition in a ''lexical mode'' and to ignore variations that are phonemically irrelevant in a ''neutral mode'' of listening to native speech.												114	130											OCT-DEC	1996	19	4					463	481		10.1016/S0163-6383(96)90007-7	http://dx.doi.org/10.1016/S0163-6383(96)90007-7												2026-01-16	WOS:A1996WF32600007
J	Issard, C; Gervain, J				Issard, Cecile; Gervain, Judit			Adult-like processing of time-compressed speech by newborns: A NIRS study	DEVELOPMENTAL COGNITIVE NEUROSCIENCE				Article								Humans can adapt to a wide range of variations in the speech signal, maintaining an invariant representation of the linguistic information it contains. Among them, adaptation to rapid or time-compressed speech has been well studied in adults, but the developmental origin of this capacity remains unknown. Does this ability depend on experience with speech (if yes, as heard in utero or as heard postnatally), with sounds in general or is it experience-independent? Using near-infrared spectroscopy, we show that the newborn brain can discriminate between three different compression rates: normal, i.e. 100% of the original duration, moderately compressed, i.e. 60% of original duration and highly compressed, i.e. 30% of original duration. Even more interestingly, responses to normal and moderately compressed speech are similar, showing a canonical hemodynamic response in the left temporoparietal, right frontal and right temporal cortex, while responses to highly compressed speech are inverted, showing a decrease in oxyhemoglobin concentration. These results mirror those found in adults, who readily adapt to moderately compressed, but not to highly compressed speech, showing that adaptation to time-compressed speech requires little or no experience with speech, and happens at an auditory, and not at a more abstract linguistic level. (C) 2016 The Authors. Published by Elsevier Ltd.												21	24											JUN	2017	25						176	184		10.1016/j.dcn.2016.10.006	http://dx.doi.org/10.1016/j.dcn.2016.10.006												2026-01-16	WOS:000422921800016
J	Brück, C; Kreifelts, B; Gössling-Arnold, C; Wertheimer, J; Wildgruber, D				Brueck, Carolin; Kreifelts, Benjamin; Goessling-Arnold, Christina; Wertheimer, Juergen; Wildgruber, Dirk			'Inner voices': the cerebral representation of emotional voice cues described in literary texts	SOCIAL COGNITIVE AND AFFECTIVE NEUROSCIENCE				Article								While non-verbal affective voice cues are generally recognized as a crucial behavioral guide in any day-to-day conversation their role as a powerful source of information may extend well beyond close-up personal interactions and include other modes of communication such as written discourse or literature as well. Building on the assumption that similarities between the different 'modes' of voice cues may not only be limited to their functional role but may also include cerebral mechanisms engaged in the decoding process, the present functional magnetic resonance imaging study aimed at exploring brain responses associated with processing emotional voice signals described in literary texts. Emphasis was placed on evaluating 'voice' sensitive as well as task- and emotion-related modulations of brain activation frequently associated with the decoding of acoustic vocal cues. Obtained findings suggest that several similarities emerge with respect to the perception of acoustic voice signals: results identify the superior temporal, lateral and medial frontal cortex as well as the posterior cingulate cortex and cerebellum to contribute to the decoding process, with similarities to acoustic voice perception reflected in a 'voice'-cue preference of temporal voice areas as well as an emotion-related modulation of the medial frontal cortex and a task-modulated response of the lateral frontal cortex.												10	12											NOV	2014	9	11					1819	1827		10.1093/scan/nst180	http://dx.doi.org/10.1093/scan/nst180												2026-01-16	WOS:000345846800022
J	Zhang, MY; Sisman, B; Zhao, L; Li, HZ				Zhang, Mingyang; Sisman, Berrak; Zhao, Li; Li, Haizhou			DeepConversion: Voice conversion with limited parallel training data	SPEECH COMMUNICATION				Article								A deep neural network approach to voice conversion usually depends on a large amount of parallel training data from source and target speakers. In this paper, we propose a novel conversion pipeline, DeepConversion, that leverages a large amount of non-parallel, multi-speaker data, but requires only a small amount of parallel training data. It is believed that we can represent the shared characteristics of speakers by training a speaker independent general model on a large amount of publicly available, non-parallel, multi-speaker speech data. Such general model can then be used to learn the mapping between source and target speaker more effectively from a limited amount of parallel training data. We also propose a strategy to make full use of the parallel data in all models along the pipeline. In particular, the parallel data is used to adapt the general model towards the source-target speaker pair to achieve a coarse grained conversion, and to develop a compact Error Reduction Network (ERN) for a fine-grained conversion. The parallel data is also used to adapt the WaveNet vocoder towards the source-target pair. The experiments show that DeepConversion that only uses a limited amount of parallel training data, consistently outperforms the traditional approaches that use a large amount of parallel training data, in both objective and subjective evaluations. (C) 2020 The Authors. Published by Elsevier B.V.												18	18											SEP	2020	122						31	43		10.1016/j.specom.2020.05.004	http://dx.doi.org/10.1016/j.specom.2020.05.004												2026-01-16	WOS:000570131600004
J	Picart, B; Drugman, T; Dutoit, T				Picart, Benjamin; Drugman, Thomas; Dutoit, Thierry			Automatic Variation of the Degree of Articulation in New HMM-Based Voices	IEEE JOURNAL OF SELECTED TOPICS IN SIGNAL PROCESSING				Article								This paper focuses on the automatic modification of the degree of articulation (hypo and hyperarticulation) of an existing standard neutral voice in the framework of HMM-based speech synthesis. Hypo and hyperarticulation refer to the production of speech respectively with a reduction and an increase of the articulatory efforts compared to the neutral style. Starting from a source speaker for which neutral, hypo and hyperarticulated speech data are available, statistical transformations are computed during the adaptation of the neutral speech synthesizer. These transformations are then applied to a new target speaker for which no hypo or hyperarticulated recordings are available. Four statistical methods are investigated, differing in the speaking style adaptation technique (model-space Linear Scaling LS vs. CMLLR) and in the speaking style transposition approach (phonetic vs. acoustic correspondence) they use. The efficiency of these techniques is assessed for the transposition of prosody and of filter coefficients separately. Besides we investigate which representation of the spectral envelope is the most suited for this purpose: MGC, LSP, PARCOR and LAR coefficients. Subjective evaluations are performed in order to determine which statistical transformation method achieves the highest performance in terms of segmental quality, reproduction of the articulation degree and speaker identity preservation. The most successful method is finally used for automatically modifying the degree of articulation of existing standard neutral voices.												1	1											APR	2014	8	2					307	322		10.1109/JSTSP.2014.2302742	http://dx.doi.org/10.1109/JSTSP.2014.2302742												2026-01-16	WOS:000333100900014
J	Yarko, M; Borysenko, M; Buchok, L; Karalius, M				Yarko, Marija; Borysenko, Maria; Buchok, Lianna; Karalius, Maria			Piano Works of Transcarpathian Composers of the 20th and Early 21st Centuries: The Phenomenon Research Algorithms	STUDIA MUSICOLOGICA				Article								The purpose of this article is to study the continuity of musical thinking professionalization on ex-amples of piano works by Transcarpathian composers, which are very significant for the formation of the Transcarpathian compositional tradition as a historical phenomenon of mastery development by Transcarpathian composers (Zsigmond Lengyel, Dezso Zador, Istvan Marton, Emil Kobulei, Mykola Popenko, Volodymir Volontyr, Anatoly Zatin, Viktor Telychko) regarding their compliance with the academic norms of musical thinking and with historically composed stylistic invariants. The approach to the research phenomenon is monadological, which means the intention to diagnose a mentally peculiar discourse of the stylistic design, combining the assimilation of historically relevant thought forms and the intonational stock of a multiethnic folklore of the Transcarpathian region. We come to the conclusion that the piano works of Transcarpathian composers reflect a historically determined manoeuvre of "catching up" with the stylistic initiatives of the whole twentieth century with its idea of a global cultural synthesis and reinterpretation/neo-restoration of traditions. It has been found that the starting point for the professionalization of music composition in Transcarpathia was the modern modality of style - a position that is usually characterized as a "post-Romantic reaction" to all the traditional and total renewal of musical thinking in order to innovate. At the same time, for the style -forming initiatives of Transcarpathian composers the discourse of stylization became most relevant - a special type of musical thinking that created the newest representation of the "intonation image of the world" and found its rather original embodiment in the postmodern phase under the guise of "in-tellectual performance."												1	1											DEC	2022	63	3-4					209	239		10.1556/6.2022.00005	http://dx.doi.org/10.1556/6.2022.00005												2026-01-16	WOS:001024543800003
J	Ortega-Llebaria, M; Wu, ZH				Ortega-Llebaria, Marta; Wu, Zhaohong			Chinese-English Speakers' Perception of Pitch in Their Non-Tonal Language: Reinterpreting English as a Tonal-Like Language	LANGUAGE AND SPEECH				Article								Changing the F0-contour of English words does not change their lexical meaning. However, it changes the meaning in tonal languages such as Mandarin. Given this important difference and knowing that words in the two languages of a bilingual lexicon interact, the question arises as to how Mandarin-English speakers process pitch in their bilingual lexicon. The few studies that addressed this question showed that Mandarin-English speakers did not perceive pitch in English words as native English speakers did. These studies, however, used English words as stimuli failing to examine nonwords and Mandarin words. Consequently, possible pre-lexical effects and L1 transfer were not ruled out. The present study fills this gap by examining pitch perception in Mandarin and English words and nonwords by Mandarin-English speakers and a group of native English controls. Results showed the tonal experience of Chinese-English speakers modulated their perception of pitch in their non-tonal language at both pre-lexical and lexical levels. In comparison to native English controls, tonal speakers were more sensitive to the acoustic salience of F0-contours in the pre-lexical processing due to top-down feedback. At the lexical level, Mandarin-English speakers organized words in their two languages according to similarity criteria based on both F0 and segmental information, whereas only the segmental information was relevant to the control group. These results in perception together with consistently reported production patterns in previous literature suggest that Mandarin-English speakers process pitch in English as if it was a one-tone language.												11	11											JUN	2021	64	2			SI		467	487	0023830919894606	10.1177/0023830919894606	http://dx.doi.org/10.1177/0023830919894606		JAN 2020										2026-01-16	WOS:000507060400001
J	Herrmann, B; Cui, ME				Herrmann, Bjorn; Cui, Mo Eric			Impaired Prosodic Processing but Not Hearing Function Is Associated with an Age-Related Reduction in AI Speech Recognition	AUDIOLOGY RESEARCH				Article								Background/Objectives: Voice artificial intelligence (AI) technology is becoming increasingly common. Recent work indicates that middle-aged to older adults are less able to identify modern AI speech compared to younger adults, but the underlying causes are unclear. Methods: The current study with younger and middle-aged to older adults investigated factors that could explain the age-related reduction in AI speech identification. Experiment 1 investigated whether high-frequency information in speech-to which middle-aged to older adults often have less access due sensitivity loss at high frequencies-contributes to age-group differences. Experiment 2 investigated whether an age-related reduction in the ability to process prosodic information in speech predicts the reduction in AI speech identification. Results: Results for Experiment 1 show that middle-aged to older adults are less able to identify AI speech for both full-bandwidth speech and speech for which information above 4 kHz is removed, making the contribution of high-frequency hearing loss unlikely. Experiment 2 shows that the ability to identify AI speech is greater in individuals who also show a greater ability to identify emotions from prosodic speech information, after accounting for hearing function and self-rated experience with voice-AI systems. Conclusions: The current results suggest that the ability to identify AI speech is related to the accurate processing of prosodic information.												1	1											FEB	2025	15	1							14	10.3390/audiolres15010014	http://dx.doi.org/10.3390/audiolres15010014												2026-01-16	WOS:001429898000001
J	Abdulrahman, AO; Othman, SI; Yasin, GB; Ali, MS				Abdulrahman, Ayub Othman; Othman, Shanga Ismail; Yasin, Gazo Badran; Ali, Meer Salam			A dataset for classifying phrases and sentences into statements, questions, or exclamations based on sound pitch	DATA IN BRIEF				Article; Data Paper								Speech is the most fundamental and sophisticated channel of human communication, and breakthroughs in Natural Language Processing (NLP) have substantially raised the quality of human-computer interaction. In particular, new wave of deep learning methods have significantly advanced human speech recognition by obtaining fine-grained acoustic cues including pitch, an acoustic feature that can be a critical ingredient in understanding communicative intent. Pitch variation is in particular important for prosodic classification tasks (i.e., statements, questions, and exclamations), which is crucial in tonal and low resource languages such as Kurdish, where intonation holds significant semantic information. This paper presents the dataset of the Statements, Questions, or Exclamations Based on Sound Pitch (SQEBSP) which contains 12,660 professionally-recorded speech audio clips by 431 native Kurdish speakers who reside in the Kurdistan Region of Iraq. Regarding utterances, 10 new phrases were articulated by each speaker per three prosodic categories: statements, questions, and exclamations. All utterances were digitized at 16 kHz and then manually checked for correctness concerning pitch-based classification. The dataset contains equal representation from all three classes, about 4200 samples per class, and metadata such as speaker gender, age group, and sentence identifiers. The original audio files, alongside resources like Mel-Frequency Cepstral Coefficients (MFCCs) and waveform visualizations, can be found on Mendeley Data. The dataset offered has significant advantages for formulating and testing pitch-based speech classification algorithms, furthers the work on pronunciation modelling for languages lacking sufficient resources. It furthermore, aids in developing speech technologies sensitive to dialects. (c) 2025 Published by Elsevier Inc. This is an open access article under the CC BY license (http://creativecommons.org/licenses/by/4.0/)												0	0											AUG	2025	61								111826	10.1016/j.dib.2025.111826	http://dx.doi.org/10.1016/j.dib.2025.111826		JUN 2025										2026-01-16	WOS:001523491900012
J	Saarimäki, H; Glerean, E; Smirnov, D; Mynttinen, H; Jääskeläinen, IP; Sams, M; Nummenmaa, L				Saarimaki, Heini; Glerean, Enrico; Smirnov, Dmitry; Mynttinen, Henri; Jaaskelainen, Iiro P.; Sams, Mikko; Nummenmaa, Lauri			Classification of emotion categories based on functional connectivity patterns of the human brain	NEUROIMAGE				Article								Neurophysiological and psychological models posit that emotions depend on connections across wide-spread cor-ticolimbic circuits. While previous studies using pattern recognition on neuroimaging data have shown differences between various discrete emotions in brain activity patterns, less is known about the differences in functional connectivity. Thus, we employed multivariate pattern analysis on functional magnetic resonance imaging data (i) to develop a pipeline for applying pattern recognition in functional connectivity data, and (ii) to test whether connectivity patterns differ across emotion categories. Six emotions (anger, fear, disgust, happiness, sadness, and surprise) and a neutral state were induced in 16 participants using one-minute-long emotional narratives with natural prosody while brain activity was measured with functional magnetic resonance imaging (fMRI). We computed emotion-wise connectivity matrices both for whole-brain connections and for 10 previously defined functionally connected brain subnetworks and trained an across-participant classifier to categorize the emotional states based on whole-brain data and for each subnetwork separately. The whole-brain classifier performed above chance level with all emotions except sadness, suggesting that different emotions are characterized by differences in large-scale connectivity patterns. When focusing on the connectivity within the 10 subnetworks, classification was successful within the default mode system and for all emotions. We thus show preliminary evidence for consistently different sustained functional connectivity patterns for instances of emotion categories particularly within the default mode system.												34	36											FEB 15	2022	247								118800	10.1016/j.neuroimage.2021.118800	http://dx.doi.org/10.1016/j.neuroimage.2021.118800		DEC 2021										2026-01-16	WOS:000736958800007
J	Sidtis, JJ				Sidtis, John J.			Functional Connectivity Associated with Acoustic Stability During Vowel Production: Implications for Vocal-Motor Control	BRAIN CONNECTIVITY				Article								Vowels provide the acoustic foundation of communication through speech and song, but little is known about how the brain orchestrates their production. Positron emission tomography was used to study regional cerebral blood flow (rCBF) during sustained production of the vowel /a/. Acoustic and blood flow data from 13, normal, right-handed, native speakers of American English were analyzed to identify CBF patterns that predicted the stability of the first and second formants of this vowel. Formants are bands of resonance frequencies that provide vowel identity and contribute to voice quality. The results indicated that formant stability was directly associated with blood flow increases and decreases in both left-and right-sided brain regions. Secondary brain regions (those associated with the regions predicting formant stability) were more likely to have an indirect negative relationship with first formant variability, but an indirect positive relationship with second formant variability. These results are not definitive maps of vowel production, but they do suggest that the level of motor control necessary to produce stable vowels is reflected in the complexity of an underlying neural system. These results also extend a systems approach to functional image analysis, previously applied to normal and ataxic speech rate that is solely based on identifying patterns of brain activity associated with specific performance measures. Understanding the complex relationships between multiple brain regions and the acoustic characteristics of vocal stability may provide insight into the pathophysiology of the dysarthrias, vocal disorders, and other speech changes in neurological and psychiatric disorders.												8	8											MAR	2015	5	2					115	125		10.1089/brain.2014.0257	http://dx.doi.org/10.1089/brain.2014.0257												2026-01-16	WOS:000448192300005
J	Martello, M				Martello, Matthew			Dramatic Poetry as Rhetorical Form: The Case of Sarah Piatt's "Mock Diamonds"	NARRATIVE				Article								The programmatic study of narrative and poetry has stalled without engaging many approaches to narrative inquiry and without comprehending the sui generis achievements of poetical representation. This essay attempts to rejuvenate nar-ratological and specifically rhetorical interest in poetry by carefully examining the dra-matic poem-where poetic form intersects with several of narrative theory's abiding enthusiasms: character, voice, perspective, performance. Marrying theoretical specu-lation to both practical criticism and literary history, the argument extrapolates from Sarah Piatt's "Mock Diamonds " a twofold rhetoric of the dramatic-poetic mode. It posits first that, often through segmentation and related phenomena, dramatic poems formally enact a competition between individual communicants and the discursive contexts that threaten to supplant their perspectival authority. Second, it maintains that dramatic poems coordinate a dialogic interplay between (1) character speech, whose semantic content manifests the character-speaker's intentions, and (2) versi-fication, whose formal qualities signify outside the represented scene. The recitative performance conventionally mandated by poetry integrates these two communicative channels such that they mean the embodied expression they specify together. That culminative detail underscores the essay's broadest implication: namely, that poetry's emphases on readerly enactment and sonic, somatic, and typographic patterning gen-erate rhetorical effects not readily available in other representational discourses. Dra-matic poetry, as epitomized by "Mock Diamonds, " demonstrates the power of poetic form to renovate, and hence to augment, prevailing theories of even the most familiar narrative constituents.												0	0											JAN	2023	31	1					26	48															2026-01-16	WOS:000935793900002
J	Hjortkjær, J; Märcher-Rorsted, J; Fuglsang, SA; Dau, T				Hjortkjaer, Jens; Marcher-Rorsted, Jonatan; Fuglsang, Soren A.; Dau, Torsten			Cortical oscillations and entrainment in speech processing during working memory load	EUROPEAN JOURNAL OF NEUROSCIENCE				Article								Neuronal oscillations are thought to play an important role in working memory (WM) and speech processing. Listening to speech in real-life situations is often cognitively demanding but it is unknown whether WM load influences how auditory cortical activity synchronizes to speech features. Here, we developed an auditory n-back paradigm to investigate cortical entrainment to speech envelope fluctuations under different degrees of WM load. We measured the electroencephalogram, pupil dilations and behavioural performance from 22 subjects listening to continuous speech with an embedded n-back task. The speech stimuli consisted of long spoken number sequences created to match natural speech in terms of sentence intonation, syllabic rate and phonetic content. To burden different WM functions during speech processing, listeners performed an n-back task on the speech sequences in different levels of background noise. Increasing WM load at higher n-back levels was associated with a decrease in posterior alpha power as well as increased pupil dilations. Frontal theta power increased at the start of the trial and increased additionally with higher n-back level. The observed alpha-theta power changes are consistent with visual n-back paradigms suggesting general oscillatory correlates of WM processing load. Speech entrainment was measured as a linear mapping between the envelope of the speech signal and low-frequency cortical activity (< 13 Hz). We found that increases in both types of WM load (background noise and n-back level) decreased cortical speech envelope entrainment. Although entrainment persisted under high load, our results suggest a top-down influence of WM processing on cortical speech entrainment.												38	41											MAR	2020	51	5					1279	1289		10.1111/ejn.13855	http://dx.doi.org/10.1111/ejn.13855												2026-01-16	WOS:000520615000013
J	Lu, XJ; Sun, YN; Ho, HT; Thompson, WF				Lu, Xuejing; Sun, Yanan; Ho, Hao Tam; Thompson, William Forde			Pitch contour impairment in congenital amusia: New insights from the Self-paced Audio-visual Contour Task (SACT)	PLOS ONE				Article								Individuals with congenital amusia usually exhibit impairments in melodic contour processing when asked to compare pairs of melodies that may or may not be identical to one another. However, it is unclear whether the impairment observed in contour processing is caused by an impairment of pitch discrimination, or is a consequence of poor pitch memory. To help resolve this ambiguity, we designed a novel Self-paced Audio-visual Contour Task (SACT) that evaluates sensitivity to contour while placing minimal burden on memory. In this task, participants control the pace of an auditory contour that is simultaneously accompanied by a visual contour, and they are asked to judge whether the two contours are congruent or incongruent. In Experiment 1, melodic contours varying in pitch were presented with a series of dots that varied in spatial height. Amusics exhibited reduced sensitivity to audio-visual congruency in comparison to control participants. To exclude the possibility that the impairment arises from a general deficit in cross-modal mapping, Experiment 2 examined sensitivity to cross-modal mapping for two other auditory dimensions: timbral brightness and loudness. Amusics and controls were significantly more sensitive to large than small contour changes, and to changes in loudness than changes in timbre. However, there were no group differences in cross-modal mapping, suggesting that individuals with congenital amusia can comprehend spatial representations of acoustic information. Taken together, the findings indicate that pitch contour processing in congenital amusia remains impaired even when pitch memory is relatively unburdened.												6	10											JUN 15	2017	12	6							e0179252	10.1371/journal.pone.0179252	http://dx.doi.org/10.1371/journal.pone.0179252												2026-01-16	WOS:000403364600027
J	Warner-Czyz, AD; Evans, D; Turkstra, L; Scheppele, M; Song, C; Evans, JL				Warner-Czyz, Andrea D.; Evans, Delaney; Turkstra, Lyn; Scheppele, Meredith; Song, Chen; Evans, Julia L.			Effect of auditory status on visual emotion recognition in adolescents	COCHLEAR IMPLANTS INTERNATIONAL				Article								Adolescents with severe to profound hearing loss who wear cochlear implants (CIs) experience significantly more peer problems compared to peers with typical hearing (TH). Differences in peer social dynamics may relate to perception not only of message content, but also message intent based on a speaker's emotion from visual (e.g. facial expressions) and auditory (e.g. prosody) cues. Pediatric CI users may experience greater difficulty with auditory emotion recognition due to an impoverished signal representation provided by the device, but the effect of auditory status on visual emotion recognition yields conflicting results. Objectives: The current study examined accuracy and speed of visual emotion recognition in adolescents with CIs and peers with TH. Methods: Participants included 58 adolescents (10-18 years) stratified by auditory status: 34 CI users and 24 TH peers. Participants identified the intended emotion (i.e. happiness, sadness, anger, fear, disgust, and surprise) of static images of faces displayed on a computer screen. Results: No significant differences by auditory status emerged for response accuracy, response time to all trials, or response time to correct trials. Type of emotion significantly affected both accuracy and response time. Conclusion: Adolescents with CIs show similar accuracy and response time in recognizing static facial expressions compared to TH peers. Future studies should explore the association between visual emotion recognition and social well-being to determine the relationship between emotion recognition and overall quality of life in adolescents with CIs.												1	2											MAY 4	2019	20	3					127	137		10.1080/14670100.2019.1573952	http://dx.doi.org/10.1080/14670100.2019.1573952												2026-01-16	WOS:000704599000004
J	Granroth-Wilding, M; Steedman, M				Granroth-Wilding, Mark; Steedman, Mark			A Robust Parser-Interpreter for Jazz Chord Sequences	JOURNAL OF NEW MUSIC RESEARCH				Article								Hierarchical structure similar to that associated with prosody and syntax in language can be identified in the rhythmic and harmonic progressions that underlie Western tonal music. Analysing such musical structure resembles natural language parsing: it requires the derivation of an underlying interpretation from an unstructured sequence of highly ambiguous elements-in the case of music, the notes. The task here is not merely to decide whether the sequence is grammatical, but rather to decide which among a large number of analyses it has. An analysis of this sort is a part of the cognitive processing performed by listeners familiar with amusical idiom, whether musically trained or not. Our focus is on the analysis of the structure of expectations and resolutions created by harmonic progressions. Building on previous work, we define a theory of tonal harmonic progression, which plays a role analogous to semantics in language. Our parser uses a formal grammar of jazz chord sequences, of a kind widely used for natural language processing (NLP), to map music, in the form of chord sequences used by performers, onto a representation of the structured relationships between chords. It uses statistical modelling techniques used for wide-coverage parsing in NLP to make practical parsing feasible in the face of considerable ambiguity in the grammar. Using machine learning over a small corpus of jazz chord sequences annotated with harmonic analyses, we show that grammar-based musical interpretation using simple statistical parsing models ismore accurate than a baseline HMM. The experiment demonstrates that statistical techniques adapted from NLP can be profitably applied to the analysis of harmonic structure.												28	28												2014	43	4					355	374		10.1080/09298215.2014.910532	http://dx.doi.org/10.1080/09298215.2014.910532												2026-01-16	WOS:000342325800001
J	Lolive, D; Barbot, N; Boeffard, O				Lolive, Damien; Barbot, Nelly; Boeffard, Olivier			B-Spline Model Order Selection With Optimal MDL Criterion Applied to Speech Fundamental Frequency Stylization	IEEE JOURNAL OF SELECTED TOPICS IN SIGNAL PROCESSING				Article								In the speech processing field, stylization of fundamental frequency F-0 has been subjected to numerous works. Models proposed in the literature rely on knowledge stemming from phonology and linguistics. We propose an approach that deals with the issue of F-0 curve stylization requiring as few linguistic assumptions as possible and in the framework of B-spline models. A B-spline model, characterized by a sequence of knots with which control points are associated, enables the formalization of discontinuities in the derivatives of the observed values sequence. Beyond the implementation of a B-spline model to stylize an open curve sampled using a constant step, we address the problem of the optimal model order choice. We propose to use a parsimony criterion based on a minimum description length (MDL) approach, in order to optimize the number of knots. We derive several criteria relying on bounds estimated from parameter values. We demonstrate the optimality of these choices in the theoretical MDL framework. We introduce a notion of variable precision of parameters which enables a good compromise between the modeling precision and degrees of freedom of the estimated models. Experiments are performed on a French speech corpus and compare three MDL criteria. The use of both B-spline model and MDL methodology enables an efficient modeling of F-0 curves and provides an RMS error around 1 Hz while allowing a relatively high compression rate about 40%.												1	1											JUN	2010	4	3					571	581		10.1109/JSTSP.2010.2048236	http://dx.doi.org/10.1109/JSTSP.2010.2048236												2026-01-16	WOS:000277777400011
J	Kosta, P				Kosta, P			On argument structure, focusing and modal sentence adverbials in Czech and Russian	ZEITSCHRIFT FUR SLAWISTIK				Article; Proceedings Paper	12th International Conference of Slavic Scholars	1998	KRAKOW, POLAND					Prototypical features of modal sentence adverbial constructions are analyzed and compared with the prototypical features of the so-called rhematizers such as only (focalizers or focus sensitive particles, cf. Hajicova 1995a; Koktova 1986; 1987; McCawley 1996; Boguslavskij 1985) in Czech and Russian sentences. The analysis is based on the assumption that the syntactic position of the surface word order of arguments and adjuncts reflects (also in its relation to sentence prosody) the categorical representation of the cognitive meaning of the sentence. In secondary cases, an adverbial of mood can also occur in the topic position of the sentence (i.e., in the leftmost position) without necessarily ascribing the sentence an existential meaning as proposed for locative sentences by Babby (1980, 101). Following Hajicova (1995ab), it seems to be necessary to distinguish between the "focus of a rhematizer," the "focus position of the adjuncts (adverbials)" and the "focus of the arguments." In addition, several Czech and Russian modal sentence adverbials and focalizers are discussed which exhibit interesting syntactic relations. The analysis is based on the dichotomy of topic and focus articulation as developed in the tradition of Prague school (Firbas 1992; Hajicova, Partee, Sgall, in prep.), but it entails also some considerations on informational structure of adjuncts and arguments (Grimshaw 1991) as described in the Minimalist program (Chomsky 1995; Kayne 1995; Kosta 1997). Also the notions of pragmatic ordering principle, of contextual boundness (Krifka 1995), of salience and the hierarchy of communicative dynamism offer convenient tools for a sufficiently detailed description of the sentence structure of Czech and Russian modal sentence adverbials.												1	1												1998	43	2					140	154															2026-01-16	WOS:000084584400002
J	Krishnan, A; Xu, YS; Gandour, JT; Cariani, PA				Krishnan, A; Xu, YS; Gandour, JT; Cariani, PA			Human frequency-following response: representation of pitch contours in Chinese tones	HEARING RESEARCH				Article								Auditory nerve single-unit population studies have demonstrated that phase-locking plays a dominant role in the neural encoding of both the spectrum and voice pitch of speech sounds. Phase-locked neural activity underlying the scalp-recorded human frequency-following response (FFR) has also been shown to encode certain spectral features of steady-state and time-variant speech sounds as well as pitch of several complex sounds that produce time-invariant pitch percepts. By extension, it was hypothesized that the human FFR may preserve pitch-relevant information for speech sounds that elicit time-variant as well as steady-state pitch percepts. FFRs were elicited in response to the four lexical tones of Mandarin Chinese as well as to a complex auditory stimulus which was spectrally different but equivalent in fundamental frequency (f(0)) contour to one of the Chinese tones. Autocorrelation-based pitch extraction measures revealed that the FFR does indeed preserve pitch-relevant information for all stimuli. Phase-locked interpeak intervals closely followed f(0). Spectrally different stimuli that were equivalent in F-0 similarly showed robust interpeak intervals that followed f(0). These FFR findings support the viability of early, population-based 'predominant interval' representations of pitch in the auditory brainstem that are based on temporal patterns of phase-locked neural activity. (C) 2004 Elsevier B.V. All rights reserved.												134	176											MAR	2004	189	1-2					1	12		10.1016/S0378-5955(03)00402-7	http://dx.doi.org/10.1016/S0378-5955(03)00402-7												2026-01-16	WOS:000220123700001
J	Goswami, U; Wang, HLS; Cruz, A; Fosker, T; Mead, N; Huss, M				Goswami, Usha; Wang, H. -L. Sharon; Cruz, Alicia; Fosker, Tim; Mead, Natasha; Huss, Martina			Language-universal Sensory Deficits in Developmental Dyslexia: English, Spanish, and Chinese	JOURNAL OF COGNITIVE NEUROSCIENCE				Article								Studies in sensory neuroscience reveal the critical importance of accurate sensory perception for cognitive development. There is considerable debate concerning the possible sensory correlates of phonological processing, the primary cognitive risk factor for developmental dyslexia. Across languages, children with dyslexia have a specific difficulty with the neural representation of the phonological structure of speech. The identification of a robust sensory marker of phonological difficulties would enable early identification of risk for developmental dyslexia and early targeted intervention. Here, we explore whether phonological processing difficulties are associated with difficulties in processing acoustic cues to speech rhythm. Speech rhythm is used across languages by infants to segment the speech stream into words and syllables. Early difficulties in perceiving auditory sensory cues to speech rhythm and prosody could lead developmentally to impairments in phonology. We compared matched samples of children with and without dyslexia, learning three very different spoken and written languages, English, Spanish, and Chinese. The key sensory cue measured was rate of onset of the amplitude envelope (rise time), known to be critical for the rhythmic timing of speech. Despite phonological and orthographic differences, for each language, rise time sensitivity was a significant predictor of phonological awareness, and rise time was the only consistent predictor of reading acquisition. The data support a language-universal theory of the neural basis of developmental dyslexia on the basis of rhythmic perception and syllable segmentation. They also suggest that novel remediation strategies on the basis of rhythm and music may offer benefits for phonological and linguistic development.												186	214											FEB	2011	23	2					325	337		10.1162/jocn.2010.21453	http://dx.doi.org/10.1162/jocn.2010.21453												2026-01-16	WOS:000283356500005
J	Tong, XH; Deacon, SH				Tong, Xiuhong; Deacon, S. Helene			The Linguistic Pathways Model: Capturing the Multiple Dimensions of Reading Development	READING RESEARCH QUARTERLY				Article								The importance of oral language skills in reading comprehension is widely recognized in contemporary models. Building on this foundation, we propose the Linguistic Pathways Model. In this model, we illuminate mechanistic and developmental detail by which individual components of oral language support reading comprehension and embrace the multiple dimensions across which reading development plays out. This is the level of theoretical detail needed to inform instruction in the classroom that is most likely to propel children on strong trajectories of reading development. We illustrate the value of this model by focusing on syntactic skills-the ability to understand and manipulate sentence structure. We hypothesize two core pathways by which syntactic skills impact reading comprehension. In the syntax-to-lexicon pathway, syntactic skills influence how readers construct lexical representations, ultimately impacting reading comprehension. In the syntax-to-sentence pathway, syntactic skills affect reading comprehension by shaping how readers parse sentences and generate predictions about upcoming information. In each, we elaborate on mechanisms of these influences. We also detail the nature of developmental effects, including changes in relative reliance on skills over time and the temporal order of effects, and the interactions between the two. This work provides a new theoretical model for understanding the precise pathways through which individual oral language skills contribute to reading comprehension development, making predictions that are testable in classrooms.												0	0											OCT	2025	60	4							e70069	10.1002/rrq.70069	http://dx.doi.org/10.1002/rrq.70069												2026-01-16	WOS:001603502000033
J	Giraud, AL; Lorenzi, C; Ashburner, J; Wable, J; Johnsrude, I; Frackowiak, R; Kleinschmidt, A				Giraud, AL; Lorenzi, C; Ashburner, J; Wable, J; Johnsrude, I; Frackowiak, R; Kleinschmidt, A			Representation of the temporal envelope of sounds in the human brain	JOURNAL OF NEUROPHYSIOLOGY				Article								The cerebral representation of the temporal envelope of sounds was studied in five normal-hearing subjects using functional magnetic resonance imaging. The stimuli were white noise, sinusoidally amplitude-modulated at frequencies ranging from 4 to 256 Hz. This range includes low AM frequencies (up to 32 Hz) essential for the perception of the manner of articulation and syllabic rate, and high AM frequencies (above 64 Hz) essential for the perception of voicing and prosody. The right lower brainstem (superior olivary complex), the right inferior colliculus, the left medial geniculate body, Heschl's gyrus, the superior temporal gyrus, the superior temporal sulcus, and the inferior parietal lobule were specifically responsive to AM. Global tuning curves in these regions suggest that the human auditory system is organized as a hierarchical filter bank, each processing level responding preferentially to a given AM frequency, 256 Hz for the lower brainstem, 32-256 Hz for the inferior colliculus, 16 Hz for the medial geniculate body, 8 Hz for the primary auditory cortex, and 4-8 Hz for secondary regions. The time course of the hemodynamic responses showed sustained and transient components with reverse frequency dependent patterns: the lower the AM frequency the better the fit with a sustained response model, the higher the AM frequency the better the fit with a transient response model. Using cortical maps of best modulation frequency, we demonstrate that the spatial representation of AM frequencies varies according to the response type. Sustained responses yield maps of low frequencies organized in large clusters. Transient responses yield maps of high frequencies represented by a mosaic of small clusters. Very few voxels were tuned to intermediate frequencies (32-64 Hz). We did not find spatial gradients of AM frequencies associated with any response type. Our results suggest that two frequency ranges (up to 16 and 128 Hz and above) are represented in the cortex by different response types. However, the spatial segregation of these two ranges is not systematic. Most cortical regions were tuned to low frequencies and only a few to high frequencies. Yet, voxels that show a preference for low frequencies were also responsive to high frequencies. Overall, our study shows that the temporal envelope of sounds is processed by both distinct (hierarchically organized series of filters) and shared (high and low AM frequencies eliciting different responses at the same cortical locus) neural substrates. This layout suggests that the human auditory system is organized in a parallel fashion that allows a degree of separate routing for groups of AM frequencies conveying different information and preserves a possibility for integration of complementary features in cortical auditory regions.												277	319											SEP	2000	84	3					1588	1598		10.1152/jn.2000.84.3.1588	http://dx.doi.org/10.1152/jn.2000.84.3.1588												2026-01-16	WOS:000089185200042
J	Gritsenko, ES; Galochkin, AE				Gritsenko, Elena S.; Galochkin, Alexander E.			Semantic dimensions of populism in English (dictionary and corpus data analysis)	VOPROSY LEKSIKOGRAFII-RUSSIAN JOURNAL OF LEXICOGRAPHY				Article								The aim of the article is to reveal the semantic content of the concept '' populism '' in modern English. The need to address this topic is driven by the fact that a significant part of the research is dedicated to the analysis of specific forms of populism or populist parties in the aspect of political science, discourse theory, political rhetoric, and ideology. From the standpoint of linguistics, the content of this concept was practically not considered. The study focuses on various structural components of the definitions and illustrative contexts of the word '' populism '' in British and American explanatory dictionaries and the texts of the Corpus of Contemporary American English (COCA). Electronic versions of explanatory English dictionaries were used for the analysis: Merriam-Webster Dictionary, Oxford English Dictionary (LEXICO), Cambridge English Dictionary, Collins English Dictionary, and Longman Dictionary of Contemporary English. Definitions, dictionary labels, and illustrative contexts of the words '' populism '' and '' populist '' were analyzed. The corpus analysis was carried out on the basis of the Corpus of Contemporary American English (COCA). The semantic content of the concept of populism was revealed by analyzing the collocates and clusters of this lexeme in accordance with the peculiarities of its syntactic representation. The selection of the collocates was carried out on the basis of the MI (mutual information) metric. The results were compared with sort by frequency; matching collocates were selected for analysis. Clusters were allocated within four words to the left or to the right of the node word, the communication distance was medium. The methods of semantic and corpus-oriented analysis, as well as the method of discourse analysis, were used to identify the evaluative tone (semantic prosody) of language units that characterize the ideologeme '' populism ''. The analysis of dictionary definitions in all considered lexicographical sources showed that the policy of populism is based on antagonism between the elite and the people, the protection of the interests of the people is emphasized as well. In the given examples of the corpus, as well as in the illustrative contexts of the dictionaries, various '' types '' of populism are mentioned: '' traditional '' vs. '' new '', '' good '' vs. '' bad '', '' progressive '', '' economic '', '' market '', '' cultural ''. The analysis of the examples showed that both in the function of the semantic object and in the function of the semantic subject, the lexeme '' populism '' is used mainly with predicates with negative connotations. Attributive collocations also indicate the negative-evaluative connotation. Based on the conducted research, it can be concluded that populism is an extremely heterogeneous phenomenon that manifests itself both in the political and socio-cultural spheres. Populism is based on the system of binary oppositions built on the confrontation of the people and the elite, with attitudes towards nationalism, protectionism, conservatism, authoritarianism, nativism (opposition to immigration), and racism.												0	0											MAR	2023		27					29	46		10.17223/22274200/27/2	http://dx.doi.org/10.17223/22274200/27/2												2026-01-16	WOS:000968090600002
J	Morningstar, M; Grannis, C; Mattson, W; Nelson, EE				Morningstar, M.; Grannis, C.; Mattson, W., I; Nelson, E. E.			Functional patterns of neural activation during vocal emotion recognition in youth with and without refractory epilepsy	NEUROIMAGE-CLINICAL				Article								Epilepsy has been associated with deficits in the social cognitive ability to decode others' nonverbal cues to infer their emotional intent (emotion recognition). Studies have begun to identify potential neural correlates of these deficits, but have focused primarily on one type of nonverbal cue (facial expressions) to the detriment of other crucial social signals that inform the tenor of social interactions (e.g., tone of voice). Less is known about how individuals with epilepsy process these forms of social stimuli, with a particular gap in knowledge about representation of vocal cues in the developing brain. The current study compared vocal emotion recognition skills and functional patterns of neural activation to emotional voices in youth with and without refractory focal epilepsy. We made novel use of inter-subject pattern analysis to determine brain areas in which activation to emotional voices was predictive of epilepsy status. Results indicated that youth with epilepsy were comparatively less able to infer emotional intent in vocal expressions than their typically developing peers. Activation to vocal emotional expressions in regions of the mentalizing and/or default mode network (e.g., right temporo-parietal junction, right hippocampus, right medial prefrontal cortex, among others) differentiated youth with and without epilepsy. These results are consistent with emerging evidence that pediatric epilepsy is associated with altered function in neural networks subserving social cognitive abilities. Our results contribute to ongoing efforts to understand the neural markers of social cognitive deficits in pediatric epilepsy, in order to better tailor and funnel interventions to this group of youth at risk for poor social outcomes.												2	2												2022	34								102966	10.1016/j.nicl.2022.102966	http://dx.doi.org/10.1016/j.nicl.2022.102966		FEB 2022										2026-01-16	WOS:000819837300009
J	He, F; He, L; Zhang, J; Li, YY; Xiong, X				He, Fei; He, Ling; Zhang, Jing; Li, Yuanyuan; Xiong, Xi			Automatic Detection of Affective Flattening in Schizophrenia: Acoustic Correlates to Sound Waves and Auditory Perception	IEEE-ACM TRANSACTIONS ON AUDIO SPEECH AND LANGUAGE PROCESSING				Article								Affective flattening is a typical negative symptom in schizophrenia that causes a diminution of normal behaviors and functions in schizophrenic patients. In this work, an automatic algorithm of schizophrenia detection is proposed. This algorithm includes three newly proposed features. These features establish a representation for the production and perception of schizophrenic speech, called the K-Sf (kurtosis skewness fraction), SPI (sound perception indicator), and EBMC (enhanced bilateral matching coefficient). The K-Sf is proposed to reflect the overall distribution of speech segments. The SPI evaluates the relation between the speech composition and the sound perception. The EBMC feature is proposed based on the theory of air pressure oscillations which could reflect the details of air modulation in the vocal tract. Experiments evaluating the discriminative capabilities of the three features are conducted using a speech dataset that is collected from 56 participants (28 schizophrenic patients and 28 healthy controls) and an ensemble classifier. Comparative experiments with SVM classifiers are also conducted. The discrimination accuracies of patients and control subjects using the K-Sf, SPI, EBMC, and the ensemble classifier are in the range of 76.8-92.9%, 82.1-92.8%, and 80.4-91.1%, respectively. When the three features are combined, the discrimination results range from 89.3% to 94.6%. The experimental results indicate that the three features have stronger robustness and better discrimination capability than those previous features relating to the detection of flat affect.												6	6												2021	29						3321	3334		10.1109/TASLP.2021.3120591	http://dx.doi.org/10.1109/TASLP.2021.3120591												2026-01-16	WOS:000716689200001
J	Star, S				Star, Summer			'For the Inscape's Sake': Sounding the Self in the Metres of Gerard Manley Hopkins	LITERATURE COMPASS				Article								This article is part of a cluster that draws material from the recent conference Metre Matters: New Approaches to Prosody, 1780-1914. It comprises an introduction by Jason David Hall and six articles presented at the conference, whose aim was to address renewed scholarly interest in versification and form across the long nineteenth century, as well as some of the methodologies underpinning it. The papers included in the cluster look both to the minutiae of Romantic and Victorian metres and to their cultural intertexts. The conference, hosted by the University of Exeter's Centre for Victorian Studies, was held 35 July 2008. The cluster is made up of the following articles: Jason David Hall, Metre, History, Context: Introduction to the Metre Matters Cluster. Emma Mason and Rhian Williams, Reciprocal Scansion in Wordsworth's There Was a Boy. Ross Wilson, Robert Browning's Compounds. Margaret A. Loose, The Internationalism of Ernest Jones's Dialectical Prosody. Nancy Jiwon Cho, Gender and Authority in British Women Hymn-Writers Use of Metre, 1760-1900. Ashley Miller, Involuntary Metrics and the Physiology of Memory. Summer Star, For the Inscape's Sake: Sounding the Self in the Metres of Gerard Manley Hopkins. This article explores the nature of (and makes an argument for) the relationship between Gerard Manley Hopkins's interests in the primary otherness in language and his philosophy of selfhood. To consider both the crucial and problematic nature of such a union, I contextualize Hopkins's own interest in primitive language with the 'natural language' theories that influenced and bourgeoned in the nineteenth century, arguing that Hopkins's 'sprung rhythm' was his own contribution to the search for the primitive roots of human speech. Hopkins's metrical expressions of physical movement in his poems with human subjects (specifically in the ` St. Dorothea' poems and ` Harry Ploughman') are a representation of the deep distinctiveness of subjective experience: the experience of ` pitch', which Hopkins theorized in his sermons, or of one's own instress. In this way, metre itself was for the poet a manifestation of an original union between the physical, bodily, and spiritual realms - enacting incarnation. Yet how can we reconcile the poeticizing of the pitch of another with Hopkins's own insistence on the utter and unapproachable difference of that other's own 'self-taste'? Responding to resonances between this problem and modern ethical theory, particularly Merleau-Ponty's notion of how we conceive of otherness through physical observation, I consider Hopkins's metrical expressions of physical embodiment as a possible answer to their own ethical problem. Looking into his often-employed concept of ` sake', defined by Hopkins himself as 'that being which a thing has outside itself ', this article finally compares the sounding of this human pitch, of hearing its echo, to Hopkins's religious faith in language as a manifestation of divine being in the world - and in a divine distinctiveness of self destined to transcend mortal limits.												1	1											MAR	2009	6	2					557	564		10.1111/j.1741-4113.2008.00619.x	http://dx.doi.org/10.1111/j.1741-4113.2008.00619.x												2026-01-16	WOS:000213181600024
J	Hesling, I; Dilharreguy, B; Clément, S; Bordessoules, M; Allard, M				Hesling, I; Dilharreguy, B; Clément, S; Bordessoules, M; Allard, M			Cerebral mechanisms of prosodic sensory integration using low-frequency bands of connected speech	HUMAN BRAIN MAPPING				Article								Even if speech perception has been reported to involve both left and right hemispheres, converging data have posited the existence of a functional asymmetry at the level of secondary auditory cortices. Using fMRI in 12 right-handed French men listening passively to long connected speech stimuli, we addressed the question of neuronal networks involved in the integration of low frequency bands of speech by comparing 1) differences in brain activity in two listening conditions (IN, NF) differing in the integration of pitch modulations (in FN, low frequencies, obtained by a low-pass filter, are addressed to the left ear while the whole acoustic message is simultaneously addressed to the right ear, NF being the reverse position); 2) differences in brain activity induced by high and low degrees of prosodic expression (expressive vs. flat); and 3) effects of the same connected speech stimulus in the two listening conditions. Each stimulus induced a specific cerebral network, the flat one weakening activations which were mainly reduced to the bilateral STG for both listening conditions. In the expressive condition, the specific sensory integration FN results in an increase of the articulatory loop and new recruitments such as right BA6-44, left BA39-40, the left posterior insula and the bilateral BA30. This finding may be accounted for by the existence of temporal windows differing both in length and in acoustic cues decoding, strengthening the "asymmetric sampling in time" hypothesis posited by Poeppel (Speech Commun 2003; 41:245-255). Such an improvement of prosodic integration could find applications in the rehabilitation of some speech disturbances.												21	21											NOV	2005	26	3					157	169		10.1002/hbm.20147	http://dx.doi.org/10.1002/hbm.20147												2026-01-16	WOS:000233056300001
J	Lausberg, H; Zaidel, E; Cruz, RF; Ptito, A				Lausberg, Hedda; Zaidel, Eran; Cruz, Robyn F.; Ptito, Alain			Speech-independent production of communicative gestures: Evidence from patients with complete callosal disconnection	NEUROPSYCHOLOGIA				Article								Recent neuropsychological, psycholinguistic, and evolutionary theories on language and gesture associate communicative gesture production exclusively with left hemisphere language production. An argument for this approach is the finding that right-handers with left hemisphere language dominance prefer the right hand for communicative gestures. However, several studies have reported distinct patterns of hand preferences for different gesture types, such as deictics, batons, or physiographs, and this calls for an alternative hypothesis. We investigated hand preference and gesture types in spontaneous gesticulation during three semi-standardized interviews of three right-handed patients and one left-handed patient with complete callosal disconnection, all with left hemisphere dominance for praxis. Three of them, with left hemisphere language dominance, exhibited a reliable left-hand preference for spontaneous communicative gestures despite their left hand agraphia and apraxia. The fourth patient, with presumed bihemispheric language representation, revealed a consistent right-hand preference for gestures. All four patients displayed batons, tosses, and shrugs more often with the left hand/shoulder, but exhibited a right hand preference for pantomime gestures. We conclude that the hand preference for certain gesture types cannot be predicted by hemispheric dominance for language or by handedness. We found distinct hand preferences for specific gesture types. This suggests a conceptual specificity of the left and right hand gestures. We propose that left hand gestures are related to specialized right hemisphere functions, such as prosody or emotion, and that they are generated independently of left hemisphere language production. Our findings challenge the traditional neuropsychological and psycholinguistic view on communicative gesture production. (C) 2007 Elsevier Ltd. All rights reserved.												36	38												2007	45	13					3092	3104		10.1016/j.neuropsychologia.2007.05.010	http://dx.doi.org/10.1016/j.neuropsychologia.2007.05.010												2026-01-16	WOS:000250257100020
J	Ragó, A; Varga, Z; Garami, L; Honbolygó, F; Csépe, V				Rago, Anett; Varga, Zsuzsanna; Garami, Linda; Honbolygo, Ferenc; Csepe, Valeria			The effect of lexical status on prosodic processing in infants learning a fixed stress language	PSYCHOPHYSIOLOGY				Article								In speech processing, in the first year of life, prosody and phoneme-relevant aspects serve different functions. Recent studies have assumed that the two aspects become integrated at around 9 months of age. The present study investigates the effect of lexical status on stress processing in a fixed stress language. We hypothesize that lexicality modulates stress processing, and where the stress cue is in conflict with the lexical status (legal deviant condition), we will observe differences in age indicating the stage of integration. We tested 69 6 and 10 month-old infants in an acoustic oddball event-related potential paradigm. A frequent word stimulus (baba) and a pseudoword (bebe) were used with legal versus illegal stress. We systematically swapped the standard and deviant roles of the different stress variants in two conditions. In the illegal deviant condition in the case of the word stimulus, the response pattern typical for the pseudoword (an MMR to the absence of the stress cue) was missing. This implies the suppression effect of lexicality. In the legal deviant condition, negative MMR (N-MMR) in the second time window indicated a facilitation effect of lexicality in both age groups. As only the 6-month-olds produced an N-MMR in the first time window, we concluded that in a fixed stress language, integration starts at 6 months but is only completed by the age of 10 months. Our results show that lexical status modulates stress processing at word level in a highly regularly stressed language in which stable, long-term language-specific stress representation exists from early infancy.												2	2											DEC	2021	58	12							e13932	10.1111/psyp.13932	http://dx.doi.org/10.1111/psyp.13932		AUG 2021										2026-01-16	WOS:000688162300001
J	Meyer, L; Elsner, A; Turker, S; Kuhnke, P; Hartwigsen, G				Meyer, Lars; Elsner, Anne; Turker, Sabrina; Kuhnke, Philipp; Hartwigsen, Gesa			Perturbation of left posterior prefrontal cortex modulates top-down processing in sentence comprehension	NEUROIMAGE				Article								Communication is an inferential process. In particular, language comprehension constantly requires top-down efforts, as often multiple interpretations are compatible with a given sentence. To assess top-down processing in the language domain, our experiment employed ambiguous sentences that allow for multiple interpretations (e.g., The client sued the murderer with the corrupt lawyer., where the corrupt lawyer could either belong to The client or the murderer). Interpretation thus depended on whether participants chunk the words of the sentence into short or long syntactic phrases. In principle, bottom-up acoustic information (i.e., the presence or absence of an intonational phrase boundary at the offset of the murderer) indicates one of the two possible interpretations. Yet, acoustic information often indicates interpretations that require words to be chunked into overly long phrases that would overburden working memory. Processing is biased against these demands, reflected in a top-down preference to chunk words into short rather than long phrases. It is often proposed, but also hotly debated, that the ability to chunk words into short phrases is subserved by the left inferior frontal gyrus (IFG). Here, we employed focal repetitive transcranial magnetic stimulation to perturb the left IFG, which resulted in a further decrease of the aptitude to tolerate long phrases, indicating the inability of the left IFG to assist the chunking of words into phrases. In contrast, the processing of auditory information was not affected. Our findings support a causal topdown role of the left inferior frontal gyrus in the chunking of words into phrases.												12	14											NOV 1	2018	181						598	604		10.1016/j.neuroimage.2018.07.059	http://dx.doi.org/10.1016/j.neuroimage.2018.07.059												2026-01-16	WOS:000445165600052
J	Suvini, F; Apicella, F; Muratori, F				Suvini, Ferdinando; Apicella, Fabio; Muratori, Filippo			Music therapy microanalysis of parent-infant interaction in a three-month-old infant later diagnosed with autism	HEALTH PSYCHOLOGY REPORT				Article								BACKGROUND Infant research literature has described for a long time the main aspects of parentese (motherese and fatherese) referring to musicality and specifically to musical language. It is believed that there is a deep analogy between the vital affects experienced by the child during interaction with the parent and the type of parentese that is a direct representation of them. Disruption of parentese has been described in early autism. The aim of this paper was to achieve a better understanding of this disruptive process. PARTICIPANTS AND PROCEDURE Sequences of parent-infant interaction extracted from one home movie of a child later diagnosed with autism were analyzed in a micro-musical way in order to create a musical score that allows the description of parent-infant interaction in a new way (considering form, pulse, rhythm, melody, timbre and silence). RESULTS Musical microanalysis is able to highlight features not brought out by other kinds of analysis. The first fragment is dominated by the anxiety of the mother, who attempts to stimulate the unresponsive infant. In the second fragment there is a change in musicality parallel to changes in the relationship: the mother participates in and coordinates the infant's experience through rhythm, prosody and musical dynamics. This change persists in the third fragment. CONCLUSIONS Musical transcription of parent-infant interactions has allowed us to highlight changes occurring in a short time during early interactions and to get a closer view of the disruptive process created by autism. This kind of research represents a potential shift in autism research, by focusing on dynamic parent-infant interactions instead of single behaviors of the child or of the parent. The usefulness of Stern's concept of intersubjective communion is discussed.												3	4												2017	5	2					151	161		10.5114/hpr.2017.63845	http://dx.doi.org/10.5114/hpr.2017.63845												2026-01-16	WOS:000396731600005
J	Zhao, YX; Kuruvilla-Dugdale, M; Song, MG				Zhao, Yunxin; Kuruvilla-Dugdale, Mili; Song, Minguang			Voice Conversion for Persons with Amyotrophic Lateral Sclerosis	IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMATICS				Article								Amyotrophic lateral sclerosis (ALS) results in progressive paralysis of voluntary muscles throughout the body. As speech deteriorates, individuals rely on pre-programmed messages available on commercial speech generating devices to communicate using one of the generic electronic voices on the device. To replace these generic voices and restore vocal identity, our aim is to develop personalized voices for people with ALS via the approach of voice conversion. The task is challenging because very few people have large quantities of their premorbid healthy speech recorded. Therefore, we have to rely on small quantities of dysarthric speech concomitant with an individual's disease stage. Further, progressive fatigue prohibits acquisition of large speech datasets and individuals display a range of dysarthria severities resulting from breathing, voice, articulation, resonance, and prosody disturbances. As the first step to address these problems, we use healthy source speakers and propose the approach of combining a structured sparse spectral transform with multiple linear regression-based frequency warping prediction for spectral conversion, and interpolating the transformed spectral frames for speech rate modification. Our experimental data included four healthy source speakers from the ARCTIC dataset, and four target ALS speakers with mild to severe dysarthria, forming 16 speaker pairs. Subjective listening evaluations showed that on average, (i) the proposed approach improved speech intelligibility by about 80% over the target speakers' speech, (ii) the converted voice was 3 times more similar to the target speakers' speech than to the source speakers' speech, and (iii) the converted speech quality was close to the MOS scale "good" relative to the source speakers' speech being "excellent."												14	18											OCT	2020	24	10					2942	2949		10.1109/JBHI.2019.2961844	http://dx.doi.org/10.1109/JBHI.2019.2961844												2026-01-16	WOS:000576429900023
J	Niesen, M; Bourguignon, M; Bertels, J; Vander Ghinst, M; Wens, V; Goldman, S; De Tiège, X				Niesen, Maxime; Bourguignon, Mathieu; Bertels, Julie; Vander Ghinst, Marc; Wens, Vincent; Goldman, Serge; De Tiege, Xavier			Cortical tracking of lexical speech units in a multi-talker background is immature in school-aged children	NEUROIMAGE				Article								Children have more difficulty perceiving speech in noise than adults. Whether this difficulty relates to an immature processing of prosodic or linguistic elements of the attended speech is still unclear. To address the impact of noise on linguistic processing per se, we assessed how babble noise impacts the cortical tracking of intelligible speech devoid of prosody in school-aged children and adults. Twenty adults and twenty children (7-9 years) listened to synthesized French monosyllabic words presented at 2.5 Hz, either randomly or in 4-word hierarchical structures wherein 2 words formed a phrase at 1.25 Hz, and 2 phrases formed a sentence at 0.625 Hz, with or without babble noise. Neuromagnetic responses to words, phrases and sentences were identified and source-localized. Children and adults displayed significant cortical tracking of words in all conditions, and of phrases and sentences only when words formed meaningful sentences. In children compared with adults, the cortical tracking was lower for all linguistic units in conditions without noise. In the presence of noise, the cortical tracking was similarly reduced for sentence units in both groups, but remained stable for phrase units. Critically, when there was noise, adults increased the cortical tracking of monosyllabic words in the inferior frontal gyri and supratemporal auditory cortices but children did not. This study demonstrates that the difficulties of school-aged children in understanding speech in a multi-talker background might be partly due to an immature tracking of lexical but not supra-lexical linguistic units.												5	6											JAN	2023	265								119770	10.1016/j.neuroimage.2022.119770	http://dx.doi.org/10.1016/j.neuroimage.2022.119770		DEC 2022										2026-01-16	WOS:000912094900001
J	Badcock, JC; Chhabra, S				Badcock, Johanna C.; Chhabra, Saruchi			Voices to reckon with: perceptions of voice identity in clinical and non-clinical voice hearers	FRONTIERS IN HUMAN NEUROSCIENCE				Article								The current review focuses on the perception of voice identity in clinical and non-clinical voice hearers. Identity perception in auditory verbal hallucinations (AVH) is grounded in the mechanisms of human (i.e., real, external) voice perception, and shapes the emotional (distress) and behavioral (help-seeking) response to the experience. Yet, the phenomenological assessment of voice identity is often limited, for example to the gender of the voice, and has failed to take advantage of recent models and evidence on human voice perception. In this paper we aim to synthesize the literature on identity in real and hallucinated voices and begin by providing a comprehensive overview of the features used to judge voice identity in healthy individuals and in people with schizophrenia. The findings suggest some subtle, but possibly systematic biases across different levels of voice identity in clinical hallucinators that are associated with higher levels of distress. Next we provide a critical evaluation of voice processing abilities in clinical and non-clinical voice hearers, including recent data collected in our laboratory. Our studies used diverse methods, assessing recognition and binding of words and voices in memory as well as multidimensional scaling of voice dissimilarity judgments. The findings overall point to significant difficulties recognizing familiar speakers and discriminating between unfamiliar speakers in people with schizophrenia, both with and without AVH. In contrast, these voice processing abilities appear to be generally intact in non-clinical hallucinators. The review highlights some important avenues for future research and treatment of AVH associated with a need for care, and suggests some novel insights into other symptoms of psychosis.												32	37											APR 3	2013	7								114	10.3389/fnhum.2013.00114	http://dx.doi.org/10.3389/fnhum.2013.00114												2026-01-16	WOS:000316986700001
J	Isaev, DY; Vlasova, RM; Di Martino, JM; Stephen, CD; Schmahmann, JD; Sapiro, G; Gupta, AS				Isaev, Dmitry Yu.; Vlasova, Roza M.; Di Martino, J. Matias; Stephen, Christopher D.; Schmahmann, Jeremy D.; Sapiro, Guillermo; Gupta, Anoopum S.			Uncertainty of Vowel Predictions as a Digital Biomarker for Ataxic Dysarthria	CEREBELLUM				Article								Dysarthria is a common manifestation across cerebellar ataxias leading to impairments in communication, reduced social connections, and decreased quality of life. While dysarthria symptoms may be present in other neurological conditions, ataxic dysarthria is a perceptually distinct motor speech disorder, with the most prominent characteristics being articulation and prosody abnormalities along with distorted vowels. We hypothesized that uncertainty of vowel predictions by an automatic speech recognition system can capture speech changes present in cerebellar ataxia. Speech of participants with ataxia (N=61) and healthy controls (N=25) was recorded during the "picture description" task. Additionally, participants' dysarthric speech and ataxia severity were assessed on a Brief Ataxia Rating Scale (BARS). Eight participants with ataxia had speech and BARS data at two timepoints. A neural network trained for phoneme prediction was applied to speech recordings. Average entropy of vowel tokens predictions (AVE) was computed for each participant's recording, together with mean pitch and intensity standard deviations (MPSD and MISD) in the vowel segments. AVE and MISD demonstrated associations with BARS speech score (Spearman's rho=0.45 and 0.51), and AVE demonstrated associations with BARS total (rho=0.39). In the longitudinal cohort, Wilcoxon pairwise signed rank test demonstrated an increase in BARS total and AVE, while BARS speech and acoustic measures did not significantly increase. Relationship of AVE to both BARS speech and BARS total, as well as the ability to capture disease progression even in absence of measured speech decline, indicates the potential of AVE as a digital biomarker for cerebellar ataxia.												3	3											APR	2024	23	2					459	470		10.1007/s12311-023-01539-z	http://dx.doi.org/10.1007/s12311-023-01539-z		APR 2023										2026-01-16	WOS:000967173100001
J	Cit, SD				Cit, Simone do Rocio			DESMEMÓRIA: REPORT ABOUT THE RECRIATION OFA SONG	DEBATES				Article								This text reports a creative journey that began based on the listening of the work Everywhere at the end of time by composer James Leyland Kirby. Kirby's composition, which he signed with the alias The Caretaker, is a musical representation of memory damage caused by Alzheimer's disease. One of the expressive resources used in the work was the electronic deterioration of a 1930s American love song named Heartaches. An exercise was proposed to me: that I should create new lyrics for this love song, approaching the same subject of Everywhere at the end of time -Alzheimer's effects -so that, after that, it could be arranged and performed as Choro. The exercise was developed based on procedures frequently employed by songwriter Chico Buarque to write song lyrics: these procedures were found in testimonials given by him through his musica l career. Two test versions were created plus a definitive one, through partnership, named Desmemoria (Unmemory): the three versions are about memory loss and the difficulty of registering new ones, treating Alzheimer on its potential analgesic effect by erasing, amongst many memories, heartaches from the past. One of the goals of the creative exercise is to reproduce Buarque's way of putting lyrics into melodies, so the main resources used in the process were the use of a thesaurus and a rhyming dictionary, followed by attention to some literary principles such as poetic forms and prosody. By the end of the report the access link to a recorded version of the choro song Desmemoria (Unmemory) is made avaliable so the listening can be possible.												0	0											DEC	2023	27	2					128	148															2026-01-16	WOS:001144085700005
J	Guan, CQ; Meng, WJ; Morett, LM; Fraundorf, SH				Guan, Connie Qun; Meng, Wanjin; Morett, Laura M.; Fraundorf, Scott H.			Mapping Pitch Accents to Memory Representations in Spoken Discourse Among Chinese Learners of English: Effects of L2 Proficiency and Working Memory	FRONTIERS IN PSYCHOLOGY				Article								We examined L2 learners' interpretation of pitch accent cues in discourse memory and how these effects vary with proficiency and working memory (WM). One hundred sixty-eight L1-Chinese participants learning L2-English listened to recorded discourses containing pairs of contrastive alternatives and then took a later recognition memory test. Their language proficiency and WM were measured through standard tests and the participants were categorized into low, medium, advanced, and high advanced language proficiency groups. We analyzed recognition memory task performance using signal detection theory to tease apart response bias (an overall tendency to affirm memory probes) from sensitivity (the ability to discern whether a specific probe statement is true). The results showed a benefit of contrastive L + H* pitch accents in rejecting probes referring to items unmentioned in a discourse, but not contrastive alternatives themselves. More proficient participants also showed more accurate memory for the discourses overall, as well as a reduced overall bias to affirm the presented statements as true. Meanwhile, that the benefit of L + H* accents in rejecting either contrast probes or unmentioned probes was modulated for people with greater working memory. Participants with higher WM were quite sure that it did not exist in the memory trace as this part of discourse wasn't mentioned. The results support a contrast-uncertainty hypothesis, in which comprehenders recall the contrast set but fail to distinguish which is the correct item. Further, these effects were influenced by proficiency and by working memory, suggesting they reflect incomplete mapping between pitch accent and discourse representation.												0	0											MAY 19	2022	13								870152	10.3389/fpsyg.2022.870152	http://dx.doi.org/10.3389/fpsyg.2022.870152												2026-01-16	WOS:000805620400001
J	Nor, NFM; Rahman, AANCA; Jaluddin, A; Abdullah, IH; Tiun, S				Nor, Nor Fariza Mohd; Rahman, Anis Anis Nadiah Che Abdul; Jaluddin, Azhar; Abdullah, Imran Ho; Tiun, Sabrina			A Corpus Driven Analysis of Representations Around the Word 'ekonomi' in Malaysian Hansard Corpus	GEMA ONLINE JOURNAL OF LANGUAGE STUDIES				Article								Politicians constantly talk about wealth, power and education, which is often justified on the grounds that it will aid economic growth, which in turn will raise living standard. Thus, many economic issues are seen through the eyes of political beliefs. This paper reports on a corpus-driven analysis around the word ekonomi (economy) in the Malaysian Hansard Corpus. The objectives are to analyse the trend concerning the word ekonomi and to find out the representations around the word ekonom. The analysis showed that the word ekonomi was at its peak in Parliament 6 and Parliament 9, but declined in Parliament 8. The analysis also involved examining the collocational meaning of the word ekonomi and its collocates to determine the categories in which the word ekonomi (economy) was referenced. Positive noun collocates such as pertumbuhan (growth) and kekukuhan (stable) are mainly categorised into the government's policy, government's plan and economic activities in the country. Whilst negative noun collocates such as kemerosotan'(decline) and kelembapan (sluggish) are mostly categorised into economic situation in the country and globally and the government's effort to handle sluggish economy in Malaysia. The findings also revealed binary conceptualisations of 'us' vs. 'them', which is common in political discourse. The binary conceptualizations demonstrated that the government's efforts are commended. On the other hand, the unfavourable economic situation which happened in the country was due to factors which are beyond the government's control. The paper concludes that the representations around the word ekonomi involved justifying or legitimizing government's course of action.The study suggests a comparison of Hansard data from other Asean or Asian countries, focusing on representation of the word 'ekonomi'.												9	9											NOV	2019	19	4					66	95		10.17576/gema-2019-1904-04	http://dx.doi.org/10.17576/gema-2019-1904-04												2026-01-16	WOS:000499479000004
J	Berro, DH; Lemée, JM; Leiber, LM; Emery, E; Menei, P; Minassian, AT				Berro, David Hassanein; Lemee, Jean-Michel; Leiber, Louis-Marie; Emery, Evelyne; Menei, Philippe; Ter Minassian, Aram			Overt speech feasibility using continuous functional magnetic resonance imaging: Isolation of areas involved in phonology and prosody	JOURNAL OF NEUROSCIENCE RESEARCH				Article								To avoid motion artifacts, almost all speech-related functional magnetic resonance imagings (fMRIs) are performed covertly to detect language activations. This method may be difficult to execute, especially by patients with brain tumors, and does not allow the identification of phonological areas. Here, we aimed to evaluate overt task feasibility. Thirty-three volunteers participated in this study. They performed two functional sessions of covert and overt generation of a short sentence semantically linked with a word. Three main contrasts were performed: Covert and Overt for the isolation of language-activated areas, and Overt > Covert for the isolation of the motor cortical activation of speech. fMRI data preprocessing was performed with and without unwarping, and with and without regression of movement parameters as confounding variables. All types of results were compared to each other. For the Overt contrast, Dice coefficients showed strong overlap between each pair of types of results: 0.98 for the pair with and without unwarping, and 0.9 for the pair with and without movement parameter regression. The Overt > Covert contrast allowed isolation of motor laryngeal activations with high statistical reliability and revealed the right-lateralized temporal activity related to acoustic feedback. Overt speaking during magnetic resonance imaging induced few artifacts and did not significantly affect the results, allowing the identification of areas involved in primary motor control and prosodic regulation of speech. Unwarping and motion artifact regression in the postprocessing step, seem to not be necessary. Changes in lateralization of cortical activity by overt speech shall be explored before using these tasks for presurgical mapping.												3	4											DEC	2020	98	12					2554	2565		10.1002/jnr.24723	http://dx.doi.org/10.1002/jnr.24723		SEP 2020										2026-01-16	WOS:000566710500001
J	Higgins, D; Xi, XM; Zechner, K; Williamson, D				Higgins, Derrick; Xi, Xiaoming; Zechner, Klaus; Williamson, David			A three-stage approach to the automated scoring of spontaneous spoken responses	COMPUTER SPEECH AND LANGUAGE				Article								This paper presents a description and evaluation of Speech Rater(SM), a system for automated scoring of non-native speakers' spoken English proficiency, based on tasks which elicit spontaneous monologues on particular topics. This system builds on much previous work in the automated scoring of test responses, but differs from previous work in that the highly unpredictable nature of the responses to this task type makes the challenge of accurate scoring much more difficult. SpeechRater uses a three-stage architecture. Responses are first processed by a filtering model to ensure that no exceptional conditions exist which might prevent them from being scored by SpeechRater. Responses not filtered out at this stage are then processed by the scoring model to estimate the proficiency rating which a human might assign to them, on the basis of features related to fluency, pronunciation, vocabulary diversity, and grammar. Finally, an aggregation model combines an examinee's scores for multiple items to calculate a total score, as well as an interval in which the examinee's score is predicted to reside with high confidence. SpeechRater's current level of accuracy and construct representation have been deemed sufficient for low-stakes practice exercises, and it has been used in a practice exam for the TOEFL since late 2006. In such a practice environment, it offers a number of advantages compared to human raters, including system load management, and the facilitation of immediate feedback to students. However, it must be acknowledged that SpeechRater presently fails to measure many important aspects of speaking proficiency (such as intonation and appropriateness of topic development), and its agreement with human ratings of proficiency does not yet approach the level of agreement between two human raters. (C) 2010 Elsevier Ltd. All rights reserved.												61	85											APR	2011	25	2			SI		282	306		10.1016/j.csl.2010.06.001	http://dx.doi.org/10.1016/j.csl.2010.06.001												2026-01-16	WOS:000284670200011
J	Chereches, L				Chereches, Lavinia			INTERPRETATIVE-ANALYTICAL HYPOSTASES IN "SEPT FRAGMENTS DE TRISTAN TZARA" 1 FOR VOICE AND PIANO BY ADRIAN POP	STUDIA UNIVERSITATIS BABES-BOLYAI MUSICA				Article								The present paper provides a descriptive analysis of the Sept fragments de Tristan Tzara, a unitary song cycle, organized on the basis of an internal dramaturgy, in which the poet's verses (used in French in original) outline the thematic framework pervaded by the central idea of love. The unity of the interpretation of the cycle of the Seven fragments from Tristan Tzara can be achieved only after a deep knowledge of the expressive and symbolic springs of the musical-poetic discourse. The study of the musical segments closely leads to the comprehension of the musical language in the process of decoding the encrypted meanings in the score, an image of the whole being configured only when the cycle is complete. The elements of assimilation, memorization and interpretation will be tracked and chiselled into the vocal-instrumental duo throughout each song. The vocal techniques used vary according to both the particularities of the language elements and the way of their psycho-affective representation in interpretation. The vocality, adapted to the rhythmic and metrical writing of the pieces, requires a perfect mastery of the interpretive technique. The vocal part, as a constitutive part of a musical discourse with a modal language of synthesis, is emphasized by the writing in the piano accompaniment, in which the chordic structures are either gravitational or geometric. Analysing the form of the works, we concluded that, in each case, they are entirely subordinate to the needs of a dramatic sense and closely related to the poetic and musical images. Nevertheless, our paper is embedded within a personal interpretative vision on the "fragments" of the cycle, bearing the imprint of the subjectivity that resides in the personal reception of the meanings of music.												0	0											DEC	2019	64	2					229	259		10.24193/subbmusica.2019.2.13	http://dx.doi.org/10.24193/subbmusica.2019.2.13												2026-01-16	WOS:000512744600014
J	Kovtun, NV				Kovtun, Natalya, V			The Image of a Schoolboy in the B. Okudzhava's War Prose	PROBLEMY ISTORICHESKOI POETIKI				Article								The article analyzes the history and poetics of Okudzhava's war prose and its role in modern literature. Particular attention is paid to the image of the schoolboy character, which structures the text. The author reflects on his orientation towards classical literature and the creators of "lieutenant prose," but treats the past with an emphatically apprentice attitude. This trusting intonation is inherited by his autobiographical protagonist, whose image emphasises the features of a private individual, an amateur. The figure of the schoolboy combines contradictory features: courage and naivety, belief in myths and fairy tales, as well as inner weariness and self-irony dictated by the author's position. A special place is held by the story "Be Well, Schoolboy," which is structured according to the soliloquy principle, when the hero's self-discovery takes place, the war becomes an initiation and a test of the book truths "about feats, about glory," which are alienated when confronted with the chaos of reality. The author demonstrates the gap between the perception of the schoolboy by those around him and his self-perception, which opens up an ambiguous and ironic perspective. The motifs of the "naked man," the Other, Mercurianism and the labyrinth, which converge in the image of the schoolboy hero, have become the key concepts in these texts. The traditional paradigm of the "little man," whose home is an overcoat, is apparent behind the character of Okudzhava's prose. A peculiar result of the author's reflections on the war is the rejection of the epic tradition of the classics. Instead, the schoolboy inherits the old spoon of the "eternal soldier" Shongin, becoming a part of his destiny, so commonplace in its tragic nature. The most important role in the representation of the battle theme is played by the cultural centrism paradigm, which helps to include the traumatic, horrible experience of war in the memory and post-memory space.												0	1												2023	21	1					236	256		10.15393/j9.art.2023.11802	http://dx.doi.org/10.15393/j9.art.2023.11802												2026-01-16	WOS:000955551400011
J	Aphonina, O				Aphonina, Olena			Code and cultural and historical tradition of "double coding" in folklore	NATIONAL ACADEMY OF MANAGERIAL STAFF OF CULTURE AND ARTS HERALD				Article								Purpose of the research is to define theoretical questions aimed at identifying folklore codes and "double coding" traditions in the folk art from the point of view of different concepts and paradigms in the scientific literature. The research methodology is the use of the systematic approach, which reveals features of folklore codes and cultural and historical traditions of "double coding" in different genres of folk art and performing. The scientific novelty of this work lies in defining of the folklore (auditory, verbal, visual) codes in different genres of folk art (music, dance, fairy tale and ritual). Through the example of performing folk groups and in the process of "double coding", the study defines the following codes: representation, evocative and intermediate. Conclusions. Based on the study of both theoretical works and practice, it is determined that the folk-image codes are associated with the mythology, history and religion. Folklore codes, as well as other types of codes, have a stable system of signs and symbols, in which they can be transcribed. Ritual actions, games, dances, songs and fairy tales have their own system of codes (images, events, etc.). Codes in a song and fairy tale are defined in the text (images, symbols), codes in music (tunes, intonation), codes in the musical and compositional structures (definable melodies in calendar ritual folklore), in choreography - music and movement codes based on texts and rhythm. Each folklore genre has performance specifics, but there are common traditions, contained in improvisation based on traditional musical and dance styles and stereotypes. "Double coding" in folklore is a multi-step process of transformation of the information, stored for a long time, constantly transmitted from one generation to the other and varying in details (in music, lyrics and stories, dance accompaniment and moves).												0	0												2016		3					45	49															2026-01-16	WOS:000431316100010
J	Liu, F; Maggu, AR; Lau, JCY; Wong, PCM				Liu, Fang; Maggu, Akshay R.; Lau, Joseph C. Y.; Wong, Patrick C. M.			Brainstem encoding of speech and musical stimuli in congenital amusia: evidence from Cantonese speakers	FRONTIERS IN HUMAN NEUROSCIENCE				Article								Congenital amusia is a neurodevelopmental disorder of musical processing that also impacts subtle aspects of speech processing. It remains debated at what stage(s) of auditory processing deficits in amusia arise. In this study, we investigated whether amusia originates from impaired subcortical encoding of speech On quiet and noise) and musical sounds in the brainstem. Fourteen Cantonese-speaking amusics and 14 matched controls passively listened to six Cantonese lexical tones in quiet, two Cantonese tones in noise (signal-to-noise ratios at 0 and 20 dB), and two cello tones in quiet while their frequency-following responses (FFRs) to these tones were recorded. All participants also completed a behavioral lexical tone identification task. The results indicated normal brainstem encoding of pitch in speech On quiet and noise) and musical stimuli in amusics relative to controls, as measured by FFR pitch strength, pitch error, and stimulus-to-response correlation. There was also no group difference in neural conduction time or FFR amplitudes. Both groups demonstrated better FFRs to speech On quiet and noise) than to musical stimuli. However, a significant group difference was observed for tone identification, with amusics showing significantly lower accuracy than controls. Analysis of the tone confusion matrices suggested that amusics were more likely than controls to confuse between tones that shared similar acoustic features. Interestingly, this deficit in lexical tone identification was not coupled with brainstem abnormality for either speech or musical stimuli. Together, our results suggest that the amusic brainstem is not functioning abnormally, although higher-order linguistic pitch processing is impaired in amusia. This finding has significant implications for theories of central auditory processing, requiring further investigations into how different stages of auditory processing interact in the human brain.												50	50											JAN 6	2015	8								1029	10.3389/fnhum.2014.01029	http://dx.doi.org/10.3389/fnhum.2014.01029												2026-01-16	WOS:000347516500002
J	Liu, YA				Liu, Yinan			Chinese Piano Music: the Role of Composer Chu Wanghua in the Evolution of Modern Piano Traditions in China (the Case of the 'Sounds of the Temple' Capriccio Suite)	MUSICA HODIE				Article								Chinese piano music is based on folk songs, Chinese poetry, and the ethnic style, which contribute to the expressiveness of the sound and refinement of the intonation and tonal system. The paper addresses the Chinese piano music and the role of composer Chu Wanghua in shaping contemporary piano traditions, using the 'Sounds of the Temple' capriccio suite as an example. Based on the direct method of standardization, the paper determined the significance of the parts of the 'Sounds of the Temple' suite. The second part (0.93) is most significant for displaying the piano music, because it involves the use of polyphonic sounds, imitating other instruments. The first part of the suite (0.87) is based on a linear representation of sounds, imitating the sounds of bells. The third part (0.69) centers around the use of slow tempo as well as major tone deviations. Significant elements of the suite (mirror reprise, rhythmic transformation, monotonous repetition of phrases and sounds, application of guo hua techniques, texture elements) were determined on the basis of the measured complexity and harmony of performance, as well as their influence on national traditions. A comparison of performance using standard deviation suggested that the differences were based on monotonous repetition of phrases and sounds (1.07), which is attributed to a greater emphasis on the difficulty of performance than on other parameters. The paper's practical implications involve the possibility of preserving expressiveness and ethnic elements while playing the piano, based on Chu Wanghua's 'Sounds of the Temple' suite. Further studies might compare the elements that contribute to the expressiveness of performance in the 'Sounds of the Temple' suite by Chu Wanghua and 'Flower Drum' by Qu Wei												3	3												2022	22								e73153	10.5216/mh.v22.73153	http://dx.doi.org/10.5216/mh.v22.73153												2026-01-16	WOS:000868183200001
J	Parncutt, R				Parncutt, Richard			The Origin of the Dominant: Schoenberg's 'Strong Progression' and the Realisation of Implied Virtual Pitches	MUSIC ANALYSIS				Article								In major-minor tonality, V implies I, and rising fourths, falling thirds and rising seconds between successive chord roots are more common than falling fourths, rising thirds and falling seconds respectively. Possible explanations involve history (in two-part medieval counterpoint, harmonic major sixths resolved to octaves - maintained in V-I); the rising leading note (V-I includes it, IV-I does not); acoustic speculation (in V-I, the third harmonic of 1$\hat 1$ resolves to the second); voice leading (in V7-I, a tritone resolves to a third by contrary step); melodic closure (a rising melodic leap implies subsequent falling steps, and melodies often end with 2$\hat 2$-1$\hat 1$, harmonised V-I); root newness (chords 'progress' if the second chord's root is not part of the first); and tonal stability (V is less stable than IV, giving it a stronger 'urge' to resolve). An additional possibility combines the 'virtual-pitch' theory of Ernst Terhardt with the 'implication-realisation' theory of Leonard B. Meyer and Eugene Narmour. Major and minor triads imply subsidiary virtual pitches (missing fundamentals; see Rameau's 'fundamental bass') at third and fifth intervals below the root. These weakly perceived pitches are realised in the next chord if the root falls by a third or rises a fourth or major second, creating a feeling of forward progression - while also facilitating intonation for singers and melodic instrumentalists. The theory correctly predicts that successive harmonic complex (but not pure) tones an octave apart sound more similar if rising, and rising octaves are more common than falling in melody. It also explains why Classical modulations are asymmetrical in the opposite direction, major keys tending to modulate to V (not IV) and minor to III (not VI): accidental flats tend to be more perceptually salient or stable than sharps.												0	0											JUL	2024	43	2					247	301		10.1111/musa.12233	http://dx.doi.org/10.1111/musa.12233		AUG 2024										2026-01-16	WOS:001284752000001
J	Wible, CG				Wible, Cynthia G.			Hippocampal temporal-parietal junction interaction in the production of psychotic symptoms: a framework for understanding the schizophrenic syndrome	FRONTIERS IN HUMAN NEUROSCIENCE				Article								A framework is described for understanding the schizophrenic syndrome at the brain systems level. It is hypothesized that over-activation of dynamic gesture and social perceptual processes in the temporal-parietal occipital junction (TPJ), posterior superior temporal sulcus (PSTS) and surrounding regions produce the syndrome (including positive and negative symptoms, their prevalence, prodromal signs, and cognitive deficits). Hippocampal system hyper-activity and atrophy have been consistently found in schizophrenia. Hippocampal activity is highly correlated with activity in the TPJ and may be a source of over-excitation of the TPJ and surrounding regions. Strong evidence for this comes from in-vivo recordings in humans during psychotic episodes. Many positive symptoms of schizophrenia can be reframed as the erroneous sense of a presence or other who is observing, acting, speaking, or controlling; these qualia are similar to those evoked during abnormal activation of the TPJ. The TPJ and PSTS play a key role in the perception (and production) of dynamic social, emotional, and attentional gestures for the self and others (e.g., body/face/eye gestures, audiovisual speech and prosody, and social attentional gestures such as eye gaze). The single cell representation of dynamic gestures is multimodal (auditory, visual, tactile), matching the predominant hallucinatory categories in schizophrenia. Inherent in the single cell perceptual signal of dynamic gesture representations is a computation of intention, agency, and anticipation or expectancy (for the self and others). Stimulation of the TPJ resulting in activation of the self representation has been shown to result a feeling of a presence or multiple presences (due to heautoscopy) and also bizarre tactile experiences. Neurons in the TPJ are also tuned, or biased to detect threat related emotions. Abnormal over-activation in this system could produce the conscious hallucination of a voice (audiovisual speech), a person or a touch. Over-activation could interfere with attentional/emotional gesture perception and production (negative symptoms). It could produce the unconscious feeling of being watched, followed, or of a social situation unfolding along with accompanying abnormal perception of intent and agency (delusions). Abnormal activity in the TPJ would also be predicted to create several cognitive disturbances that are characteristic of schizophrenia, including abnormalities in attention, predictive social processing, working memory, and a bias to erroneously perceive threat.												42	47											JUN 22	2012	6								180	10.3389/fnhum.2012.00180	http://dx.doi.org/10.3389/fnhum.2012.00180												2026-01-16	WOS:000305789500001
J	Eitan, Z; Timmers, R				Eitan, Zohar; Timmers, Renee			Beethoven's last piano sonata and those who follow crocodiles: Cross-domain mappings of auditory pitch in a musical context	COGNITION				Article								Though auditory pitch is customarily mapped in Western cultures onto spatial verticality (high-low), both anthropological reports and cognitive studies suggest that pitch may be mapped onto a wide variety of other domains. We collected a total number of 35 pitch mappings and investigated in four experiments how these mappings are used and structured. In particular, we inquired (1) how Western subjects apply Western and non-Western metaphors to "high" and "low" pitches, (2) whether mappings applied in an abstract conceptual task are similarly applied by listeners to actual music, (3) how mappings of spatial height relate to these pitch mappings, and (4) how mappings of "high" and "low" pitch associate with other dimensions, in particular quantity, size, intensity and valence. The results show strong agreement among Western participants in applying familiar and unfamiliar metaphors for pitch, in both an abstract, conceptual task (Exp. 1) and in a music listening task (Exp. 2), indicating that diverse cross-domain mappings for pitch exist latently besides the common verticality metaphor. Furthermore. limited overlap between mappings of spatial height and pitch height was found, suggesting that, the Ubiquity of the verticality metaphor in Western usage notwithstanding, cross-domain pitch mappings are largely independent of that metaphor, and seem to be based upon other underlying dimensions. Part of the discrepancy between spatial height and pitch height is that, for pitch, "up" is not necessarily "more," nor is it necessarily "good." High pitch is only "more" for height, intensity and brightness. It is "less" for mass, size and quantity. We discuss implications of these findings for music and speech prosody, and their relevance to notions of embodied cognition and of cross-domain magnitude representation. (c) 2009 Elsevier B.V. All rights reserved.												162	192											MAR	2010	114	3					405	422		10.1016/j.cognition.2009.10.013	http://dx.doi.org/10.1016/j.cognition.2009.10.013												2026-01-16	WOS:000275799400009
J	Ou, SC				Ou, Shu-chen			The role of lexical stress in spoken English word recognition by listeners of English and Taiwan Mandarin	LANGUAGE AND LINGUISTICS				Article								Two perceptual experiments investigated how the suprasegmental information of monosyllables is perceived and exploited in spoken English word recognition by listeners of English and Taiwan Mandarin (TM). Using an auditory lexical decision task in which correctly stressed English words and mis-stressed nonwords (e.g. camPAIGN vs. *CAMpaign) were presented for lexical decisions, Experiment I demonstrated that TM listeners could perceive the differences between stressed and unstressed syllables with native-like accuracy and rapidity. To examine how the perceived suprasegmental contrast would constrain English lexical access, Experiment II was conducted. It used a cross-modal fragment priming task in which a lexical decision had to be made for a visually presented English word or nonword following an auditory prime, which was a spoken word-initial syllable. The results showed that English and TM listeners recognized the displayed word (e.g. campus) faster both after a stress-matching (e.g. CAM-) prime and a stress-mismatching (e.g. cam-) prime than after a control prime (e.g. MOUN , with mismatching segments). This indicates that suprasegmental information does not inhibit a segmentally matching but suprasegmentally mismatching word candidate for both the two groups, although TM is a language where lexical prosody is expressed syllabically and its listeners tend to interpret lexical stress tonally. Yet, the two groups' responses were slower after the stressed primes than after the unstressed ones, presumably because the former generally had more possible continuations than the latter do. It is therefore concluded that when recognizing spoken English words, both the native and non-native (TM-speaking) listeners can exploit the suprasegmental cues of monosyllables, which, however, are not so effective that they will outweigh the segmental cues.												3	4												2019	20	4					569	600		10.1075/lali.00049.ou	http://dx.doi.org/10.1075/lali.00049.ou												2026-01-16	WOS:000496239100003
J	Irurtzun, A				Irurtzun, Aritz			The "Globularization Hypothesis" of the Language-ready Brain as a Developmental Frame for Prosodic Bootstrapping Theories of Language Acquisition	FRONTIERS IN PSYCHOLOGY				Article								In recent research (Boeckx arid Benitez-Burra( o, 2014a,b) have advanced the hypothesis that our species-specific language-ready brain should be understood as the outcome of developmental changes that occurred in our species after the split from Neanderthals-Denisovans, which resulted in a more globular braincase configuration in comparison to our closest relatives, who had elongated endocasts. According to these authors, the development of a globular brain is an essential ingredient for the language faculty and in particular, it is the centrality occupied by the thalamus in a globular brain that allows its modulatory or regulatory role, essential for syntactico-semantic computations. Their hypothesis is that the syntactico-semantic capacities arise in humans as a consequence of a process of globularization, which significantly takes place postnatally (cf. Neubauer et al., 2010). In this paper, I show that Boeckx and Benitez-Burraco's hypothesis makes an interesting developmental prediction regarding the path of language acquisition: it teases apart the onset of phonological acquisition and the onset of syntactic acquisition (the latter starting significantly later, after globularization). I argue that this hypothesis provides a developmental rationale for the prosodic bootstrapping hypothesis of language acquisition (cf. La. Gleitman arid Wanner, 1982; Mehler et al., 1988, et seq.; Gervain and Werker, 2013), which claim that prosodic cues are employed for syntactic parsing. The literature converges in the observation that a large amount of such prosodic cues (in particular, rhythmic cues) are already acquired before the completion of the globularization phase, which paves the way for the premises of the prosodic bootstrapping hypothesis, allowing babies to have a rich knowledge of the prosody of their target language before they can start parsing the primary linguistic data syntactically.												4	5											DEC 9	2015	6								1817	10.3389/fpsyg.2015.01817	http://dx.doi.org/10.3389/fpsyg.2015.01817												2026-01-16	WOS:000366920700001
J	Coath, M; Balaguer-Ballester, E; Denham, SL; Denham, M				Coath, M.; Balaguer-Ballester, E.; Denham, S. L.; Denham, M.			The linearity of emergent spectro-temporal receptive fields in a model of auditory cortex	BIOSYSTEMS				Article; Proceedings Paper	7th International Workshop on Information Processing in Cells and Tissue	AUG 29-31, 2007	Oxford, ENGLAND					The responses of cortical neurons are often characterized by measuring their spectro-temporal receptive fields (STRFs). The STRIP of a cell can be thought of as a representation of its stimulus 'preference' but it is also a filter or 'kernel' that represents the best linear prediction of the response of that cell to any stimulus. A range of in vivo STRFs with varying properties have been reported in various species, although none in humans. Using a computational model it has been shown that responses of ensembles of artificial STRFs, derived from limited sets of formative stimuli, preserve information about utterance class and prosody as well as the identity and sex of the speaker in a model speech classification system. In this work we help to put this idea on a biologically plausible footing by developing a simple model thalamo-cortical system built of conductance based neurons and synapses some of which exhibit spike-time-dependent plasticity. We show that the neurons in such a model when exposed to formative stimuli develop STRFs with varying temporal properties exhibiting a range of heterotopic integration. These model neurons also, in common with neurons measured in vivo, exhibit a wide range of non-linearities; this deviation from linearity can be exposed by characterizing the difference between the measured response of each neuron to a stimulus, and the response predicted by the STRF estimated for that neuron. The proposed model, with its simple architecture, learning rule, and modest number of neurons (< 1000), is suitable for implementation in neuromorphic analogue VLSI hardware and hence could form the basis of a developmental, real time, neuromorphic sound classification system. (C) 2008 Elsevier Ireland Ltd. All rights reserved.												4	6											OCT-NOV	2008	94	1-2			SI		60	67		10.1016/j.biosystems.2008.05.011	http://dx.doi.org/10.1016/j.biosystems.2008.05.011												2026-01-16	WOS:000261139500009
J	Vekkot, S; Gupta, D; Zakariah, M; Alotaibi, YA				Vekkot, Susmitha; Gupta, Deepa; Zakariah, Mohammed; Alotaibi, Yousef Ajami			Emotional Voice Conversion Using a Hybrid Framework With Speaker-Adaptive DNN and Particle-Swarm-Optimized Neural Network	IEEE ACCESS				Article								We propose a hybrid network-based learning framework for speaker-adaptive vocal emotion conversion, tested on three different datasets (languages), namely, EmoDB (German), IITKGP (Telugu), and SAVEE (English). The optimized learning model introduced is unique because of its ability to synthesize emotional speech with an acceptable perceptive quality while preserving speaker characteristics. The multilingual model is extremely beneficial in scenarios wherein emotional training data from a specific target speaker are sparsely available. The proposed model uses speaker-normalized mel-generalized cepstral coefficients for spectral training with data adaptation using the seed data from the target speaker. The fundamental frequency (F0) is transformed using a wavelet synchrosqueezed transform prior to mapping to obtain a sharpened time & x2013;frequency representation. Moreover, a feedforward artificial neural network, together with particle swarm optimization, was used for F0 training. Additionally, static-intensity modification was also performed for each test utterance. Using the framework, we were able to capture the spectral and pitch contour variabilities of emotional expression better than with other state-of-the-art methods used in this study. Considering the overall performance scores across datasets, an average melcepstral distortion (MCD) of 4.98 and root mean square error (RMSE-F0) of 10.67 were obtained in objective evaluations, and an average comparative mean opinion score (CMOS) of 3.57 and speaker similarity score of 3.70 were obtained for the proposed framework. Particularly, the best MCD of 4.09 (EmoDB-happiness) and RMSE-F0 of 9.00 (EmoDB-anger) were obtained, along with the maximum CMOS of 3.7 and speaker similarity of 4.6, thereby highlighting the effectiveness of the hybrid network model.												15	18												2020	8						74627	74647		10.1109/ACCESS.2020.2988781	http://dx.doi.org/10.1109/ACCESS.2020.2988781												2026-01-16	WOS:000530830800095
J	Lavan, N; Rankin, G; Lorking, N; Scott, S; McGettigan, C				Lavan, Nadine; Rankin, Georgia; Lorking, Nicole; Scott, Sophie; McGettigan, Carolyn			Neural correlates of the affective properties of spontaneous and volitional laughter types	NEUROPSYCHOLOGIA				Article								Previous investigations of vocal expressions of emotion have identified acoustic and perceptual distinctions between expressions of different emotion categories, and between spontaneous and volitional (or acted) variants of a given category. Recent work on laughter has identified relationships between acoustic properties of laughs and their perceived affective properties (arousal and valence) that are similar across spontaneous and volitional types (Bryant & Aktipis, 2014; Lavan et al., 2016). In the current study, we explored the neural correlates of such relationships by measuring modulations of the BOLD response in the presence of itemwise variability in the subjective affective properties of spontaneous and volitional laughter. Across all laughs, and within spontaneous and volitional sets, we consistently observed linear increases in the response of bilateral auditory cortices (including Heschrs gyrus and superior temporal gyrus [STG]) associated with higher ratings of perceived arousal, valence and authenticity. Areas in the anterior medial prefrontal cortex (amPFC) showed negative linear correlations with valence and authenticity ratings across the full set of spontaneous and volitional laughs; in line with previous research (McGettigan et al., 2015; Szameitat etal., 2010), we suggest that this reflects increased engagement of these regions in response to laughter of greater social ambiguity. Strikingly, an investigation of higher-order relationships between the entire laughter set and the neural response revealed a positive quadratic profile of the BOLD response in right-dominant STG (extending onto the dorsal bank of the STS), where this region responded most strongly to laughs rated at the extremes of the authenticity scale. While previous studies claimed a role for right STG in bipolar representation of emotional valence, we instead argue that this may in fact exhibit a relatively categorical response to emotional signals, whether positive or negative.												22	26											JAN 27	2017	95						30	39		10.1016/j.neuropsychologia.2016.12.012	http://dx.doi.org/10.1016/j.neuropsychologia.2016.12.012												2026-01-16	WOS:000393723900004
J	Heisterueber, M; Klein, E; Willmes, K; Heim, S; Domahs, F				Heisterueber, Miriam; Klein, Elise; Willmes, Klaus; Heim, Stefan; Domahs, Frank			Processing word prosody - behavioral and neuroimaging evidence for heterogeneous performance in a language with variable stress	FRONTIERS IN PSYCHOLOGY				Article								In the present behavioral and fMRI study, we investigated for the first time interindividual variability in word stress processing in a language with variable stress position (German) in order to identify behavioral predictors and neural correlates underlying these differences. It has been argued that speakers of languages with variable stress should perform relatively well in tasks tapping into the representation and processing of word stress, given that this is a relevant feature of their language. Nevertheless, in previous studies on word stress processing large degrees of interindividual variability have been observed but were ignored or left unexplained. Twenty-five native speakers of German performed a sequence recall task using both segmental and suprasegmental stimuli. In general, the suprasegmental condition activated a subcortico-cortico-cerebellar network including, amongst others, bilateral inferior frontal gyrus, insula, precuneus, cerebellum, the basal ganglia, pre-SMA and SMA, which has been suggested to be dedicated to the processing of temporal aspects of speech. However, substantial interindividual differences were observed. In particular, main effects of group were observed in the left middle temporal gyrus (below vs. above average performance in stress processing) and in the left precuneus (above vs. below average). Moreover, condition (segmental vs. suprasegmental) and group (above vs. below average) interacted in the right hippocampus and cerebellum. At the behavioral level, differences in word stress processing could be partly explained by individual performance in basic auditory perception including duration discrimination and by working memory performance (WM). We conclude that even in a language with variable stress, interindividual differences in behavioral performance and in the neuro-cognitive foundations of stress processing can be observed which may partly be traced back to individual basic auditory processing and WM performance.												12	14											APR 29	2014	5								365	10.3389/fpsyg.2014.00365	http://dx.doi.org/10.3389/fpsyg.2014.00365												2026-01-16	WOS:000335972600001
J	Jiang, XM; Gossack-Keenan, K; Pell, MD				Jiang, Xiaoming; Gossack-Keenan, Kira; Pell, Marc D.			To believe or not to believe? How voice and accent information in speech alter listener impressions of trust	QUARTERLY JOURNAL OF EXPERIMENTAL PSYCHOLOGY				Article								Our decision to believe what another person says can be influenced by vocally expressed confidence in speech and by whether the speaker-listener are members of the same social group. The dynamic effects of these two information sources on neurocognitive processes that promote believability impressions from vocal cues are unclear. Here, English Canadian listeners were presented personal statements (She has access to the building) produced in a confident or doubtful voice by speakers of their own dialect (in-group) or speakers from two different "out-groups" (regional or foreign-accented English). Participants rated how believable the speaker is for each statement and event-related potentials (ERPs) were analysed from utterance onset. Believability decisions were modulated by both the speaker's vocal confidence level and their perceived in-group status. For in-group speakers, ERP effects revealed an early differentiation of vocally expressed confidence (i.e., N100, P200), highlighting the motivational significance of doubtful voices for drawing believability inferences. These early effects on vocal confidence perception were qualitatively different or absent when speakers had an accent; evaluating out-group voices was associated with increased demands on contextual integration and re-analysis of a non-native representation of believability (i.e., increased N400, late negativity response). Accent intelligibility and experience with particular out-group accents each influenced how vocal confidence was processed for out-group speakers. The N100 amplitude was sensitive to out-group attitudes and predicted actual believability decisions for certain out-group speakers. We propose a neurocognitive model in which vocal identity information (social categorization) dynamically influences how vocal expressions are decoded and used to derive social inferences during person perception.												58	64											JAN	2020	73	1					55	79		10.1177/1747021819865833	http://dx.doi.org/10.1177/1747021819865833												2026-01-16	WOS:000502392000004
J	Greve, M				Greve, Martin			Kurdish Music?. Music from Dersim?.: Conflicting Identities and the Challenge of Categorization in Central-Eastern Anatolia	WORLD OF MUSIC-NEW SERIES				Article								In almost all international literature on music of the Middle East, the main categories are still either states or ethnic and/or religious groups (e.g., "music in Turkey," "Turkish music," "Kurdish music," "Alevi music," "Armenian music"). The population structure of the central portion of eastern Anatolia, however, is neither homogeneous nor historically stable. Among the numerous ethnic Sunni-Muslim, Alevi, and Christian groups, who variously speak Kurdish, Zaza, Turkish, and Circassian languages, exchange and migration has been constant, leading to a complex and dynamic population structure. A number of tribes have not only migrated over time, but subsets within them have even changed their language or denomination. Faced with all these cases, no consensus exists as to which identity discourses deserve more attention from musicologists. In the interest of musical analysis, further typological distinctions are vital to consider, for example socioeconomic structures and contexts, such as ruralmountainous versus urban environments. Since the twentieth century, mediatization, urbanization, and migration have led to an even growing multiplicity of social identities and musical styles, calling into question static, coherent narratives. In this article, the contradictions and inadequacies of prevailing approaches will be emphasized through comparisons of music drawn from different social categories in central eastern Anatolia. Obviously, no unified musical tradition exists in the region, but rather a complex, uneven, and highly creative field of intensely localized and, recently, increasingly individual musical styles, influenced by numerous spheres of identity discourse. Looking only at musical features, however, the issue does not get easier. Not only a paucity of research but also methodological problems impede the comparison of the numerous traditions of singer-poets, laments, and religious poetic texts of different denominations. For the analysis of vocal styles for example, not only intonation and melodic structure have to be taken into account but also the performative dimensions of timbre, vocal intensity, the use of vibrato, dynamics, and the regulation of rhythm and tempo, all elements for whom satisfactory methods of representation and analysis have yet to be developed.												0	0												2022	11	2					141	167															2026-01-16	WOS:000974773000007
J	Bouchard, D				Bouchard, Denis			Brain readiness and the nature of language	FRONTIERS IN PSYCHOLOGY				Article								To identify the neural components that make a brain ready for language, it is important to have well defined linguistic phenotypes, to know precisely what language is. There are two central features to language: the capacity to form signs (words), and the capacity to combine them into complex structures. We must determine how the human brain enables these capacities. A sign is a link between a perceptual form and a conceptual meaning. Acoustic elements and content elements, are already brain-internal in non-human animals, but as categorical systems linked with brain-external elements. Being indexically tied to objects of the world, they cannot freely link to form signs. A crucial property of a language-ready brain is the capacity to process perceptual forms and contents offline, detached from any brain-external phenomena, so their "representations" may be linked into signs. These brain systems appear to have pleiotropic effects on a variety of phenotypic traits and not to be specifically designed for language. Syntax combines signs, so the combination of two signs operates simultaneously on their meaning and form. The operation combining the meanings long antedates its function in language: the primitive mode of predication operative in representing some information about an object. The combination of the forms is enabled by the capacity of the brain to segment vocal and visual information into discrete elements. Discrete temporal units have order and juxtaposition, and vocal units have intonation, length, and stress. These are primitive combinatorial processes. So the prior properties of the physical and conceptual elements of the sign introduce combinatoriality into the linguistic system, and from these primitive combinatorial systems derive concatenation in phonology and combination in morphosyntax. Given the nature of language, a key feature to our understanding of the language-ready brain is to be found in the mechanisms in human brains that enable the unique means of representation that allow perceptual forms and contents to be linked into signs.												2	3											SEP 9	2015	6								1376	10.3389/fpsyg.2015.01376	http://dx.doi.org/10.3389/fpsyg.2015.01376												2026-01-16	WOS:000443425000001
J	Hassan, AQA; Alanazi, MH; Al-Anazi, RG; Alzaidi, MSA; Aljohani, NJ; Alzahrani, KA; Alzubaidi, U; Hilal, AM				Hassan, Abdulkhaleq Q. A.; Alanazi, Meshari H.; Al-Anazi, Reema G.; Alzaidi, Muhammad Swaileh A.; Aljohani, Nouf J.; Alzahrani, Khadija Abdullah; Alzubaidi, Umkalthoom; Hilal, Anwer Mustafa			INTEGRATING APPLIED LINGUISTICS WITH ARTIFICIAL INTELLIGENCE-ENABLED ARABIC TEXT-TO-SPEECH SYNTHESIZER	FRACTALS-COMPLEX GEOMETRY PATTERNS AND SCALING IN NATURE AND SOCIETY				Article								Currently, Text-to-Speech (TTS) or speech synthesis, the ability of the complex system to generate a human-like sounding voice from the written text, is becoming increasingly popular in speech processing in various complex systems. TTS is the artificial generation of human speech. A classical TTS system translates a language text into a waveform. Several English TTS systems produce human-like, mature, and natural speech synthesizers. On the other hand, other languages, such as Arabic, have just been considered. The present Arabic speech synthesis solution is of low quality and slow, and the naturalness of synthesized speech is lower than that of English synthesizers. Also, they lack crucial primary speech factors, including rhythm, intonation, and stress. Several studies have been proposed to resolve these problems, integrating using concatenative techniques like parametric or unit selection methods. This paper proposes an Applied Linguistics with Artificial Intelligence-Enabled Arabic Text-to-Speech Synthesizer (ALAI-ATTS) model. This ALAI-ATTS technique includes three essential components: data preprocessing through phonetization and diacritization, Extreme Learning Machine (ELM)-based speech synthesis, and Grey Wolf Fractals Optimization (GWO)-based parameter tuning. Initially, the data preprocessing step includes diacritization, where diacritics are restored to unvoweled text to ensure correct pronunciation, followed by phonetization, translating the text into its phonetic representation. Then, the ELM-based speech synthesis model uses the processed dataset for speech generation. ELMs, well known for their excellent generalization performance and fast learning speed, are especially suitable for real-time TTS applications, balancing high-quality speech output and computational efficiency. Lastly, the GWO methodology is employed to tune the parameters of the ELM. The simulation outcomes validate that the ALAI-ATTS technique considerably enhances the intelligibility and naturalness of Arabic synthesized speech compared to existing approaches. The experimental results of the ALAI-ATTS technique portrayed a lesser value of 3.48, 0.15 and 1.37, 0.25 under WER and DER.												0	0												2024	32	09N10								10.1142/S0218348X2540050X	http://dx.doi.org/10.1142/S0218348X2540050X		DEC 2024										2026-01-16	WOS:001379152300001
J	Souter, NE; Lindquist, KA; Jefferies, E				Souter, Nicholas E.; Lindquist, Kristen A.; Jefferies, Elizabeth			Impaired emotion perception and categorization in semantic aphasia	NEUROPSYCHOLOGIA				Article								According to a constructionist model of emotion, conceptual knowledge plays a foundational role in emotion perception; reduced availability of relevant conceptual knowledge should therefore impair emotion perception. Conceptual deficits can follow both degradation of semantic knowledge (e.g., semantic 'storage' deficits in semantic dementia) and deregulation of retrieval (e.g., semantic 'access' deficits in semantic aphasia). While emotion recognition deficits are known to accompany degraded conceptual knowledge, less is known about the impact of semantic access deficits. Here, we examined emotion perception and categorization tasks in patients with semantic aphasia, who have difficulty accessing semantic information in a flexible and controlled fashion following left hemisphere stroke. In Study 1, participants were asked to sort faces according to the emotion they portrayed - with numbers, written labels and picture examples each provided as category anchors across tasks. Semantic aphasia patients made more errors and showed a larger benefit from word anchors that reduced the need to internally constrain categorization than comparison participants. They successfully sorted portrayals that differed in valence (positive vs. negative) but had difficulty categorizing different negative emotions. They were unimpaired on a control task that involved sorting faces by identity. In Study 2, participants matched facial emotion portrayals to written labels following vocal emotion prosody cues, miscues, or no cues. Patients presented with overall poorer performance and benefited from cue trials relative to within-valence miscue trials. This same effect was seen in comparison participants, who also showed deleterious effects of within-valence miscue relative to no cue trials. Overall, we found that patients with deregulated semantic retrieval have deficits in emotional perception but that word anchors and cue conditions can facilitate emotion perception by increasing access to relevant emotion concepts and reducing reliance on semantic control. Semantic control may be of particular importance in emotion perception when it is necessary to interpret ambiguous inputs, or when there is interference between conceptually similar emotional states. These findings extend constructionist accounts of emotion to encompass difficulties in controlled semantic retrieval.												13	18											NOV 12	2021	162								108052	10.1016/j.neuropsychologia.2021.108052	http://dx.doi.org/10.1016/j.neuropsychologia.2021.108052		OCT 2021										2026-01-16	WOS:000707716800006
J	Salmelin, R; Schnitzler, A; Schmitz, F; Freund, HJ				Salmelin, R; Schnitzler, A; Schmitz, F; Freund, HJ			Single word reading in developmental stutterers and fluent speakers	BRAIN				Article								Ten fluent speakers and nine developmental stutterers read isolated nouns aloud in a delayed reading paradigm. Cortical activation sequences were mapped with a whole-head magnetoencephalography system. The stutterers were mostly fluent in this task. Although the overt performance was essentially identical in the two groups, the cortical activation patterns showed clear differences, both in the evoked responses, time-locked to word presentation and mouth movement onset, and in task-related suppression of 20-Hz oscillations. Within the first 400 ms after seeing the word, processing in fluent speakers advanced from the left inferior frontal cortex (articulatory programming) to the left lateral central sulcus and dorsal premotor cortex (motor preparation). This sequence was reversed in the stutterers, who showed an early left motor cortex activation followed by a delayed left inferior frontal signal. Stutterers thus appeared to initiate motor programmes before preparation of the articulatory code. During speech production, the right motor/premotor cortex generated consistent evoked activation in fluent speakers but was silent in stutterers. On the other hand, suppression of motor cortical 20-Hz rhythm, reflecting task-related neuronal processing, occurred bilaterally in both groups. Moreover, the suppression was right-hemisphere dominant in stutterers, as opposed to left-hemisphere dominant in fluent speakers. Accordingly, the right frontal cortex of stutterers was highly active during speech production but did not generate synchronous time-locked responses. The speech-related 20-Hz suppression concentrated in the mouth area in fluent speakers, but was evident in both the hand and mouth areas in stutterers. These findings may reflect imprecise functional connectivity within the right frontal cortex and incomplete segregation between the adjacent hand and mouth motor representations in stutterers during speech production. A network including the left inferior frontal cortex and the right motor/premotor cortex, likely to be relevant in merging linguistic and affective prosody with articulation during fluent speech, thus appears to be partly dysfunctional in developmental stutterers.												216	245											JUN	2000	123		6				1184	1202		10.1093/brain/123.6.1184	http://dx.doi.org/10.1093/brain/123.6.1184												2026-01-16	WOS:000087603100011
J	Shao, J; Zhang, CC				Shao, Jing; Zhang, Caicai			Talker normalization in typical Cantonese-speaking listeners and congenital amusics: Evidence from event-related potentials	NEUROIMAGE-CLINICAL				Article								Despite the lack of invariance in the mapping between the acoustic signal and phonological representation, typical listeners are capable of using information of a talker's vocal characteristics to recognize phonemes, a process known as "talker normalization". The current study investigated the time course of talker normalization in typical listeners and individuals with congenital amusia, a neurodevelopmental disorder of refined pitch processing. We examined the event-related potentials (ERPs) underling lexical tone processing in 24 Cantonese-speaking amusics and 24 typical listeners (controls) in two conditions: blocked-talker and mixed-talker conditions. The results demonstrated that for typical listeners, effects of talker variability can be observed as early as in the N1 time-window (100-150 ms), with the N1 amplitude reduced in the mixed-talker condition. Significant effects were also found in later components: the N2b/c peaked significantly earlier and the P3a and P3b amplitude was enhanced in the blocked-talker condition relative to the mixed-talker condition, especially for the tone pair that is more difficult to discriminate. These results suggest that the blocked-talker mode of stimulus presentation probably facilitates auditory processing and requires less attentional effort with easier speech categorization than the mixed-talker condition, providing neural evidence for the "active control theory". On the other hand, amusics exhibited comparable N1 amplitude to controls in both conditions, but deviated from controls in later components. They demonstrated overall later N2b/c peak latency significantly reduced P3a amplitude in the blocked-talker condition and reduced P3b amplitude irrespective of talker conditions. These results suggest that the amusic brain was intact in the auditory processing of talker normalization processes, as reflected by the comparable N1 amplitude, but exhibited reduced automatic attentional switch to tone changes in the blocked-talker condition, as captured by the reduced P3a amplitude, which presumably underlies a previously reported perceptual "anchoring" deficit in amusics. Altogether, these findings revealed the time course of talker normalization processes in typical listeners and extended the finding that conscious pitch processing is impaired in the amusic brain.												9	9												2019	23								101814	10.1016/j.nicl.2019.101814	http://dx.doi.org/10.1016/j.nicl.2019.101814												2026-01-16	WOS:000485804400006
J	Wang, L; Ong, JH; Ponsot, E; Hou, QQ; Jiang, CM; Liu, F				Wang, Li; Ong, Jia Hoong; Ponsot, Emmanuel; Hou, Qingqi; Jiang, Cunmei; Liu, Fang			Mental representations of speech and musical pitch contours reveal a diversity of profiles in autism spectrum disorder	AUTISM				Article								As an information-bearing auditory attribute of sound, pitch plays a crucial role in the perception of speech and music. Studies examining pitch processing in autism spectrum disorder have produced equivocal results. To understand this discrepancy from a mechanistic perspective, we used a novel data-driven method, the reverse-correlation paradigm, to explore whether the equivocal findings in autism spectrum disorder have high-level origins in top-down comparisons of internal mental representations of pitch contours. Thirty-two Mandarin-speaking autistic individuals and 32 non-autistic individuals undertook three subtasks testing mental representations of pitch contours in speech, complex tone and melody, respectively. The results indicate that while the two groups exhibited similar representations of pitch contours across the three conditions, the autistic group showed a significantly higher intra-group variability than the non-autistic group. In addition, the two groups did not differ significantly in internal noise, a measure of the robustness of participant responses to external variability, suggesting that the present findings translate genuinely qualitative differences and similarities between groups in pitch processing. These findings uncover for the first time that pitch patterns in speech and music are mentally represented in a similar manner in autistic and non-autistic individuals, through domain-general top-down mechanisms. Lay abstract As a key auditory attribute of sounds, pitch is ubiquitous in our everyday listening experience involving language, music and environmental sounds. Given its critical role in auditory processing related to communication, numerous studies have investigated pitch processing in autism spectrum disorder. However, the findings have been mixed, reporting either enhanced, typical or impaired performance among autistic individuals. By investigating top-down comparisons of internal mental representations of pitch contours in speech and music, this study shows for the first time that, while autistic individuals exhibit diverse profiles of pitch processing compared to non-autistic individuals, their mental representations of pitch contours are typical across domains. These findings suggest that pitch-processing mechanisms are shared across domains in autism spectrum disorder and provide theoretical implications for using music to improve speech for those autistic individuals who have language problems.												11	12											APR	2023	27	3					629	646		10.1177/13623613221111207	http://dx.doi.org/10.1177/13623613221111207		JUL 2022										2026-01-16	WOS:000826666900001
J	Matkarimova, SM; Davlatova, ST; Botirova, NX; Masharipova, GK				Matkarimova, Sadokat M.; Davlatova, Saodat T.; Botirova, Nafosat X.; Masharipova, Gularam K.			Tashkent in the Imperial Project of Russian Colonization of the Turkestan Region in the second half of the 19th-early 20th centuries: Discourse and Practices	BYLYE GODY				Article								The article, based on the materials of notes, essays, memoirs and reminiscences of Russian officials, publicists, writers, social and political figures, united by the 'frame' of imperial experts, reveals the content of discourse and ideas about the city of Tashkent as an outpost of Russian colonization of the Turkestan region in the second half of the 19th-early 20th centuries. The method of discourse analysis allowed us to identify key patterns in experts' perceptions of the representation of Tashkent as a model of internal colonization of the eastern periphery of the empire. In the course of the study, it was established that the construction of the image of Tashkent as the imperial centre of the Turkestan region implied the fixation of the city's special military and administrative status in the personal texts of imperial experts, which was expressed in the massive 'occupation' narrative prevailing on the pages of published materials. In the publications of the second half of the 19th century, the intonation of the empire's militaristic presence and dominance in the region was clearly traced, and Tashkent was labelled as a Russian military facility with a predominance of the military population over the civilian population, which provided relatively comfortable conditions for the administration and broadcasting of imperial power as a transformative and culturalising force. In the early 20th century, the content of Tashkent's discourse and the understanding of the empire's practical plans in Central Asia underwent significant changes, which, according to experts, was due to the final 'pacification' of the periphery and gave rise to cultural initiatives of a Russification nature, and with them the promotion of the idea of Russian national conservatives about the need to promote such a variant of the development and "appropriation" of the east, in which cultural differences would be gradually erased and a 'large Russian nation' would be formed. In this regard, Tashkent was presented to imperial experts as a 'platform' for the processing, taking into account local conditions, of Russian culture by means of education and dissemination of domestic experience of farming, designed to sedentarise the nomads and establish sedentarisation of the remaining groups of the autochthonous population.												0	0											DEC	2025	20	4					1897	1906		10.13187/bg.2025.4.1897	http://dx.doi.org/10.13187/bg.2025.4.1897												2026-01-16	WOS:001635521100023
J	Krusha, I; Schörkhuber, F				Krusha, Ilir; Schorkhuber, Franz			THE FORMAL AND SEMANTIC PROPERTIES OF INTERROGATIVE SENTENCES IN ALBANIAN AND GERMAN USAGE	FOLIA LINGUISTICA ET LITTERARIA				Article								This paper provides a comparison of two languages that are very distinct in grammar and pronunciation, respectively German and Albanian. Since research opportunities in comparative linguistics are infinite, this paper focuses on interrogative sentences and their sentence types. Through a detailed analysis of sentence examples of the grammar used in Albanian and German, we examine the similarities and differences related to different forms of interrogative sentences. As a framework for the classification of interrogative sentences in both languages, we have distinguished sentences into general interrogative sentences and complementary ones. In the end, the knowledge gained is summerised in a general overview. The aim of this work is to compare two languages that are very different in grammar, style and pronunciation, German and Albanian. Since the field of possible investigations in comparative linguistics is endless, the present work focuses on interrogative sentences and their respective linguistic forms. Through the detailed analysis of sentence examples, which are taken from common German and Albanian grammars, the similarities and differences in interrogative sentences are shown. The distinction between yes/no questions and questions that require a supplement serves as a regulatory framework. At the end of the work, the knowledge gained is summarized in an overview. Since these two Indo-European languages do not share major linguistic similarities, we hypothetically assume with Gerd-Dieter Nehring (2002) that on a grammatical level in the Albanian standard language (ASS) there is a basic system of marking tokens in contrast to German: "The ASL (Albanian Standard language) agrees with German in terms of the division of parts of speech into word classes. However, there are also clear differences. In contrast to the article following the noun, the preceding article in Albanian has no determining function (e.g. topi i djalit - 'the boy's ball'), despite their common genetic origin" (Nehring 2002, 51; our transl.). Detailed syntactical analysis demonstrates why the sentence order is flexible in German and relatively free in Albanian, a finding that could form the basis for further research on AlbanianGerman contrastive syntax. As an excerpt from a larger research project, this work provides insights into selected areas of German and Albanian grammar. The demonstration of connecting and disconnecting factors between both languages should thus be expanded and deepened. New insights are gained by combining various systematic linguistic methods with semantic and syntactic analysis. Due to the importance and the strong desire for good language skills, this research can be valuable for teachers as well as scholars of German. The aim of the study is to give an overview of and an insight into a still little researched and discussed part of the theory of interrogative sentences, mainly in the morphosyntax, to explain various examples in both languages and to present the variations of the interrogative sentences. An additional aim of this work is to examine the translations of literary works with regard to possible alternatives, or to clarify to what extent, e.g. the B. position and modes of verbs, intonation and melodic design, allow certain freedoms or, conversely, are bound by grammatical constraints. With regard to the analytical method used, an attempt is made to isolate the possible syntactic features of Albanian and German in order to bring them forward as relevant factors for distinguishing the interrogative sentences in the two languages. Through this analysis, we aim to show the differences between the two language systems, and as such, contribute to the language comparison between Albanian and German with regard to sentence types. By constantly referring to alternative forms of presentation and representation, knowledge about the linguistic variation of sentence types should also be increased. Because the structure of the sentences (and this includes not only the verb order in the sentence) significantly affects different types of sentences, when selecting the sentences to be examined, a large number of these factors had to be taken into account or included to a controllable extent. First, the selection of the sentences to be examined follows, as described above, the structural properties discussed in standard grammars. Second, it was also necessary to find examples that have content and linguistic relevance in both languages. And third, the semantic content of the sample sentences was also taken into account. Based on the research question of how the interrogative sentences in German and Albanian differ from each other, the following aspects and characteristics (which then guided the investigation) could be determined: (1) The sentence formation patterns in German and Albanian differ widely and require a specific focus on the respective semantic content. (2) The usual bracket formation in German does not occur in Albanian. However, what does it correspond to in this language? and (3) In both languages, the verb with its valences is the central element in the sentence. In German, the personal form of the verbal part is usually placed in the second position in the main clause (the declarative clause), but in the subordinate clause, it is usually placed at the end of the sentence. But there are also subordinate clauses with constant verb position, notably in the case of conditional clauses and indirect speech. This different rule for main and subordinate clauses does not apply in Albanian. So, while in German the position of the verbal parts changes in the subordinate clause, in Albanian this is the same as in the main clause. Accordingly, Albanian essentially has a verb in the second position. Another main goal of the project, albeit only an indirect one (through the practice of the research itself), is to show how a combination of traditional syntactic methods and experiments, which have so far only been used in other disciplines of linguistics, can also bring insights into sentence types that can be used in research. The interrogative sentence serves to express different types of interrogation. In German, a basic distinction is made between two large groups of question sentences: (1) supplementary question sentences or word question sentences and (2) decision question sentences or sentence question sentences. "The decision question assumes that it is uncertain whether the description of the facts has or will have any relation to reality" (Sommerfeldt/Starke 1989, 261; our transl.). On the other hand, in Albanian a distinction is made between supplementary interrogative sentences and decisive interrogative sentences, as well as direct and indirect interrogative sentences (main and subordinate clauses). According to specific modal aspects, the interrogative sentences are divided into neutral, dubitative, deliberative and polemical interrogation. Polemical interrogativity is expressed in interrogative and exclamatory sentences. Sentences with neutral interrogativity occur as decision and supplementary interrogative sentences (cf. Buchholz/Fiedler 1987, 498-9). Pitch progressions that fulfill the same linguistic functions form the realization level of the same intonation contours. There is only one indirect connection here. However, there is an agreement on the subject of interrogative sentences. Here almost all grammars agree on the classification of the following types of question sentences in both Albanian and German: decision questions, supplementary questions, alternative questions and echo questions. A further distinction is made between direct and indirect questions at the syntactic level (cf. Laposa 2003). Morphological, syntactic, and semantic criteria were created for the structure of the interrogative sentences, as they are also used as delimitation features in many other studies (cf. Buchholz/Fiedler 1987, Sommerlfeldt/Starke 1989, Duden 2009 and Helbig/Buscha 2007). A distinction is made between word questions and sentence questions, depending on whether a question word (English: "Wh...?") is used or not. The default answer to set questions is "Ja" or "Nein". The aim of this work was to examine the syntactic and semantic differences as well as the similarities between the interrogative sentences in Albanian and German, as there are still no corresponding results in the literature comparing the two languages. A distinction is made between two subgroups of questions: (1) the decision questions and (2) the supplementary questions. Interrogative sentences always expect a reaction from the other person, be it between speaker and listener or between writer and reader. There is usually a question mark at the end of the question sentence. Similarities and differences of the two languages in terms of the form of interrogative sentences: - Sentence questions have their own question particle "a" in Albanian, which is used frequently, but not exclusively. The declarative sentence can be changed in both languages by placing a question mark and changing the intonation to a decisive question. The Albanian interrogative particle " a" is either omitted or added in this case. - In Albanian, interrogative sentences are divided into neutral, dubitative, deliberative and polemical interrogation according to specific modal aspects. Apart from the specific intonation, the neutral decision question does not require any special elements, but the particle "a", which has a morphological status, can express interrogation (cf. Buchholz/Fiedler 1987, 498). - The negative word "nicht" can be used in both languages in the decision question sentence. The German "nicht" corresponds to the Albanian "jo". - In German, a typical form of interrogative sentences is distinguished, namely the "W-interrogative sentences". - In German, the conjunction "oder" ("apo, ose") is then added. The word "not" comes after the conjunction "oder" at the end of the sentence. In Albanian, on the other hand, the conjunction does not appear at the end of the sentence. Kommt Martha morgen oder nicht? - A vjen neser Martha apo jo? - In the German decision question, the predicate is placed in front. In Albanian, the decision interrogative sentence differs from the declarative sentence only by the question particle "a" or by the use of rising intonation. In the Albanian question-and-answer sentence, the question particle "a" is at the beginning of the sentence. - The declarative sentence and the decision question sentence differ by the question particle "a", "mos valle", "a mos valle" and the question mark or the point. On the other hand, in a German question-and-answer sentence, the finite verb takes the first position, the top of the sentence (a Verberst interrogative sentence or a Verberst interrogative sentence). This syntactic question type is particularly often combined with the falling intonation contour (a question with a falling accent). - The word order in the question sentence is different in Albanian and German. In German, the verb usually comes first, followed by the subject and the other parts of the sentence. In Albanian, on the other hand, decision-making questions have a different structure. A change from the declarative sentence to decision questions is easier in German. Du isst. Ti han (Declarative sentence); Isst du? A po han ti? (decision question). - In the Albanian example sentences, the question particle "a (po)" stands out as the main difference. Here, a normal decision question consists of a statement and a question particle. Spielst du jeden Tag Fu ss ball? - A luan ti cdo dite futboll? The position of the clauses does not change in this case. The finite verb is found at the beginning of the sentence. The intonation is interrogative in both languages. - In Albanian there are two ways of expressing the normal decision question, but they are equivalent. Bist du in der Fabrik? - A je ti ne fabrike? / Je ne fabrike ti? In Albanian, the alternative question is marked by the order V+O+S. - In German, in addition to the answers "ja" and "nein", there is also the answer option "doch"= "ja". Something similar exists in Albanian with por, vetem, megjithate. In decision questions with a negation word, the relationship between agreement and negation changes in the answer. Seid ihr mit euren Arbeitsbedingungen nicht zufrieden? - A nuk jeni ju te kenaqur me kushtet e punes? - Nein, wir sind nicht glucklich. (Bestatigung) - Jo, ne nuk jemi te lumtur. - Doch, wir sind glucklich. (Verneinung) - Megjithate, ne jemi te lumtur. - In Albanian, the answers "ja" und "nein" are also used. One answers in the affirmative in Albanian by repeating the verb of the decision question sentence. In Albanian, on the other hand, the negative word for "not" - "a mos" - is added before the verb when negating. Gehst du? - A shkon ti? / A mos po shkon ti? - [Ja], gehen wir. - Po, ne po shkojme. (Bejahung) // [Nein], gehen wir nicht. - Jo, ne nuk po shkojme (Verneinung). - Tag questions serve to ask whether something has been understood correctly or is still valid. In German, the tag question always requires the particle "doch". In Albanian, a particle ("apo", "po si") is also used and placed at the end of the sentence. However, the intonation for the tag question is different. Du sprichst doch Deutsch? - Ti po flet gjermanisht, apo? Not least because of migration and cultural exchange, German and Albanian have a fruitful relationship with each other. The present analysis of the different forms of interrogative sentences in both languages can be used by language learners as well as linguists for further research. Without claiming to be exhaustive, the analyzes available so far form a first insight into and an overview of the various interrogative sentences and their respective constructions in general, as well as with regard to their roles in the Albanian and German languages in particular. In the best case, the work should serve as a basis for teaching and learning materials and close a gap in the research field of contrastive linguistics.												0	0												2022		40					291	314		10.31902/fll.40.2022.15	http://dx.doi.org/10.31902/fll.40.2022.15												2026-01-16	WOS:000946298900015
J	Zulfiqar, I; Moerel, M; Formisano, E				Zulfiqar, Isma; Moerel, Michelle; Formisano, Elia			Spectro-Temporal Processing in a Two-Stream Computational Model of Auditory Cortex	FRONTIERS IN COMPUTATIONAL NEUROSCIENCE				Article								Neural processing of sounds in the dorsal and ventral streams of the (human) auditory cortex is optimized for analyzing fine-grained temporal and spectral information, respectively. Here we use a Wilson and Cowan firing-rate modeling framework to simulate spectro-temporal processing of sounds in these auditory streams and to investigate the link between neural population activity and behavioral results of psychoacoustic experiments. The proposed model consisted of two core (A1 and R, representing primary areas) and two belt (Slow and Fast, representing rostral and caudal processing respectively) areas, differing in terms of their spectral and temporal response properties. First, we simulated the responses to amplitude modulated (AM) noise and tones. In agreement with electrophysiological results, we observed an area-dependent transition from a temporal (synchronization) to a rate code when moving from low to high modulation rates. Simulated neural responses in a task of amplitude modulation detection suggested that thresholds derived from population responses in core areas closely resembled those of psychoacoustic experiments in human listeners. For tones, simulated modulation threshold functions were found to be dependent on the carrier frequency. Second, we simulated the responses to complex tones with missing fundamental stimuli and found that synchronization of responses in the Fast area accurately encoded pitch, with the strength of synchronization depending on number and order of harmonic components. Finally, using speech stimuli, we showed that the spectral and temporal structure of the speech was reflected in parallel by the modeled areas. The analyses highlighted that the Slow stream coded with high spectral precision the aspects of the speech signal characterized by slow temporal changes (e.g., prosody), while the Fast stream encoded primarily the faster changes (e.g., phonemes, consonants, temporal pitch). Interestingly, the pitch of a speaker was encoded both spatially (i.e., tonotopically) in Slow area and temporally in Fast area. Overall, performed simulations showed that the model is valuable for generating hypotheses on how the different cortical areas/streams may contribute toward behaviorally relevant aspects of auditory processing. The model can be used in combination with physiological models of neurovascular coupling to generate predictions for human functional MRI experiments.												17	17											JAN 22	2020	13								95	10.3389/fncom.2019.00095	http://dx.doi.org/10.3389/fncom.2019.00095												2026-01-16	WOS:000511353000001
J	Nikiforova, SV				Nikiforova, S., V			ETHNOGRAPHIC CINEMA: TO THE PROBLEM OF GENRE BOUNDARIES	TOMSKII ZHURNAL LINGVISTICHESKIKH I ANTROPOLOGICHESKIKH ISSLEDOVANII-TOMSK JOURNAL OF LINGUISTICS AND ANTHROPOLOGY				Article								We analyze "artistic and ethnographic" (as the authors position it) of the film "Yakut Wedding. XIX century" (2016), in which creation the leading ethnographers of the republic took an active part. The film is an example of anthropological staged movie. Visualization of the folklore text (wedding ceremony), as a parade, displays the cultural codes of the ethnos, a semiotic analysis of which is proposed in order to determine the genre specificity of ethnographic cinema. The film as a visual anthropological study of folklore text offers an interpretation of the chromatic code of the Yakut culture (analysis of the semantics of white in the culture of herders). The analysis of the musical and acoustic code is carried out: the bride's long song - reconstruction of the archaic meloform; analysis of intonation of the participants of the ritual as a speech characteristic. In addition, an analysis of the kinetic, culinary, and numerical codes of culture visualized in the film is presented. Based on the materials of festival cinema and the works of modern researchers in the field of visual anthropology, the characteristics of ethnographic cinema are generalized. Criteria are proposed, that distinguish ethnographic from other genres of documentary films. In our opinion, any representation, including a visual one made by a person about a person, is anthropological in nature. It is revealed that the genre of ethnographic cinema involves a detailed accented consideration of everyday life; search for similarities and differences of cultural texts; scientific commentary (interpretation); direction of collective perception (manipulation); creating the illusion of being here and now; the desire to convey the aura of culture as much as possible; implantation or indigenous films; "embed" the camera; "included" cinema, the achievement of naturalness; iconophobia "avoiding direct gaze "; the inclusion of the viewer in reflective activity (empathy); obligatory consonance of film aesthetics with aesthetics of culture; preference for the look of a "stranger "; "the illusion of a neutral observer". The features of the stylistics of cinematic ethnography of the Yakuts, the problems of mutual framing in multilevel and multivalent indigenous cinema are considered. It is proved that ethnographic cinema is not only a commentary on culture, and self-portrait is not an end in itself. The film is not limited to the experience of reconstruction of the rite, but it represents a mentality, is an act of self-awareness of culture.												1	1												2020		3					151	160		10.23951/2307-6119-2020-3-151-160	http://dx.doi.org/10.23951/2307-6119-2020-3-151-160												2026-01-16	WOS:000598754600014
J	Janssen, U; Domahs, F				Janssen, Ulrike; Domahs, Frank			Going on with optimised feet: Evidence for the interaction between segmental and metrical structure in phonological encoding from a case of primary progressive aphasia	APHASIOLOGY				Article								Background: Our knowledge about the interaction between segmental and metrical levels of representation in word production is still largely underspecified. In particular, there is only sparse evidence of how syllables are hierarchically organised into higher-level prosodic structures such as prosodic feet and words. Furthermore, the question whether stress assignment in German is sensitive to syllable weight is unresolved so far. While quantity-insensitive accounts state that stress is predominantly assigned to a default position (i.e., to the penultimate syllable) and other stress patterns are exceptional, quantity-sensitive accounts assume that stress assignment is determined by the weight of the final two syllables. Aims: Impaired lexical retrieval may lead to regularisations of stress assignment. Such an error pattern will be examined to gain insights into the interrelation between different tiers of prosodic representations (e.g., syllable, foot, prosodic word). Methods & Procedures: A reading and a repetition task were conducted with German-speaking patient HT, suffering from primary progressive aphasia, which especially affected her retrieval of lexical information. The material consisted of polysyllabic words with varying stress patterns and syllable structures. Outcomes & Results: In reading, HT produced hardly any segmental errors, but a substantial amount of stress errors. Importantly, the patient not only over-generalised the default penultimate stress as would have been predicted by quantity-insensitive approaches. Instead, she over-applied different stress patterns depending on the weight of the last two syllables. In repetition, HT's output can be characterised as phonological jargon. Crucially, however, she hardly produced any stress errors. Rather, thorough analyses revealed that segmental deviations in her output led to optimised prosodic structures. For instance, insertions of rhyme segments could be observed mainly in strong syllables, i.e., syllables bearing main or secondary stress, whereas deletions occurred predominantly in weak, unstressed syllables. Conclusions: The present data provide evidence for specific forms of interaction between segmental and metrical knowledge: On the one hand, segmental information influenced the patient's stress assignment errors in reading. On the other hand, prosodic information modified segmental errors even in severe jargon observed in repetition. With respect to the prosodic system of German, the observed error patterns show that the structure of the final syllable determines how syllables of a word are parsed into prosodic feet and, accordingly, which syllable has to be prominent. Thus, our results support quantity-sensitive approaches of stress assignment.												20	20												2008	22	11					1157	1175		10.1080/02687030701820436	http://dx.doi.org/10.1080/02687030701820436												2026-01-16	WOS:000260051900004
J	Pietrzak, W				Pietrzak, Wit			Lyric Poetry and the Disorientation of Empathy	JOURNAL OF LITERARY THEORY				Article								In the present essay, I argue that empathy constitutes the mode in which lyric poetry registers in the readers. However, unlike in prose, where the reader is allowed to empathize with the characters via the mediation of the narrator, in poetry, as Jonathan Culler and a number of other theoreticians of the lyric have indicated, the reader assumes the position of the speaker, thus becoming a reperformer of the text. This positioning, in turn, creates a situation in which the text, rather than representing a mental state, embodies it and in the process of being enacted impels the reader to internalize this state. I then move on to complement this distinction between poetry and prose by noting the fact that critics who explore how empathy is employed in reading fiction appear to depart from assumptions of comprehensibility and stability of the representations of characters' mental states. This is shown in the analysis of the work of such critics as Suzanne Keen and Liza Zunshine. By contrast, in lyric poetry, empathy is both necessitated and simultaneously disoriented through the discontinuous, open-ended nature of the poetic text. As a result, the reader is perpetually made to feel into the speaker's evocations of mental states but his or her empathic efforts are thwarted by the operations of the text in which a given affect is being evoked and disarticulated at the same time. This dialectic of empathy and disorientation is a dynamic process that can take various forms. In the last section of the present essay, I analyze three poems, "Punishment" by Seamus Heaney, "The Loaf" by Paul Muldoon and "Geis" by Caitriona O'Reilly, in order to show how the empathic impulse is both triggered and disoriented by the tensions between the poems' denotative meanings and their formal features, mainly prosody and rhyme scheme. Thus, a tentative conclusion is that lyric poetry's formal complexity and its non-mimetic nature enter into a dynamic relationship with the propositional content - a dynamic which contributes to the continual disorientation of our empathic capacity that is the essential form of our performance of the poetic text. This tension may manifest itself in how form and content challenge each other or how they cooperate, which in either case leaves us with a rather uncomfortable feeling of having witnessed not a representation of but an embodied, real-time moment of intimate and essentially aporetic experiential performance.												1	1											AUG 30	2022	16	2					351	369		10.1515/jlt-2022-2029	http://dx.doi.org/10.1515/jlt-2022-2029												2026-01-16	WOS:000869052100008
J	Rajendran, S; Jayagopal, P				Rajendran, Sukumar; Jayagopal, Prabhu			RETRACTED: Preserving learnability and intelligibility at the point of care with assimilation of different speech recognition techniques (Retracted Article)	INTERNATIONAL JOURNAL OF SPEECH TECHNOLOGY				Article; Retracted Publication								The neoteric introduction of 5G technology in mobile internet is transforming Internet of mobile Things (IoMT) massively by addressing low latency, support for a large number of IoMT devices, and less power consumption, thereby delivering cost-effective solutions to low-end devices. This transformational technology enables a ubiquitous connected critical communication network between the healthcare system and IoT, as they largely depend on low-end devices for gathering data at the point of care. Gathering and interpolation of data from things are moved over to the cloud, making the extraction of knowledge and decision-making capabilities more robust. Vocal signals form the basis of communication between human beings with the transfer of complex data with variations in thrust, pitch, and tones. The representation and recognition of these analog signals by digital systems prove to be quite exciting and challenging. The spoken language models are converted to digital signals to be identifiable based on different cues like phonetic, prosodic, phonotactic, and lexical features. Voice patterns tend to be specific for every individual with a slight orientation towards the language spoken by the individual of a particular region. While speech patterns tend to alter the meaning of words with tones, high and low pitches in the utterance of the words, NLP tends to learn specific associations of words through vectors. The focus on learned networks in solving the problem of speech synthesis to text with minimal loss and high predictability of syllable of word, sentence, and paraphrase is needed. The creation of a knowledge base corpus of learned variable prosody of features helps in the learnability of interestingness directly without any perturbations. The learning algorithms to realize the degree of understandability of speech with the word, sentence identified, and transcription with substantial noise interference. The transfer of the acoustic features learned by algorithms proves to be quiet challenging as they are distorted by sudden environmental changes. Syllable extracted from the speech translation may or may not represent the Sentiment of the word, with different phonetical modulation. Utilization of the MobileNets and DistillBERT to transfer the language extraction and the edge reducing the time of processing and reducing the corpus of the size, reducing the adversial learning of the voice features and the patterns, reducing the Transfer of learned corpus and patterns.												3	3											JUN	2020	23	2			SI		265	276		10.1007/s10772-020-09687-x	http://dx.doi.org/10.1007/s10772-020-09687-x		FEB 2020										2026-01-16	WOS:000516381300001
J	Maklyukova, OI				Maklyukova, Olesya I.			THE PARTICLE DA IN ANSWERS TO QUESTIONS (IN THE CONTEXT OF LEXICOGRAPHICAL PARAMETERIZATION)	TOMSK STATE UNIVERSITY JOURNAL				Article								Particles are very difficult for foreign students who study Russian, especially modal particles that are still poorly researched both theoretically and methodologically. A dictionary of particles for foreigners could meet this need. The special purpose of the dictionary requires new parameters for particle description. The author has analyzed the representation of particle DA in different dictionaries and concluded that the existing description cannot meet the goals. This article focuses on the description of the modal particle DA as functioning in speech acts, in particular, in answering a question. The author found out that DA is not used in initiating phrases. The meaning of modal particles derives from its pragmatic essence, so the author characterizes them in terms of pragmatic linguistics. Based on J. R. Searle's classification of speech acts (SA) and later researchers of SA (N.A. Trofimova and so on), the author has worked out her own classification of SA, in which the particle DA functions: a) representatives; b) directives; c) commisives; g) interrogatives; d) expressives. The author also has mixed SA, such as expressive directives and expressive interrogatives as a peculiarity for particle DA. Material for the analysis was the dialogical speech from fiction. The author notes that the difference between the natural dialogue and the fiction one is irrelevant. The analysis showed that the particle functions naturally in response phrases because the most common meaning for DA is a reference to the presupposition: "I say P, because you asked". DA is always used at the beginning of SA and connects the previous phrase (the question) to the next one (the answer), in other words, the role of DA is always to serve as a connector in a dialogue. In answering questions DA functions mainly in representatives, and is used with particles UZH, VOT, VED', as well as in interrogatives, together with particles RAZVE, ZH. All these particles make speech acts more expressive. The author has differentiated the general meaning of reference into more specific meanings depending on the tone of the phrases in which DA functions, and got seven meanings: 1) perplexity/bewilderment DA; 2) DA of reflections; 3) DA of reference to what was mentioned; 4) DA of reference to the experience of interlocutors and their knowledge of situation; 5) DA of reference to some components of the situation noticed only by the speaker; 6) DA of strengthening of emotions, mostly negative ones; 7) categorical/confident DA. In the first two groups DA is uttered in a little bit stretched manner, while in others it is uttered briefly, it emphasizes the proposition, thus, slow response contrasts with fast response. In all cases DA is unstressed.												0	0											AUG	2015		397					27	32		10.17223/15617793/397/5	http://dx.doi.org/10.17223/15617793/397/5												2026-01-16	WOS:000421019400005
J	Sankar, MSA; Sathidevi, PS				Sankar, M. S. Arun; Sathidevi, P. S.			An investigation on the degradation of different features extracted from the compressed American English speech using narrowband and wideband codecs	INTERNATIONAL JOURNAL OF SPEECH TECHNOLOGY				Article								Speech coding facilitates speech compression without perceptual loss that results in the elimination or deterioration of both speech and speaker specific features used for a wide range of applications like automatic speaker and speech recognition, biometric authentication, prosody evaluations etc. The present work investigates the effect of speech coding in the quality of features which include Mel Frequency Cepstral Coefficients, Gammatone Frequency Cepstral Coefficients, Power-Normalized Cepstral Coefficients, Perceptual Linear Prediction Cepstral Coefficients, Rasta-Perceptual Linear Prediction Cepstral Coefficients, Residue Cepstrum Coefficients and Linear Predictive Coding-derived cepstral coefficients extracted from codec compressed speech. The codecs selected for this study are G.711, G.729, G.722.2, Enhanced Voice Services, Mixed Excitation Linear Prediction and also three codecs based on compressive sensing frame work. The analysis also includes the variation in the quality of extracted features with various bit-rates supported by Enhanced Voice Services, G.722.2 and compressive sensing codecs. The quality analysis of extracted epochs, fundamental frequency and formants estimated from codec compressed speech was also performed here. In the case of various features extracted from the output of selected codecs, the variation introduced by Mixed Excitation Linear Prediction codec is the least due to its unique method for the representation of excitation. In the case of compressive sensing based codecs, there is a drastic improvement in the quality of extracted features with the augmentation of bit rate due to the waveform type coding used in compressive sensing based codecs. For the most popular Code Excited Linear Prediction codec based on Analysis-by-Synthesis coding paradigm, the impact of Linear Predictive Coding order in feature extraction is investigated. There is an improvement in the quality of extracted features with the order of linear prediction and the optimum performance is obtained for Linear Predictive Coding order between 20 and 30, and this varies with gender and statistical characteristics of speech. Even though the basic motive of a codec is to compress single voice source, the performance of codecs in multi speaker environment is also studied, which is the most common environment in majority of the speech processing applications. Here, the multi speaker environment with two speakers is considered and there is an augmentation in the quality of individual speeches with increase in diversity of mixtures that are passed through codecs. The perceptual quality of individual speeches extracted from the codec compressed speech is almost same for both Mixed Excitation Linear Prediction and Enhanced Voice Services codecs but regarding the preservation of features, the Mixed Excitation Linear Prediction codec has shown a superior performance over Enhanced Voice Services codec.												1	1											DEC	2018	21	4					861	876		10.1007/s10772-018-09559-5	http://dx.doi.org/10.1007/s10772-018-09559-5												2026-01-16	WOS:000452913900010
J	Prikhodovskaya, EA; Okisheva, AA				Prikhodovskaya, Ekaterina A.; Okisheva, Anna A.			COMPOSER-PERFORMING PRACTICE OF A PIANIST AS A WAY TO COMPREHEND THE FIGURATIVE-EMOTIONAL RANGE OF A MUSICAL WORK	VESTNIK TOMSKOGO GOSUDARSTVENNOGO UNIVERSITETA-KULTUROLOGIYA I ISKUSSTVOVEDENIE-TOMSK STATE UNIVERSITY JOURNAL OF CULTURAL STUDIES AND ART HISTORY				Article								The article discusses one of the methods for comprehending the content of a musical work through the interaction of the pianist's composing and performing practice. No one can deny that the listener "gets" a work only "from the hands" of the performerpianist, and if the composer is not a pianist, then the audience in the hall will inevitably receive the product of joint creativity. That is why it seems appropriate to talk about the fact of a single composing and performing practice, without special emphasis on the composing or performing component of the creative process. When such an intratextual structure as the figurative-emotional series of a work is brought to the fore, the line between the composer and the performer becomes even more blurred. Of course, one cannot speak of replacing one with another - each has its own field of activity but it seems to be quite adequate to assert the presence of some creative conglomerate. Of course, in every piece of music there are many components that must be observed by the performer unconditionally: size, key signs, etc. This article will focus specifically on the figurative and emotional content of the work. As you know, each performer expresses the vision of a musical work in his own way. From the side of performing practice, a detailed analysis of the Second Piano Concerto by Ekaterina Prikhodovskaya was carried out. It is interesting that the composition in question was created practically "in a dialogue" between the authors of the article - the composer who wrote the concerto for piano and orchestra, and the pianist for whom this concerto was written and dedicated. The compositions of Anna Okisheva are considered as a composer's activity. On the example of her own works, Anna Okisheva gives an associative analysis, using works of art and literature as an addition to the figurative-emotional range. The uniqueness of this method lies in the fact that the performer, being a composer, already has an idea of the figurative and emotional content. In this example, we clearly see the process of "encryption" and "decryption" of a musical composition. Together and separately, these works demonstrate a fairly extensive representation of the figurative and emotional range. Thanks to the appeal to related arts (in particular, literature and painting), a more accurate and versatile formulation of the fan-shaped model of the creative process occurs (it was specified earlier). So, there is an inseparable, perhaps invisible at first glance, interconnection between composing and performing practice. Comprehension of the figurative-emotional range of a musical work in fact, its content - is indeed the right way to create an incentive for cooperation between the composer, performer and listener (even taking into account time distances).												0	0											SEP	2022	47						190	203		10.17223/22220836/47/16	http://dx.doi.org/10.17223/22220836/47/16												2026-01-16	WOS:000870268600016
J	Nesterova, NG; Ju, CY				Nesterova, Natalia G.; Ju, Chuanya			Cultural and Educational Radio Discourse: On Basic Features and Communicative-Pragmatic Specifics	TOMSK STATE UNIVERSITY JOURNAL				Article								The article aims to consider cultural and educational radio discourse as a specific phenomenon, to describe its basic features and communicative and pragmatic specifics. The sources of the empirical material were the cultural and educational programs of the Echo of Moscow radio station arranged in the genre of conversation: Book Casino, Culture Shock, Non-Past Time released in 20112019, and listeners' comments. The archive of the contexts includes 1,290 statements of the hosts and guests of the studio, 297 comments. The material was analyzed in three stages: 1) listening to the on-air recording: the communicative intentions of the program participants were determined, taking into account the intonation features of the interlocutors' speech; 2) describing the linguistic means of implementing communicative tactics, taking into account the contextual use; 3) analyzing listeners' comments on the basis of comprehending the communicative situation of the program the comment was on, the intentions expressed by the author, and the contextual use of linguistic units. The study employed a communicative-pragmatic approach, implemented by a number of methods. The method of discourse analysis was used to determine the structure of radio discourse, to identify cultural and educational radio discourse as its segment, to argue for the inclusion of listeners' comments in the studied discourse field. The method of intent analysis was used to identify communicative tactics. The linguistic representation of strategies and tactics was examined using linguistic analysis, including the contextual analysis of linguistic units. The basic features of cultural and educational radio discourse were described according to the following parameters: communicative goal, subject matter, distribution channel, type of authorship, forms of existence, functional-genre type, way of perception, participants. It has been substantiated that the communicative goal of education in the sphere of culture is specific; it shapes the studied variety of discourse. The hosts determine the organization of the discourse. Guests play the dominant role in providing the content of the program. Listeners participate in communication as equal participants. Based on the basic features, cultural and educational radio discourse is defined as a type of radio discourse, which is distinguished by the communicative goal of education in the field of culture, which determines the topics of the programs, the choice of communication strategies and tactics, the nature of the speech behavior of the participants in communication. The communicative and pragmatic specifics of cultural and educational radio discourse have been analyzed through the study of the strategies of: (1) presentation of the guest of the program, (2) discussion of the cultural event, (3) evaluation of the presenters of the program in listeners' (addressees') comments. It has been revealed that the statements of program participants and listeners are replete with linguistic units with pragmatic potential that develops the cognitive sphere of the addressee.												0	0											DEC	2020		461					45	56		10.17223/15617793/461/6	http://dx.doi.org/10.17223/15617793/461/6												2026-01-16	WOS:000624433400006
J	Ankita; Shahnawazuddin, S				Ankita; Shahnawazuddin, S.			Developing children's ASR system under low-resource conditions using end-to-end architecture	DIGITAL SIGNAL PROCESSING				Article								The work presented in this paper aims at enhancing the performance of end -to -end (E2E) speech recognition task for children's speech under low resource conditions. For majority of the languages, there is hardly any speech data from child speakers. Furthermore, even the available children's speech corpora are limited in terms of the number of hours of data. On the other hand, large amounts of adults' speech data are freely available for research as well as commercial purposes. As a consequence, developing an effective E2E automatic speech recognition (ASR) system for children becomes a very challenging task. One may develop an ASR system using adults' speech and then use it to transcribe children's data, but this leads to very poor recognition rates due to the stark differences in the acoustic attributes of adults' and children's speech. In order to overcome these hurdles and to develop a robust children's ASR system employing E2E architecture, we have resorted to several out -of -domain and in -domain data augmentation techniques. For out -of -domain data augmentation, we have explicitly modified adults' speech to render it acoustically similar to that of children's speech before pooling into training. On the other hand, in the case of in -domain data augmentation, we have slightly modified the pitch and duration of children's speech in order to create more data capturing greater diversity. Data augmentation approaches helps in mitigating the ill-effects resulting from the scarcity of data from child domain to a certain extent. This, in turn, reduces the error rates by a large margin. In addition to data augmentation, we have also studied the efficacy of Gamma -tone frequency cepstral coefficients (GFCC) and frequency domain linear prediction (FDLP) technique along with the most commonly used Mel -frequency cepstral coefficients (MFCC) for front-end speech parameterization. Both MFCC as well as GFCC capture and model the spectral envelope of speech. On the other hand, application of linear prediction on the frequency domain representation of speech signal helps to effectively capture the temporal envelope during front-end feature extraction. Employing FDLP features that model the temporal envelope provides important cues for the perception and understanding of stop bursts and, at times, complete phonemes. This motivated us to perform a comparative experimental study of the effectiveness of the three aforementioned front-end acoustic features. In our experimental explorations, the use of proposed data augmentation in combination of FDLP features has shown a relative improvement in character error rate by 67.6% over the baseline system. The combination of data augmentation with MFCC or GFCC features is observed to result in lower recognition performances.												5	7											MAR	2024	146								104385	10.1016/j.dsp.2024.104385	http://dx.doi.org/10.1016/j.dsp.2024.104385		JAN 2024										2026-01-16	WOS:001156449400001
J	Perfilyeva, NP				Perfilyeva, Nataliya P.			ON THE CONCEPT OF A SYSTEMIC DICTIONARY OF META-INDICATORS	VOPROSY LEKSIKOGRAFII-RUSSIAN JOURNAL OF LEXICOGRAPHY				Article								The multidimensional illustrative dictionary of meta-indicators includes lexemes, phraseological units and word combinations that regularly explicate metatext in A. Wierzbicka's interpretation. The aim of the article is to substantiate the expediency of the composition of the dictionary entry and the depth of the description of its components (zones, lexicographic parameters) and to show the dependence of the lexicographic type of meta-indicators on the number of lexicographic parameters and their specifics. Each lexicographic type of metatextual indicators is a group of dictionary units selected on the basis of a set of interconnected integral and differential heterogeneous lexicographic parameters, description zones. Variants of dictionary entries represent three lexicographic types of meta-indicators: connectors (takim obrazom 'this way', prezhde vsego 'first of all', slovom 'in a word', itak 'so', nakonets 'finally', vo-pervykh 'firstly'), quasiperformatives (povtoryu 'I'll repeat', dobavlyu I'll add') and semasiological metaelements (v pryamom smysle 'literally', v polnom smysle slova 'in the full sense of the word', v plokhom smysle slova 'in a bad sense of the word', obrazno govorya 'figuratively speaking'). The dictionary entry is considered as a text consisting of several zones. A zone is understood as a compositional part of a dictionary entry that has a length from a word to a complex syntactic unit, represents areas of the description of a dictionary unit in a certain aspect, is characterised by the integrity of the representation of this information and contains one (or more) lexicographic parameter. Dictionary entries have the same set of mandatory lexicographic parameters and differ in the number of zones and optional lexicographic parameters. Obligatory parameters include the following zones: the title with mandatory (spelling) and optional (information on the variation of the meta-indicator expression and on the grammatical paradigm of some vocabulary units) parameters; the scope of operation with mandatory parameters (distribution characteristic of the dictionary unit, the scope of its operation, the range of the meta-indicator); the status in the language system with mandatory (grammatical qualification of the dictionary unit) and optional (prosody, punctuation and functional homonymy) parameters; semantics with mandatory (interpretation, pragmatic program, functional-stylistic) and optional (synonyms, negative material) parameters. "Formal functions" is an optional zone. In the dictionary of meta-indicators a dictionary entry includes up to seven zones and 14 lexicographic parameters that reflect the word-and text-centered, systemic-structural approaches to the study of metatext and naturally connect information of different sections of linguistics and semiotics. Lexicographic units of the same type have minor variations of the set of lexicographic parameters quantitatively (1-2), e.g., dictionary entries of connector meta-indicators may vary in the presence / absence of the functional homonymy zone in lexical units. Different types of lexicographic meta-indicators are identified based on (1) the number of zones and lexicographic parameters; (2) differential lexicographic parameters.												0	0												2017	12						61	82		10.17223/22274200/12/4	http://dx.doi.org/10.17223/22274200/12/4												2026-01-16	WOS:000424306500004
J	Arras, T; Rachman, L; van Wieringen, A; Baskent, D				Arras, Tine; Rachman, Laura; van Wieringen, Astrid; Baskent, Deniz			Perception of voice cues and speech-in-speech by children with prelingual single-sided deafness and a cochlear implant	HEARING RESEARCH				Article								Voice cues, such as fundamental frequency (F0) and vocal tract length (VTL), help listeners identify the speaker's gender, perceive the linguistic and emotional prosody, and segregate competing talkers. Postlingually implanted adult cochlear implant (CI) users seem to have difficulty in perceiving and making use of voice cues, especially of VTL. Early implanted child CI users, in contrast, perceive and make use of both voice cues better than CI adults, and in patterns similar to their peers with normal hearing (NH). In our study, we investigated the perception and use of voice cues in children with single-sided deafness (SSD) who received their CI at an early age (SSD+CI), in an attempt to bridge the gap between these two groups. The SSD+CI children have access to bilateral auditory information and often receive their CI at an early age, similar to CI children. They may also have dominant acoustic representations, similar to CI adults who acquired hearing loss at a later age. As such, the current study aimed to investigate the perception and use of voice cues by a group of nine early-implanted children with prelingual SSD. The study consisted of three experiments: F0 and VTL discrimination, voice gender categorization, and speech-in-speech perception. In each experiment, the results of the SSD group are compared to children and adults with CIs (for their CI ear) and with typical hearing (for their NH ear). Overall, the SSD+CI children had poorer VTL detection thresholds with their CI compared to their NH ear, while their F0 perception was similar across ears. Detection thresholds for both F0 and VTL with their CI ear was comparable to those of bilaterally implanted CI children, suggesting that SSD+CI children do not only rely on their NH ear, but actually make use of their CI. SSD+CI children relied more heavily on F0 cues than on VTL cues for voice gender categorization, with cue weighting patterns comparable to those of CI adults. In contrast to CI children, the SSD+CI children showed limited speech perception benefit based on F0 and VTL differences between the target and masker speaker, which again corresponded to the results of CI adults. Altogether, the SSD+CI children make good use of their CI, despite a good-hearing ear, however, the perceptual patterns seem to fall in-between those of CI children and CI adults. Perhaps a combination of childhood neuroplasticity, limited experience with relying only on the CI, and a dominant acoustic representation of voice gender explain these results.												1	2											DEC	2024	454								109133	10.1016/j.heares.2024.109133	http://dx.doi.org/10.1016/j.heares.2024.109133		NOV 2024										2026-01-16	WOS:001359183900001
J	Tikhomirova, YA				Tikhomirova, Yulia A.			A.S. PUSHKIN IN MODERN ENGLISH TRANSLATIONS: STRATEGIES OF POETRY REPRESENTATION	TOMSK STATE UNIVERSITY JOURNAL				Article								Despite all the two-centuries long efforts of numerous translators to render A.S. Pushkin's lyric poetry into English, an English-speaking reader still has not acquired more or less adequate idea about it, as stated by many renowned scholars and translators themselves. The very features of Pushkin's lyric text structure and poetics account for it: he can't be adequately translated because the base of Pushkin's poetic style is a masterful and delightful use of all the shades of meaning which is imparted to the language by the existence of case inflections and a free word order. The absence of them in the target language gives some ''straightforwardness'' to translations' style; the themes and literary images turn out plain and simple. But the interest to Pushkin's poetry on behalf of the English-speaking word-cultures has been genuine and intense, which is obvious from a great number of new continuously emerging translations and translation projects. Without claiming to be a comprehensive survey of all modern translations from Pushkin, this paper focuses on several most recent and interesting issues of Pushkin's poetry in English. One of the strategies to be most productive and relevant to the material is the strategy which has been demonstrated by the translator Julian Henry Lowenfeld. His is the strategy of vocal translation, mostly used to render the texts which display a rhythmical and intonation structure, which is adopted to musical melody and inseparable from it. The existence of this melodic base gives the opportunity to hold the text in memory and enables the translator to find adequate imagery, stylistic, rhythmical and phonetic means of rendering the stylistic effect of the original text. The translator himself names the sense of rhythm among the most important qualities in translating Pushkin's verse. The above-mentioned strategy is opposed to another one, which has been demonstrated in one of the recent editions of Pushkin's poetry in English: ''After Pushkin. Versions of the poems of Alexander Sergeevich Pushkin by contemporary poets'', 1999. On reading this edition which in its contents presents the most traditional set of Pushkin's poetry, readers' expectations turn out to be completely ruined. In some translations Pushkin appears a modernist, in others - an existentialist; some translations in their poetic quality are very much akin to Pushkin's poetics style and adequately represent his style, some of them clearly present word-for-word translations. And in the context of this edition these word-for-word translations acquire the status of an aesthetic phenomenon. The very Pushkin's conception of poetic creativity seems to have fallen apart and is presented through individual conceptions of his interpreters, which is demonstrated by the peculiarities of translations' poetics, new text titles, as well as stated in the editor's introductory word, who comments on the working principles of various translations' authors. Notwithstanding the difference in the approach principles to the material for translation, the strategies described imply one and the same aim: to help an English- speaking reader answer the question: why Pushkin stand side by side with Byron, Shakespeare, Goethe and other genius men of the world word- culture.												4	4											AUG	2013		373					29	+															2026-01-16	WOS:000421549200005
J	Siedenburg, K; Graves, J; Pressnitzer, D				Siedenburg, Kai; Graves, Jackson; Pressnitzer, Daniel			A unitary model of auditory frequency change perception	PLOS COMPUTATIONAL BIOLOGY				Article								Author summaryAs we speak or play music, the sounds we produce change their frequency content over time. Perceiving such frequency changes is crucial to e.g. differentiating vowels and understanding prosody in speech, or following melodies in music. Traditionally, such frequency changes have been described as perceptual changes in "pitch" or "timbre", with some contradictory experimental findings as to the independence between such dimensions. Here, we study frequency change perception by generalizing a classic auditory stimulus, the so-called Shepard tones, in order to concurrently manipulate acoustic cues to pitch and timbre in fully symmetric and parametric manner. Our main conclusion is that listeners use a compound perceptual dimension to achieve the ecological task of tracking frequency-change across sounds. Interestingly, this dimension can be modeled as an adaptive combination of acoustic cues, weighted according to task demands and listener-specific biases. In addition to suggesting a resolution for discrepancies in the pitch literature, our model reveals basic analogies between the seemingly mysterious concepts of "pitch" and "timbre" and other perceptual dimensions, such as auditory space, which have long been known to be derived from cue combination. Changes in the frequency content of sounds over time are arguably the most basic form of information about the behavior of sound-emitting objects. In perceptual studies, such changes have mostly been investigated separately, as aspects of either pitch or timbre. Here, we propose a unitary account of "up" and "down" subjective judgments of frequency change, based on a model combining auditory correlates of acoustic cues in a sound-specific and listener-specific manner. To do so, we introduce a generalized version of so-called Shepard tones, allowing symmetric manipulations of spectral information on a fine scale, usually associated to pitch (spectral fine structure, SFS), and on a coarse scale, usually associated timbre (spectral envelope, SE). In a series of behavioral experiments, listeners reported "up" or "down" shifts across pairs of generalized Shepard tones that differed in SFS, in SE, or in both. We observed the classic properties of Shepard tones for either SFS or SE shifts: subjective judgements followed the smallest log-frequency change direction, with cases of ambiguity and circularity. Interestingly, when both SFS and SE changes were applied concurrently (synergistically or antagonistically), we observed a trade-off between cues. Listeners were encouraged to report when they perceived "both" directions of change concurrently, but this rarely happened, suggesting a unitary percept. A computational model could accurately fit the behavioral data by combining different cues reflecting frequency changes after auditory filtering. The model revealed that cue weighting depended on the nature of the sound. When presented with harmonic sounds, listeners put more weight on SFS-related cues, whereas inharmonic sounds led to more weight on SE-related cues. Moreover, these stimulus-based factors were modulated by inter-individual differences, revealing variability across listeners in the detailed recipe for "up" and "down" judgments. We argue that frequency changes are tracked perceptually via the adaptive combination of a diverse set of cues, in a manner that is in fact similar to the derivation of other basic auditory dimensions such as spatial location.												7	10											JAN	2023	19	1							e1010307	10.1371/journal.pcbi.1010307	http://dx.doi.org/10.1371/journal.pcbi.1010307												2026-01-16	WOS:000944258700001
J	Kotzé, E				Kotze, Ernst			An orthographic bridge between Japanese and Afrikaans - the choice of a roman transliteration system	TYDSKRIF VIR GEESTESWETENSKAPPE				Article								In this article the focus is on the linguistic, and more particularly the orthographic, aspect of a translating dictionary between Afrikaans and Japanese to be published shortly. The orthographic aspect specifically relates to the transliteration of the indigenous Japanese script in the roman alphabet and the linguistic considerations which influenced the choice of particular forms. The fact that the two languages are typologically, genealogically and geographically as far apart as is possible on this planet, brings about certain challenges to ensure optimal accessibility to the other language, and in particular to Japanese. These challenges led to decisions regarding the representation of Japanese words written in the roman alphabet this forms the basis of the article. Japanese utilises various systems of writing, but the most general and default form is the logographic writing system, which is based on Chinese. This fact makes it extremely difficult for the average Western learner of Japanese to master simultaneously the orthography, the pronunciation and grammar of the language. Unlike Chinese, Japanese utilises, in addition to the logographic system (kanji), also a phonetic system of 46 basic syllabic symbols (hiragana), mainly to represent grammatical words and affixes, but also as pronunciation guidance for words written in kanji. A parallel phonetic system (also 46 symbols), to wit katakana, which is a mirror image of hiragana, is used for loan words, to express emphasis, for onomatopoeic words, terminology and some names of Japanese companies and products. In addition to the abovementioned writing systems, Japanese is also written in the roman alphabet. Three comparable writing systems exist, namely the so-called Hepburn-system (or Hebon-shiki), Kunrei-shiki, and Nihon-shiki. In Japanese, the systems are collectively known as roomaji [ro:mad3i 1, and all Japanese already learn at primary school level to use one of the systems, in particular Kunrei-shiki. (In translating dictionaries a choice for a specific system is normally done, mostly for Hebon-shiki, or adapted versions, for reasons to be discussed shortly) In short, romanised Japanese is used predominantly to make texts accessible to non-Japanese foreigners, while the logographic-cum-syllabic system is used by Japanese among themselves. As an introduction, an outline is given of the historical development of roomaji from the first Japanese-Portuguese dictionary in 1603 to the present-day situation. One of the functionally most important reasons for the use of roomaji in handbooks and dictionaries for foreigners is that it enables the learner to concentrate from the outset on the grammar and pronunciation of the language a much simpler task than first having to learn to read and write logographically. Unlike in the case of inflecting languages, the grammar ofJapanese is also relatively uncomplicated One would hence be able to regard the use of a roomaji orthography as a bridgingfacility, until such time as the learner ofJapanese has become conversant with the indigenous writing system(s). A further contributing factor is the fact that logographic-syllabic writing does not utilise spaces between words, so that syntactic and morphological categories in Japanese operate invisibly at the level of orthography. In Afrikaans, spacing of words is naturally of importance, because it is one of the ways to distinguish between affixes and independent grammatical words. By way of example: Ek gebruik 'n Powerpoint-aanbieding vir my voordrag. (I use a PowerPoint presentation for my address) In this sentence, all kanji symbols are black, katakana (for loanwords from Western languages) blue, and hiragana (for affixes and particles) red. If the Japanese sentence is romanised, the orthographic parsing becomes visible: [GRAPHICS] Although orthographical differences form the most important category, the spectrum of dfferences can be divided as follows: (a) Typological (Japanese as agglutinating language, as against the semi-inflecting, analytical nature of Afrikaans) (b) Grammatical (a corollary of typological differences) (c) Phonological (opposite complexities as regards the vocalism compared to the consonantism) (d) Orthographical (an alphabetic -phonological system in Afrikaans, as against a combination of an ideo-or logogrammatical and a syllabic-moraic system in the case of Japanese) As regards typological differences, the combination with indigenous agglutinating languages is not unusual for Afrikaans a facilitating factor being that (especially as regards the Nguni languages) a mutual orthography is used, which simplifies access to both languages considerably. In the case of Japanese, however, it is a crucial factor as is demonstrated in the article. Grammatical differences of importance are found in particular at the level of morphology, such as the processes of word formation and derivation. As far as phonological differences are concerned, the most important difference regarding the roman systems of writing is the fact that the length of both Japanese vowels and consonants is reflected in the spelling in terms of the number of morae. In Afrikaans, vowel length and the doubling of consonants (at least as they are reflected in the orthography) have different functions, as will be indicated below Regarding Japanese, the doubling of a vowel mora (or lengthening of a vowel) could be indicated in roomaji by: (a) doubling the vowel letter kankyoo (environment) seesan (production) shoyuu (posession) (b) adding an i or u to the relevant syllabic single vowel, as is done also in the hiragana syllabarium (also in Nihon-shiki and Kunrei-shiki) Or (c) by placing a macron on the relevant vowel letter (as in Hebon-shiki), particularly o and As regards consonants, the roomaji character is always doubled, and the pronunciation of the consonant also lasts two counts, as in the sentence: Vowel length in Afrikaans is only semantically distinctive in the case of one vowel, namely /a/ as against /a:/ (for instance mat [mat] versus maat [ma:t]), and a long /a:/ is also written as one letter in open syllables, for example in mate. The doubling of consonants, on the other hand, unlike Japanese, determines the nature of the vowel in the preceding closed syllable (as in wette/wete [veta], bosse/bose). In view of these differences (as well as some grammatical considerations explicated in the article), some of the choices made at the various levels of description will now be highlighted. Firstly, to express a double vowel mora, the doubling of vowel letters was preferred above the addition of u or i, because the combination of o+u and e+i in both cases represent diphtongs in Afrikaans, and could hence be misleading to learners attempting to interpret the pronunciation. Naturally, when u and i introduce a new syllable, as in ou above and omou, the sequence is written as such, since the second vowel in the sequence representsthe sound which occurs in the diphthong. An example from the text: In some dictionaries attempts are made to reflect the prosody (for instance tone accent) in the roomaji orthography to assist the learner. An investigation of such attempts led to the conclusion that the result would render the text more cumbersome and have restricted utility only. Furthermore, the kana orthography, which does not contain such prosodic indicators, is more transparent, without the encumbrance of diacritic symbols, in reflecting individual speech sounds from a segmental perspective. For this reason it was decided not to use prosodic markers, but to supplement the orthographic representation of all Japanese lemmas, as in the case of Afrikaans, by means of a sound bite accessible via a hyperlink in the text, in which the lemma is pronounced by a mother tongue speaker. As far as the morphology is concerned: Because Japanese verb forms which are derived by means of the verb sum (meaning do or make) from nouns, and sometimes adjectives, are mostly translated as a single word in Afrikaans, the Japanese verb in roomaji is also written as a single compound verb (by means of a hyphen). If adjectival or adverbial derivations are formed in Japanese by means of the addition of the suffixes na or ni, such derivations are also written as hyphenated words, as in: In the case of compounds, the principle is likewise applied that such items, when not linked by means of the genitive particle no, represent single words, mostly written with a hyphen, especially when word length could represent an obstacle: A last morphological consideration is the use of honorific prefixes before nouns, which are an unusual morpheme forAfrikaans learners of Japanese, and would thus require the use of a hyphen, as in the case of o- (prefix to tanjoobi 'birthday): The list of directives is obviously not exhaustive. By scrutinising some selected categories, an element of academic precision (and accountability) could be applied in the process of compiling a dictionary in which a common orthography is used with a view to bridge a gap and facilitate mutual access to Afrikaans and Japanese for speakers of the two languages.												0	0											JUN	2016	56	2					438	453		10.17159/2224-7912/2016/v56n2-1a9	http://dx.doi.org/10.17159/2224-7912/2016/v56n2-1a9												2026-01-16	WOS:000378469600010
