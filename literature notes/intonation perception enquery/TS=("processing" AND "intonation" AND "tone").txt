PT	AU	BA	BE	GP	AF	BF	CA	TI	SO	SE	BS	LA	DT	CT	CY	CL	SP	HO	DE	ID	AB	C1	C3	RP	EM	RI	OI	FU	FP	FX	CR	NR	TC	Z9	U1	U2	PU	PI	PA	SN	EI	BN	J9	JI	PD	PY	VL	IS	PN	SU	SI	MA	BP	EP	AR	DI	DL	D2	EA	PG	WC	WE	SC	GA	PM	OA	HC	HP	DA	UT
J	Wang, L; Xiao, SR; Jiang, CM; Hou, QQ; Chan, AHD; Wong, PCM; Liu, F				Wang, Li; Xiao, Sanrong; Jiang, Cunmei; Hou, Qingqi; Chan, Alice H. D.; Wong, Patrick C. M.; Liu, Fang			The form and function processing of lexical tone and intonation in tone-language-speaking children with autism spectrum disorder	JOURNAL OF THE ACOUSTICAL SOCIETY OF AMERICA				Article								Studies on how the form versus function aspect of tone and intonation is processed by autistic individuals have mainly focused on speakers of non-tonal languages (e.g., English) with equivocal results. While the samples' heterogeneous cognitive abilities may be contributing factors, the phenotype of tone and intonation processing in autism may also vary with one's language background. Thirty-eight cognitively able autistic and 32 non-autistic Mandarin-speaking children completed tone and intonation perception tasks, each containing a function and form condition. Results suggested that the abilities to discriminate tone and intonation were not impaired at either the form or function level in these autistic children, and that these abilities were positively associated with one another in both autistic and non-autistic groups. The more severe the autism symptoms, the worse the form- and function-level of tone and intonation processing. While enhanced tone and intonation processing has been found in a subgroup of autistic children, it may not be a general characteristic of the autistic population with long-term tone language experience. These findings reveal typical tone and intonation processing at both the form and function levels in cognitively able Mandarin-speaking autistic children and provide evidence for associated tone and intonation processing abilities across levels.												5	5											JUL	2023	154	1					467	481		10.1121/10.0020271	http://dx.doi.org/10.1121/10.0020271												2026-01-16	WOS:001036228000003
J	Chien, PJ; Friederici, AD; Hartwigsen, G; Sammler, D				Chien, Pei-Ju; Friederici, Angela D.; Hartwigsen, Gesa; Sammler, Daniela			Intonation processing increases task-specific fronto-temporal connectivity in tonal language speakers	HUMAN BRAIN MAPPING				Article								Language comprehension depends on tight functional interactions between distributed brain regions. While these interactions are established for semantic and syntactic processes, the functional network of speech intonation - the linguistic variation of pitch - has been scarcely defined. Particularly little is known about intonation in tonal languages, in which pitch not only serves intonation but also expresses meaning via lexical tones. The present study used psychophysiological interaction analyses of functional magnetic resonance imaging data to characterise the neural networks underlying intonation and tone processing in native Mandarin Chinese speakers. Participants categorised either intonation or tone of monosyllabic Mandarin words that gradually varied between statement and question and between Tone 2 and Tone 4. Intonation processing induced bilateral fronto-temporal activity and increased functional connectivity between left inferior frontal gyrus and bilateral temporal regions, likely linking auditory perception and labelling of intonation categories in a phonological network. Tone processing induced bilateral temporal activity, associated with the auditory representation of tonal (phonemic) categories. Together, the present data demonstrate the breadth of the functional intonation network in a tonal language including higher-level phonological processes in addition to auditory representations common to both intonation and tone.												10	11											JAN	2021	42	1					161	174		10.1002/hbm.25214	http://dx.doi.org/10.1002/hbm.25214		SEP 2020										2026-01-16	WOS:000573645300001
J	Tang, LR; Xu, YXX; Yang, ST; Meng, XY; Du, BQ; Sun, C; Liu, L; Dong, Q; Nan, Y				Tang, Lirong; Xu, Yangxiaoxue; Yang, Shiting; Meng, Xiangyun; Du, Boqi; Sun, Chen; Liu, Li; Dong, Qi; Nan, Yun			Mandarin-Speaking Amusics' Online Recognition of Tone and Intonation	JOURNAL OF SPEECH LANGUAGE AND HEARING RESEARCH				Article								Purpose: Congenital amusia is a neurogenetic disorder of musical pitch processing. Its linguistic consequences have been examined separately for speech intonations and lexical tones. However, in a tonal language such as Chinese, the processing of intonations and lexical tones interacts with each other during online speech perception. Whether and how the musical pitch disorder might affect linguistic pitch processing during online speech perception remains unknown. Method: We investigated this question with intonation (question vs. statement) and lexical tone (rising Tone 2 vs. falling Tone 4) identification tasks using the same set of sentences, comparing behavioral and event -related potential measurements between Mandarin -speaking amusics and matched controls. We specifically focused on the amusics without behavioral lexical tone deficits (the majority, i.e., pure amusics). Results: Results showed that, despite relative to normal performance when tested in word lexical tone test, pure amusics demonstrated inferior recognition than controls during sentence tone and intonation identification. Compared to controls, pure amusics had larger N400 amplitudes in question stimuli during tone task and smaller P600 amplitudes in intonation task. Conclusion: These data indicate that musical pitch disorder affects both tone and intonation processing during sentence processing even for pure amusics, whose lexical tone processing was intact when tested with words.												0	0											APR	2024	67	4					1107	1116		10.1044/2024_JSLHR-23-00520	http://dx.doi.org/10.1044/2024_JSLHR-23-00520												2026-01-16	WOS:001244512900006
J	Liu, M; Chen, YY; Schiller, NO				Liu, Min; Chen, Yiya; Schiller, Niels O.			Online processing of tone and intonation in Mandarin: Evidence from ERPs	NEUROPSYCHOLOGIA				Article								Event-related potentials (ERPs) were used to investigate the online processing of tone and intonation in Mandarin at the attentive stage. We examined the behavioral and electrophysiological responses of native Mandarin listeners to Mandarin sentences, which contrast in final tones (rising Tone2 or falling Tone4) and intonations (Question or Statement). A clear P300 effect was observed for question-statement contrast in sentences ending with Tone4, but no ERP effect was found for question-statement contrast in sentences ending with Tone2. Our results provide ERP evidence for the interaction of tone and intonation in Mandarin, confirming the findings with behavioral metalinguistic data that native Mandarin listeners can distinguish between question intonation and statement intonation when the intonation is associated with a final Tone4, but fail to do so when the intonation is associated with a final Tone2. Our study extended the understanding of online processing of tone and intonation (1) from the pre-attentive stage to the attentive stage and (2) within a larger domain (i.e. multi-word utterances) than a single word utterance. (C) 2016 Elsevier Ltd. All rights reserved.												17	17											OCT	2016	91						307	317		10.1016/j.neuropsychologia.2016.08.025	http://dx.doi.org/10.1016/j.neuropsychologia.2016.08.025												2026-01-16	WOS:000387194200027
J	Liu, M; Chen, YY; Schiller, NO				Liu, Min; Chen, Yiya; Schiller, Niels O.			Context Matters for Tone and Intonation Processing in Mandarin	LANGUAGE AND SPEECH				Article								In tonal languages such as Mandarin, both lexical tone and sentence intonation are primarily signaled by F0. Their F0 encodings are sometimes in conflict and sometimes in congruency. The present study investigated how tone and intonation, with F0 encodings in conflict or in congruency, are processed and how semantic context may affect their processing. To this end, tone and intonation identification experiments were conducted in both semantically neutral and constraining contexts. Results showed that the overall performance of tone identification was better than that of intonation. Specifically, tone identification was seldom affected by intonation information irrespective of semantic contexts. However, intonation identification, particularly question intonation, was susceptible to the final lexical tone identity and affected by the semantic context. In the semantically neutral context, questions ending with a rising tone and a falling tone were equally difficult to identify. In the semantically constraining context, questions ending with a falling tone were much better identified than those ending with a rising tone. This perceptual asymmetry suggests that top-down information provided by the semantically constraining context can play a facilitating role for listeners to disentangle intonational information from tonal information, but mainly in sentences with the lexical falling tone in the final position.												6	6											MAR	2022	65	1					52	72	0023830920986174	10.1177/0023830920986174	http://dx.doi.org/10.1177/0023830920986174		JAN 2021										2026-01-16	WOS:000618452600001
J	Wang, HLS; Chen, IC; Chiang, CH; Lai, YH; Tsao, Y				Wang, Hsiao-Lan S.; Chen, I-Chen; Chiang, Chun-Han; Lai, Ying-Hui; Tsao, Yu			Auditory Perception, Suprasegmental Speech Processing, and Vocabulary Development in Chinese Preschoolers	PERCEPTUAL AND MOTOR SKILLS				Article								The current study examined the associations between basic auditory perception, speech prosodic processing, and vocabulary development in Chinese kindergartners, specifically, whether early basic auditory perception may be related to linguistic prosodic processing in Chinese Mandarin vocabulary acquisition. A series of language, auditory, and linguistic prosodic tests were given to 100 preschool children who had not yet learned how to read Chinese characters. The results suggested that lexical tone sensitivity and intonation production were significantly correlated with children's general vocabulary abilities. In particular, tone awareness was associated with comprehensive language development, whereas intonation production was associated with both comprehensive and expressive language development. Regression analyses revealed that tone sensitivity accounted for 36% of the unique variance in vocabulary development, whereas intonation production accounted for 6% of the variance in vocabulary development. Moreover, auditory frequency discrimination was significantly correlated with lexical tone sensitivity, syllable duration discrimination, and intonation production in Mandarin Chinese. Also it provided significant contributions to tone sensitivity and intonation production. Auditory frequency discrimination may indirectly affect early vocabulary development through Chinese speech prosody.												8	10											OCT	2016	123	2					365	382		10.1177/0031512516663164	http://dx.doi.org/10.1177/0031512516663164												2026-01-16	WOS:000382950300001
J	Zhang, GY; Shao, J; Zhang, CC; Wang, L				Zhang, Gaoyuan; Shao, Jing; Zhang, Caicai; Wang, Lan			The Perception of Lexical Tone and Intonation in Whispered Speech by Mandarin-Speaking Congenital Amusics	JOURNAL OF SPEECH LANGUAGE AND HEARING RESEARCH				Article								Purpose: A fundamental feature of human speech is variation, including the manner of phonation, as exemplified in the case of whispered speech. In this study, we employed whispered speech to examine an unresolved issue about congenital amusia, a neurodevelopmental disorder of musical pitch processing, which also affects speech pitch processing such as lexical tone and intonation perception. The controversy concerns whether amusia is a pitch-processing disorder or can affect speech processing beyond pitch. Method: We examined lexical tone and intonation recognition in 19 Mandarin-speaking amusics and 19 matched controls in phonated and whispered speech, where fundamental frequency (f(o)) information is either present or absent. Results: The results revealed that the performance of congenital amusics was inferior to that of controls in lexical tone identification in both phonated and whispered speech. These impairments were also detected in identifying intonation (statements/questions) in phonated and whispered modes. Across the experiments, regression models revealed that f(o) and non-f(o) (duration, intensity, and formant frequency) acoustic cues predicted tone and intonation recognition in phonated speech, whereas non-f(o) cues predicted tone and intonation recognition in whispered speech. There were significant differences between amusics and controls in the use of both f(o) and non-f(o) cues. Conclusion: The results provided the first evidence that the impairments of amusics in lexical tone and intonation identification prevail into whispered speech and support the hypothesis that the deficits of amusia extend beyond pitch processing.												3	4											APR	2022	65	4					1331	1348		10.1044/2021_JSLHR-21-00345	http://dx.doi.org/10.1044/2021_JSLHR-21-00345												2026-01-16	WOS:000830953900007
J	Jiang, J; Liu, F; Wan, X; Jiang, CM				Jiang, Jun; Liu, Fang; Wan, Xuan; Jiang, Cunmei			Perception of Melodic Contour and Intonation in Autism Spectrum Disorder: Evidence From Mandarin Speakers	JOURNAL OF AUTISM AND DEVELOPMENTAL DISORDERS				Article								Tone language experience benefits pitch processing in music and speech for typically developing individuals. No known studies have examined pitch processing in individuals with autism who speak a tone language. This study investigated discrimination and identification of melodic contour and speech intonation in a group of Mandarin-speaking individuals with high-functioning autism. Individuals with autism showed superior melodic contour identification but comparable contour discrimination relative to controls. In contrast, these individuals performed worse than controls on both discrimination and identification of speech intonation. These findings provide the first evidence for differential pitch processing in music and speech in tone language speakers with autism, suggesting that tone language experience may not compensate for speech intonation perception deficits in individuals with autism.												55	63											JUL	2015	45	7					2067	2075		10.1007/s10803-015-2370-4	http://dx.doi.org/10.1007/s10803-015-2370-4												2026-01-16	WOS:000356351800013
J	Chien, PJ; Friederici, AD; Hartwigsen, G; Sammler, D				Chien, Pei-Ju; Friederici, Angela D.; Hartwigsen, Gesa; Sammler, Daniela			Neural correlates of intonation and lexical tone in tonal and non-tonal language speakers	HUMAN BRAIN MAPPING				Article								Intonation, the modulation of pitch in speech, is a crucial aspect of language that is processed in right-hemispheric regions, beyond the classical left-hemispheric language system. Whether or not this notion generalises across languages remains, however, unclear. Particularly, tonal languages are an interesting test case because of the dual linguistic function of pitch that conveys lexical meaning in form of tone, in addition to intonation. To date, only few studies have explored how intonation is processed in tonal languages, how this compares to tone and between tonal and non-tonal language speakers. The present fMRI study addressed these questions by testing Mandarin and German speakers with Mandarin material. Both groups categorised mono-syllabic Mandarin words in terms of intonation, tone, and voice gender. Systematic comparisons of brain activity of the two groups between the three tasks showed large cross-linguistic commonalities in the neural processing of intonation in left fronto-parietal, right frontal, and bilateral cingulo-opercular regions. These areas are associated with general phonological, specific prosodic, and controlled categorical decision-making processes, respectively. Tone processing overlapped with intonation processing in left fronto-parietal areas, in both groups, but evoked additional activity in bilateral temporo-parietal semantic regions and subcortical areas in Mandarin speakers only. Together, these findings confirm cross-linguistic commonalities in the neural implementation of intonation processing but dissociations for semantic processing of tone only in tonal language speakers.												27	28											MAY	2020	41	7					1842	1858		10.1002/hbm.24916	http://dx.doi.org/10.1002/hbm.24916		JAN 2020										2026-01-16	WOS:000508026600001
J	Ren, GQ; Yang, Y; Li, X				Ren, G. -Q.; Yang, Y.; Li, X.			EARLY CORTICAL PROCESSING OF LINGUISTIC PITCH PATTERNS AS REVEALED BY THE MISMATCH NEGATIVITY	NEUROSCIENCE				Article								Previous brain imaging studies have shown the left hemispheric dominance for processing of lexical tone in native speakers. However, the low temporal resolution related to neuroimaging techniques might not explicitly detect the brain activities that occur at a relatively small or a determined time frame. We used the mismatch negativity (MMN) and a source estimation technique (low-resolution electromagnetic tomography [LORETA]) to probe the brain activities underlying the early pre-attentive processing of Mandarin lexical tone and intonation. A passive oddball paradigm was applied to present tone and intonation contrast in a speech and nonspeech context. The results showed that no difference of the MMN amplitudes existed between speech and nonspeech conditions, although a larger MMN was found for tone than intonation condition. Source localization of the MMNs for all of the conditions showed the right hemispheric dominance, regardless of their linguistic functions (tone vs. intonation) or speech context (speech vs. nonspeech). Interestingly, the MMN generator for normal tone and hummed tone originated from the same cortical area (right parietal lobe, BA 19). These findings suggest that the pre-attentive cortical processing can be modulated not only by speech stimuli, but also by their nonspeech hums. Our data are compatible with the acoustic hypothesis of speech processing. Crown Copyright (C) 2009 Published by Elsevier Ltd on behalf of IBRO. All rights reserved.												46	61											AUG 4	2009	162	1					87	95		10.1016/j.neuroscience.2009.04.021	http://dx.doi.org/10.1016/j.neuroscience.2009.04.021												2026-01-16	WOS:000267200300010
J	Potisuk, S; Harper, MP; Gandour, J				Potisuk, S; Harper, MP; Gandour, J			Classification of Thai tone sequences in syllable-segmented speech using the analysis-by-synthesis method	IEEE TRANSACTIONS ON SPEECH AND AUDIO PROCESSING				Article																				24	24											JAN	1999	7	1					95	102		10.1109/89.736336	http://dx.doi.org/10.1109/89.736336												2026-01-16	WOS:000077702700011
J	Kung, C; Chwilla, DJ; Schriefers, H				Kung, Carmen; Chwilla, Dorothee J.; Schriefers, Herbert			The interaction of lexical tone, intonation and semantic context in on-line spoken word recognition: An ERP study on Cantonese Chinese	NEUROPSYCHOLOGIA				Article								In two ERP experiments, we investigate the on-line interplay of lexical tone, intonation and semantic context during spoken word recognition in Cantonese Chinese. Experiment 1 shows that lexical tone and intonation interact immediately. Words with a low lexical tone at the end of questions (with a rising question intonation) lead to a processing conflict. This is reflected in a low accuracy in lexical identification and in a P600 effect compared to the same words at the end of a statement. Experiment 2 shows that a strongly biasing semantic context leads to much better lexical-identification performance for words with a low tone at the end of questions and to a disappearance of the P600 effect. These results support the claim that semantic context plays a major role in disentangling the tonal information from the intonational information, and thus, in resolving the on-line conflict between intonation and tone. However, the ERP data indicate that the introduction of a semantic context does not entirely eliminate on-line processing problems for words at the end of questions. This is revealed by the presence of an N400 effect for words with a low lexical tone and for words with a high-mid lexical tone at the end of questions. The ERP data thus show that, while semantic context helps in the eventual lexical identification, it makes the deviation of the contextually expected lexical tone from the actual acoustic signal more salient. (C) 2013 Elsevier Ltd. All rights reserved.												16	20											JAN	2014	53						293	309		10.1016/j.neuropsychologia.2013.11.020	http://dx.doi.org/10.1016/j.neuropsychologia.2013.11.020												2026-01-16	WOS:000331663100031
J	Wang, R; Wang, MR; Georgiev, GV				Wang, Rui; Wang, Mengru; Georgiev, Georgi V.			Intonation processing of interrogative words in Mandarin: an event-related potential study	FRONTIERS IN HUMAN NEUROSCIENCE				Article								Intonation is the variation in pitch used in speech, which forms the premise of tonal and non-tonal languages. Interrogative words are words that introduce questions. Previous research lacks clarity regarding the specific cues used in the processing of word intonation. To address this gap, this study used the event-related potential electroencephalogram (EEG) research method to explore the intonation processing of tone two (mid-rising) interrogative words in Mandarin. For this, the word "shui," meaning "who," was selected as the experimental material. To avoid the influence of the environment, gender, and semantics, the Hum version, corresponding to the stimulus material, was also adopted for the experiment. This study used a passive oddball paradigm to examine the clues of intonation information processing in automatic cognitive processing through amplitude, latency, time window, and evoked location potential mismatch negativity. The standard stimulus was the declarative intonation with a high probability of occurrence (90%), and the deviant stimulus was the interrogative intonation with a low probability of occurrence (10%). In the time window of 370-450 ms, the mismatch negativity was found at the F3, F4, C3, Cz, and C4 channels. The findings show that, in the passive oddball paradigm, lexical semantics are essential for intonation processing at the pre-attentive level, which is dominated by the frontal and central areas of the brain. The results support the functional and comprehensive hypotheses that the processing of intonation is based on the function of language and that bilateral regions are involved in this processing. This study makes an important contribution by providing event-related potential evidence that lexical semantics plays a key role in the pre-attentive processing of intonation, as shown by the significant differences between semantic and non-semantic conditions.												0	0											DEC 15	2023	17								1326602	10.3389/fnhum.2023.1326602	http://dx.doi.org/10.3389/fnhum.2023.1326602												2026-01-16	WOS:001133119600001
J	Li, Q; Meng, Y; Li, QL; Zhao, H; Li, SY				Li, Qiang; Meng, Yuan; Li, Qiuli; Zhao, Heng; Li, Shiyu			Preliminary study on the neural mechanisms of four tone recognition in deaf children using fMRI	SCIENTIFIC REPORTS				Article								Vocal intonation, a fundamental element of speech, is pivotal for comprehending and communicating effectively. Nevertheless, children suffering from hearing impairment encounter difficulties in recognizing vocal intonation patterns, primarily stemming from their auditory deficits. In 2020, a study conducted at Tianjin Medical University General Hospital in Tianjin, China, recruited five deaf children and two children with normal hearing (male; mean age = 10.21 +/- 0.4 years) to compare the differences between deaf and normal children in four Chinese tone recognition tasks. The results revealed that (1) Due to hearing loss, some of the auditory cortices responsible for processing vocal intonation in deaf children do not function optimally, (2) When decoding vocal intonation information, deaf children might utilize alternative neural pathways or networks, (3) Deaf children exhibit hemispheric specialization in their processing of vocal intonation cues.												0	0											JUL 27	2025	15	1							27320	10.1038/s41598-025-13308-5	http://dx.doi.org/10.1038/s41598-025-13308-5												2026-01-16	WOS:001537667200009
J	Liu, F; Patel, AD; Fourcin, A; Stewart, L				Liu, Fang; Patel, Aniruddh D.; Fourcin, Adrian; Stewart, Lauren			Intonation processing in congenital amusia: discrimination, identification and imitation	BRAIN				Article								This study investigated whether congenital amusia, a neuro-developmental disorder of musical perception, also has implications for speech intonation processing. In total, 16 British amusics and 16 matched controls completed five intonation perception tasks and two pitch threshold tasks. Compared with controls, amusics showed impaired performance on discrimination, identification and imitation of statements and questions that were characterized primarily by pitch direction differences in the final word. This intonation-processing deficit in amusia was largely associated with a psychophysical pitch direction discrimination deficit. These findings suggest that amusia impacts upon one's language abilities in subtle ways, and support previous evidence that pitch processing in language and music involves shared mechanisms.												164	182											JUN	2010	133		6				1682	1693		10.1093/brain/awq089	http://dx.doi.org/10.1093/brain/awq089												2026-01-16	WOS:000278226700011
J	Voyer, D; Vu, JP				Voyer, Daniel; Vu, Janie P.			Using Sarcasm to Compliment: Context, Intonation, and the Perception of Statements with a Negative Literal Meaning	JOURNAL OF PSYCHOLINGUISTIC RESEARCH				Article								The present study extended findings of contrast effects in an auditory sarcasm perception task manipulating context and tone of voice. In contrast to previous research that had used sarcastic and sincere statements with a positive literal meaning, the present experiment examined how statements with a negative literal meaning would affect the results. Eighty-four undergraduate students completed a task in which an ambiguous, positive, or negative computer-generated context spoken in a flat emotional tone was followed by a statement with a negative literal meaning spoken in a sincere or sarcastic tone of voice. Results for both the proportion of sarcastic responses and response time showed a significant context by tone interaction, reflecting relatively fast sarcastic responses for the situation in which sarcasm would turn the statement into a compliment (positive context, sarcastic intonation) and fast sincere responses when the literal insult was emphasized (negative context, sincere intonation). However, the ambiguous context produced a pattern of results modulated by the tone of voice that was similar to that observed when the context/intonation pairing could not be interpreted as a compliment or an insult (negative context/sarcastic intonation or positive context/sincere intonation). These findings add to the body of literature suggesting that situational contrast, context, and intonation influence how sarcasm is perceived while demonstrating the importance of the literal meaning in sarcasm perception. They can be interpreted in the context of models of sarcasm comprehension that postulate two stages of processing.												6	9											JUN	2016	45	3					615	624		10.1007/s10936-015-9363-5	http://dx.doi.org/10.1007/s10936-015-9363-5												2026-01-16	WOS:000374897900008
J	Larrouy-Maestri, P; Pfordresher, PQ				Larrouy-Maestri, Pauline; Pfordresher, Peter Q.			Pitch Perception in Music: Do Scoops Matter?	JOURNAL OF EXPERIMENTAL PSYCHOLOGY-HUMAN PERCEPTION AND PERFORMANCE				Article								Studies of musical pitch perception typically treat pitches as if they are stable within a tone. Although pitches are represented this way in notation, performed tones are rarely stable, particularly in singing, which is arguably the most common form of melody production. This paper examines how brief dynamic changes at the beginnings and endings of sung pitches, a.k.a. "scoops," influence intonation perception. Across three experiments, 110 participants evaluated the intonation of four-tone melodies in which the third tone's tuning could vary within the central steady-state (the asymptote), or by virtue of scoops at the beginning and/or end of the tone. As expected, listeners were sensitive to mistuning. Importantly, our results also point to unique contributions of scoops. As in the language domain, dynamic changes in a small time window are perceptually significant in music. More specifically, this study revealed the coexistence of two distinct mechanisms: sensitivity to the average pitch across the duration of the tone (assimilating the scoop), and processing the relationship of the scoop to the surrounding context. In addition to clarifying intonation perception in music, the identification of these mechanisms paves the way to cross-domain comparisons and, more generally, to the better understanding of auditory sequences processing.												11	13											OCT	2018	44	10					1523	1541		10.1037/xhp0000550	http://dx.doi.org/10.1037/xhp0000550												2026-01-16	WOS:000445961700004
J	Patel, AD; Wong, M; Foxton, J; Lochy, A; Peretz, I				Patel, Aniruddh D.; Wong, Meredith; Foxton, Jessica; Lochy, Aliette; Peretz, Isabelle			Speech intonation perception deficits in musical tone deafness (congenital amusia)	MUSIC PERCEPTION				Article								TO WHAT EXTENT DO MUSIC and language share neural mechanisms for processing pitch patterns? Musical tone-deafness (amusia) provides important evidence on this question. Amusics have problems with musical melody perception, yet early work suggested that they had no problems with the perception of speech intonation (Ayotte, Peretz, & Hyde, 2002). However, here we show that about 30% of amusics from independent studies (British and French-Canadian) have difficulty discriminating a statement from a question on the basis of a final pitch fall or rise. This suggests that pitch direction perception deficits in amusia (known from previous psychophysical work) can extend to speech. For British amusics, the direction deficit is related to the rate of change of the final pitch glide in statements/questions, with increased discrimination difficulty when rates are relatively slow. These findings suggest that amusia provides a useful window on the neural relations between melodic processing in language and music.												106	124											APR	2008	25	4					357	368		10.1525/MP.2008.25.4.357	http://dx.doi.org/10.1525/MP.2008.25.4.357												2026-01-16	WOS:000254746000010
J	Prom-on, S; Xu, Y; Thipakorn, B				Prom-on, Santitham; Xu, Yi; Thipakorn, Bundit			Modeling tone and intonation in Mandarin and English as a process of target approximation	JOURNAL OF THE ACOUSTICAL SOCIETY OF AMERICA				Article								This paper reports the development of a quantitative target approximation (qTA) model for generating F-0 contours of speech. The qTA model simulates the production of tone and intonation as a process of syllable-synchronized sequential target approximation [Xu, Y. (2005). "Speech melody as articulatorily implemented communicative functions," Speech Commun. 46, 220-251]. It adopts a set of biomechanical and linguistic assumptions about the mechanisms of speech production. The communicative functions directly modeled are lexical tone in Mandarin and lexical stress in English and focus in both languages. The qTA model is evaluated by extracting function-specific model parameters from natural speech via supervised learning (automatic analysis by synthesis) and comparing the F-0 contours generated with the extracted parameters to those of natural utterances through numerical evaluation and perceptual testing. The F-0 contours generated by the qTA model with the learned parameters were very close to the natural contours in terms of root mean square error, rate of human identification of tone, and focus and judgment of naturalness by human listeners. The results demonstrate that the qTA model is both an effective tool for research on tone and intonation and a potentially effective system for automatic synthesis of tone and intonation.												123	137											JAN	2009	125	1					405	424		10.1121/1.3037222	http://dx.doi.org/10.1121/1.3037222												2026-01-16	WOS:000262672600051
J	Liu, F; Jiang, CM; Thompson, WF; Xu, Y; Yang, YF; Stewart, L				Liu, Fang; Jiang, Cunmei; Thompson, William Forde; Xu, Yi; Yang, Yufang; Stewart, Lauren			The Mechanism of Speech Processing in Congenital Amusia: Evidence from Mandarin Speakers	PLOS ONE				Article								Congenital amusia is a neuro-developmental disorder of pitch perception that causes severe problems with music processing but only subtle difficulties in speech processing. This study investigated speech processing in a group of Mandarin speakers with congenital amusia. Thirteen Mandarin amusics and thirteen matched controls participated in a set of tone and intonation perception tasks and two pitch threshold tasks. Compared with controls, amusics showed impaired performance on word discrimination in natural speech and their gliding tone analogs. They also performed worse than controls on discriminating gliding tone sequences derived from statements and questions, and showed elevated thresholds for pitch change detection and pitch direction discrimination. However, they performed as well as controls on word identification, and on statement-question identification and discrimination in natural speech. Overall, tasks that involved multiple acoustic cues to communicative meaning were not impacted by amusia. Only when the tasks relied mainly on pitch sensitivity did amusics show impaired performance compared to controls. These findings help explain why amusia only affects speech processing in subtle ways. Further studies on a larger sample of Mandarin amusics and on amusics of other language backgrounds are needed to consolidate these results.												58	64											FEB 8	2012	7	2							e30374	10.1371/journal.pone.0030374	http://dx.doi.org/10.1371/journal.pone.0030374												2026-01-16	WOS:000302730100010
J	Tillmann, B				Tillmann, Barbara			PITCH PROCESSING IN MUSIC AND SPEECH	ACOUSTICS AUSTRALIA				Article								The present paper proposes an overview of research that investigates pitch processing by considering cognitive processes (related to context, learning, memory and/or knowledge) for both music and language materials. Research investigating cross-domain influences of expertise (either in music or tone languages) and deficits (as in congenital amusia), referred to as positive and negative transfer effects, also contributes to our understanding of domain-specificity or - generality of mechanisms involved in pitch processing.												8	10											AUG	2014	42	2					124	130															2026-01-16	WOS:000347787300008
J	Chen, Y; Xu, Y				Chen, Yue; Xu, Yi			Sequential perception of tone and focus in parallel-A computational simulation	SPEECH COMMUNICATION				Article								Speech is produced continuously over time. So, the information it conveys, including intonational functions, also unfolds over time. But many intonational functions are encoded across whole utterances rather than only within certain words. How can perception process speech signals continuously over time, even for communicative functions that are globally encoded? In this study we used computational simulation to test the idea that even for intonational functions with large temporal scopes, it is possible to process f0 contours syllable-by-syllable, and recognize the functions by continuous estimation of progressive probabilistic inference. We trained SVM and GRU models to simulate the perception of Mandarin tone and sentence focus with either syllable-sized or sentence-sized f0 contours as input. The sentence-wide f0 contours are gated at different syllable locations to test the incrementality of the recognition of tone and intonation. We also tested human listeners' perception of tone and focus with full and fragmented f0 contours from the same dataset to evaluate the validity of the simulated perception. The results showed that the simulated syllable-by-syllable processing of tone and focus generated the closest recognition patterns to human perception. The simulations also show that there is little difference whether tone and focus are recognized separately or as tone-focus combinations, which suggests that despite sharing the same acoustic dimension, the two functions are sufficiently separated from each other in their f0 coding.												0	0											MAR	2025	168								103173	10.1016/j.specom.2024.103173	http://dx.doi.org/10.1016/j.specom.2024.103173		DEC 2024										2026-01-16	WOS:001413433300001
J	Tillmann, B; Burnham, D; Nguyen, S; Grimault, N; Gosselin, N; Peretz, I				Tillmann, Barbara; Burnham, Denis; Nguyen, Sebastien; Grimault, Nicolas; Gosselin, Nathalie; Peretz, Isabelle			Congenital amusia (or tone-deafness) interferes with pitch processing in tone languages	FRONTIERS IN PSYCHOLOGY				Article								Congenital amusia is a neurogenetic disorder that affects music processing and that is ascribed to a deficit in pitch processing. We investigated whether this deficit extended to pitch processing in speech, notably the pitch changes used to contrast lexical tones in tonal languages. Congenital amusics and matched controls, all non-tonal language speakers, were tested for lexical tone discrimination in Mandarin Chinese (Experiment 1) and in Thai (Experiment 2). Tones were presented in pairs and participants were required to make same/different judgments. Experiment 2 additionally included musical analogs of Thai tones for comparison. Performance of congenital amusics was inferior to that of controls for all materials, suggesting a domain-general pitch-processing deficit. The pitch deficit of amusia is thus not limited to music, but may compromise the ability to process and learn tonal languages. Combined with acoustic analyses of the tone material, the present findings provide new insights into the nature of the pitch-processing deficit exhibited by amusics.												57	58												2011	2								120	10.3389/fpsyg.2011.00120	http://dx.doi.org/10.3389/fpsyg.2011.00120												2026-01-16	WOS:000208863700131
J	Zhang, CC; Shao, J				Zhang, Caicai; Shao, Jing			Normal pre-attentive and impaired attentive processing of lexical tones in Cantonese-speaking congenital amusics	SCIENTIFIC REPORTS				Article								The neural underpinnings of congenital amusia, an innate neurogenetic disorder of musical pitch processing, are not well understood. Previous studies suggest that amusia primarily impairs attentive processing (P300) of small pitch deviations in music, leaving pre-attentive pitch processing (mismatch negativity or MMN) more or less intact. However, it remains unknown whether the same neuro-dynamic mechanism of deficiency underlies pitch processing in speech, where amusics also often show impairment behaviorally. The current study examined how lexical tones are processed in pre-attentive (MMN) and attentive (P300) conditions in 24 Cantonese-speaking amusics and 24 matched controls. At the pre-attentive level, Cantonese-speaking amusics exhibited normal MMN responses to lexical tone changes, even for tone pairs with small pitch differences (mid level vs. low level tone; high rising vs. low rising tone). However, at the attentive level, amusics exhibited reduced P3a amplitude for all tone pairs, and further reduced P3b amplitude for tone pairs with small pitch differences. These results suggest that the amusic brain detects tone changes normally pre-attentively, but shows impairment in consciously detecting the same tone differences. Consistent with previous findings in nonspeech pitch processing, this finding provides support for a domain-general neuro-dynamic mechanism of deficient attentive pitch processing in amusia.												12	12											MAY 30	2018	8								8420	10.1038/s41598-018-26368-7	http://dx.doi.org/10.1038/s41598-018-26368-7												2026-01-16	WOS:000433539800018
J	Gandour, J; Wong, D; Dzemidzic, M; Lowe, M; Tong, YX; Li, XJ				Gandour, J; Wong, D; Dzemidzic, M; Lowe, M; Tong, YX; Li, XJ			A cross-linguistic fMRI study of perception of intonation and emotion in Chinese	HUMAN BRAIN MAPPING				Article								Conflicting data from neurobehavioral studies of the perception of intonation (linguistic) and emotion (affective) in spoken language highlight the need to further examine how functional attributes of prosodic stimuli are related to hemispheric differences in processing capacity. Because of similarities in their acoustic profiles, intonation and emotion permit us to assess to what extent hemispheric lateralization of speech prosody depends on functional instead of acoustical properties. To examine how the brain processes linguistic and affective prosody, an fMRI study was conducted using Chinese, a tone language in which both intonation and emotion may be signaled prosodically, in addition to lexical tones. Ten Chinese and 10 English subjects were asked to perform discrimination judgments of intonation (1: statement, question) and emotion (E: happy, angry, sad) presented in semantically neutral Chinese sentences. A baseline task required passive listening to the same speech stimuli (S). In direct between-group comparisons, the Chinese group showed left-sided frontoparietal activation for both intonation (I vs. S) and emotion (E vs. S) relative to baseline. When comparing intonation relative to emotion (I vs. E), the Chinese group demonstrated prefrontal activation bilaterally; parietal activation in the left hemisphere only. The reverse comparison (E vs. I), on the other hand, revealed that activation occurred in anterior and posterior prefrontal regions of the right hemisphere only. These findings show that some aspects of perceptual processing of emotion are dissociable from intonation, and, moreover, that they are mediated by the right hemisphere. Hum. Brain Mapping 18:149-157, 2003. (C) 2003 Wiley-Liss, Inc.												66	81											MAR	2003	18	3					149	157		10.1002/hbm.10088	http://dx.doi.org/10.1002/hbm.10088												2026-01-16	WOS:000181381900002
J	Nan, Y; Huang, WT; Wang, WJ; Liu, C; Dong, Q				Nan, Yun; Huang, Wan-ting; Wang, Wen-jing; Liu, Chang; Dong, Qi			Subgroup differences in the lexical tone mismatch negativity (MMN) among Mandarin speakers with congenital amusia	BIOLOGICAL PSYCHOLOGY				Article								The association/dissociation of pitch processing between music and language is a long lasting debate. We examined this music-language relationship by investigating to what extent pitch deficits in these two domains were dissociable. We focused on a special neurodevelopmental pitch disorder congenital amusia, which primarily affects musical pitch processing. Recent research has also revealed lexical tone deficits in speech among amusics. Approximately one-third of Mandarin amusics exhibits behavioural difficulties in lexical tone perception, which is known as tone agnosia. Using mismatch negativities (MMNs), our current work probed lexical tone encoding at the pre-attentive level among the Mandarin amusics with (tone agnosics) and without (pure amusics) behavioural lexical tone deficits compared with age- and IQ-matched controls. Relative to the controls and the pure amusics, the tone agnosics exhibited reduced MMNs specifically in response to lexical tone changes. Their tone-consonant MMNs were intact and similar to those of the other two groups. Moreover, the tone MMN reduction over the left hemisphere was tightly linked to behavioural insensitivity to lexical tone changes. The current study thus provides the first psychophysiological evidence of subgroup differences in lexical tone processing among Mandarin amusics and links amusics' behavioural tone deficits to impaired pre-attentive tone processing. Despite the overall music pitch deficits, the subgroup differences in lexical tone processing in Mandarin-speaking amusics suggest dissociation of pitch deficits between music and speech. (C) 2015 Elsevier B.V. All rights reserved.												19	21											JAN	2016	113						59	67		10.1016/j.biopsycho.2015.11.010	http://dx.doi.org/10.1016/j.biopsycho.2015.11.010												2026-01-16	WOS:000366757000007
J	Wildgruber, D; Hertrich, I; Riecker, A; Erb, M; Anders, S; Grodd, W; Ackermann, H				Wildgruber, D; Hertrich, I; Riecker, A; Erb, M; Anders, S; Grodd, W; Ackermann, H			Distinct frontal regions subserve evaluation of linguistic and emotional aspects of speech intonation	CEREBRAL CORTEX				Article								In addition to the propositional content of verbal utterances, significant linguistic and emotional information is conveyed by the tone of speech. To differentiate brain regions subserving processing of linguistic and affective aspects of intonation, discrimination of sentences differing in linguistic accentuation and emotional expressiveness was evaluated by functional magnetic resonance imaging. Both tasks yielded rightward lateralization of hemodynamic responses at the level of the dorsolateral frontal cortex as well as bilateral thalamic and temporal activation. Processing of linguistic and affective intonation, thus, seems to be supported by overlapping neural networks comprising partially right-sided brain regions. Comparison of hemodynamic activation during the two different tasks, however, revealed bilateral orbito-frontal responses restricted to the affective condition as opposed to activation of the left lateral inferior frontal gyrus confined to evaluation of linguistic intonation. These findings indicate that distinct frontal regions contribute to higher level processing of intonational information depending on its communicational function. In line with other components of language processing, discrimination of linguistic accentuation seems to be lateralized to the left inferior-lateral frontal region whereas bilateral orbito-frontal areas subserve evaluation of emotional expressiveness.												152	168											DEC	2004	14	12					1384	1389		10.1093/cercor/bhh099	http://dx.doi.org/10.1093/cercor/bhh099												2026-01-16	WOS:000225077400010
J	Tjuka, A; Nguyen, HTT; Spalek, K				Tjuka, Annika; Huong Thi Thu Nguyen; Spalek, Katharina			Foxes, deer, and hedgehogs: The recall of focus alternatives in Vietnamese	LABORATORY PHONOLOGY				Article								In tonal languages, the role of intonation in information-structuring has yet to be fully investigated. Intuitively, one would expect intonation to play only a small role in expressing communicative functions. However, experimental studies with Vietnamese native speakers show that intonation contours vary across different contexts and are used to mark certain types of information, for example, focus (Jannedy, 2007). In non-tonal languages (e.g., English), the marking of focus by intonation can influence the processing of focus alternatives (Fraundorf, Watson, & Benjamin, 2010). If Vietnamese also uses intonation to mark focus, the question arises whether the behavioral consequences of prosodic focus marking in Vietnamese are comparable to languages such as English or German. To test this, we replicate a study on memory for focus alternatives, originally carried out in German (Koch & Spalek, in progress), with Vietnamese language stimuli. In the original study, memory for focus alternatives was improved in a delayed recall task for focused elements produced with contrastive intonation in female speakers. Here, we replicate this finding with Northern Vietnamese native speakers: Contrastive intonation seems to improve later recall for focus alternatives in Northern Vietnamese, but only for female participants, in line with the findings by Koch and Spalek (in progress). These results indicate that prosodic focus marking in Vietnamese makes alternatives to the focused element more salient.												8	8											OCT 26	2020	11	1							16	10.5334/labphon.253	http://dx.doi.org/10.5334/labphon.253												2026-01-16	WOS:000583443300001
J	Kurumada, C; Brown, M; Bibyk, S; Pontillo, DF; Tanenhaus, MK				Kurumada, Chigusa; Brown, Meredith; Bibyk, Sarah; Pontillo, Daniel F.; Tanenhaus, Michael K.			Is it or isn't it: Listeners make rapid use of prosody to infer speaker meanings	COGNITION				Article								A visual world experiment examined the time course for pragmatic inferences derived from visual context and contrastive intonation contours. We used the construction It looks like an X pronounced with either (a) a H pitch accent on the final noun and a low boundary tone, or (b) a contrastive L + H* pitch accent and a rising boundary tone, a contour that can support contrastive inference (e.g., It LOOKSL+H* like a zebra(L-H%) ... (but it is not)). When the visual display contained a single related set of contrasting pictures (e.g. a zebra vs. a zebra-like animal), effects of LOOKSL+H* emerged prior to the processing of phonemic information from the target noun. The results indicate that the prosodic processing is incremental and guided by contextually-supported expectations. Additional analyses ruled out explanations based on context-independent heuristics that might substitute for online computation of contrast. (C) 2014 Elsevier B.V. All rights reserved.												59	65											NOV	2014	133	2					335	342		10.1016/j.cognition.2014.05.017	http://dx.doi.org/10.1016/j.cognition.2014.05.017												2026-01-16	WOS:000343358700001
J	Ip, MHK; Cutler, A				Ip, Martin Ho Kwan; Cutler, Anne			Universals of listening: Equivalent prosodic entrainment in tone and non-tone languages	COGNITION				Article								In English and Dutch, listeners entrain to prosodic contours to predict where focus will fall in an utterance. Here, we ask whether this strategy is universally available, even in languages with very different phonological systems (e.g., tone versus non-tone languages). In a phoneme detection experiment, we examined whether prosodic entrainment also occurs in Mandarin Chinese, a tone language, where the use of various suprasegmental cues to lexical identity may take precedence over their use in salience. Consistent with the results from Germanic languages, response times were facilitated when preceding intonation predicted high stress on the target-bearing word, and the lexical tone of the target word (i.e., rising versus falling) did not affect the Mandarin listeners' response. Further, the extent to which prosodic entrainment was used to detect the target phoneme was the same in both English and Mandarin listeners. Nevertheless, native Mandarin speakers did not adopt an entrainment strategy when the sentences were presented in English, consistent with the suggestion that L2 listening may be strained by additional functional load from prosodic processing. These findings have implications for how universal and language-specific mechanisms interact in the perception of focus structure in everyday discourse.												22	24											SEP	2020	202								104311	10.1016/j.cognition.2020.104311	http://dx.doi.org/10.1016/j.cognition.2020.104311												2026-01-16	WOS:000551338900012
J	Li, P; Zhang, Y; Baills, F; Prieto, P				Li, Peng; Zhang, Yuan; Baills, Florence; Prieto, Pilar			Musical perception skills predict speech imitation skills: differences between speakers of tone and intonation languages	LANGUAGE AND COGNITION				Article; Early Access								The ability to imitate speech is linked to individual cognitive abilities such as working memory and the auditory processing of music. However, little research has focused on the role of specific components of musical perception aptitude in relation to an individual's native language from a crosslinguistic perspective. This study explores the predictive role of four components of musical perception skills and working memory on phonetic language abilities for speakers of two typologically different languages, Catalan (an intonation language) and Chinese (a tone language). Sixty-one Catalan and 144 Chinese participants completed four subtests (accent, melody, pitch and rhythm) of the Profile of Music Perception Skills, a forward digit span task and a speech imitation task. The results showed that for both groups of participants, musical perception skills predicted speech imitation accuracy but working memory did not. Importantly, among the components of musical perception skills, accent was the only predictive factor for Chinese speakers, whereas melody was the only predictive factor for Catalan speakers. These findings suggest that speech imitation ability is predicted by musical perception skills rather than working memory and that the predictive role of specific musical components may depend on the phonological properties of the native language.												2	2											2023 NOV 7	2023										10.1017/langcog.2023.52	http://dx.doi.org/10.1017/langcog.2023.52		NOV 2023										2026-01-16	WOS:001096173200001
J	Gorsuch, GJ				Gorsuch, Greta J.			HELPING INTERNATIONAL TEACHING ASSISTANTS ACQUIRE DISCOURSE INTONATION: EXPLICIT AND IMPLICITL2 KNOWLEDGE	JOURNAL OF TEACHING ENGLISH FOR SPECIFIC AND ACADEMIC PURPOSES				Article								This study explored a theoretically-driven permutation of an intervention designed to improve ITAs' spoken Discourse Intonation (DI). The object was to learn if implicit knowledge growth in DI could be found as the result of an experimental group participating in explicit instruction and in audio-assisted repeated reading treatments using twice-weekly easy, popular science texts for 14 weeks. In a read-aloud condition where speech processing burdens were reduced, both an experimental and control group (who received explicit instruction only) improved over time on speech rate, planning pauses versus hesitation pauses, prominence, tone choices, and length of tone choice pause groups. In a free-response task where processing burdens were increased, however, there was little evidence of change in implicit knowledge of DI for the experimental group. One positive thing was learned: Explicit DI instruction did not reduce participants' speech rate and thus participants could focus on form as well as meaning in extended speech. Explicit DI instruction, where form is linked to meaning, is worthwhile in that explicit knowledge may become proceduralized and available for learners' extemporaneous use. Implicit knowledge building in DI, while difficult to demonstrate, may still be worthwhile if it builds learners' knowledge of vocabulary (to improve prominence) and builds their experience hearing DI features linked to meaning within extended texts.												3	4												2013	1	2					67	92															2026-01-16	WOS:000218718500001
J	Tang, W; Wang, XJ; Li, JQ; Liu, C; Dong, Q; Nan, Y				Tang, Wei; Wang, Xi-jian; Li, Jia-qi; Liu, Chang; Dong, Qi; Nan, Yun			Vowel and tone recognition in quiet and in noise among Mandarin-speaking amusics	HEARING RESEARCH				Article								Music and language are two intricately linked communication modalities in humans. A deficit in music pitch processing as manifested in the condition of congenital amusia has been related to difficulties in lexical tone processing for both tone and non-tonal languages. However, it is still unclear whether amusia also affects the perception of vowel phonemes in quiet and in noise. In this study, we examined vowel-plustone identification in quiet and noise conditions among Mandarin-speaking amusics with and without speech tone difficulties (tone agnosics and pure amusics, respectively), and IQ- and age-matched controls. Overall, pure amusics showed vowel and tone identification comparable to the controls in both quiet and noise conditions. Compared to pure amusics and controls, tone agnosics showed deficits in tone perception in both quiet and noise conditions. More importantly, their vowel perception was lower than pure amusics and controls in noise conditions, e.g., at a signal-to-noise ratio of -4 dB, although they showed normal-like performance in quiet and at a signal-to-noise ratio of -8 dB. These results suggest that when amusia affected speech tone processing (e.g., tone agnosics), it could also compromise vowel processing in noise. However, amusia alone does not affect tone or vowel perception in Mandarin Chinese either in quiet or in noise. Overall, the current study highlights the necessity of taking heterogeneity within the amusic group into account when considering the related speech deficits in this group. (C) 2018 Elsevier B.V. All rights reserved.												16	17											JUN	2018	363						62	69		10.1016/j.heares.2018.03.004	http://dx.doi.org/10.1016/j.heares.2018.03.004												2026-01-16	WOS:000432758700006
J	Wu, ZH; Ortega-Llebaria, M				Wu, Zhaohong; Ortega-Llebaria, Marta			Pitch shape modulates the time course of tone vs pitch-accent identification in Mandarin Chinese	JOURNAL OF THE ACOUSTICAL SOCIETY OF AMERICA				Article								In Mandarin Chinese pitch is used to express both lexical meanings via tones and sentence-level meanings via pitch-accents raising the question of which information is processed first. While research with meaningful sentence materials suggested a general processing advantage of tone over pitch-accents, research on pure tones and nonce speech in pre-attentive processing found that the f0-shape led to timing and site processing differences. The current study reconciles these results by exploring whether the tone advantage found in meaningful speech materials is modulated by the f0-shape by establishing via a gating paradigm the relative timing of tone and pitch-accent identification. Target words containing static (T1) and dynamic (T2, T4) tones were embedded into meaningful sentences and were divided into 50 ms gates which were added incrementally either from the left-or right-edge of the target word. Results showed that dynamic targets had either a tone or pitch-accent advantage contingent on the direction of gate processing. In contrast, for static T1 targets, tone and pitch-accent were identified simultaneously regardless of the direction of gate processing. Altogether, these results indicate that the f0-shape, as defined by pitch dimensions of f0 and pitch range, mediates the timing of tone and pitch-accent identification in meaningful speech supporting highly interactive models of speech perception. (C) 2017 Acoustical Society of America.												5	5											MAR	2017	141	3					2263	2276		10.1121/1.4979052	http://dx.doi.org/10.1121/1.4979052												2026-01-16	WOS:000398962500104
J	Liu, D; Reed, M				Liu, Di; Reed, Marnie			Exploring the Complexity of the L2 Intonation System: An Acoustic and Eye-Tracking Study	FRONTIERS IN COMMUNICATION				Article								Phonological research has demonstrated that English intonation, variably referred to as prosody, is a multidimensional and multilayered system situated at the interface of information structure, morphosyntactic structure, phonological phenomena, and pragmatic functions. The structural and functional complexity of the intonational system, however, is largely under-addressed in L2 pronunciation teaching, leading to a lack of spontaneous use of intonation despite successful imitation in classrooms. Focusing on contrastive and implicational sentence stress, this study explored the complexity of the English intonation system by investigating how L1 English and Mandarin-English L2 speakers use multiple acoustic features (i.e., pitch range, pitch level, duration, and intensity) in signaling contrastive and implicational information and how one acoustic feature (maximum pitch level) is affected by information structure (contrast), morphosyntactic structure (phrasal boundary), and a phonological phenomenon (declination) in L1 English and Mandarin-English L2 speakers' speech. Using eye-tracking technology, we also investigated (1) L1 English and Mandarin-English L2 speakers' real-time processing of lexical items that carry information structure (i.e., contrast) and typically receive stress in L1 speakers' speech; (2) the influence of visual enhancement (italics and bold) on L1 English and Mandarin-English L2 speakers' processing of contrastive information; and (3) L1 English and Mandarin-English L2 speakers' processing of pictures with contrastive information. Statistical analysis using linear mixed-effects models showed that L1 English speakers and Mandarin-English L2 speakers differed in their use of acoustic cues in signaling contrastive and implicational information. They also differed in the use of maximum pitch level in signaling sentence stress influenced by contrast, phrasal boundary, and declination. We did not find differences in L1 English and Mandarin-English L2 speakers' processing of contrastive and implicational information at the sentence level, but the two groups of participants differ in their processing of contrastive information in passages and pictures. These results suggest that processing limitations may be the reason why L2 speakers did not use English intonation spontaneously. The findings of this study also suggest that Complexity Theory (CT), which emphasizes the complex and dynamic nature of intonation, is a theoretical framework that has the potential of bridging the gap between L2 phonology and L2 pronunciation teaching.												6	7											APR 6	2021	6								627316	10.3389/fcomm.2021.627316	http://dx.doi.org/10.3389/fcomm.2021.627316												2026-01-16	WOS:000678089800001
J	Roll, M; Horne, M; Lindgren, M				Roll, Mikael; Horne, Merle; Lindgren, Magnus			Left-edge boundary tone and main clause verb effects on syntactic processing in embedded clauses - An ERP study	JOURNAL OF NEUROLINGUISTICS				Article								We examined the effects of main clause verb pragmatics and left-edge boundary tones on syntactic processing in Swedish embedded clauses, using listener judgments and Event-Related Potentials. When the syntactic structure did not match the expectation based on the occurrence of a left-edge boundary tone, the acceptance rate decreased significantly, and a biphasic positive effect with an early peak (P345) and a late peak (P600) showed increased processing load. A larger continuous positive effect (P600) was obtained by changing an assertive main clause verb to a nonassertive verb. thereby modifying the lexical pragmatic context of the embedded clause. Increased positivity was also seen at the left-edge boundary tone when it mismatched a preceding nonassertive verb. We conclude that left-edge boundary tones are used in addition to verb pragmatics to guide the syntactic processing of embedded clauses in Swedish, and that pragmatic and prosodic information is integrated immediately. (c) 2008 Elsevier Ltd. All rights reserved.												23	23											JAN	2009	22	1					55	73		10.1016/j.jneuroling.2008.06.001	http://dx.doi.org/10.1016/j.jneuroling.2008.06.001												2026-01-16	WOS:000262112500004
J	Delogu, F; Lampis, G; Belardinelli, MO				Delogu, Franco; Lampis, Giulia; Belardinelli, Marta Olivetti			From melody to lexical tone: Musical ability enhances specific aspects of foreign language perception	EUROPEAN JOURNAL OF COGNITIVE PSYCHOLOGY				Article								Previous research shows that music ability provides positive effects on language processing. This study aims at better clarifying the involvement of different linguistic subdomains in this cross-domain link, assessing whether or not musicality and music expertise enhance phonological and lexical tone processing of Mandarin Chinese. In two experiments different groups of adults and children with no previous experience in tonal languages, were invited to perform a same-different task trying to detect phonological and tonal variations in pairs of sequences of monosyllabic Mandarin Chinese words. Main results show that all subjects perform significantly better in detecting phonological variations rather than tonal ones. They also show that both melodic proficiency and music expertise are good predictors for a better tonal, but not phonological identification. Data lead to a model of music-to-language transfer effect in which musicality selectively affects linguistic intonation while leaving phonological processing substantially unaffected.												82	94												2010	22	1					46	61		10.1080/09541440802708136	http://dx.doi.org/10.1080/09541440802708136												2026-01-16	WOS:000274915800004
J	Chen, F; Cheung, CCH; Peng, G				Chen, Fei; Cheung, Candice Chi-Hang; Peng, Gang			Linguistic Tone and Non-Linguistic Pitch Imitation in Children with Autism Spectrum Disorders: A Cross-Linguistic Investigation	JOURNAL OF AUTISM AND DEVELOPMENTAL DISORDERS				Article								The conclusions on prosodic pitch features in autism spectrum disorders (ASD) have primarily been derived from studies in non-tonal language speakers. This cross-linguistic study evaluated the performance of imitating Cantonese lexical tones and their non-linguistic (nonspeech) counterparts by Cantonese- and Mandarin-speaking children with and without ASD. Acoustic analyses showed that, compared with typically developing peers, children with ASD exhibited increased pitch variations when imitating lexical tones, while performed similarly when imitating the nonspeech counterparts. Furthermore, Mandarin-speaking children with ASD failed to exploit the phonological knowledge of segments to improve the imitation accuracy of non-native lexical tones. These findings help clarify the speech-specific pitch processing atypicality and phonological processing deficit in tone-language-speaking children with ASD.												17	18											MAY	2022	52	5					2325	2343		10.1007/s10803-021-05123-4	http://dx.doi.org/10.1007/s10803-021-05123-4		JUN 2021										2026-01-16	WOS:000659415100004
J	Zahner-Ritter, K; Zhao, TY; Einfeldt, M; Braun, B				Zahner-Ritter, Katharina; Zhao, Tianyi; Einfeldt, Marieke; Braun, Bettina			How experience with tone in the native language affects the L2 acquisition of pitch accents	FRONTIERS IN PSYCHOLOGY				Article								This paper tested the ability of Mandarin learners of German, whose native language has lexical tone, to imitate pitch accent contrasts in German, an intonation language. In intonation languages, pitch accents do not convey lexical information; also, pitch accents are sparser than lexical tones as they only associate with prominent words in the utterance. We compared two kinds of German pitch-accent contrasts: (1) a "non-merger" contrast, which Mandarin listeners perceive as different and (2) a "merger" contrast, which sounds more similar to Mandarin listeners. Speakers of a tone language are generally very sensitive to pitch. Hypothesis 1 (H1) therefore stated that Mandarin learners produce the two kinds of contrasts similarly to native German speakers. However, the documented sensitivity to tonal contrasts, at the expense of processing phrase-level intonational contrasts, may generally hinder target-like production of intonational pitch accents in the L2 (Hypothesis 2, H2). Finally, cross-linguistic influence (CLI) predicts a difference in the realization of these two contrasts as well as improvement with higher proficiency (Hypothesis 3, H3). We used a delayed imitation paradigm, which is well-suited for assessing L2-phonetics and -phonology because it does not necessitate access to intonational meaning. We investigated the imitation of three kinds of accents, which were associated with the sentence-final noun in short wh-questions (e.g., Wer malt denn Mandalas, lit: "Who draws PRT mandalas?" "Who likes drawing mandalas?"). In Experiment 1, 28 native speakers of Mandarin participated (14 low- and 14 high-proficient). The learners' productions of the two kinds of contrasts were analyzed using General Additive Mixed Models to evaluate differences in pitch accent contrasts over time, in comparison to the productions of native German participants from an earlier study in our lab. Results showed a more pronounced realization of the non-merger contrast compared to German natives and a less distinct realization of the merger contrast, with beneficial effects of proficiency, lending support to H3. Experiment 2 tested low-proficient Italian learners of German (whose L1 is an intonation language) to contextualize the Mandarin data and further investigate CLI. Italian learners realized the non-merger contrast more target-like than Mandarin learners, lending additional support to CLI (H3).												5	6											AUG 19	2022	13								903879	10.3389/fpsyg.2022.903879	http://dx.doi.org/10.3389/fpsyg.2022.903879												2026-01-16	WOS:000861273800001
J	Zhang, CC; Shao, J; Huang, XN				Zhang, Caicai; Shao, Jing; Huang, Xunan			Deficits of congenital amusia beyond pitch: Evidence from impaired categorical perception of vowels in Cantonese-speaking congenital amusics	PLOS ONE				Article								Congenital amusia is a lifelong disorder of fine-grained pitch processing in music and speech. However, it remains unclear whether amusia is a pitch-specific deficit, or whether it affects frequency/spectral processing more broadly, such as the perception of formant frequency in vowels, apart from pitch. In this study, in order to illuminate the scope of the deficits, we compared the performance of 15 Cantonese-speaking amusics and 15 matched controls on the categorical perception of sound continua in four stimulus contexts: lexical tone, pure tone, vowel, and voice onset time (VOT). Whereas lexical tone, pure tone and vowel continua rely on frequency/spectral processing, the VOT continuum depends on duration/temporal processing. We found that the amusic participants performed similarly to controls in all stimulus contexts in the identification, in terms of the across-category boundary location and boundary width. However, the amusic participants performed systematically worse than controls in discriminating stimuli in those three contexts that depended on frequency/spectral processing (lexical tone, pure tone and vowel), whereas they performed normally when discriminating duration differences (VOT). These findings suggest that the deficit of amusia is probably not pitch specific, but affects frequency/spectral processing more broadly. Furthermore, there appeared to be differences in the impairment of frequency/spectral discrimination in speech and nonspeech contexts. The amusic participants exhibited less benefit in between-category discriminations than controls in speech contexts (lexical tone and vowel), suggesting reduced categorical perception; on the other hand, they performed inferiorly compared to controls across the board regardless of between-and within-category discriminations in nonspeech contexts (pure tone), suggesting impaired general auditory processing. These differences imply that the frequency/spectral-processing deficit might be manifested differentially in speech and nonspeech contexts in amusics D it is manifested as a deficit of higher-level phonological processing in speech sounds, and as a deficit of lower-level auditory processing in nonspeech sounds.												36	36											AUG 22	2017	12	8							e0183151	10.1371/journal.pone.0183151	http://dx.doi.org/10.1371/journal.pone.0183151												2026-01-16	WOS:000408085100029
J	Shang, PZ; Wu, YX				Shang, Peizhu; Wu, Yuxi			The impact of multifaceted factors on auditory mapping between acoustic cues and Spanish intonation categories in a cross-linguistic context	HUMANITIES & SOCIAL SCIENCES COMMUNICATIONS				Article								Recent research has revealed cross-linguistic and individual variations in the processing of acoustic cues for phonetic categorization. This study extends this line of inquiry by examining the auditory perception of native Spanish listeners and Chinese learners of Spanish, focusing on their ability to map acoustic signals onto intonation categories. Through two identification tasks employing synthesized stimuli with systematically varied acoustic and stress patterns, we investigated how listeners navigate multiple cues in recognizing Spanish sentence types. Results indicated that changes in fundamental frequency (F0), duration, and intensity significantly influenced native Spanish listeners' intonation judgments, while Chinese learners predominantly relied on F0 modulations to differentiate statements from yes/no questions. Compared to native Spanish listeners, Chinese learners demonstrated lower sensitivity to changes across the three cues and less proficiency in reconciling cue trade-offs. Furthermore, our study revealed that both Spanish and Chinese listeners' perceptual performance was modulated by stress patterns and their chronological age. Overall, our research elucidates the multifaceted nature of intonation perception, underscoring the critical role of linguistic background, individual characteristics, and lower-level prosodic context in the transformation of acoustic details into intonation categories.												0	0											DEC 20	2024	11	1							1701	10.1057/s41599-024-04216-6	http://dx.doi.org/10.1057/s41599-024-04216-6												2026-01-16	WOS:001381664800006
J	Jiang, CM; Hamm, JP; Lim, VK; Kirk, IJ; Yang, YF				Jiang, Cunmei; Hamm, Jeff P.; Lim, Vanessa K.; Kirk, Ian J.; Yang, Yufang			Processing melodic contour and speech intonation in congenital amusics with Mandarin Chinese	NEUROPSYCHOLOGIA				Article								Congenital amusia is a disorder in the perception and production of musical pitch. It has been suggested that early exposure to a tonal language may compensate for the pitch disorder (Peretz, 2008). If so, it is reasonable to expect that there would be different characterizations of pitch perception in music and speech in congenital amusics who speak a tonal language, such as Mandarin. In this study, a group of 11 adults with amusia whose first language was Mandarin were tested with melodic contour and speech intonation discrimination and identification tasks. The participants with amusia were impaired in discriminating and identifying melodic contour. These abnormalities were also detected in identifying both speech and non-linguistic analogue derived patterns for the Mandarin intonation tasks. In addition, there was an overall trend for the participants with amusia to show deficits with respect to controls in the intonation discrimination tasks for both speech and non-linguistic analogues. These findings suggest that the amusics' melodic pitch deficits may extend to the perception of speech, and could potentially result in some language deficits in those who speak a tonal language. (C) 2010 Elsevier Ltd. All rights reserved.												81	89											JUL	2010	48	9					2630	2639		10.1016/j.neuropsychologia.2010.05.009	http://dx.doi.org/10.1016/j.neuropsychologia.2010.05.009												2026-01-16	WOS:000280573300024
J	Roll, M; Horne, M; Lindgren, M				Roll, Mikael; Horne, Merle; Lindgren, Magnus			Activating without Inhibiting: Left-edge Boundary Tones and Syntactic Processing	JOURNAL OF COGNITIVE NEUROSCIENCE				Article								Right-edge boundary tones have earlier been found to restrict syntactic processing by closing a clause for further integration of incoming words. The role of left-edge intonation, however, has received little attention to date. We show that Swedish left-edge boundary tones selectively facilitate the on-line processing of main clauses, the syntactic structure they are associated with. In spoken Swedish, main clauses are produced with a left-edge boundary tone, which is absent in subordinate clauses. Main and subordinate clauses are further distinguished syntactically by word order when containing sentence adverbs. The effects of tone and word order on the processing of embedded main, subordinate, and neutral clauses (lacking sentence adverbs) were measured using ERPs. A posterior P600 in embedded main clauses and a smaller P600 in subordinate clauses indicated that embedded clauses with sentence adverbs were structurally less expected than neutral clauses and thus were reanalyzed. The tone functioned as a cue for main clause word order, selectively reducing the P600 in embedded main clauses, without affecting the processing of subordinate or neutral clauses. Its perception was reflected in a right frontal P200 effect. The left-edge boundary tone thus seems to activate a main clause structure, albeit without suppressing alternative structures. The P600 was also preceded by a short positive effect in cases where a left-edge boundary tone was absent.												20	22											MAY	2011	23	5					1170	1179		10.1162/jocn.2010.21430	http://dx.doi.org/10.1162/jocn.2010.21430												2026-01-16	WOS:000289062000013
J	Li, MS; Tang, W; Liu, C; Nan, Y; Wang, WJ; Dong, Q				Li, Mingshuang; Tang, Wei; Liu, Chang; Nan, Yun; Wang, Wenjing; Dong, Qi			Vowel and Tone Identification for Mandarin Congenital Amusics: Effects of Vowel Type and Semantic Content	JOURNAL OF SPEECH LANGUAGE AND HEARING RESEARCH				Article								Purpose: This study aimed to explore the effects of Mandarin congenital amusia with or without lexical tone deficit (i.e., tone agnosia and pure amusia) on Mandarin vowel and tone identification in different types of vowels (e.g., monophthong, diphthongs, and triphthongs) embedded in consonant-vowel contexts with and without semantic content. Method: Thirteen pure amusics (i.e., amusics with normal lexical processing), 5 tone agnosics (i.e., with lexical tone deficit), and 12 controls were screened with Montreal Battery of Evaluation of Amusia and lexical tone tests (Nan et al., 2010; Peretz et al., 2003). Vowel-plus-tone identification tasks with the factors of vowel type and syllables with and without semantic content (e.g., real and nonsense words) were examined among the 3 groups, and identification scores were calculated in 3 formats: vowel-plus-tone identification, vowel identification, and tone identification. Results: Tone agnosics showed significantly poorer performances on identifications of vowel, tone, and vowel plus tone across monophthongs, diphthongs, and triphthongs in both real and nonsense words compared to pure amusics and controls. Their deficits were similar across the 3 types of vowels, while the deficit on vowel-plus-tone identification was more severe in nonsense words than in real words. On the other hand, pure amusics performed similarly with controls across all these conditions. Conclusions: Tone agnosia might affect both musical pitch and phonological processing, resulting in deficits in lexical tone and vowel perception. On the contrary, pure amusics's effect is primarily on musical pitch perception but not on lexical tone or phonemic deficit. Vowel type did not affect speech deficits for tone agnosics, while they relied more on semantic content as a compensation.												4	4											DEC	2019	62	12					4300	4308		10.1044/2019_JSLHR-S-18-0440	http://dx.doi.org/10.1044/2019_JSLHR-S-18-0440												2026-01-16	WOS:000561769300006
J	Peng, SC; Lu, HP; Lu, N; Lin, YS; Deroche, MLD; Chatterjee, M				Peng, Shu-Chen; Lu, Hui-Ping; Lu, Nelson; Lin, Yung-Song; Deroche, Mickael L. D.; Chatterjee, Monita			Processing of Acoustic Cues in Lexical-Tone Identification by Pediatric Cochlear-Implant Recipients	JOURNAL OF SPEECH LANGUAGE AND HEARING RESEARCH				Article								Purpose: The objective was to investigate acoustic cue processing in lexical-tone recognition by pediatric cochlear-implant (CI) recipients who are native Mandarin speakers. Method: Lexical-tone recognition was assessed in pediatric CI recipients and listeners with normal hearing (NH) in 2 tasks. In Task 1, participants identified naturally uttered words that were contrastive in lexical tones. For Task 2, a disyllabic word (yanjing) was manipulated orthogonally, varying in fundamental-frequency (F0) contours and duration patterns. Participants identified each token with the second syllable jing pronounced with Tone 1 (a high level tone) as eyes or with Tone 4 (a high falling tone) as eyeglasses. Results: CI participants' recognition accuracy was significantly lower than NH listeners' in Task 1. In Task 2, CI participants' reliance on F0 contours was significantly less than that of NH listeners; their reliance on duration patterns, however, was significantly higher than that of NH listeners. Both CI and NH listeners' performance in Task 1 was significantly correlated with their reliance on F0 contours in Task 2. Conclusion: For pediatric CI recipients, lexical-tone recognition using naturally uttered words is primarily related to their reliance on F0 contours, although duration patterns may be used as an additional cue.												45	49											MAY	2017	60	5					1223	1235		10.1044/2016_JSLHR-S-16-0048	http://dx.doi.org/10.1044/2016_JSLHR-S-16-0048												2026-01-16	WOS:000402754000004
J	Ito, A; Kishiyama, T; Yamashita, Y; Hirose, Y				Ito, Aine; Kishiyama, Takeshi; Yamashita, Yoichiro; Hirose, Yuki			Effects of sandhi-based predictability in Kansai Japanese depend on markedness: a visual-world eye-tracking study	LANGUAGE COGNITION AND NEUROSCIENCE				Article; Early Access								During comprehension, various aspects of upcoming input can be anticipated. However, it is unclear to what extent listeners exploit suprasegmental information to facilitate lexical retrieval. In Japanese, a Kansai-dialect-specific pitch accent system and a sandhi rule create a situation where the final tone of certain modifiers is conditioned by the initial tone of the following noun, thereby making the upcoming tone predictable. Both Tokyo and Kansai speakers showed increased fixations on the target when its initial tone was predictable based on an all-L-tone modifier, suggesting that this "predictability effect" may reflect an increased anticipation of upcoming input that disrupts a marked L-tone sequence, without necessarily invoking the dialect-specific sandhi rule. However, Kansai speakers were quicker to identify the target in this condition, suggesting that they utilised dialect-specific knowledge about the lexically determined pitch accent of the target noun to facilitate processing, particularly when the modifier tone deviated from the default.												0	0											2025 DEC 4	2025										10.1080/23273798.2025.2595193	http://dx.doi.org/10.1080/23273798.2025.2595193		DEC 2025										2026-01-16	WOS:001645608500001
J	Jiang, CM; Hamm, JP; Lim, VK; Kirk, IJ; Yang, YF				Jiang, Cunmei; Hamm, Jeff P.; Lim, Vanessa K.; Kirk, Ian J.; Yang, Yufang			Impaired categorical perception of lexical tones in Mandarin-speaking congenital amusics	MEMORY & COGNITION				Article								The degree to which cognitive resources are shared in the processing of musical pitch and lexical tones remains uncertain. Testing Mandarin amusics on their categorical perception of Mandarin lexical tones may provide insight into this issue. In the present study, a group of 15 amusic Mandarin speakers identified and discriminated Mandarin tones presented as continua in separate blocks. The tonal continua employed were from a high-level tone to a mid-rising tone and from a high-level tone to a high-falling tone. The two tonal continua were made in the contexts of natural speech and of nonlinguistic analogues. In contrast to the controls, the participants with amusia showed no improvement for discrimination pairs that crossed the classification boundary for either speech or nonlinguistic analogues, indicating a lack of categorical perception. The lack of categorical perception of Mandarin tones in the amusic group shows that the pitch deficits in amusics may be domain-general, and this suggests that the processing of musical pitch and lexical tones may share certain cognitive resources and/or processes (Patel 2003, 2008, 2012).												65	67											OCT	2012	40	7					1109	1121		10.3758/s13421-012-0208-2	http://dx.doi.org/10.3758/s13421-012-0208-2												2026-01-16	WOS:000309229700010
J	Ortega-Llebaria, M; Nemogá, M; Presson, N				Ortega-Llebaria, Marta; Nemoga, Maritza; Presson, Nora			Long-term experience with a tonal language shapes the perception of intonation in English words: How Chinese-English bilinguals perceive "Rose?" vs. "Rose"	BILINGUALISM-LANGUAGE AND COGNITION				Article								Long-term experience with a tonal language shapes pitch perception in specific ways, and consequently Chinese speakers may not process pitch in English words -e.g., "Rose?" spoken as a question versus "Rose" spoken as a statement-in the same way as native speakers of non-tonal languages do. If so, what are those pitch processing differences and how do they affect Chinese recognition of English words? We investigated these questions by administering a primed lexical-decision task in English to proficient Chinese-English bilinguals and two control groups, namely, Spanish-English and native English speakers. Prime-target pairs differed in one sound and/or in pitch. Results showed specific cross-language differences in pitch processing between the Chinese speakers and the control groups, confirming that experience with a tonal language shaped the perception of English words' intonation. Moreover, such experience helps to incorporate pitch into models of word-recognition for bilinguals of tonal and non-tonal languages.												19	19											MAR	2017	20	2					367	383		10.1017/S1366728915000723	http://dx.doi.org/10.1017/S1366728915000723												2026-01-16	WOS:000399400700012
J	Braun, B; Galts, T; Kabak, B				Braun, Bettina; Galts, Tobias; Kabak, Baris			Lexical encoding of L2 tones: The role of L1 stress, pitch accent and intonation	SECOND LANGUAGE RESEARCH				Article								Native language prosodic structure is known to modulate the processing of non-native suprasegmental information. It has been shown that native speakers of French, a language without lexical stress, have difficulties storing non-native stress contrasts. We investigated whether the ability to store lexical tone (as in Mandarin Chinese) also depends on the first language (L I) prosodic structure and, if so, how. We tested participants from a stress language (German), a language without word stress (French), a language with restricted lexical tonal contrasts (Japanese), and Mandarin Chinese controls. Furthermore, German has a rich intonational structure, while French and Japanese dispose of fewer utterance-level pitch contrasts. The participants learnt associations between disyllabic non-words (4 tonal contrasts) and objects and indicated whether picture word pairs matched with what they had learnt (complete match, segmental or tonal mismatch conditions). In the tonal mismatch condition, the Mandarin Chinese controls had the highest sensitivity, followed by the German participants. The French and Japanese participants showed no sensitivity towards these tonal contrasts. Utterance-level prosody is hence better able to predict success in second language (L2) tone learning than word prosody.												27	37											JUL	2014	30	3					323	350		10.1177/0267658313510926	http://dx.doi.org/10.1177/0267658313510926												2026-01-16	WOS:000337654200003
J	Braun, B; Johnson, EK				Braun, Bettina; Johnson, Elizabeth K.			Question or tone 2? How language experience and linguistic function guide pitch processing	JOURNAL OF PHONETICS				Article								How does language experience shape pitch processing? Do speakers of tone languages, which use pitch to signal lexical contrasts (e.g., Mandarin Chinese) attend to pitch movements more closely than speakers of intonation languages (e.g., Dutch)? Contradictory findings have been reported in the literature. In the current study, we hypothesize that listeners should be particularly attentive to any pitch information that signals meaningful information in the native language. This includes pitch movements signaling lexical contrasts (present in tone languages only) as well as postlexical contrasts (present in all languages). Both Mandarin and Dutch listeners performed speeded ABX match to sample tasks on the same sets of nonsense words. As predicted, the same pitch movements were attended to differentially by the two language populations depending on the role that information played in the native language. Mandarin listeners were more attentive than Dutch listeners to pitch movements as these signaled potential lexical contrasts in Mandarin (but not Dutch). Importantly, Dutch listeners were more attentive to pitch movements signaling postlexical information than to pitch movements signaling no meaningful linguistic information. These findings underscore the importance of postlexical information in online speech processing and explain apparent contradictions in the literature. (C) 2011 Elsevier Ltd. All rights reserved.												44	52											OCT	2011	39	4					585	594		10.1016/j.wocn.2011.06.002	http://dx.doi.org/10.1016/j.wocn.2011.06.002												2026-01-16	WOS:000296402000012
J	Yang, WX; Feng, J; Huang, WT; Zhang, CX; Nan, Y				Yang, Wu-xia; Feng, Jie; Huang, Wan-ting; Zhang, Cheng-xiang; Nan, Yun			Perceptual pitch deficits coexist with pitch production difficulties in music but not Mandarin speech	FRONTIERS IN PSYCHOLOGY				Article								Congenital amusia is a musical disorder that mainly affects pitch perception. Among Mandarin speakers, some amusics also have difficulties in processing lexical tones (tone agnosics). To examine to what extent these perceptual deficits may be related to pitch production impairments in music and Mandarin speech, eight amusics, eight tone agnosics, and 12 age- and IQ-matched normal native Mandarin speakers were asked to imitate music note sequences and Mandarin words of comparable lengths. The results indicated that both the amusics and tone agnosics underperformed the controls on musical pitch production. However, tone agnosics performed no worse than the amusics, suggesting that lexical tone perception deficits may not aggravate musical pitch production difficulties. Moreover, these three groups were all able to imitate lexical tones with perfect intelligibility. Taken together, the current study shows that perceptual musical pitch and lexical tone deficits might coexist with musical pitch production difficulties. But at the same time these perceptual pitch deficits might not affect lexical tone production or the intelligibility of the speech words that were produced. The perception-production relationship for pitch among individuals with perceptual pitch deficits may be, therefore, domain-dependent.												18	19											JAN 16	2014	4								1024	10.3389/fpsyg.2013.01024	http://dx.doi.org/10.3389/fpsyg.2013.01024												2026-01-16	WOS:000331262500001
J	Liu, F; Chan, AHD; Ciocca, V; Roquet, C; Peretz, I; Wong, PCM				Liu, Fang; Chan, Alice H. D.; Ciocca, Valter; Roquet, Catherine; Peretz, Isabelle; Wong, Patrick C. M.			Pitch perception and production in congenital amusia: Evidence from Cantonese speakers	JOURNAL OF THE ACOUSTICAL SOCIETY OF AMERICA				Article								This study investigated pitch perception and production in speech and music in individuals with congenital amusia (a disorder of musical pitch processing) who are native speakers of Cantonese, a tone language with a highly complex tonal system. Sixteen Cantonese-speaking congenital amusics and 16 controls performed a set of lexical tone perception, production, singing, and psychophysical pitch threshold tasks. Their tone production accuracy and singing proficiency were subsequently judged by independent listeners, and subjected to acoustic analyses. Relative to controls, amusics showed impaired discrimination of lexical tones in both speech and non-speech conditions. They also received lower ratings for singing proficiency, producing larger pitch interval deviations and making more pitch interval errors compared to controls. Demonstrating higher pitch direction identification thresholds than controls for both speech syllables and piano tones, amusics nevertheless produced native lexical tones with comparable pitch trajectories and intelligibility as controls. Significant correlations were found between pitch threshold and lexical tone perception, music perception and production, but not between lexical tone perception and production for amusics. These findings provide further evidence that congenital amusia is a domain-general language-independent pitch-processing deficit that is associated with severely impaired music perception and production, mildly impaired speech perception, and largely intact speech production. (C) 2016 Acoustical Society of America.												26	29											JUL	2016	140	1					563	575		10.1121/1.4955182	http://dx.doi.org/10.1121/1.4955182												2026-01-16	WOS:000382406500075
J	Quam, C; Creel, SC				Quam, Carolyn; Creel, Sarah C.			Mandarin-English Bilinguals Process Lexical Tones in Newly Learned Words in Accordance with the Language Context	PLOS ONE				Article								Previous research has mainly considered the impact of tone-language experience on ability to discriminate linguistic pitch, but proficient bilingual listening requires differential processing of sound variation in each language context. Here, we ask whether Mandarin-English bilinguals, for whom pitch indicates word distinctions in one language but not the other, can process pitch differently in a Mandarin context vs. an English context. Across three eye tracked word-learning experiments, results indicated that tone-intonation bilinguals process tone in accordance with the language context. In Experiment 1, 51 Mandarin-English bilinguals and 26 English speakers without tone experience were taught Mandarin-compatible novel words with tones. Mandarin-English bilinguals out-performed English speakers, and, for bilinguals, overall accuracy was correlated with Mandarin dominance. Experiment 2 taught 24 Mandarin-English bilinguals and 25 English speakers novel words with Mandarin like tones, but English-like phonemes and phonotactics. The Mandarin-dominance advantages observed in Experiment 1 disappeared when words were English-like. Experiment 3 contrasted Mandarin-like vs. English-like words in a within-subjects design, providing even stronger evidence that bilinguals can process tone language-specifically. Bilinguals (N = 58), regardless of language dominance, attended more to tone than English speakers without Mandarin experience (N = 28), but only when words were Mandarin-like not when they were English-like. Mandarin-English bilinguals thus tailor tone processing to the within-word language context.												9	12											JAN 11	2017	12	1							e0169001	10.1371/journal.pone.0169001	http://dx.doi.org/10.1371/journal.pone.0169001												2026-01-16	WOS:000391857100020
J	Liu, F; Maggu, AR; Lau, JCY; Wong, PCM				Liu, Fang; Maggu, Akshay R.; Lau, Joseph C. Y.; Wong, Patrick C. M.			Brainstem encoding of speech and musical stimuli in congenital amusia: evidence from Cantonese speakers	FRONTIERS IN HUMAN NEUROSCIENCE				Article								Congenital amusia is a neurodevelopmental disorder of musical processing that also impacts subtle aspects of speech processing. It remains debated at what stage(s) of auditory processing deficits in amusia arise. In this study, we investigated whether amusia originates from impaired subcortical encoding of speech On quiet and noise) and musical sounds in the brainstem. Fourteen Cantonese-speaking amusics and 14 matched controls passively listened to six Cantonese lexical tones in quiet, two Cantonese tones in noise (signal-to-noise ratios at 0 and 20 dB), and two cello tones in quiet while their frequency-following responses (FFRs) to these tones were recorded. All participants also completed a behavioral lexical tone identification task. The results indicated normal brainstem encoding of pitch in speech On quiet and noise) and musical stimuli in amusics relative to controls, as measured by FFR pitch strength, pitch error, and stimulus-to-response correlation. There was also no group difference in neural conduction time or FFR amplitudes. Both groups demonstrated better FFRs to speech On quiet and noise) than to musical stimuli. However, a significant group difference was observed for tone identification, with amusics showing significantly lower accuracy than controls. Analysis of the tone confusion matrices suggested that amusics were more likely than controls to confuse between tones that shared similar acoustic features. Interestingly, this deficit in lexical tone identification was not coupled with brainstem abnormality for either speech or musical stimuli. Together, our results suggest that the amusic brainstem is not functioning abnormally, although higher-order linguistic pitch processing is impaired in amusia. This finding has significant implications for theories of central auditory processing, requiring further investigations into how different stages of auditory processing interact in the human brain.												50	50											JAN 6	2015	8								1029	10.3389/fnhum.2014.01029	http://dx.doi.org/10.3389/fnhum.2014.01029												2026-01-16	WOS:000347516500002
J	Gandour, J; Tong, YX; Wong, D; Talavage, T; Dzemidzic, M; Xu, YS; Li, XJ; Lowe, M				Gandour, J; Tong, YX; Wong, D; Talavage, T; Dzemidzic, M; Xu, YS; Li, XJ; Lowe, M			Hemispheric roles in the perception of speech prosody	NEUROIMAGE				Article; Proceedings Paper	11th Annual Meeting of the Cognitive-Neuroscience-Society	APR, 2004	San Francisco, CA					Speech prosody is processed in neither a single region nor a specific hemisphere, but engages multiple areas comprising a large-scale spatially distributed network in both hemispheres. It remains to be elucidated whether hemispheric lateralization is based on higher-level prosodic representations or lower-level encoding of acoustic cues, or both. A cross-language (Chinese; English) fMRI study was conducted to examine brain activity elicited by selective attention to Chinese intonation (I) and tone (T) presented in three-syllable (I3, T3) and one-syllable (I1, T1) utterance pairs in a speeded response, discrimination paradigm. The Chinese group exhibited greater activity than the English in a left inferior parietal region across tasks (I1, I3, T1, T3). Only the Chinese group exhibited a leftward asymmetry in inferior parietal and posterior superior temporal (I1, I3, T1, T3), anterior temporal (I1, I3, T1, T3), and frontopolar (I1, I3) regions. Both language groups shared a rightward asymmetry in the mid portions of the superior temporal sulcus and middle frontal gyrus irrespective of prosodic unit or temporal interval. Hemispheric laterality effects enable us to distinguish brain activity associated with higher-order prosodic representations in the Chinese group from that associated with lower-level acoustic/auditory processes that are shared among listeners regardless of language experience. Lateralization is influenced by language experience that shapes the internal prosodic representation of an external auditory signal. We propose that speech prosody perception is mediated primarily by the RH, but is left-lateralized to task-dependent regions when language processing is required beyond the auditory analysis of the complex sound. (C) 2004 Elsevier Inc. All rights reserved.												180	211											SEP	2004	23	1					344	357		10.1016/j.neuroimage.2004.06.004	http://dx.doi.org/10.1016/j.neuroimage.2004.06.004												2026-01-16	WOS:000223645000037
J	Jiang, CM; Hamm, JP; Kim, VK; Kirk, IJ; Chen, XH; Yang, YF				Jiang, Cunmei; Hamm, Jeff P.; Kim, Vanessa K.; Kirk, Ian J.; Chen, Xuhai; Yang, Yufang			Amusia Results in Abnormal Brain Activity following Inappropriate Intonation during Speech Comprehension	PLOS ONE				Article								Pitch processing is a critical ability on which humans' tonal musical experience depends, and which is also of paramount importance for decoding prosody in speech. Congenital amusia refers to deficits in the ability to properly process musical pitch, and recent evidence has suggested that this musical pitch disorder may impact upon the processing of speech sounds. Here we present the first electrophysiological evidence demonstrating that individuals with amusia who speak Mandarin Chinese are impaired in classifying prosody as appropriate or inappropriate during a speech comprehension task. When presented with inappropriate prosody stimuli, control participants elicited a larger P600 and smaller N100 relative to the appropriate condition. In contrast, amusics did not show significant difference between the appropriate and inappropriate conditions in either the N100 or the P600 component. This provides further evidence that the pitch perception deficits associated with amusia may also affect intonation processing during speech comprehension in those who speak a tonal language such as Mandrian, and suggests music and language share some cognitive and neural resources.												76	79											JUL 27	2012	7	7							e41411	10.1371/journal.pone.0041411	http://dx.doi.org/10.1371/journal.pone.0041411												2026-01-16	WOS:000306950200061
J	Green, T; Faulkner, A; Rosen, S; Macherey, O				Green, T; Faulkner, A; Rosen, S; Macherey, O			Enhancement of temporal periodicity cues in cochlear implants: Effects on prosodic perception and vowel identification	JOURNAL OF THE ACOUSTICAL SOCIETY OF AMERICA				Article								Standard continuous interleaved sampling processing, and a modified processing strategy designed to enhance temporal cues to voice pitch, were compared on tests of intonation perception, and vowel perception, both in implant users and in acoustic simulations. In standard processing, 400 Hz low-pass envelopes modulated either pulse trains (implant users) or noise carriers (simulations). In the modified strategy, slow-rate envelope modulations, which convey dynamic spectral variation crucial for speech understanding, were extracted by low-pass filtering (32 Hz). In addition, during voiced speech, higher-rate temporal modulation in each channel was provided by 100% amplitude-modulation by a sawtooth-like wave form whose periodicity followed the fundamental frequency (FO) of the input. Channel levels were determined by the product of the lower- and higher-rate modulation components. Both in acoustic simulations and in implant users, the ability to use intonation information to identify sentences as question or statement was significantly better with modified processing. However, while there was no difference in vowel recognition in the acoustic simulation, implant users performed worse with modified processing both in vowel recognition and in formant frequency discrimination. It appears that, while enhancing pitch perception, modified processing harmed the transmission of spectral information. (c) 2005 Acoustical Society of America.												72	88											JUL	2005	118	1					375	385		10.1121/1.1925827	http://dx.doi.org/10.1121/1.1925827												2026-01-16	WOS:000230356200033
J	Jiang, CM; Liu, F; Thompson, WF				Jiang, Cunmei; Liu, Fang; Thompson, William Forde			IMPAIRED EXPLICIT PROCESSING OF MUSICAL SYNTAX AND TONALITY IN A GROUP OF MANDARIN-SPEAKING CONGENITAL AMUSICS	MUSIC PERCEPTION				Article								pitch discrimination impairments were associated with syntax and tonality processing. In Experiment 1, we assessed whether congenital amusia is associated with impaired explicit processing of musical syntax. Congruity ratings were examined for syntactically regular or irregular endings in harmonic and melodic contexts. Unlike controls, amusic participants failed to explicitly distinguish regular from irregular endings in both contexts. Surprisingly, however, a concurrent manipulation of pitch distance did not affect the processing of musical syntax for amusics, and their impaired music-syntactic processing was uncorrelated with their pitch discrimination thresholds. In Experiment 2, we assessed tonality perception using a probe-tone paradigm. Recovery of the tonal hierarchy was less evident for the amusic group than for the control group, and this reduced sensitivity to tonality in amusia was also unrelated to poor pitch discrimination. These findings support the view that music structure is processed by cognitive and neural resources that operate independently of pitch discrimination, and that these resources are impaired in explicit judgments for individuals with congenital amusia.												13	15											APR	2016	33	4					401	413		10.1525/MP.2016.33.4.401	http://dx.doi.org/10.1525/MP.2016.33.4.401												2026-01-16	WOS:000374509200001
J	Stewart, L				Stewart, Lauren			Characterizing congenital amusia	QUARTERLY JOURNAL OF EXPERIMENTAL PSYCHOLOGY				Article								The ability to make sense of the music in our environment involves sophisticated cognitive mechanisms that, for most people, are acquired effortlessly and in early life. A special population of individuals, with a disorder termed congenital amusia, report lifelong difficulties in this regard. Exploring the nature of this developmental disorder provides a window onto the cognitive architecture of typical musical processing, as well as allowing a study of the relationship between processing of music and other domains, such as language. The present article considers findings concerning pitch discrimination, pitch memory, contour processing, experiential aspects of music listening in amusia, and emerging evidence concerning the neurobiology of the disorder. A simplified model of melodic processing is outlined, and possible loci of the cognitive deficit are discussed.												40	43												2011	64	4					625	638	PII 932314953	10.1080/17470218.2011.552730	http://dx.doi.org/10.1080/17470218.2011.552730												2026-01-16	WOS:000288952600001
J	Besson, M; Chobert, J; Marie, C				Besson, Mireille; Chobert, Julie; Marie, Celine			Language and Music in the Musician Brain	LANGUAGE AND LINGUISTICS COMPASS				Article								Results of numerous experiments conducted over the past 15 years by using behavioural as well as brain imaging methods have shown that musical expertise influences brain anatomy, brain functions and behaviour. The musician' brain is thus considered as a very good model of brain plasticity. Moreover, many results have demonstrated that musical expertise not only impacts on music processing but also on several aspects of speech processing including lexical pitch, sentence intonation and the metric structure of words. Conversely, recent results indicated that linguistic expertise with tone or quantity languages such as Mandarin Chinese, Thai, Finnish and Japanese, influences the processing of harmonic tones and musical intervals. We discuss possible interpretations of these findings in terms of common processing of the acoustic parameters involved in music and speech and in terms of bidirectional transfer of training effects between music and speech processing.												16	23											SEP	2011	5	9					617	634		10.1111/j.1749-818x.2011.00302.x	http://dx.doi.org/10.1111/j.1749-818x.2011.00302.x												2026-01-16	WOS:000214210600002
J	Thompson, WF; Marin, MM; Stewart, L				Thompson, William Forde; Marin, Manuela M.; Stewart, Lauren			Reduced sensitivity to emotional prosody in congenital amusia rekindles the musical protolanguage hypothesis	PROCEEDINGS OF THE NATIONAL ACADEMY OF SCIENCES OF THE UNITED STATES OF AMERICA				Article								A number of evolutionary theories assume that music and language have a common origin as an emotional protolanguage that remains evident in overlapping functions and shared neural circuitry. The most basic prediction of this hypothesis is that sensitivity to emotion in speech prosody derives from the capacity to process music. We examined sensitivity to emotion in speech prosody in a sample of individuals with congenital amusia, a neurodevelopmental disorder characterized by deficits in processing acoustic and structural attributes of music. Twelve individuals with congenital amusia and 12 matched control participants judged the emotional expressions of 96 spoken phrases. Phrases were semantically neutral but prosodic cues (tone of voice) communicated each of six emotional states: happy, tender, afraid, irritated, sad, and no emotion. Congenitally amusic individuals were significantly worse than matched controls at decoding emotional prosody, with decoding rates for some emotions up to 20% lower than that of matched controls. They also reported difficulty understanding emotional prosody in their daily lives, suggesting some awareness of this deficit. The findings support speculations that music and language share mechanisms that trigger emotional responses to acoustic attributes, as predicted by theories that propose a common evolutionary link between these domains.												119	131											NOV 13	2012	109	46					19027	19032		10.1073/pnas.1210344109	http://dx.doi.org/10.1073/pnas.1210344109												2026-01-16	WOS:000311576300080
J	Liu, F; Jiang, CM; Pfordresher, PQ; Mantell, JT; Xu, Y; Yang, YF; Stewart, L				Liu, Fang; Jiang, Cunmei; Pfordresher, Peter Q.; Mantell, James T.; Xu, Yi; Yang, Yufang; Stewart, Lauren			Individuals with congenital amusia imitate pitches more accurately in singing than in speaking: Implications for music and language processing	ATTENTION PERCEPTION & PSYCHOPHYSICS				Article								In this study, we investigated the impact of congenital amusia, a disorder of musical processing, on speech and song imitation in speakers of a tone language, Mandarin. A group of 13 Mandarin-speaking individuals with congenital amusia and 13 matched controls were recorded while imitating a set of speech and two sets of song stimuli with varying pitch and rhythm patterns. The results indicated that individuals with congenital amusia were worse than controls in both speech and song imitation, in terms of both pitch matching (absolute and relative) and rhythm matching (relative time and number of time errors). Like the controls, individuals with congenital amusia achieved better absolute and relative pitch matching and made fewer pitch interval and contour errors in song than in speech imitation. These findings point toward domain-general pitch (and time) production deficits in congenital amusia, suggesting the presence of shared pitch production mechanisms but distinct requirements for pitch-matching accuracy in language and music processing.												29	32											NOV	2013	75	8					1783	1798		10.3758/s13414-013-0506-1	http://dx.doi.org/10.3758/s13414-013-0506-1												2026-01-16	WOS:000329098800015
J	Wildgruber, D; Pihan, H; Ackermann, H; Erb, M; Grodd, W				Wildgruber, D; Pihan, H; Ackermann, H; Erb, M; Grodd, W			Dynamic brain activation during processing of emotional intonation: Influence of acoustic parameters, emotional valence, and sex	NEUROIMAGE				Article								Appreciation of the emotional tone of verbal utterances represents an important aspect of social life. It is still unsettled, however, which brain areas mediate processing of intonational information and whether the presumed right-sided superiority depends upon acoustic properties of the speech signal. Functional magnetic resonance imaging was used to disentangle brain activation associated with W extraction of specific acoustic cues and (ii) detection of specific emotional states. Stimulus material comprised pairs of emotionally intonated utterances, exclusively differing either in pitch range or in the length of stressed vowels. Hemodynamic responses showed a dynamic pattern of cerebral activation including sequenced bilateral responses of various cortical and subcortical structures. Activation associated with discrimination of emotional expressiveness predominantly emerged within the right inferior parietal lobule, within the bilateral mesiofrontal cortex and-with an asymmetry toward the right hemisphere at the level of bilateral dorsolateral frontal cortex. Lateralization did not depend upon acoustic structure or emotional valence of stimuli. These findings might prove helpful in reconciling the controversial previous clinical and experimental data. (C) 2002 Elsevier Science (USA).												115	133											APR	2002	15	4					856	869		10.1006/nimg.2001.0998	http://dx.doi.org/10.1006/nimg.2001.0998												2026-01-16	WOS:000174689100010
J	Zou, T; Caspers, J; Chen, YY				Zou, Ting; Caspers, Johanneke; Chen, Yiya			Perception of Different Tone Contrasts at Sub-Lexical and Lexical Levels by Dutch Learners of Mandarin Chinese	FRONTIERS IN PSYCHOLOGY				Article								This study explores the difficulties in distinguishing different lexical tone contrasts at both sub-lexical and lexical levels for beginning and advanced Dutch learners of Mandarin, using a sequence-recall task and an auditory lexical decision task. In both tasks, the Tone 2-Tone 3 contrast is most prone to errors for both groups of learners. A significant improvement in the advanced group was found for this tone contrast in the sub-lexical sequence recall task, but not in the lexical decision task. This is taken as evidence that utilizing tones in on-line spoken word recognition is more complex and demanding for L2 learners than in a memory-based task. The results of the lexical decision task also revealed that advanced learners have developed a stronger sensitivity to Tone 1 compared to the other three tones, with Tone 4 showing the least sensitivity. These findings suggest different levels of robustness and distinctiveness for the representation of different lexical tones in L2 learners' lexicon and consequently different levels of proficiency in integrating tones for lexical processing. The observed patterns of difficulty are potentially related to the acoustic characteristics of different lexical tone contrasts as well as to the interference of the suprasegmental features of learner's native language (i.e., the tonal contrasts of Dutch intonation) on the acquisition of the Mandarin lexical tone contrasts.												3	3											JUN 6	2022	13								891756	10.3389/fpsyg.2022.891756	http://dx.doi.org/10.3389/fpsyg.2022.891756												2026-01-16	WOS:000813299300001
J	Tillmann, B; Rusconi, E; Traube, C; Butterworth, B; Umiltà, C; Peretz, I				Tillmann, Barbara; Rusconi, Elena; Traube, Caroline; Butterworth, Brian; Umilta, Carlo; Peretz, Isabelle			Fine-grained pitch processing of music and speech in congenital amusia	JOURNAL OF THE ACOUSTICAL SOCIETY OF AMERICA				Article								Congenital amusia is a lifelong disorder of music processing that has been ascribed to impaired pitch perception and memory. The present study tested a large group of amusics (n = 17) and provided evidence that their pitch deficit affects pitch processing in speech to a lesser extent: Fine-grained pitch discrimination was better in spoken syllables than in acoustically matched tones. Unlike amusics, control participants performed fine-grained pitch discrimination better for musical material than for verbal material. These findings suggest that pitch extraction can be influenced by the nature of the material (music vs speech), and that amusics' pitch deficit is not restricted to musical material, but extends to segmented speech events. (C) 2011 Acoustical Society of America. [DOI: 10.1121/1.3658447]												34	39											DEC	2011	130	6					4089	4096		10.1121/1.3658447	http://dx.doi.org/10.1121/1.3658447												2026-01-16	WOS:000298569100063
J	Deroche, MLD; Lu, HP; Lin, YS; Chatterjee, M; Peng, SC				Deroche, Mickael L. D.; Lu, Hui-Ping; Lin, Yung-Song; Chatterjee, Monita; Peng, Shu-Chen			Processing of Acoustic Information in Lexical Tone Production and Perception by Pediatric Cochlear Implant Recipients	FRONTIERS IN NEUROSCIENCE				Article								Purpose: This study examined the utilization of multiple types of acoustic information in lexical tone production and perception by pediatric cochlear implant (CI) recipients who are native speakers of Mandarin Chinese. Methods: Lexical tones were recorded from CI recipients and their peers with normal hearing (NH). Each participant was asked to produce a disyllabic word, yan jing, with which the first syllable was pronounced as Tone 3 (a low dipping tone) while the second syllable was pronounced as Tone 1 (a high level tone, meaning "eyes") or as Tone 4 (a high falling tone, meaning "eyeglasses"). In addition, a parametric manipulation in fundamental frequency (F0) and duration of Tones 1 and 4 used in a lexical tone recognition task in Peng et al. (2017) was adopted to evaluate the perceptual reliance on each dimension. Results: Mixed-effect analyses of duration, intensity, and F0 cues revealed that NH children focused exclusively on marking distinct F0 contours, while CI participants shortened Tone 4 or prolonged Tone 1 to enhance their contrast. In line with these production strategies, NH children relied primarily on F0 cues to identify the two tones, whereas CI children showed greater reliance on duration cues. Moreover, CI participants who placed greater perceptual weight on duration cues also tended to exhibit smaller changes in their F0 production. Conclusion: Pediatric CI recipients appear to contrast the secondary acoustic dimension (duration) in addition to F0 contours for both lexical tone production and perception. These findings suggest that perception and production strategies of lexical tones are well coupled in this pediatric CI population.												22	24											JUN 20	2019	13								639	10.3389/fnins.2019.00639	http://dx.doi.org/10.3389/fnins.2019.00639												2026-01-16	WOS:000472227600001
J	Marin, MM; Thompson, WF; Gingras, B; Stewart, L				Marin, Manuela M.; Thompson, William Forde; Gingras, Bruno; Stewart, Lauren			Affective evaluation of simultaneous tone combinations in congenital amusia	NEUROPSYCHOLOGIA				Article								Congenital amusia is a neurodevelopmental disorder characterized by impaired pitch processing. Although pitch simultaneities are among the fundamental building blocks of Western tonal music, affective responses to simultaneities such as isolated dyads varying in consonance/dissonance or chords varying in major/minor quality have rarely been studied in amusic individuals. Thirteen amusics and thirteen matched controls enculturated to Western tonal music provided pleasantness ratings of sine-tone dyads and complex-tone dyads in piano timbre as well as perceived happiness/sadness ratings of sine-tone triads and complex-tone triads in piano timbre. Acoustical analyses of roughness and harmonicity were conducted to determine whether similar acoustic information contributed to these evaluations in amusics and controls. Amusic individuals' pleasantness ratings indicated sensitivity to consonance and dissonance for complex-tone (piano timbre) dyads and, to a lesser degree, sine-tone dyads, whereas controls showed sensitivity when listening to both tone types. Furthermore, amusic individuals showed some sensitivity to the happiness-major association in the complex-tone condition, but not in the sinetone condition. Controls rated major chords as happier than minor chords in both tone types. Linear regression analyses revealed that affective ratings of dyads and triads by amusic individuals were predicted by roughness but not harmonicity, whereas affective ratings by controls were predicted by both roughness and harmonicity. We discuss affective sensitivity in congenital amusia in view of theories of affective responses to isolated chords in Western listeners. (C) 2015 The Authors. Published by Elsevier Ltd.												21	23											NOV	2015	78						207	220		10.1016/j.neuropsychologia.2015.10.004	http://dx.doi.org/10.1016/j.neuropsychologia.2015.10.004												2026-01-16	WOS:000365053800021
J	Liu, F; Yin, YJ; Chan, AHD; Yip, V; Wong, PCM				Liu, Fang; Yin, Yanjun; Chan, Alice H. D.; Yip, Virginia; Wong, Patrick C. M.			Individuals with congenital amusia do not show context-dependent perception of tonal categories	BRAIN AND LANGUAGE				Article								Perceptual adaptation is an active cognitive process where listeners re-analyse speech categories based on new contexts/situations/talkers. It involves top-down influences from higher cortical levels on lower-level auditory processes. Individuals with congenital amusia have impaired pitch processing with reduced connectivity between frontal and temporal regions. This study examined whether deficits in amusia would lead to impaired perceptual adaptation in lexical tone perception. Thirteen Mandarin-speaking amusics and 13 controls identified the category of target tones on an 8-step continuum ranging from rising to high-level, either in isolation or in a high-/ low-pitched context. For tones with no context, amusics exhibited reduced categorical perception than controls. While controls? lexical tone categorization demonstrated a significant context effect due to perceptual adaptation, amusics showed similar categorization patterns across both contexts. These findings suggest that congenital amusia impacts the extraction of context-dependent tonal categories in speech perception, indicating that perceptual adaptation may depend on listeners? perceptual acuity.												9	9											APR	2021	215								104908	10.1016/j.bl.2021.104908	http://dx.doi.org/10.1016/j.bl.2021.104908												2026-01-16	WOS:000636792100002
J	Jansson-Verkasalo, E; Ceponiene, R; Kielinen, M; Suominen, K; Jäntti, V; Linna, SL; Moilanen, I; Näätänen, R				Jansson-Verkasalo, E; Ceponiene, R; Kielinen, M; Suominen, K; Jäntti, V; Linna, SL; Moilanen, I; Näätänen, R			Deficient auditory processing in children with Asperger Syndrome, as indexed by event-related potentials	NEUROSCIENCE LETTERS				Article								Asperger Syndrome (AS) is characterized by normal language development but deficient understanding and use of the intonation and prosody of speech. While individuals with AS report difficulties in auditory perception, there are no studies addressing auditory processing at the sensory level. In this study, event-related potentials (ERP) were recorded for syllables and tones in children with AS and in their control counterparts. Children with AS displayed abnormalities in transient sound-feature encoding, as indexed by the obligatory ERPs, and in sound discrimination, as indexed by the mismatch negativity. These deficits were more severe for the tone stimuli than for the syllables. These results indicate that auditory sensory processing is deficient in children with AS, and that these deficits might be implicated in the perceptual problems encountered by children with AS. (C) 2002 Elsevier Science Ireland Ltd. All rights reserved.												108	127											MAR 6	2003	338	3					197	200		10.1016/S0304-3940(02)01405-2	http://dx.doi.org/10.1016/S0304-3940(02)01405-2												2026-01-16	WOS:000181076000006
J	Hsieh, IH; Guo, YJ				Hsieh, I-Hui; Guo, Yu-Jyun			No Musician Advantage in the Perception of Degraded-Fundamental Frequency Speech in Noisy Environments	JOURNAL OF SPEECH LANGUAGE AND HEARING RESEARCH				Article								Purpose: Pitch variations of the fundamental frequency (fo) contour contribute to speech perception in noisy environments, but whether musicians confer an advantage in speech in noise (SIN) with altered fo information remains unclear. This study investigated the effects of different levels of degraded fo contour (i.e., conveying lexical tone or intonation information) on musician advantage in speech-in-noise perception.Method: A cohort of native Mandarin Chinese speakers, comprising 30 trained musicians and 30 nonmusicians, were tested on the intelligibility of Mandarin Chinese sentences with natural, flattened-tone, flattened-intonation, and flattened-all fo contours embedded in background noise masked under three signal-to-noise ratios (0, -5, and -9 dB). Pitch difference thresholds and innate musical skills associated with speech-in-noise benefits were also assessed.Results: Speech intelligibility score improved with increasing signal-to-noise level for both musicians and nonmusicians. However, no musician advantage was observed for identifying any type of flattened-fo contour SIN. Musicians exhibited smaller fo pitch discrimination limens than nonmusicians, which correlated with benefits for perceiving speech with intact tone-level fo information. Regardless of musician status, performance on the pitch and accent musical skill subtests correlated with speech intelligibility score. Conclusions: Collectively, these results provide no evidence for a musician advantage for perceiving speech with distorted fo information in noisy environments. Results further show that perceptual musical skills on pitch and accent processing may benefit the perception of SIN, independent of formal musical training. Our findings suggest that the potential application of music training in speech perception in noisy backgrounds is not contingent on the ability to process fo pitch contours, at least for Mandarin Chinese speakers.Supplemental Material: https://doi.org/10.23641/asha.23706354												1	1											AUG	2023	66	8					2643	2655		10.1044/2023_JSLHR-22-00662	http://dx.doi.org/10.1044/2023_JSLHR-22-00662												2026-01-16	WOS:001056733600006
J	Zhu, JQ; Chen, XX; Chen, F; Zhang, CC; Shao, J; Wiener, S				Zhu, Jiaqiang; Chen, Xiaoxiang; Chen, Fei; Zhang, Caicai; Shao, Jing; Wiener, Seth			Research Article Tone Deafness in Music Does Not Preclude Distributional Learning of Nonnative Tonal Languages in Individuals With Congenital Amusia	JOURNAL OF SPEECH LANGUAGE AND HEARING RESEARCH				Article								Purpose: Previous studies have shown that individuals with congenital amusia exhibit deficient pitch processing across music and language domains. This study investigated whether adult Chinese-speaking listeners with amusia were still able to learn Thai lexical tones based on stimulus frequency of statistical distribution via distributional learning, despite their degraded lexical tone perception. Method: Following a pretest-training-posttest design, 21 amusics and 23 typical, musically intact listeners were assigned into bimodal and unimodal distribution conditions. Listeners were asked to discriminate minimal pairs of Thai midlevel tone and falling tone superimposed on variable base syllables and uttered by different speakers. The perceptual accuracy for each test session and improvement from pretest to posttest were collected and analyzed between the two groups using generalized mixed-effects models. Results: When discriminating Thai lexical tones, amusics were less accurate than typical listeners. Nonetheless, similarly to control listeners, perceptual gains from pretest to posttest were observed in bimodally rather than unimodally trained amusics, as evidenced by both trained and nontrained test words. Conclusions: Amusics are able to learn lexical tones in a second or foreign context of speech. This extends previous research by showing that amusics' distributional learning of linguistic pitch remains largely preserved despite their degraded pitch processing. It is thus likely that manifestations of amusia in speech could not result from their abnormal statistical learning mechanism. This study meanwhile provides a heuristic approach for future studies to apply this paradigm into amusics' treatment to mitigate their pitch-processing disorder.												5	6											JUL	2023	66	7					2461	2477		10.1044/2023_JSLHR-22-00572	http://dx.doi.org/10.1044/2023_JSLHR-22-00572												2026-01-16	WOS:001041295400018
J	Morett, LM				Morett, Laura M.			The Influence of Tonal and Atonal Bilingualism on Children's Lexical and Non-Lexical Tone Perception	LANGUAGE AND SPEECH				Article								This study examined how bilingualism in an atonal language, in addition to a tonal language, influences lexical and non-lexical tone perception and word learning during childhood. Forty children aged 5;3-7;2, bilingual either in English and Mandarin or English and another atonal language, were tested on Mandarin lexical tone discrimination, level-pitch sine-wave tone discrimination, and learning of novel words differing minimally in Mandarin lexical tone. Mandarin-English bilingual children discriminated between and learned novel words differing minimally in Mandarin lexical tone more accurately than their atonal-English bilingual peers. However, Mandarin-English and atonal-English bilingual children discriminated between level-pitch sine-wave tones with similar accuracy. Moreover, atonal-English bilingual children showed a tendency to perceive differing Mandarin lexical and level-pitch sine-wave tones as identical, whereas their Mandarin-English peers showed no such tendency. These results indicate that bilingualism in a tonal language in addition to an atonal language-but not bilingualism in two atonal languages-allows for continued sensitivity to lexical tone beyond infancy. Moreover, they suggest that although tonal-atonal bilingualism does not enhance sensitivity to differences in pitch between sine-wave tones beyond infancy any more effectively than atonal-atonal bilingualism, it protects against the development of biases to perceive differing lexical and non-lexical tones as identical. Together, the results indicate that, beyond infancy, tonal-atonal bilinguals process lexical tones using different cognitive mechanisms than atonal-atonal bilinguals, but that both groups process level-pitch non-lexical tone using the same cognitive mechanisms.												7	8											JUN	2020	63	2					221	241		10.1177/0023830919834679	http://dx.doi.org/10.1177/0023830919834679												2026-01-16	WOS:000537760600002
J	Xu, KY; Yan, JT; Ma, CL; Chang, XH; Chien, YF				Xu, Kunyu; Yan, Jinting; Ma, Chenlu; Chang, Xuhui; Chien, Yu-Fu			Atypical patterns of tone production in tone-language-speaking children with autism	FRONTIERS IN PSYCHOLOGY				Article								Speakers with autism spectrum disorder (ASD) are found to exhibit atypical pitch patterns in speech production. However, little is known about the production of lexical tones (T1, T2, T3, T4) as well as neutral tones (T1N, T2N, T3N, T4N) by tone-language speakers with ASD. Thus, this study investigated the height and shape of tones produced by Mandarin-speaking children with ASD and their age-matched typically developing (TD) peers. A pronunciation experiment was conducted in which the participants were asked to produce reduplicated nouns. The findings from the acoustic analyses showed that although ASD children generally produced both lexical tones and neutral tones with distinct tonal contours, there were significant differences between the ASD and TD groups for tone height and shape for T1/T1N, T3/T3N, and T4/T4N. However, we did not find any difference in T2/T2N. These data implied that the atypical acoustic pattern in the ASD group could be partially due to the suppression of the F0 range. Moreover, we found that ASD children tended to produce more errors for T2/T2N, T3/T3N than for T1/T1N, T4/T4N. The pattern of tone errors could be explained by the acquisition principle of pitch, similarities among different tones, and tone sandhi. We thus concluded that deficits in pitch processing could be responsible for the atypical tone pattern of ASD children, and speculated that the atypical tonal contours might also be due to imitation deficits. The present findings may eventually help enhance the comprehensive understanding of the representation of atypical pitch patterns in ASD across languages.												1	1											NOV 3	2022	13								1023205	10.3389/fpsyg.2022.1023205	http://dx.doi.org/10.3389/fpsyg.2022.1023205												2026-01-16	WOS:000886002800001
J	Lu, S; Wayland, R; Kaan, E				Lu, Shuang; Wayland, Ratree; Kaan, Edith			Effects of production training and perception training on lexical tone perception - A behavioral and ERP study	BRAIN RESEARCH				Article								The present study recorded both behavioral data and event-related brain potentials to examine the effectiveness of a perception-only training and a perception-plus-production training procedure on the intentional and unintentional perception of lexical tone by native English listeners. In the behavioral task, both the perception-only and the perception-plus-production groups improved on the tone discrimination abilities after the training session. Moreover, the participants in both groups generalized the improvements gained through the trained stimuli to the untrained stimuli. In the ERP task, the Mismatch Negativity was smaller in the post-training task than in the pre-training task. However, the two training groups did not differ in tone processing at the intentional or unintentional level after training. These results suggest that the employment of the motor system does not specifically benefit the tone perceptual skills. Furthermore, the present study investigated whether some tone pairs are more easily confused than others by native English listeners, and whether the order of tone presentation influences non-native tone discrimination. In the behavioral task, Tone2-Tone1 (rising-level) and Tone2-Tone4 (rising-falling) were the most difficult tone pairs, while Tone1-Tone2 and Tone4-Tone2 were the easiest tone pairs, even though they involved the same tone contrasts respectively. In the ERP task, the native English listeners had good discrimination when Tone2 and Tone4 were embedded in strings of Tone1, while poor discrimination when Tone1 was inserted in the context of Tone2 or Tone4. These asymmetries in tone perception might be attributed to the interference of native intonation system and can be altered by training. (C) 2015 Elsevier B.V. All rights reserved.												20	30											OCT 22	2015	1624						28	44		10.1016/j.brainres.2015.07.014	http://dx.doi.org/10.1016/j.brainres.2015.07.014												2026-01-16	WOS:000365050100004
J	Zhang, CC; Shao, J; Chen, S				Zhang, Caicai; Shao, Jing; Chen, Si			Impaired perceptual normalization of lexical tones in Cantonese-speaking congenital amusics	JOURNAL OF THE ACOUSTICAL SOCIETY OF AMERICA				Article								Human listeners perceive speech sounds relative to acoustic cues in context. In this study the authors examined how congenital amusia, a pitch-processing disorder, affects perceptual normalization of lexical tones according to the distribution of F0 cues in context. Sixteen Cantonese-speaking amusics and 16 controls were tested on the effects of shifting F0 level in four types of contexts on tone perception: nonspeech, reversed speech, semantically anomalous speech, and meaningful speech contexts. Performance of controls replicated previous studies, showing contrastive changes of tone perception according to the shifted F0 level of anomalous and meaningful contexts, which were native speech contexts with phonological cues to estimate a talker's tone space. Effects of nonspeech and reversed contexts were small and inconsistent, and tone perception performance varied depending on the typicality of a talker's F0 range. In contrast to controls, amusics showed reduced context effects in anomalous and meaningful contexts, but largely comparable context effects in nonspeech and reversed contexts, indicating a deficit of amusics in tone normalization through phonological cues in native speech contexts. These findings suggest that the ability to perceive speech sounds relative to acoustic cues in context is not a universal endowment, and that this ability is impaired substantially in amusics. (C) 2018 Acoustical Society of America.												15	15											AUG	2018	144	2					634	647		10.1121/1.5049147	http://dx.doi.org/10.1121/1.5049147												2026-01-16	WOS:000443620700021
J	Marmel, F; Tillmann, B				Marmel, Frederic; Tillmann, Barbara			TONAL PRIMING BEYOND TONICS	MUSIC PERCEPTION				Article								THE MUSICAL PRIMING PARADIGM ALLOWS FOR INVESTIGATION of listeners' expectations based on their implicit knowledge of tonal stability. To date, priming data are limited to reports of facilitated processing for tonic over nontonic events. The special status of the tonic as a cognitive reference point brings into question the subtlety of listeners' tonal knowledge: Is the facilitated processing observed in priming studies limited to tonic events, or is tone processing influenced by subtler tonal contrasts? The present study investigated tonal priming for mediants (the third scale degree) over leading tones (the seventh scale degree) presented in melodic contexts. Experiment 1 used a timbre discrimination task and Experiment 2 an intonation task. Facilitated processing was observed for the more tonally stable mediants over the less stable leading tones, thus showing that priming effects are not limited to pairs of tonal degrees including the tonic. This finding emphasizes the subtlety of nonexpert listeners' tonal knowledge.												22	33											FEB	2009	26	3					211	221		10.1525/MP.2009.26.3.211	http://dx.doi.org/10.1525/MP.2009.26.3.211												2026-01-16	WOS:000262861800005
J	Pralus, A; Fornoni, L; Bouet, R; Gomot, M; Bhatara, A; Tillman, B; Caclin, A				Pralus, A.; Fornoni, L.; Bouet, R.; Gomot, M.; Bhatara, A.; Tillman, B.; Caclin, A.			Emotional prosody in congenital amusia: Impaired and spared processes	NEUROPSYCHOLOGIA				Article								Congenital amusia is a lifelong deficit of music processing, in particular of pitch processing. Most research investigating this neurodevelopmental disorder has focused on music perception, but pitch also has a critical role for intentional and emotional prosody in speech. Two previous studies investigating amusics' emotional prosody recognition have shown either some deficit or no deficit (compared to controls). However, these previous studies have used only long sentence stimuli, which allow for limited control over acoustic content. Here, we tested amusic individuals for emotional prosody perception in sentences and vowels. For each type of material, participants performed an emotion categorization task, followed by intensity ratings of the recognized emotion. Compared to controls, amusic individuals had similar recognition of emotion in sentences, but poorer performance in vowels, especially when distinguishing sad and neutral stimuli. These lower performances in amusics were linked with difficulties in processing pitch and spectro-temporal parameters of the vowel stimuli. For emotion intensity, neither sentence nor vowel ratings differed between participant groups, suggesting preserved implicit processing of emotional prosody in amusia. These findings can be integrated into previous data showing preserved implicit processing of pitch and emotion in amusia alongside deficits in explicit recognition tasks. They are thus further supporting the hypothesis of impaired conscious analysis of pitch and timbre in this neurodevelopmental disorder.												25	26											NOV	2019	134								107234	10.1016/j.neuropsychologia.2010.107234	http://dx.doi.org/10.1016/j.neuropsychologia.2010.107234												2026-01-16	WOS:000496994700008
J	Yan, JT; Chen, F; Gao, XT; Peng, G				Yan, Jinting; Chen, Fei; Gao, Xiaotian; Peng, Gang			Auditory-Motor Mapping Training Facilitates Speech and Word Learning in Tone Language-Speaking Children With Autism: An Early Efficacy Study	JOURNAL OF SPEECH LANGUAGE AND HEARING RESEARCH				Article								Purpose: It has been reported that tone language-speaking children with autism demonstrate speech-specific lexical tone processing difficulty, although they have intact or even better-than-normal processing of nonspeech/melodic pitch analogues. In this early efficacy study, we evaluated the therapeutic potential of Auditory-Motor Mapping Training (AMMT) in facilitating speech and word output for Mandarin-speaking nonverbal and low-verbal children with autism, in comparison with a matched non-AMMT-based control treatment. Method: Fifteen Mandarin-speaking nonverbal and low-verbal children with autism spectrum disorder participated and completed all the AMMT-based treatment sessions by intoning (singing) and tapping the target words delivered via an app, whereas another 15 participants received control treatment. Generalized linear mixed-effects models were created to evaluate speech production accuracy and word production intelligibility across different groups and conditions. Results: Results showed that the AMMT-based treatment provided a more effective training approach in accelerating the rate of speech (especially lexical tone) and word learning in the trained items. More importantly, the enhanced training efficacy on lexical tone acquisition remained at 2 weeks after therapy and generalized to untrained tones that were not practiced. Furthermore, the low-verbal participants showed higher improvement compared to the nonverbal participants. Conclusions: These data provide the first empirical evidence for adopting the AMMT-based training to facilitate speech and word learning in Mandarin-speaking nonverbal and low-verbal children with autism. This early efficacy study holds promise for improving lexical tone production in Mandarin-speaking children with autism but should be further replicated in larger scale randomized studies. Supplemental Material: https://doi.org/10.23641/asha.16834627												17	21											DEC	2021	64	12					4664	4681		10.1044/2021_JSLHR-21-00029	http://dx.doi.org/10.1044/2021_JSLHR-21-00029												2026-01-16	WOS:000756142500008
J	Orrico, R; D'Imperio, M				Orrico, Riccardo; D'Imperio, Mariapaola			Individual empathy levels affect gradual intonation-meaning mapping: The case of biased questions in Salerno Italian	LABORATORY PHONOLOGY				Article								The paper investigates the interplay between intonational cues and individual variability in the perceptual assessment of speakers' epistemic bias in Salerno Italian yes-no questions. We present a perception experiment in which we manipulated pitch span within the nuclear configuration (both nuclear accent and boundary tone) to predict degree of perceived positive bias (i.e., expected positive answer) to yes-no question stimuli. Our results show that a wider pitch span within the nuclear region predicts a higher degree of perceived positive bias, while negative bias is predicted by narrow pitch span. Crucially, though, two interacting sources of listener variability were uncovered, i.e., prolonged exposure to a non-native dialect as well as degree of empathy (i.e., Empathy Quotient, EQ). Exposure to non-native phonological systems was found to affect the way pitch span is mapped onto perceived epistemic bias, through category interference, though mediated by EQ levels. Specifically, high-empathy listeners were more affected by degree of non-native dialect exposure. EQ scores were hence found to have an effect on gradual span manipulation by interacting with the dialect exposure effect. These results advance our understanding of the intonation-meaning mapping by taking into account both the impact of gradual phonetic cues on meaning processing as well as uncovering sources of cognitive variability at the perceiver's level.												10	11											SEP 18	2020	11	1							12	10.5334/labphon.238	http://dx.doi.org/10.5334/labphon.238												2026-01-16	WOS:000573378900001
J	Yun, J; Lee, HS				Yun, Jiwon; Lee, Hye-Sook			Prosodic disambiguation of questions in Korean Theory and processing	KOREAN LINGUISTICS				Article								This study aims to identify the acoustic and perceptual properties that contribute to identifying the meaning of Korean sentences that are ambiguous between wh-question and yes-no question readings. While in most cases the Accentual Phrase (AP) tonal pattern (Jun 1993) differs between the two question readings, there are cases where the two readings are predicted to have the same AP tonal pattern. However, our experimental results indicate that even in those cases a typical AP tonal contrast between the two question interpretations, i.e. the presence vs. absence of the tone in the syllable that immediately follows the wh-word, is observed in production and plays a meaningful role in perception. The results suggest that there is a production and processing strategy to utilize a consistent contrast in accentual phrasing between the two types of questions for disambiguation.												3	4											MAR 28	2022	18	1					18	47		10.1075/kl.00014.yun	http://dx.doi.org/10.1075/kl.00014.yun												2026-01-16	WOS:000871390800002
J	Jiam, NT; Caldwell, M; Deroche, ML; Chatterjee, M; Limb, CJ				Jiam, N. T.; Caldwell, M.; Deroche, M. L.; Chatterjee, M.; Limb, C. J.			Voice emotion perception and production in cochlear implant users	HEARING RESEARCH				Article								Voice emotion is a fundamental component of human social interaction and social development. Unfortunately, cochlear implant users are often forced to interface with highly degraded prosodic cues as a result of device constraints in extraction, processing, and transmission. As such, individuals with cochlear implants frequently demonstrate significant difficulty in recognizing voice emotions in comparison to their normal hearing counterparts. Cochlear implant-mediated perception and production of voice emotion is an important but relatively understudied area of research. However, a rich understanding of the voice emotion auditory processing offers opportunities to improve upon CI biomedical design and to develop training programs benefiting CI performance. In this review, we will address the issues, current literature, and future directions for improved voice emotion processing in cochlear implant users. (C) 2017 Elsevier B.V. All rights reserved.												63	70											SEP	2017	352						30	39		10.1016/j.heares.2017.01.006	http://dx.doi.org/10.1016/j.heares.2017.01.006												2026-01-16	WOS:000408298500004
J	Shao, J; Zhang, CC				Shao, Jing; Zhang, Caicai			Talker normalization in typical Cantonese-speaking listeners and congenital amusics: Evidence from event-related potentials	NEUROIMAGE-CLINICAL				Article								Despite the lack of invariance in the mapping between the acoustic signal and phonological representation, typical listeners are capable of using information of a talker's vocal characteristics to recognize phonemes, a process known as "talker normalization". The current study investigated the time course of talker normalization in typical listeners and individuals with congenital amusia, a neurodevelopmental disorder of refined pitch processing. We examined the event-related potentials (ERPs) underling lexical tone processing in 24 Cantonese-speaking amusics and 24 typical listeners (controls) in two conditions: blocked-talker and mixed-talker conditions. The results demonstrated that for typical listeners, effects of talker variability can be observed as early as in the N1 time-window (100-150 ms), with the N1 amplitude reduced in the mixed-talker condition. Significant effects were also found in later components: the N2b/c peaked significantly earlier and the P3a and P3b amplitude was enhanced in the blocked-talker condition relative to the mixed-talker condition, especially for the tone pair that is more difficult to discriminate. These results suggest that the blocked-talker mode of stimulus presentation probably facilitates auditory processing and requires less attentional effort with easier speech categorization than the mixed-talker condition, providing neural evidence for the "active control theory". On the other hand, amusics exhibited comparable N1 amplitude to controls in both conditions, but deviated from controls in later components. They demonstrated overall later N2b/c peak latency significantly reduced P3a amplitude in the blocked-talker condition and reduced P3b amplitude irrespective of talker conditions. These results suggest that the amusic brain was intact in the auditory processing of talker normalization processes, as reflected by the comparable N1 amplitude, but exhibited reduced automatic attentional switch to tone changes in the blocked-talker condition, as captured by the reduced P3a amplitude, which presumably underlies a previously reported perceptual "anchoring" deficit in amusics. Altogether, these findings revealed the time course of talker normalization processes in typical listeners and extended the finding that conscious pitch processing is impaired in the amusic brain.												9	9												2019	23								101814	10.1016/j.nicl.2019.101814	http://dx.doi.org/10.1016/j.nicl.2019.101814												2026-01-16	WOS:000485804400006
J	Liu, F; Jiang, CM; Wang, B; Xu, Y; Patel, AD				Liu, Fang; Jiang, Cunmei; Wang, Bei; Xu, Yi; Patel, Aniruddh D.			A music perception disorder (congenital amusia) influences speech comprehension	NEUROPSYCHOLOGIA				Article								This study investigated the underlying link between speech and music by examining whether and to what extent congenital amusia, a musical disorder characterized by degraded pitch processing, would impact spoken sentence comprehension for speakers of Mandarin, a tone language. Sixteen Mandarin-speaking amusics and 16 matched controls were tested on the intelligibility of news-like Mandarin sentences with natural and flat fundamental frequency (F-0) contours (created via speech resynthesis) under four signal-to-noise (SNR) conditions (no noise, +5, 0, and -5 dB SNR). While speech intelligibility in quiet and extremely noisy conditions (SNR= -5 dB) was not significantly compromised by flattened F-0, both amusic and control groups achieved better performance with natural-F-0 sentences than flat-F-0 sentences under moderately noisy conditions (SNR= +5 and 0 dB). Relative to normal listeners, amusics demonstrated reduced speech intelligibility in both quiet and noise, regardless of whether the F-0 contours of the sentences were natural or flattened. This deficit in speech intelligibility was not associated with impaired pitch perception in amusia. These findings provide evidence for impaired speech comprehension in congenital amusia, suggesting that the deficit of amusics extends beyond pitch processing and includes segmental processing. (C) 2014 Elsevier Ltd. All rights reserved.												43	47											JAN	2015	66						111	118		10.1016/j.neuropsychologia.2014.11.001	http://dx.doi.org/10.1016/j.neuropsychologia.2014.11.001												2026-01-16	WOS:000348626200012
J	Zheng, TT; Levelt, CC; Chen, YY				Zheng, Tingting; Levelt, Clara C.; Chen, Yiya			The affective iconicity of lexical tone: Evidence from standard Chinesea)	JOURNAL OF THE ACOUSTICAL SOCIETY OF AMERICA				Article								Previous studies suggested that pitch characteristics of lexical tones in Standard Chinese influence various sensory perceptions, but whether they iconically bias emotional experience remained unclear. We analyzed the arousal and valence ratings of bi-syllabic words in two corpora (Study 1) and conducted an affect rating experiment using a carefully designed corpus of bi-syllabic words (Study 2). Two-alternative forced-choice tasks further tested the robustness of lexical tones' affective iconicity in an auditory nonce word context (Study 3). Hierarchical linear models, generalized linear mixed models, and cross-validation were employed to understand the relationship between lexical tones and the emotional responses of tone-carrying words. Results consistently indicated that words with a falling-falling tonal sequence, both real and nonce words, received higher arousal ratings than those with rising-rising and rising-low tones. Only in nonce words, the high-high sequence was more likely to be associated with the low-arousal option; the falling-falling tone sequence was more often linked to negative-valence choice, while high-high and rising-rising tones with positive-valence. These findings, though subtle, suggest that the use of pitch in lexical tones influences emotional responses during the processing of tone-carrying words, pointing to an inherent iconic quality in lexical tones that may subtly shape speakers' emotional experiences.												2	2											JAN	2025	157	1					396	408		10.1121/10.0034863	http://dx.doi.org/10.1121/10.0034863												2026-01-16	WOS:001405930900002
J	Abesser, J; Frieler, K; Cano, E; Pfleiderer, M; Zaddach, WG				Abesser, Jakob; Frieler, Klaus; Cano, Estefania; Pfleiderer, Martin; Zaddach, Wolf-Georg			Score-Informed Analysis of Tuning, Intonation, Pitch Modulation, and Dynamics in Jazz Solos	IEEE-ACM TRANSACTIONS ON AUDIO SPEECH AND LANGUAGE PROCESSING				Article								Both the collection and analysis of large music repertoires constitute major challenges within musicological disciplines such as jazz research. Automatic methods of music analysis based on audio signal processing have the potential to assist researchers and to accelerate the transcription and analysis of music recordings significantly. In this paper, we propose a framework for analyzing improvised monophonic solos in multi-instrumental jazz recordings with special focus on reed and brass instruments. The analysis algorithms rely on prior score-information, which is taken from high quality manual solo transcriptions. Following an initial solo and accompaniment source separation, we propose algorithms for tone-wise extraction of fundamental frequency and intensity contours. Based on this fine-grained representation of recorded jazz solos, we perform several exploratory experiments motivated by questions relating to jazz research in order to analyze the use of expressive stylistic devices such as intonation, pitch modulation, and dynamics in jazz solos. The results show that a score-informed audio analysis of jazz recordings can provide valuable insights into the individual stylistic characteristics of jazz musicians.												6	11											JAN	2017	25	1					168	177		10.1109/TASLP.2016.2627186	http://dx.doi.org/10.1109/TASLP.2016.2627186												2026-01-16	WOS:000391491700013
J	Wildgruber, D; Riecker, A; Hertrich, I; Erb, M; Grodd, W; Ethofer, T; Ackermann, H				Wildgruber, D; Riecker, A; Hertrich, I; Erb, M; Grodd, W; Ethofer, T; Ackermann, H			Identification of emotional intonation evaluated by fMRI	NEUROIMAGE				Article								During acoustic communication among human beings, emotional information can be expressed both by the propositional content of verbal utterances and by the modulation of speech melody (affective prosody). It is well established that linguistic processing is bound predominantly to the left hemisphere of the brain. By contrast, the encoding of emotional intonation has been assumed to depend specifically upon right-sided cerebral structures. However, prior clinical and functional imaging studies yielded discrepant data with respect to interhemispheric lateralization and intrahemispheric localization of brain regions contributing to processing of affective prosody. In order to delineate the cerebral network engaged in the perception of emotional tone, functional magnetic resonance imaging (fMRI) was performed during recognition of prosodic expressions of five different basic emotions (happy, sad, angry, fearful, and disgusted) and during phonetic monitoring of the same stimuli. As compared to baseline at rest, both tasks yielded widespread bilateral hemodynamic responses within frontal, temporal, and parietal areas, the thalamus, and the cerebellum. A comparison of the respective activation maps, however, revealed comprehension of affective prosody to be bound to a distinct right-hemisphere pattern of activation, encompassing posterior superior temporal sulcus (Brodmann Area [BA] 22), dorsolateral (BA 44/45), and orbitobasal (BA 47) frontal areas. Activation within left-sided speech areas, in contrast, was observed during the phonetic task. These findings indicate that partially distinct cerebral networks subserve processing of phonetic and intonational information during speech perception. (C) 2004 Elsevier Inc. All rights reserved.												268	320											FEB 15	2005	24	4					1233	1241		10.1016/j.neuroimage.2004.10.034	http://dx.doi.org/10.1016/j.neuroimage.2004.10.034												2026-01-16	WOS:000226788100032
J	Tao, DD; Deng, R; Jiang, Y; Galvin, JJ; Fu, QJ; Chen, B				Tao, Duoduo; Deng, Rui; Jiang, Ye; Galvin, John J., III; Fu, Qian-Jie; Chen, Bing			Melodic Pitch Perception and Lexical Tone Perception in Mandarin-Speaking Cochlear Implant Users	EAR AND HEARING				Article								Objectives: To examine the relationship between lexical tone perception and melodic pitch perception in Mandarin-speaking cochlear implant (CI) users and to investigate the influence of previous acoustic hearing on CI users' speech and music perception. Design: Lexical tone perception and melodic contour identification (MCI) were measured in 21 prelingual and 11 postlingual young (aged 6-26 years) Mandarin-speaking CI users. Lexical tone recognition was measured for four tonal patterns: tone 1 (flat F0), tone 2 (rising F0), tone 3 (falling-rising F0), and tone 4 (falling F0). MCI was measured using nine five-note melodic patterns that contained changes in pitch contour, as well as different semitone spacing between notes. Results: Lexical tone recognition was generally good (overall mean = 81% correct), and there was no significant difference between subject groups. MCI performance was generally poor (mean = 23% correct). MCI performance was significantly better for postlingual (mean = 32% correct) than for prelingual CI participants (mean = 18% correct). After correcting for outliers, there was no significant correlation between lexical tone recognition and MCI performance for prelingual or postlingual CI participants. Age at deafness was significantly correlated with MCI performance only for postlingual participants. CI experience was significantly correlated with MCI performance for both prelingual and postlingual participants. Duration of deafness was significantly correlated with tone recognition only for prelingual participants. Conclusions: Despite the prevalence of pitch cues in Mandarin, the present CI participants had great difficulty perceiving melodic pitch. The availability of amplitude and duration cues in lexical tones most likely compensated for the poor pitch perception observed with these CI listeners. Previous acoustic hearing experience seemed to benefit postlingual CI users' melodic pitch perception. Longer CI experience was associated with better MCI performance for both subject groups, suggesting that CI users' music perception may improve as they gain experience with their device.												38	51											JAN	2015	36	1					102	110		10.1097/AUD.0000000000000086	http://dx.doi.org/10.1097/AUD.0000000000000086												2026-01-16	WOS:000346911200011
J	Jiang, CL; Gao, Y; Ng, WWY; Zhou, JY; Zhong, JH; Zhen, HZ; Hu, XP				Jiang, Chenglong; Gao, Ying; Ng, Wing W. Y.; Zhou, Jiyong; Zhong, Jinghui; Zhen, Hongzhong; Hu, Xiping			Semantic dependency and local convolution for enhancing naturalness and tone in text-to-speech synthesis	NEUROCOMPUTING				Article								Self-attention-based networks have become increasingly popular due to their exceptional performance in parallel training and global context modeling. However, it may fall short of capturing local dependencies, particularly in datasets with strong local correlations. To address this challenge, we propose a novel method that utilizes semantic dependency to extract linguistic information from the original text. The semantic relationship between nodes serves as prior knowledge to refine the self-attention distribution. Additionally, to better fuse local contextual information, we introduce a one-dimensional convolution neural network to generate the query and value matrices in the self-attention mechanism, taking advantage of the strong correlation between input characters. We apply this variant of the self-attention network to text-to-speech tasks and propose a non-autoregressive neural text-to-speech model. To enhance pronunciation accuracy, we separate tones from phonemes as independent features in model training. Experimental results show that our model yields good performance in speech synthesis. Specifically, the proposed method significantly improves the processing of pause, stress, and intonation in speech.												1	2											DEC 1	2024	608								128430	10.1016/j.neucom.2024.128430	http://dx.doi.org/10.1016/j.neucom.2024.128430		AUG 2024										2026-01-16	WOS:001303332700001
J	Prom-on, S; Liu, F; Xu, Y				Prom-on, Santitham; Liu, Fang; Xu, Yi			Post-low bouncing in Mandarin Chinese: Acoustic analysis and computational modeling	JOURNAL OF THE ACOUSTICAL SOCIETY OF AMERICA				Article								Post-low bouncing is a phenomenon whereby after reaching a very low pitch in a low lexical tone, F-0 bounces up and then gradually drops back in the following syllables. This paper reports the results of an acoustic analysis of the phenomenon in two Mandarin Chinese corpora and presents a simple mechanical model that can effectively simulate this bouncing effect. The acoustic analysis shows that most of the F-0 dynamic features profiling the bouncing effect strongly correlate with the amount of F-0 lowering in the preceding low-tone syllable, and that the additional F-0 raising commences at the onset of the first post-low syllable. Using the quantitative Target Approximation model, this bouncing effect was simulated by adding an acceleration adjustment to the initial F-0 state of the first post-low syllable. A highly linear relation between F-0 lowering and estimated acceleration adjustment was found. This relation was then used to effectively simulate the bouncing effect in both the neutral tone and the full tones. The results of the analysis and simulation are consistent with the hypothesis that the bouncing effect is due to a temporary perturbation of the balance between antagonistic forces in the laryngeal control in producing a very low pitch. (C) 2012 Acoustical Society of America. [http://dx.doi.org/10.1121/1.4725762]												25	26											JUL	2012	132	1					421	432		10.1121/1.4725762	http://dx.doi.org/10.1121/1.4725762												2026-01-16	WOS:000306362200050
J	Kuang, C; Chen, F; Yan, JT; Peng, G				Kuang, Chen; Chen, Fei; Yan, Jinting; Peng, Gang			Reduced Context Effect on Lexical Tone Normalization in Children with Autism Spectrum Disorder: A Speech-Specific Mechanism	JOURNAL OF AUTISM AND DEVELOPMENTAL DISORDERS				Article; Early Access								Existing literature has demonstrated that individuals with autism spectrum disorder (ASD) exhibit atypical use of contextual information in their surroundings. However, there is limited understanding regarding their integration of contextual cues in speech processing. This study aims to explore how Mandarin-speaking children with and without ASD identify lexical tones in speech and nonspeech contexts, and to determine whether the size of context effect would be modulated by children's cognitive abilities. Twenty-five children with ASD and 25 typically developing (TD) children were asked to identify Mandarin lexical tones preceded by three types of contexts (speech, nonspeech, and nonspeech-flattened contexts). We also tested child participants' verbal intelligence, nonverbal intelligence, and working memory capacity. Results revealed that the context effect was only observed in the speech contexts, where Mandarin-speaking children with ASD exhibited a reduced context effect compared to TD children. Moreover, TD children with higher verbal intelligence demonstrated a diminished context effect. However, nonverbal intelligence and working memory capacity were not significantly associated with the size of context effect in either group. These findings revealed a subtle yet important difference between ASD and TD children's utilization of speech contexts in lexical tone identification, and validated a speech-specific mechanism underpinning children's lexical tone normalization.												0	0											2025 MAR 7	2025										10.1007/s10803-025-06775-2	http://dx.doi.org/10.1007/s10803-025-06775-2		MAR 2025										2026-01-16	WOS:001438996300001
J	Jin, ZS; Liu, H; Wu, DX; Zhang, P; Lu, XJ				Jin Zhishuai; Liu Hong; Wu Daxing; Zhang Pin; Lu Xuejing			Processing of emotional faces in congenital amusia: An emotional music priming event-related potential study	NEUROIMAGE-CLINICAL				Article								Congenital amusia is characterized by lifelong impairments in music perception and processing. It is unclear whether pitch detection deficits impact amusic individuals perception of musical emotion. In the current work, 19 amusics and 21 healthy controls were subjected to electroencephalography (EEG) while being exposed to music excerpts and emotional faces. We assessed each individual's ability to discriminate positive- and negative-valenced emotional faces and analyzed electrophysiological indices, in the form of event-related potentials (ERPs) recorded at 32 sites, following exposure to emotionally positive or negative music excerpts. We observed smaller N2 amplitudes in response to facial expressions in the amusia group than in the control group, suggesting that amusics were less affected by the musical stimuli. The late-positive component (LPC) in amusics was similar to that in controls. Our results suggest that the neurocognitive deficit characteristic of congenital amusia is fundamentally an impairment in musical information processing rather than an impairment in emotional processing. (C) 2017 The Authors. Published by Elsevier Inc. This is an open access article under the CC BY-NC-ND license (http://creativecommons.org/licenses/by-nc-nd/4.0/).												3	3												2017	14						602	609		10.1016/j.nicl.2017.02.024	http://dx.doi.org/10.1016/j.nicl.2017.02.024												2026-01-16	WOS:000405984300064
J	Tillmann, B; Graves, JE; Talamini, F; Lévêque, Y; Fornoni, L; Hoarau, C; Pralus, A; Ginzburg, J; Albouy, P; Caclin, A				Tillmann, Barbara; Graves, Jackson E.; Talamini, Francesca; Leveque, Yohana; Fornoni, Lesly; Hoarau, Caliani; Pralus, Agathe; Ginzburg, Jeremie; Albouy, Philippe; Caclin, Anne			Auditory cortex and beyond: Deficits in congenital amusia	HEARING RESEARCH				Article								Congenital amusia is a neuro-developmental disorder of music perception and production, with the observed deficits contrasting with the sophisticated music processing reported for the general population. Musical deficits within amusia have been hypothesized to arise from altered pitch processing, with impairments in pitch discrimination and, notably, short-term memory. We here review research investigating its behavioral and neural correlates, in particular the impairments at encoding, retention, and recollection of pitch information, as well as how these impairments extend to the processing of pitch cues in speech and emotion. The impairments have been related to altered brain responses in a distributed fronto-temporal network, which can be observed also at rest. Neuroimaging studies revealed changes in connectivity patterns within this network and beyond, shedding light on the brain dynamics underlying auditory cognition. Interestingly, some studies revealed spared implicit pitch processing in congenital amusia, showing the power of implicit cognition in the music domain. Building on these findings, together with audiovisual integration and other beneficial mechanisms, we outline perspectives for training and rehabilitation and the future directions of this research domain.												7	7											SEP 15	2023	437								108855	10.1016/j.heares.2023.108855	http://dx.doi.org/10.1016/j.heares.2023.108855		AUG 2023										2026-01-16	WOS:001061641300001
J	Leitman, DI; Foxe, JJ; Butler, PD; Saperstein, A; Revheim, N; Javitt, DC				Leitman, DI; Foxe, JJ; Butler, PD; Saperstein, A; Revheim, N; Javitt, DC			Sensory contributions to impaired prosodic processing in schizophrenia	BIOLOGICAL PSYCHIATRY				Article; Proceedings Paper	Annual Meeting of the Society-for-Biological-Psychiatry	MAY 29-JUN 01, 2004	New York, NY					Background: Deficits in affect recognition are prominent features of schizophrenia. Within the auditory domain, patients show difficulty in interpreting vocal emotional cues based on intonation (prosody). The relationship of these symptoms to deficits in basic sensory processing has not been previously evaluated. Methods: Forty-three patients and 34 healthy comparison subjects were tested on two affective prosody measures: voice emotion identification and voice emotion discrimination. Basic auditory sensdory processing was measured using a tone-matching paradigm and the Distorted Tunes Test (DTT). A subset of subjects was also tested on facial affect identification and discrimination tasks. Results: Patients showed significantly impaired performance on all all emotion processing tasks. Within the patient group, a principal components analysis demonstrated significant intercorrelations between basic pitch perception and affective prosodic performance. In contrast, facial affect recognition deficits represented a distinct second component. Prosodic affect measures correlated significantly with severity of negative symptoms and impaired global outcome. Conclusions: These results demonstrate significant relationships between basic auditory processing deficits and impaired receptive prosody in schizophrenia. The separate loading of auditory and visual affective recognition measures suggests that within-modality factors may be more significant than cross-modality factors in the etiology of affect recognition deficits in schizophrenia.												173	198											JUL 1	2005	58	1					56	61		10.1016/j.biopsych.2005.02.034	http://dx.doi.org/10.1016/j.biopsych.2005.02.034												2026-01-16	WOS:000230260100008
J	Zinszer, BD; Chen, PY; Wu, H; Shu, H; Li, P				Zinszer, Benjamin D.; Chen, Peiyao; Wu, Han; Shu, Hua; Li, Ping			Second language experience modulates neural specialization for first language lexical tones	JOURNAL OF NEUROLINGUISTICS				Article								Recent neuroimaging studies have revealed distinct functional roles of left and right temporal lobe structures in the processing of lexical tones in Chinese. In the present study, we ask whether knowledge of a second language (English) modulates this pattern of activation in the perception of tonal contrasts. Twenty-four native Chinese speakers were recruited from undergraduate and graduate students at Beijing Normal University, China. Participants listened to blocks of computationally manipulated /ba/ syllables which were varied to form within- and across-category deviants at equal acoustic intervals from a standard tone while their cortical blood oxygenation was measured by functional near-infrared spectroscopy (fNIRS). Blocks were analyzed for peak blood oxygenation (HbO) levels, and several linear models were estimated for these data, including effects of deviant tone type (within- or across-category), behavioral differences in tone identification, age of earliest exposure to English (spoken), and proficiency in English. Functional changes in HbO indicated a significantly greater response to within-category contrasts in right STG, consistent with previous findings. However, the effect of deviant type in left MTG was significantly modulated by the age of participants' earliest English exposure: Average across-category activation exceeded within-category activation only for participants exposed to English after 13 years of age. While previous research has established the importance of left MTG in the categorical perception of lexical tones, our findings suggest that the functional specialization of this region is sensitive to second language experience, even in the processing of native language. (C) 2014 The Authors. Published by Elsevier Ltd. This is an open access article under the CC BY-NC-ND license (http://creativecommons.org/licenses/by-nc-nd/3.0/).												8	14											FEB	2015	33				SI		50	66		10.1016/j.jneuroling.2014.09.005	http://dx.doi.org/10.1016/j.jneuroling.2014.09.005												2026-01-16	WOS:000347766700005
J	Nie, K; Hannaford, S; Director, HM; Nishigaki, MA; Drennan, WR; Rubinstein, JT				Nie, Kaibao; Hannaford, Sophia; Director, Hannah M.; Nishigaki, Micah A.; Drennan, Ward R.; Rubinstein, Jay T.			Mandarin tone recognition in English speakers with normal hearing and with cochlear implants	INTERNATIONAL JOURNAL OF AUDIOLOGY				Article								Objective: Mandarin-speaking cochlear implant users have difficulty perceiving tonal changes in speech with current signal processing strategies. The purpose of this study was to evaluate whether English-speaking cochlear implant and normal hearing listeners can be trained to recognise closed-set Mandarin tones. The validity of using native-English speakers to evaluate Mandarin tone perception in cochlear implants was tested. Design: Two groups of native-English speaking participants were evaluated. All listeners were given training rounds and evaluation rounds in which their tonal identification was tested. The normal-hearing group was also tested with acoustic simulations of the traditional Continuous Interleaved Sampling (CIS) strategy. Study sample: Ten normal-hearing English speakers and seven cochlear implant listeners participated. Results: The normal-hearing group correctly identified unprocessed tones at 87% and CIS-processed tones at 58% on average. The cochlear implant listeners achieved 56% correct identification on average. Conclusions: This level of performance for native English speaking CI users was comparable to previous studies using native Mandarin-speaking CI listeners, which showed a mean of 59% in 19 CI users.												1	2											DEC 2	2019	58	12					913	922		10.1080/14992027.2019.1632498	http://dx.doi.org/10.1080/14992027.2019.1632498		JUN 2019										2026-01-16	WOS:000473884500001
J	Yang, XH; Yang, YF				Yang, Xiaohong; Yang, Yufang			Prosodic Realization of Rhetorical Structure in Chinese Discourse	IEEE TRANSACTIONS ON AUDIO SPEECH AND LANGUAGE PROCESSING				Article								The research reported in this paper is an acoustic experiment attempting to elucidate the relationship between prosodic variation and rhetorical structure in discourse. Based on Rhetorical Structure Theory, facets of discourse structure such as hierarchy, relation, and the relative importance of discourse segment were identified. Five speakers of standard Chinese were recorded reading ten paragraphs with two repetitions. Boundary pause duration, f0 max, f0 min, and pitch range of the segments were measured. It was found that speakers realized longer pauses at boundaries of higher hierarchy. Furthermore, compared with segments linked by nucleus-satellite relation, segments linked by multinuclear relation were found to have wider pre-boundary pitch range. Additionally, important segments were found to be articulated with wider pitch range than unimportant segments. These results suggest that rhetorical structure is reliably conveyed by prosodic parameters in standard Chinese.												9	9											MAY	2012	20	4					1196	1206		10.1109/TASL.2011.2173676	http://dx.doi.org/10.1109/TASL.2011.2173676												2026-01-16	WOS:000300427600005
J	Bogach, N; Boitsova, E; Chernonog, S; Lamtev, A; Lesnichaya, M; Lezhenin, I; Novopashenny, A; Svechnikov, R; Tsikach, D; Vasiliev, K; Pyshkin, E; Blake, J				Bogach, Natalia; Boitsova, Elena; Chernonog, Sergey; Lamtev, Anton; Lesnichaya, Maria; Lezhenin, Iurii; Novopashenny, Audrey; Svechnikov, Roman; Tsikach, Daria; Vasiliev, Konstantin; Pyshkin, Evgeny; Blake, John			Speech Processing for Language Learning: A Practical Approach to Computer-Assisted Pronunciation Teaching	ELECTRONICS				Article								This article contributes to the discourse on how contemporary computer and information technology may help in improving foreign language learning not only by supporting better and more flexible workflow and digitizing study materials but also through creating completely new use cases made possible by technological improvements in signal processing algorithms. We discuss an approach and propose a holistic solution to teaching the phonological phenomena which are crucial for correct pronunciation, such as the phonemes; the energy and duration of syllables and pauses, which construct the phrasal rhythm; and the tone movement within an utterance, i.e., the phrasal intonation. The working prototype of StudyIntonation Computer-Assisted Pronunciation Training (CAPT) system is a tool for mobile devices, which offers a set of tasks based on a "listen and repeat" approach and gives the audio-visual feedback in real time. The present work summarizes the efforts taken to enrich the current version of this CAPT tool with two new functions: the phonetic transcription and rhythmic patterns of model and learner speech. Both are designed on a base of a third-party automatic speech recognition (ASR) library Kaldi, which was incorporated inside StudyIntonation signal processing software core. We also examine the scope of automatic speech recognition applicability within the CAPT system workflow and evaluate the Levenstein distance between the transcription made by human experts and that obtained automatically in our code. We developed an algorithm of rhythm reconstruction using acoustic and language ASR models. It is also shown that even having sufficiently correct production of phonemes, the learners do not produce a correct phrasal rhythm and intonation, and therefore, the joint training of sounds, rhythm and intonation within a single learning environment is beneficial. To mitigate the recording imperfections voice activity detection (VAD) is applied to all the speech records processed. The try-outs showed that StudyIntonation can create transcriptions and process rhythmic patterns, but some specific problems with connected speech transcription were detected. The learners feedback in the sense of pronunciation assessment was also updated and a conventional mechanism based on dynamic time warping (DTW) was combined with cross-recurrence quantification analysis (CRQA) approach, which resulted in a better discriminating ability. The CRQA metrics combined with those of DTW were shown to add to the accuracy of learner performance estimation. The major implications for computer-assisted English pronunciation teaching are discussed.												24	36											FEB	2021	10	3							235	10.3390/electronics10030235	http://dx.doi.org/10.3390/electronics10030235												2026-01-16	WOS:000614965300001
J	Fournier, R; Gussenhoven, C; Jensen, O; Hagoort, P				Fournier, R.; Gussenhoven, C.; Jensen, O.; Hagoort, P.			Lateralization of tonal and intonational pitch processing: An MEG study	BRAIN RESEARCH				Article								An MEG experiment was carried out in order to compare the processing of lexical-tonal and intonational contrasts, based on the tonal dialect of Roermond (the Netherlands). A set of words with identical phoneme sequences but distinct pitch contours, which represented different lexical meanings or discourse meanings (statement vs. question), were presented to native speakers as well as to a control group of speakers of Standard Dutch, a non-tone language. The stimuli were arranged in a mismatch paradigm, under three experimental conditions: in the first condition (lexical), the pitch contour differences between standard and deviant stimuli reflected differences between lexical meanings; in the second condition (intonational), the stimuli differed in their discourse meaning; in the third condition (combined), they differed both in their lexical and discourse meaning. In all three conditions, native as well as non-native responses showed a clear MMNm (magnetic mismatch negativity) in a time window from 150 to 250 ms after the divergence point of standard and deviant pitch contours. In the lexical condition, a stronger response was found over the left temporal cortex of native as well as non-native speakers. In the intonational condition, the same activation pattern was observed in the control group, but not in the group of native speakers, who showed a right-hemisphere dominance instead. Finally, in the combined (lexical and intonational) condition, brain reactions appeared to represent the summation of the patterns found in the other two conditions. In sum, the lateralization of pitch processing is condition-dependent in the native group only, which suggests that language experience determines how processes should be distributed over both temporal cortices, according to the functions available in the grammar. (C) 2010 Elsevier B.V. All rights reserved.												15	16											APR 30	2010	1328						79	88		10.1016/j.brainres.2010.02.053	http://dx.doi.org/10.1016/j.brainres.2010.02.053												2026-01-16	WOS:000277682400008
J	Huang, WT; Wong, LLN; Chen, F				Huang, Wanting; Wong, Lena L. N.; Chen, Fei			Just-Noticeable Differences of Fundamental Frequency Change in Mandarin-Speaking Children with Cochlear Implants	BRAIN SCIENCES				Article								Fundamental frequency (F0) provides the primary acoustic cue for lexical tone perception in tonal languages but remains poorly represented in cochlear implant (CI) systems. Currently, there is still a lack of understanding of sensitivity to F0 change in CI users who speak tonal languages. In the present study, just-noticeable differences (JNDs) of F0 contour and F0 level changes in Mandarin-speaking children with CIs were measured and compared with those in their age-matched normal-hearing (NH) peers. Results showed that children with CIs demonstrated significantly larger JND of F0 contour (JND-C) change and F0 level (JND-L) change compared to NH children. Further within-group comparison revealed that the JND-C change was significantly smaller than the JND-L change among children with CIs, whereas the opposite pattern was observed among NH children. No significant correlations were seen between JND-C change/JND-L change and age at implantation /duration of CI use. The contrast between children with CIs and NH children in sensitivity to F0 contour and F0 level change suggests different mechanisms of F0 processing in these two groups as a result of different hearing experiences.												3	4											APR	2022	12	4							443	10.3390/brainsci12040443	http://dx.doi.org/10.3390/brainsci12040443												2026-01-16	WOS:000785521700001
J	Morrill, TH; Dilley, LC; McAuley, JD				Morrill, Tuuli H.; Dilley, Laura C.; McAuley, J. Devin			Prosodic patterning in distal speech context: Effects of list intonation and f0 downtrend on perception of proximal prosodic structure	JOURNAL OF PHONETICS				Article								Prosodic structure is often perceived as exhibiting regularities in the patterning of tone sequences or stressed syllables. Recently, prosodic regularities in the distal (non-local) context have been shown to influence the perceived prosodic constituency of syllables. Three experiments tested the nature of distal prosodic patterns influencing perceptions of prosodic structure, using eight-syllable items ending in ambiguous lexical structures (e.g., tie murder bee, timer derby). For distinct combinations of distal fundamental frequency (f0) and/or timing cues, two patterns were resynthesized on the initial five syllables of experimental items; these were predicted to favor prosodic grouping of final syllables such that listeners would hear a final disyllabic or monosyllabic word, respectively. Results showed distal prosodic patterning affected perceived prosodic constituency when (1) patterns consisted of regularity in timing cues, f0 cues, or both (Experiments 1-2); (2) items ended with either a low high (Experiment 1) or a high low (Experiment 2) tonal pattern; and (3) tonal patterns consisted of altemating low and high-pitched syllables with progressive f0 decrease, i.e., a 'downtrend' (Experiment 3). The results reveal that a variety of prosodic patterns in the distal context can influence perceived prosodic constituency and thus lexical processing, and provide a perceptually-motivated explanation for the organization of acoustic speech input into prosodic constituents. (C) 2014 Elsevier Ltd. All rights reserved.												16	19											SEP	2014	46						68	85		10.1016/j.wocn.2014.06.001	http://dx.doi.org/10.1016/j.wocn.2014.06.001												2026-01-16	WOS:000341279900005
J	Liu, T; Jiang, CM; Francart, T; Chan, AHD; Wong, PCM				Liu, Tang; Jiang, Cunmei; Francart, Tom; Chan, Alice H. D.; Wong, Patrick C. M.			PERCEPTUAL LEARNING OF PITCH DIRECTION IN CONGENITAL AMUSIA: EVIDENCE FROM CHINESE SPEAKERS	MUSIC PERCEPTION				Article								CONGENITAL AMUSIA IS A LIFELONG DISORDER OF musical processing for which no effective treatments have been found. The present study aimed to treat amusics' impairments in pitch direction identification through auditory training. Prior to training, twenty Chinese-speaking amusics and 20 matched controls were tested on the Montreal Battery of Evaluation of Amusia (MBEA) and two psychophysical pitch threshold tasks for identification of pitch direction in speech and music. Subsequently, ten of the twenty amusics undertook 10 sessions of adaptive-tracking pitch direction training, while the remaining 10 received no training. Post training, all amusics were retested on the pitch threshold tasks and on the three pitch-based MBEA subtests. Trained amusics demonstrated significantly improved thresholds for pitch direction identification in both speech and music, to the level of non-amusic control participants, although no significant difference was observed between trained and untrained amusics in the MBEA subtests. This provides the first clear positive evidence for improvement in pitch direction processing through auditory training in amusia. Further training studies are required to target different deficit areas in congenital amusia, so as to reveal which aspects of improvement will be most beneficial to the normal functioning of musical processing.												18	20											FEB	2017	34	3					335	351		10.1525/MP.2017.34.3.335	http://dx.doi.org/10.1525/MP.2017.34.3.335												2026-01-16	WOS:000393254800008
J	Hamilton, N; Green, T; Faulkner, A				Hamilton, Nicholas; Green, Tim; Faulkner, Andrew			Use of a single channel dedicated to conveying enhanced temporal periodicity cues in cochlear implants: Effects on prosodic perception and vowel identification	INTERNATIONAL JOURNAL OF AUDIOLOGY				Article								The continuous interleaved sampling (CIS) strategy for cochlear implants has well-established limitations for the perception of pitch changes in speech. This study investigated a modification of CIS in which one channel was dedicated to the transmission of a temporal encoding of fundamental frequency (F0). Normal hearing subjects listening to noise-excited vocoders, and implantees were tested on labelling the pitch movement of diphthongal glides, on using intonation information to identify sentences as question or statement, and on vowel recognition. There were no significant differences between modified processing and CIS in vowel recognition. However, while there was limited evidence of improved pitch perception relative to CIS with simplified F0 modulation applied to the most basal channel, in general it appears that for most implant users, restricting F0-related modulation to one channel does not provide significantly enhanced pitch information.												8	10											MAY	2007	46	5					244	253		10.1080/14992020601053340	http://dx.doi.org/10.1080/14992020601053340												2026-01-16	WOS:000247255300006
J	Liu, XL				Liu, Xiaoluan			Prominence and Expectation in Speech and Music Through the Lens of Pitch Processing	FRONTIERS IN PSYCHOLOGY				Article								Speech and music reflect extraordinary aspects of human cognitive abilities. Pitch, as an important parameter in the auditory domain, has been the focus of previous research on the relations between speech and music. The present study continues this line of research by focusing on two aspects of pitch processing: pitch prominence and melodic expectation. Specifically, we examined the perceived boundary of prominence for focus/accent in speech and music, plus the comparison between the pitch expectation patterns of music and speech. Speech (Mandarin Chinese) and music stimuli were created with different interval steps that increased from 1 semitone to 12 semitones from the third to the fourth word/note of a sentence/melody. The results showed that ratings of both accent/focus and expectation/surprise increased with increasing semitone distance from the baseline (though this pattern was mixed with tonal stability profiles for the melodies). Nevertheless, the perceived boundary of prominence was different for music and speech, with the boundary for detecting prominence in speech higher than that in music. Expectation also showed different patterns for speech and music. The results thus favor the suggestion that speech prosody and music melody tend to require specialized pitch patterns unique to their own respective communication purposes.												2	2											JUL 8	2021	12								620640	10.3389/fpsyg.2021.620640	http://dx.doi.org/10.3389/fpsyg.2021.620640												2026-01-16	WOS:000675507600001
J	Tseng, CY				Tseng, Chiu-yu			An F0 Analysis of Discourse Construction and Global Information in Realized Narrative Prosody	LANGUAGE AND LINGUISTICS				Article								The aim of the present study is to show how the time varying F0 signal in paragraph prosody output is composed of contributions from multiple ranks of local between-unit concatenation and global higher-level layering. Discourse specified positioning, pre-boundary lengthening, and post-boundary pauses are also contributing variables. Both adjacency smoothing and higher level layering collectively make up the output F0, as supported by quantitative results. Results also reveal distinct patterns of phrase-level F0 height modulations within and between paragraphs, confirming the significance of phrase-level global prosody context in addition to tone-intonation interaction. Cross-speaker analysis of speech data varying in prosodic style show systematic patterns of contribution distribution by style, thus proving one base form is sufficient for both the planning and processing of surface variations. The study also shows why both methodology and interpretation must reflect the relative nature of suprasegmental cues, and how corpus analysis sheds new light on acoustic analysis.												7	7											APR	2010	11	2					183	218															2026-01-16	WOS:000277074100001
J	D'Alessandro, HD; Ballantyne, D; Boyle, PJ; De Seta, E; DeVincentiis, M; Mancini, P				D'Alessandro, Hilal Dincer; Ballantyne, Deborah; Boyle, Patrick J.; De Seta, Elio; DeVincentiis, Marco; Mancini, Patrizia			Temporal Fine Structure Processing, Pitch, and Speech Perception in Adult Cochlear Implant Recipients	EAR AND HEARING				Article								Objectives: The aim of the study was to investigate the link between temporal fine structure (TFS) processing, pitch, and speech perception performance in adult cochlear implant (CI) recipients, including bimodal listeners who may benefit better low-frequency (LF) temporal coding in the contralateral ear. Design: The study participants were 43 adult CI recipients (23 unilateral, 6 bilateral, and 14 bimodal listeners). Two new LF pitch perception tests-harmonic intonation (HI) and disharmonic intonation (DI)-were used to evaluate TFS sensitivity. HI and DI were designed to estimate a difference limen for discrimination of tone changes based on harmonic or inharmonic pitch glides. Speech perception was assessed using the newly developed Italian Sentence Test with Adaptive Randomized Roving level (STARR) test where sentences relevant to everyday contexts were presented at low, medium, and high levels in a fluctuating background noise to estimate a speech reception threshold (SRT). Results: Although TFS and STARR performances in the majority of CI recipients were much poorer than those of hearing people reported in the literature, a considerable intersubject variability was observed. For CI listeners, median just noticeable differences were 27.0 and 147.0 Hz for HI and DI, respectively. HI outcomes were significantly better than those for DI. Median STARR score was 14.8 dB. Better performers with speech reception thresholds less than 20 dB had a median score of 8.6 dB. A significant effect of age was observed for both HI/DI tests, suggesting that TFS sensitivity tended to worsen with increasing age. CI pure-tone thresholds and duration of profound deafness were significantly correlated with STARR performance. Bimodal users showed significantly better TFS and STARR performance for bimodal listening than for their CI-only condition. Median bimodal gains were 33.0 Hz for the HI test and 95.0 Hz for the DI test. DI outcomes in bimodal users revealed a significant correlation with unaided hearing thresholds for octave frequencies lower than 1000 Hz. Median STARR scores were 17.3 versus 8.1 dB for CI only and bimodal listening, respectively. STARR performance was significantly correlated with HI findings for CI listeners and with those of DI for bimodal listeners. Conclusions: LF pitch perception was found to be abnormal in the majority of adult CI recipients, confirming poor IFS processing of CIs. Similarly, the STARR findings reflected a common performance deterioration with the HI/DI tests, suggesting the cause probably being a lack of access to TFS information. Contralateral hearing aid users obtained a remarkable bimodal benefit for all tests. Such results highlighted the importance of TFS cues for challenging speech perception and the relevance to everyday listening conditions. HI/DI and STARR tests show promise for gaining insights into how TFS and speech perception are being limited and may guide the customization of CI program parameters and support the fine tuning of bimodal listening.												26	27											JUL-AUG	2018	39	4					679	686		10.1097/AUD.0000000000000525	http://dx.doi.org/10.1097/AUD.0000000000000525												2026-01-16	WOS:000442151500009
J	TOMPKING, CA; FLOWERS, CR				TOMPKING, CA; FLOWERS, CR			PERCEPTION OF EMOTIONAL INTONATION BY BRAIN-DAMAGED ADULTS - THE INFLUENCE OF TASK PROCESSING LEVELS	JOURNAL OF SPEECH AND HEARING RESEARCH				Article								This research examined perception of moods from the tone-of-voice of semantically neutral phrases following unilateral cerebrovascular accident. It was hypothesized that right hemisphere damage (RHD) would impair even low-level discrimination and recognition of affective prosody, while left hemisphere damage (LHD) would affect performance only as associational-congnitive task demands increased. Thirty-three male subjects, 11 each in RHD, LHD, and normal groups, were given three tasks that varied in presumed amounts of processing undertaken for successful completion. Discrimination of prosodic patterns was expected to require the fewest cognitive operations. An intermediate task involved selecting from two possibilities the label that described moods conveyed prosodically. In the third task, prosodic mood selection was made from four choices, increasing the number of comparisons necessary for accurate judgement. As hypothesized, RHD subjects were inferior to normal subjects in all tasks. LHD subjects were equivalent to normal subjects for the first two tasks, but fell to the level of the RHD group for the third task. These results indicated that the right hemisphere in men was primarily involved in the reception and recognition of emotional prosodic stimuli. Increasing cognitive demands, however, brought about a shift in emphasis from the right hemisphere to both hemispheres. An implication of these findings concerns the need to examine performance levels that invoke changes from expected pattens of hemispheric specialization to advance our knowledge of functional asymmetries.												77	81												1985	28	4					527	538		10.1044/jshr.2804.527	http://dx.doi.org/10.1044/jshr.2804.527												2026-01-16	WOS:A1985AVS0500009
J	Reed, CL; Cahn, SJ; Cory, C; Szaflarski, JP				Reed, Catherine L.; Cahn, Steven J.; Cory, Christopher; Szaflarski, Jerzy P.			Impaired perception of harmonic complexity in congenital amusia: A case study	COGNITIVE NEUROPSYCHOLOGY				Article								This study investigates whether congenital amusia (an inability to perceive music from birth) also impairs the perception of musical qualities that do not rely on fine-grained pitch discrimination. We established that G. G. (64-year-old male, age-typical hearing) met the criteria of congenital amusia and demonstrated music-specific deficits (e.g., language processing, intonation, prosody, fine-grained pitch processing, pitch discrimination, identification of discrepant tones and direction of pitch for tones in a series, pitch discrimination within scale segments, predictability of tone sequences, recognition versus knowing memory for melodies, and short-term memory for melodies). Next, we conducted tests of tonal fusion, harmonic complexity, and affect perception: recognizing timbre, assessing consonance and dissonance, and recognizing musical affect from harmony. G. G. displayed relatively unimpaired perception and production of environmental sounds, prosody, and emotion conveyed by speech compared with impaired fine-grained pitch perception, tonal sequence discrimination, and melody recognition. Importantly, G. G. could not perform tests of tonal fusion that do not rely on pitch discrimination: He could not distinguish concurrent notes, timbre, consonance/dissonance, simultaneous notes, and musical affect. Results indicate at least three distinct problems-one with pitch discrimination, one with harmonic simultaneity, and one with musical affect-and each has distinct consequences for music perception.												0	3												2011	28	5					305	321		10.1080/02643294.2011.646972	http://dx.doi.org/10.1080/02643294.2011.646972												2026-01-16	WOS:000300165400001
J	Kao, CE; Zhang, Y				Kao, Chieh; Zhang, Yang			Sex Differences in Processing Emotional Speech Prosody: Preliminary Findings from a Multi-Feature Oddball Study	BRAIN SCIENCES				Article								Background/Objectives: Emotional prosody, the intonation and rhythm of speech that conveys emotions, is vital for speech communication as it provides essential context and nuance to the words being spoken. This study explored how listeners automatically process emotional prosody in speech, focusing on different neural responses for the prosodic categories and potential sex differences. Methods: The pilot data here involved 11 male and 11 female adult participants (age range: 18-28). A multi-feature oddball paradigm was used, in which participants were exposed to sequences of non-repeating English words with emotional (angry, happy, sad) or neutral prosody while watching a silent movie. Results: Both mismatch negativity (MMN) and P3a components were observed, indicating automatic perceptual grouping and neural sensitivity to emotional variations in speech. Women showed stronger MMN to angry than sad prosody, while men showed stronger MMN to angry than happy prosody. Happy prosody elicited the strongest P3a, but only in men. Conclusions: The findings challenge the notion that all facets of emotion processing are biased toward female superiority. However, these results from 22 young adult native English speakers should be interpreted with caution, as data from a more adequate sample size are needed to test the generalizability of the findings. Combined with results from studies on children and elderly adults, these preliminary data underscore the need to explore the complexities of emotional speech processing mechanisms to account for category and sex differences across the lifespan in a longitudinal perspective.												1	2											DEC	2024	14	12							1216	10.3390/brainsci14121216	http://dx.doi.org/10.3390/brainsci14121216												2026-01-16	WOS:001386778100001
J	Nygaard, LC; Herold, DS; Namy, LL				Nygaard, Lynne C.; Herold, Debora S.; Namy, Laura L.			The Semantics of Prosody: Acoustic and Perceptual Evidence of Prosodic Correlates to Word Meaning	COGNITIVE SCIENCE				Article								This investigation examined whether speakers produce reliable prosodic correlates to meaning across semantic domains and whether listeners use these cues to derive word meaning from novel words. Speakers were asked to produce phrases in infant-directed speech in which novel words were used to convey one of two meanings from a set of antonym pairs (e.g., big/small). Acoustic analyses revealed that some acoustic features were correlated with overall valence of the meaning. However, each word meaning also displayed a unique acoustic signature, and semantically related meanings elicited similar acoustic profiles. In two perceptual tests, listeners either attempted to identify the novel words with a matching meaning dimension (picture pair) or with mismatched meaning dimensions. Listeners inferred the meaning of the novel words significantly more often when prosody matched the word meaning choices than when prosody mismatched. These findings suggest that speech contains reliable prosodic markers to word meaning and that listeners use these prosodic cues to differentiate meanings. That prosody is semantic suggests a reconceptualization of traditional distinctions between linguistic and nonlinguistic properties of spoken language.												104	123											JAN-FEB	2009	33	1					127	146		10.1111/j.1551-6709.2008.01007.x	http://dx.doi.org/10.1111/j.1551-6709.2008.01007.x												2026-01-16	WOS:000266589500007
J	Guo, N; Si, XP; Zhang, Y; Ding, Y; Zhou, WJ; Zhang, D; Hong, B				Guo, Ning; Si, Xiaopeng; Zhang, Yang; Ding, Yue; Zhou, Wenjing; Zhang, Dan; Hong, Bo			Speech frequency-following response in human auditory cortex is more than a simple tracking	NEUROIMAGE				Article								The human auditory cortex is recently found to contribute to the frequency following response (FFR) and the cortical component has been shown to be more relevant to speech perception. However, it is not clear how cortical FFR may contribute to the processing of speech fundamental frequency (F0) and the dynamic pitch. Using intracranial EEG recordings, we observed a significant FFR at the fundamental frequency (F0) for both speech and speech-like harmonic complex stimuli in the human auditory cortex, even in the missing fundamental condition. Both the spectral amplitude and phase coherence of the cortical FFR showed a significant harmonic preference, and attenuated from the primary auditory cortex to the surrounding associative auditory cortex. The phase coherence of the speech FFR was found significantly higher than that of the harmonic complex stimuli, especially in the left hemisphere, showing a high timing fidelity of the cortical FFR in tracking dynamic F0 in speech. Spectrally, the frequency band of the cortical FFR was largely overlapped with the range of the human vocal pitch. Taken together, our study parsed the intrinsic properties of the cortical FFR and reveals a preference for speech-like sounds, supporting its potential role in processing speech intonation and lexical tones.												11	12											FEB 1	2021	226								117545	10.1016/j.neuroimage.2020.117545	http://dx.doi.org/10.1016/j.neuroimage.2020.117545												2026-01-16	WOS:000608035900024
J	Vuvan, DT; Nunes-Silva, M; Peretz, I				Vuvan, Dominique T.; Nunes-Silva, Marilia; Peretz, Isabelle			Meta-analytic evidence for the non-modularity of pitch processing in congenital amusia	CORTEX				Article								A major theme driving research in congenital amusia is related to the modularity of this musical disorder, with two possible sources of the amusic pitch perception deficit. The first possibility is that the amusic deficit is due to a broad disorder of acoustic pitch processing that has the effect of disrupting downstream musical pitch processing, and the second is that amusia is specific to a musical pitch processing module. To interrogate these hypotheses, we performed a meta-analysis on two types of effect sizes contained within 42 studies in the amusia literature: the performance gap between amusics and controls on tasks of pitch discrimination, broadly defined, and the correlation between specifically acoustic pitch perception and musical pitch perception. To augment the correlation database, we also calculated this correlation using data from 106 participants tested by our own research group. We found strong evidence for the acoustic account of amusia. The magnitude of the performance gap was moderated by the size of pitch change, but not by whether the stimuli were composed of tones or speech. Furthermore, there was a significant correlation between an individuals acoustic and musical pitch perception. However, individual cases show a double dissociation between acoustic and musical processing, which suggests that although most amusic cases are probably explainable by an acoustic deficit, there is heterogeneity within the disorder. Finally, we found that tonal language fluency does not influence the performance gap between amusics and controls, and that there was no evidence that amusics fare worse with pitch direction tasks than pitch discrimination tasks. These results constitute a quantitative review of the current literature of congenital amusia, and suggest several new directions for research, including the experimental induction of amusic behaviour through transcranial magnetic stimulation (TMS) and the systematic exploration of the developmental trajectory of this disorder. (C) 2015 Elsevier Ltd. All rights reserved.												43	47											AUG	2015	69						186	200		10.1016/j.cortex.2015.05.002	http://dx.doi.org/10.1016/j.cortex.2015.05.002												2026-01-16	WOS:000359330200018
J	Ortega-Llebaria, M; Wu, ZH				Ortega-Llebaria, Marta; Wu, Zhaohong			Chinese-English Speakers' Perception of Pitch in Their Non-Tonal Language: Reinterpreting English as a Tonal-Like Language	LANGUAGE AND SPEECH				Article								Changing the F0-contour of English words does not change their lexical meaning. However, it changes the meaning in tonal languages such as Mandarin. Given this important difference and knowing that words in the two languages of a bilingual lexicon interact, the question arises as to how Mandarin-English speakers process pitch in their bilingual lexicon. The few studies that addressed this question showed that Mandarin-English speakers did not perceive pitch in English words as native English speakers did. These studies, however, used English words as stimuli failing to examine nonwords and Mandarin words. Consequently, possible pre-lexical effects and L1 transfer were not ruled out. The present study fills this gap by examining pitch perception in Mandarin and English words and nonwords by Mandarin-English speakers and a group of native English controls. Results showed the tonal experience of Chinese-English speakers modulated their perception of pitch in their non-tonal language at both pre-lexical and lexical levels. In comparison to native English controls, tonal speakers were more sensitive to the acoustic salience of F0-contours in the pre-lexical processing due to top-down feedback. At the lexical level, Mandarin-English speakers organized words in their two languages according to similarity criteria based on both F0 and segmental information, whereas only the segmental information was relevant to the control group. These results in perception together with consistently reported production patterns in previous literature suggest that Mandarin-English speakers process pitch in English as if it was a one-tone language.												11	11											JUN	2021	64	2			SI		467	487	0023830919894606	10.1177/0023830919894606	http://dx.doi.org/10.1177/0023830919894606		JAN 2020										2026-01-16	WOS:000507060400001
J	Lu, XJ; Sun, YN; Ho, HT; Thompson, WF				Lu, Xuejing; Sun, Yanan; Ho, Hao Tam; Thompson, William Forde			Pitch contour impairment in congenital amusia: New insights from the Self-paced Audio-visual Contour Task (SACT)	PLOS ONE				Article								Individuals with congenital amusia usually exhibit impairments in melodic contour processing when asked to compare pairs of melodies that may or may not be identical to one another. However, it is unclear whether the impairment observed in contour processing is caused by an impairment of pitch discrimination, or is a consequence of poor pitch memory. To help resolve this ambiguity, we designed a novel Self-paced Audio-visual Contour Task (SACT) that evaluates sensitivity to contour while placing minimal burden on memory. In this task, participants control the pace of an auditory contour that is simultaneously accompanied by a visual contour, and they are asked to judge whether the two contours are congruent or incongruent. In Experiment 1, melodic contours varying in pitch were presented with a series of dots that varied in spatial height. Amusics exhibited reduced sensitivity to audio-visual congruency in comparison to control participants. To exclude the possibility that the impairment arises from a general deficit in cross-modal mapping, Experiment 2 examined sensitivity to cross-modal mapping for two other auditory dimensions: timbral brightness and loudness. Amusics and controls were significantly more sensitive to large than small contour changes, and to changes in loudness than changes in timbre. However, there were no group differences in cross-modal mapping, suggesting that individuals with congenital amusia can comprehend spatial representations of acoustic information. Taken together, the findings indicate that pitch contour processing in congenital amusia remains impaired even when pitch memory is relatively unburdened.												6	10											JUN 15	2017	12	6							e0179252	10.1371/journal.pone.0179252	http://dx.doi.org/10.1371/journal.pone.0179252												2026-01-16	WOS:000403364600027
J	Li, YN; Tang, C; Lu, JF; Wu, JS; Chang, EF				Li, Yuanning; Tang, Claire; Lu, Junfeng; Wu, Jinsong; Chang, Edward F.			Human cortical encoding of pitch in tonal and non-tonal languages	NATURE COMMUNICATIONS				Article								Languages can use a common repertoire of vocal sounds to signify distinct meanings. In tonal languages, such as Mandarin Chinese, pitch contours of syllables distinguish one word from another, whereas in non-tonal languages, such as English, pitch is used to convey intonation. The neural computations underlying language specialization in speech perception are unknown. Here, we use a cross-linguistic approach to address this. Native Mandarin- and English- speaking participants each listened to both Mandarin and English speech, while neural activity was directly recorded from the non-primary auditory cortex. Both groups show language-general coding of speaker-invariant pitch at the single electrode level. At the electrode population level, we find language-specific distribution of cortical tuning parameters in Mandarin speakers only, with enhanced sensitivity to Mandarin tone categories. Our results show that speech perception relies upon a shared cortical auditory feature processing mechanism, which may be tuned to the statistics of a given language. Different languages rely on different vocal sounds to convey meaning. Here the authors show that language-general coding of pitch occurs in the non-primary auditory cortex for both tonal (Mandarin Chinese) and non-tonal (English) languages, with some language specificity on the population level.												51	59											FEB 19	2021	12	1							1161	10.1038/s41467-021-21430-x	http://dx.doi.org/10.1038/s41467-021-21430-x												2026-01-16	WOS:000621489800003
J	Mahar, SA; Mahar, MH; Danwar, SH; Mahar, JA				Mahar, Shahid Ali; Mahar, Mumtaz Hussain; Danwar, Shahid Hussain; Mahar, Javed Ahmed			Investigation of Pitch and Duration Range in Speech of Sindhi Adults for Prosody Generation Module	INTERNATIONAL JOURNAL OF ADVANCED COMPUTER SCIENCE AND APPLICATIONS				Article								Prosody refers to structure of sound and rhythm and both are essential parts of speech processing applications. It comprises of tone, stress, intonation and rhythm. Pitch and duration are the core elements of acoustic and that information can make easy to design and development for application module. Through these two peculiarities, the prosody module can be validated. These two factors have been investigated using the sounds of Sindhi adults and presented in this paper. For the experiment and analysis, 245 male and female undergraduate students were selected as speakers belonging from five different districts of upper Sindh and categorized into groups according to their age. Particular sentences were given and recorded individually from the speakers. Afterward, these sentences segmented into words and stored in a database consisting of 1960 sounds. Thus, distance of the frequency in pitch was measured via Standard Deviation (SD). The lowest Mean SD accompanied 0.25Hz and 0.28Hz received from male and female group of district Sukkur. The highest Mean SD has measured with male and female group of district Ghotki along 0.42Hz and 0.49Hz. Generally, the pitch of female's speakers was found high in contrast to male's speaker by 0.072Hz variation.												1	1											SEP	2019	10	9					187	195															2026-01-16	WOS:000499999000025
J	Wang, L; Ong, JH; Ponsot, E; Hou, QQ; Jiang, CM; Liu, F				Wang, Li; Ong, Jia Hoong; Ponsot, Emmanuel; Hou, Qingqi; Jiang, Cunmei; Liu, Fang			Mental representations of speech and musical pitch contours reveal a diversity of profiles in autism spectrum disorder	AUTISM				Article								As an information-bearing auditory attribute of sound, pitch plays a crucial role in the perception of speech and music. Studies examining pitch processing in autism spectrum disorder have produced equivocal results. To understand this discrepancy from a mechanistic perspective, we used a novel data-driven method, the reverse-correlation paradigm, to explore whether the equivocal findings in autism spectrum disorder have high-level origins in top-down comparisons of internal mental representations of pitch contours. Thirty-two Mandarin-speaking autistic individuals and 32 non-autistic individuals undertook three subtasks testing mental representations of pitch contours in speech, complex tone and melody, respectively. The results indicate that while the two groups exhibited similar representations of pitch contours across the three conditions, the autistic group showed a significantly higher intra-group variability than the non-autistic group. In addition, the two groups did not differ significantly in internal noise, a measure of the robustness of participant responses to external variability, suggesting that the present findings translate genuinely qualitative differences and similarities between groups in pitch processing. These findings uncover for the first time that pitch patterns in speech and music are mentally represented in a similar manner in autistic and non-autistic individuals, through domain-general top-down mechanisms. Lay abstract As a key auditory attribute of sounds, pitch is ubiquitous in our everyday listening experience involving language, music and environmental sounds. Given its critical role in auditory processing related to communication, numerous studies have investigated pitch processing in autism spectrum disorder. However, the findings have been mixed, reporting either enhanced, typical or impaired performance among autistic individuals. By investigating top-down comparisons of internal mental representations of pitch contours in speech and music, this study shows for the first time that, while autistic individuals exhibit diverse profiles of pitch processing compared to non-autistic individuals, their mental representations of pitch contours are typical across domains. These findings suggest that pitch-processing mechanisms are shared across domains in autism spectrum disorder and provide theoretical implications for using music to improve speech for those autistic individuals who have language problems.												11	12											APR	2023	27	3					629	646		10.1177/13623613221111207	http://dx.doi.org/10.1177/13623613221111207		JUL 2022										2026-01-16	WOS:000826666900001
J	Spreckelmeyer, KN; Altenmüller, E; Colonius, H; Münte, TF				Spreckelmeyer, Katja N.; Altenmueller, Eckart; Colonius, Hans; Muente, Thomas F.			Preattentive processing of emotional musical tones: a multidimensional scaling and ERP study	FRONTIERS IN PSYCHOLOGY				Article								Musical emotion can be conveyed by subtle variations in timbre. Here, we investigated whether the brain is capable to discriminate tones differing in emotional expression by recording event-related potentials (ERPs) in an oddball paradigm under preattentive listening conditions. First, using multidimensional Fechnerian scaling, pairs of violin tones played with a happy or sad intonation were rated same or different by a group of non-musicians. Three happy and three sad tones were selected for the ERP experiment. The Fechnerian distances between tones within an emotion were in the same range as the distances between tones of different emotions. In two conditions, either 3 happy and 1 sad or 3 sad and 1 happy tone were presented in pseudo-random order. A mismatch negativity for the emotional deviant was observed, indicating that in spite of considerable perceptual differences between the three equiprobable tones of the standard emotion, a template was formed based on timbral cues against which the emotional deviant was compared. Based on Juslin's assumption of redundant code usage, we propose that tones were grouped together, because they were identified as belonging to one emotional category based on different emotion-specific cues. These results indicate that the brain forms an emotional memory trace at a preattentive level and thus, extends previous investigations in which emotional deviance was confounded with physical dissimilarity. Differences between sad and happy tones were observed which might be due to the fact that the happy emotion is mostly communicated by suprasegmental features.												9	10											SEP 23	2013	4								656	10.3389/fpsyg.2013.00656	http://dx.doi.org/10.3389/fpsyg.2013.00656												2026-01-16	WOS:000331586100001
J	Mitchell, RLC; Elliott, R; Barry, M; Cruttenden, A; Woodruff, PWR				Mitchell, RLC; Elliott, R; Barry, M; Cruttenden, A; Woodruff, PWR			The neural response to emotional prosody, as revealed by functional magnetic resonance imaging	NEUROPSYCHOLOGIA				Article								Prosody is an important feature of language, comprising intonation, loudness, and tempo. Emotional prosodic processing forms an integral part of our social interactions. The main aim of this study was to use bold contrast fMRI to clarify the normal functional neuroanatomy of emotional prosody, in passive and active contexts. Subjects performed six separate scanning studies, within which two different conditions were contrasted: (1) "pure" emotional prosody versus rest; (2) congruent emotional prosody versus 'neutral' sentences; (3) congruent emotional prosody versus rest; (4) incongruent emotional prosody versus rest; (5) congruent versus incongruent emotional prosody; and (6) an active experiment in which subjects were instructed to either attend to the emotion conveyed by semantic content or that conveyed by tone of voice. Data resulting from these contrasts were analysed using SPM99. Passive listening to emotional prosody consistently activated the lateral temporal lobe (superior and/or middle temporal gyri). This temporal lobe response was relatively right-lateralised with or without semantic information. Both the separate and direct comparisons of congruent and incongruent emotional prosody revealed that subjects used fewer brain regions to process incongruent emotional prosody than congruent. The neural response to attention to semantics, was left lateralised, and recruited an extensive network not activated by attention to emotional prosody. Attention to emotional prosody modulated the response to speech, and induced right-lateralised activity, including the middle temporal gyrus. In confirming the results of lesion and neuropsychological studies, the current study emphasises the importance of the right hemisphere in the processing of emotional prosody, specifically the lateral temporal lobes. (C) 2003 Elsevier Science Ltd. All rights reserved.												275	316												2003	41	10					1410	1421		10.1016/S0028-3932(03)00017-4	http://dx.doi.org/10.1016/S0028-3932(03)00017-4												2026-01-16	WOS:000183368300012
J	Tang, P; Yuen, I; Demuth, K; Rattanasone, NX				Tang, Ping; Yuen, Ivan; Demuth, Katherine; Rattanasone, Nan Xu			The Acquisition of Contrastive Focus During Online Sentence-Comprehension by Children Learning Mandarin Chinese	DEVELOPMENTAL PSYCHOLOGY				Article								Contrastive focus, conveyed by prosodic cues, marks important information. Studies have shown that 6-year-olds learning English and Japanese can use contrastive focus during online sentence comprehension: focus used in a contrastive context facilitates the identification of a target referent (speeding up processing), whereas focus used inappropriately in a noncontrastive context misleads listeners to predict an incorrect referent, hindering the identification process (Ito et al., 2012, 2014). In Mandarin Chinese, the mapping between prosodic form and contrastive focus is less transparent, potentially delaying the acquisition of contrastive focus. This study assessed the online processing of contrastive focus by 196 Mandarin-speaking 4-10-year-olds and 34 adults in China, using the visual world paradigm. Stimuli contained a target NP in a mini discourse, with focus being used in contrastive (Experiment 1) versus Noncontrastive contexts (Experiment 2). Experiment 1 showed that the appropriate use of prosodic form for contrastive focus facilitated the identification of a target referent for 7-10-year-olds and adults, though not younger children. Experiment 2 showed that the inappropriate use of prosodic form for contrastive focus slowed the identification process only for 10-year-olds and adults. Thus, whereas 7-10-year-olds are sensitive to prosodic form for contrastive focus, only 10-year-olds use it as a primary cue to predict an upcoming referent like adults. The acquisition of contrastive focus in Mandarin is therefore a gradual process, with children showing sensitivity to contrastive focus during the early school years, and developing adult-like form-function mapping between prosody and focus until the end of primary school.												6	6											MAY	2023	59	5					845	861		10.1037/dev0001498	http://dx.doi.org/10.1037/dev0001498		DEC 2022										2026-01-16	WOS:000894788700001
J	Jeong, E; Kim, G; Kang, SW				Jeong, Eunseo; Kim, Gyunyeop; Kang, Sangwoo			Multimodal Prompt Learning in Emotion Recognition Using Context and Audio Information	MATHEMATICS				Article								Prompt learning has improved the performance of language models by reducing the gap in language model training methods of pre-training and downstream tasks. However, extending prompt learning in language models pre-trained with unimodal data to multimodal sources is difficult as it requires additional deep-learning layers that cannot be attached. In the natural-language emotion-recognition task, improved emotional classification can be expected when using audio and text to train a model rather than only natural-language text. Audio information, such as voice pitch, tone, and intonation, can give more information that is unavailable in text to predict emotions more effectively. Thus, using both audio and text can enable better emotion prediction in speech emotion-recognition models compared to semantic information alone. In this paper, in contrast to existing studies that use multimodal data with an additional layer, we propose a method for improving the performance of speech emotion recognition using multimodal prompt learning with text-based pre-trained models. The proposed method is using text and audio information in prompt learning by employing a language model pre-trained on natural-language text. In addition, we propose a method to improve the emotion-recognition performance of the current utterance using the emotion and contextual information of the previous utterances for prompt learning in speech emotion-recognition tasks. The performance of the proposed method was evaluated using the English multimodal dataset MELD and the Korean multimodal dataset KEMDy20. Experiments using both the proposed methods obtained an accuracy of 87.49%, F1 score of 44.16, and weighted F1 score of 86.28.												7	9											JUL	2023	11	13							2908	10.3390/math11132908	http://dx.doi.org/10.3390/math11132908												2026-01-16	WOS:001034178300001
J	Loutrari, A; Lorch, MP				Loutrari, Ariadne; Lorch, Marjorie Perlman			Preserved appreciation of aesthetic elements of speech and music prosody in an amusic individual: A holistic approach	BRAIN AND COGNITION				Article								We present a follow-up study on the case of a Greek amusic adult, B.Z., whose impaired performance on scale, contour, interval, and meter was reported by Paraskevopoulos, Tsapkini, and Peretz in 2010, employing a culturally-tailored version of the Montreal Battery of Evaluation of Amusia. In the present study, we administered a novel set of perceptual judgement tasks designed to investigate the ability to appreciate holistic prosodic aspects of 'expressiveness' and emotion in phrase length music and speech stimuli. Our results show that, although diagnosed as a congenital amusic, B.Z. scored as well as healthy controls (N = 24) on judging 'expressiveness' and emotional prosody in both speech and music stimuli. These findings suggest that the ability to make perceptual judgements about such prosodic qualities may be preserved in individuals who demonstrate difficulties perceiving basic musical features such as melody or rhythm. B.Z.'s case yields new insights into amusia and the processing of speech and music prosody through a holistic approach. The employment of novel stimuli with relatively fewer non-naturalistic manipulations, as developed for this study, may be a useful tool for revealing unexplored aspects of music and speech cognition and offer the possibility to further the investigation of the perception of acoustic streams in more authentic auditory conditions.												4	4											JUL	2017	115						1	11		10.1016/j.bandc.2017.03.010	http://dx.doi.org/10.1016/j.bandc.2017.03.010												2026-01-16	WOS:000401881100001
J	Kirchberger, MJ; Russo, FA				Kirchberger, Martin J.; Russo, Frank A.			Development of the Adaptive Music Perception Test	EAR AND HEARING				Article								Objectives: Despite vast amounts of research examining the influence of hearing loss on speech perception, comparatively little is known about its influence on music perception. No standardized test exists to quantify music perception of hearing-impaired (HI) persons in a clinically practical manner. This study presents the Adaptive Music Perception (AMP) test as a tool to assess important aspects of music perception with hearing loss. Design: A computer-driven test was developed to determine the discrimination thresholds of 10 low-level physical dimensions (e.g., duration, level) in the context of perceptual judgments about musical dimensions: meter, harmony, melody, and timbre. In the meter test, the listener is asked to judge whether a tone sequence is duple or triple in meter. The harmony test requires that the listener make judgments about the stability of the chord sequences. In the melody test, the listener must judge whether a comparison melody is the same as a standard melody when presented in transposition and in the context of a chordal accompaniment that serves as a mask. The timbre test requires that the listener determines which of two comparison tones is different in timbre from a standard tone (ABX design). Twenty-one HI participants and 19 normal-hearing (NH) participants were recruited to carry out the music tests. Participants were tested twice on separate occasions to evaluate test-retest reliability. Results: The HI group had significantly higher discrimination thresholds than the NH group in 7 of the 10 low-level physical dimensions: frequency discrimination in the meter test, dissonance and intonation perception in the harmony test, melody-to-chord ratio for both melody types in the melody test, and the perception of brightness and spectral irregularity in the timbre test. Small but significant improvement between test and retest was observed in three dimensions: frequency discrimination (meter test), dissonance (harmony test), and attack length (timbre test). All other dimensions did not show a session effect. Test-retest reliability was poor (<0.6) for spectral irregularity (timbre test); acceptable (>0.6) for pitch and duration (meter test), dissonance and intonation (harmony test), and melody-to-chord ratio I and II (melody test); and excellent (>0.8) for level (meter test) and attack (timbre test). Conclusion: The AMP test revealed differences in a wide range of music perceptual abilities between NH and HI listeners. The recognition of meter was more difficult for HI listeners when the listening task was based on frequency discrimination. The HI group was less sensitive to changes in harmony and had more difficulties with distinguishing melodies in a background of music. In addition, the thresholds to discriminate timbre were significantly higher for the HI group in brightness and spectral irregularity dimensions. The AMP test can be used as a research tool to further investigate music perception with hearing aids and compare the benefit of different music processing strategies for the HI listener. Future testing will involve larger samples with the inclusion of hearing aided conditions allowing for the establishment of norms so that the test might be appropriate for use in clinical practice.												22	27											MAR-APR	2015	36	2					217	228															2026-01-16	WOS:000350254700013
J	Hoekert, M; Bais, L; Kahn, RS; Aleman, A				Hoekert, Marjolijn; Bais, Leonie; Kahn, Rene S.; Aleman, Andre			Time Course of the Involvement of the Right Anterior Superior Temporal Gyrus and the Right Fronto-Parietal Operculum in Emotional Prosody Perception	PLOS ONE				Article								In verbal communication, not only the meaning of the words convey information, but also the tone of voice (prosody) conveys crucial information about the emotional state and intentions of others. In various studies right frontal and right temporal regions have been found to play a role in emotional prosody perception. Here, we used triple-pulse repetitive transcranial magnetic stimulation (rTMS) to shed light on the precise time course of involvement of the right anterior superior temporal gyrus and the right fronto-parietal operculum. We hypothesized that information would be processed in the right anterior superior temporal gyrus before being processed in the right fronto-parietal operculum. Right-handed healthy subjects performed an emotional prosody task. During listening to each sentence a triplet of TMS pulses was applied to one of the regions at one of six time points (400-1900 ms). Results showed a significant main effect of Time for right anterior superior temporal gyrus and right fronto-parietal operculum. The largest interference was observed half-way through the sentence. This effect was stronger for withdrawal emotions than for the approach emotion. A further experiment with the inclusion of an active control condition, TMS over the EEG site POz (midline parietal-occipital junction), revealed stronger effects at the fronto-parietal operculum and anterior superior temporal gyrus relative to the active control condition. No evidence was found for sequential processing of emotional prosodic information from right anterior superior temporal gyrus to the right fronto-parietal operculum, but the results revealed more parallel processing. Our results suggest that both right fronto-parietal operculum and right anterior superior temporal gyrus are critical for emotional prosody perception at a relatively late time period after sentence onset. This may reflect that emotional cues can still be ambiguous at the beginning of sentences, but become more apparent half-way through the sentence.												37	43											MAY 21	2008	3	5							e2244	10.1371/journal.pone.0002244	http://dx.doi.org/10.1371/journal.pone.0002244												2026-01-16	WOS:000262258700052
J	Deliens, G; Stercq, F; Mary, A; Slama, H; Cleeremans, A; Peigneux, P; Kissine, M				Deliens, Gaetane; Stercq, Fanny; Mary, Alison; Slama, Hichem; Cleeremans, Axel; Peigneux, Philippe; Kissine, Mikhail			Impact of Acute Sleep Deprivation on Sarcasm Detection	PLOS ONE				Article								There is growing evidence that sleep plays a pivotal role on health, cognition and emotional regulation. However, the interplay between sleep and social cognition remains an uncharted research area. In particular, little is known about the impact of sleep deprivation on sarcasm detection, an ability which, once altered, may hamper everyday social interactions. The aim of this study is to determine whether sleep-deprived participants are as able as sleep-rested participants to adopt another perspective in gauging sarcastic statements. At 9am, after a whole night of sleep (n = 15) or a sleep deprivation night (n = 15), participants had to read the description of an event happening to a group of friends. An ambiguous voicemail message left by one of the friends on another's phone was then presented, and participants had to decide whether the recipient would perceive the message as sincere or as sarcastic. Messages were uttered with a neutral intonation and were either: (1) sarcastic from both the participant's and the addressee's perspectives (i.e. both had access to the relevant background knowledge to gauge the message as sarcastic), (2) sarcastic from the participant's but not from the addressee's perspective (i.e. the addressee lacked context knowledge to detect sarcasm) or (3) sincere. A fourth category consisted in messages sarcastic from both the participant's and from the addressee's perspective, uttered with a sarcastic tone. Although sleep-deprived participants were as accurate as sleep-rested participants in interpreting the voice message, they were also slower. Blunted reaction time was not fully explained by generalized cognitive slowing after sleep deprivation; rather, it could reflect a compensatory mechanism supporting normative accuracy level in sarcasm understanding. Introducing prosodic cues compensated for increased processing difficulties in sarcasm detection after sleep deprivation. Our findings support the hypothesis that sleep deprivation might damage the flow of social interactions by slowing perspective-taking processes.												13	19											NOV 4	2015	10	11							e0140527	10.1371/journal.pone.0140527	http://dx.doi.org/10.1371/journal.pone.0140527												2026-01-16	WOS:000364298400023
J	Ma, LJ; Ma, YX; He, XQ; Liu, HT; Zhang, JY				Ma Lijun; Ma Yunxiao; He Xiaoqing; Liu Haitao; Zhang Jingyu			Processing of Chinese homophonic two-part allegoric sayings: Effects of familiarity and homophone	ACTA PSYCHOLOGICA SINICA				Article								Two-part allegorical sayings are a typical language form in Chinese. Understanding two-part allegorical saying involves the ability to understand figurative meanings. Chinese two-part allegorical sayings convey figurative meanings by activating either homophonic or conceptual associations. Homophonic associations are realized based on a conceptual connection between the two homophonic expressions: the second part of the sayings and the expression of the idiomatic meaning. Within the example of Lao tai tai shang ji wo ((sic))-ben dan ((sic)), a situation is described as an old lady (lao tai tai or (sic)) is about to walk towards a henhouse (shang ji wo or (sic)), which is reflected in the second part that the purpose of doing this is "heading for eggs" (ben dan or (sic)). The intended interpretation of the saying "an idiot" (ben dan or (sic)) could not be worked out without the help of a very crucial apparatus-sound association; that is, "heading for eggs" is pronounced the same with "an idiot" in Chinese with respect to the same segmental combinations and tone patterns. Within the paradigm of sound association, the meaning identified in the source domain (the first part; in our example, the old lady's behavior) is also observed in the target domain (the second part; in our example, the figurative meaning of the old lady's behavior) in a metaphoric way through mapping between the two domains, resulting in a shifting from a concrete concept to an abstract one. Mapping, which was described by Lakoff and Johnson in their Conceptual Metaphor Theory, has been considered a powerful theory in interpreting metaphors. Fauconnier proposed Conceptual Blending Theory, emphasizing that mapping happens across spaces via connecting counterparts in the input mental spaces. In our example, it connects one mental space contained the image of an old lady walking towards a henhouse and another mental space describing the purpose of carrying out this behavior. Then the mapping happens when the mental apparatus identifies the sound similarity and generates the intended meaning. Meanwhile, the knowledge of recognizing implicature (Xu, 2005) in pragmatic inference also plays a crucial role in processing two-part allegorical sayings. From this perspective, Chinese two-part allegorical sayings are one of the ideal languages. The successful understanding of them couldn't be accomplished without considering how people interpret in their real usage. There are three theories relevant to interpreting of Chines two-part allegorical sayings, but what we wonder is which theory is more powerful in explaining the processing of homophonic two-part allegorical sayings in terms of various degrees? Does sound association play a crucial role in the processing? In order to answer these questions, two experiments were designed by using eye-movement instrument: experiment 1 investigated the effect of various degrees of familiarity on the processing of two different types of back parts (homophonic association/phonography), for example, (sic) is phonography because there is no metaphoric inference between front and back parts, but (sic) is with homophonic association because the implied meaning (sic) is inferred from the words (sic) through sound similarity. We asked the participants to judge the semantic relatedness between front and back parts and we found that the judgment was determined by the type of back parts, that is, the homophone facilitated the participants' judgment because of the sound association; while phonography forced participants to infer the implied meaning of the sayings. Meanwhile, participants took longer time to process the sayings with high familiarity and made more errors in the judgment task, the reason of which might be caused by the negative effect of long-term memory. The result supported the Conceptual Metaphor theory and Conceptual Blending theory. However, participants adopted a quite different processing strategy called the on-line processing strategy when the sayings were with low familiarity. The result supported the Pragmatic Inference theory. Experiment 2 investigated how various intonations affected the judgment of semantic relatedness between front and back parts. The results showed that the characters with the same sound pattern but not with the same intonation (e. g. (sic)) exerted different influences on the judgment. Specifically, the character "(sic)", which does not fit into the meaning of any of the two parts, did not play a role in the processing. The result does not support the Conceptual Blending theory.												2	2											DEC	2019	51	12					1306	1317		10.3724/SP.J.1041.2019.01306	http://dx.doi.org/10.3724/SP.J.1041.2019.01306												2026-01-16	WOS:000551496500002
J	Segal, O; Houston, D; Kishon-Rabin, L				Segal, Osnat; Houston, Derek; Kishon-Rabin, Liat			Auditory Discrimination of Lexical Stress Patterns in Hearing-Impaired Infants with Cochlear Implants Compared with Normal Hearing: Influence of Acoustic Cues and Listening Experience to the Ambient Language	EAR AND HEARING				Article								Objectives: To assess discrimination of lexical stress pattern in infants with cochlear implant (CI) compared with infants with normal hearing (NH). While criteria for cochlear implantation have expanded to infants as young as 6 months, little is known regarding infants' processing of suprasegmental-prosodic cues which are known to be important for the first stages of language acquisition. Lexical stress is an example of such a cue, which, in hearing infants, has been shown to assist in segmenting words from fluent speech and in distinguishing between words that differ only the stress pattern. To date, however, there are no data on the ability of infants with CIs to perceive lexical stress. Such information will provide insight to the speech characteristics that are available to these infants in their first steps of language acquisition. This is of particular interest given the known limitations that the CI device has in transmitting speech information that is mediated by changes in fundamental frequency. Design: Two groups of infants participated in this study. The first group included 20 profoundly hearing-impaired infants with CI, 12 to 33 months old, implanted under the age of 2.5 years (median age of implantation = 14.5 months), with 1 to 6 months of CI use (mean = 2.7 months) and no known additional problems. The second group of infants included 48 NH infants, 11 to 14 months old with normal development and no known risk factors for developmental delays. Infants were tested on their ability to discriminate between nonsense words that differed on their stress pattern only (/doti/ versus /doti/ and /doti/ versus /doti/) using the visual habituation procedure. The measure for discrimination was the change in looking time between the last habituation trial (e.g., /doti/) and the novel trial (e.g., /doti/). Results: (1) Infants with CI showed discrimination between lexical stress pattern with only limited auditory experience with their implant device, (2) discrimination of stress patterns in infants with CI was reduced compared with that of infants with NH, (3) both groups showed directional asymmetry in discrimination, that is, increased discrimination from the uncommon to the common stress pattern in Hebrew (/doti/ versus /doti/) compared with the reversed condition. Conclusions: The CI device transmitted sufficient acoustic information (amplitude, duration, and fundamental frequency) to allow discrimination between stress patterns in young hearing-impaired infants with CI. The present pattern of results is in support of a discrimination model in which both auditory capabilities and "top-down" interactions are involved. That is, the CI infants detected changes between stressed and unstressed syllables after which they developed a bias for the more common weak-strong stress pattern in Hebrew. The latter suggests that infants with CI were able to extract the statistical distribution of stress patterns by listening to the ambient language even after limited auditory experience with the CI device. To conclude, in relation to processing of lexical stress patterns, infants with CI followed similar developmental milestones as hearing infants thus establishing important prerequisites for early language acquisition.												18	20											MAR-APR	2016	37	2					225	234		10.1097/AUD.0000000000000243	http://dx.doi.org/10.1097/AUD.0000000000000243												2026-01-16	WOS:000371748300011
