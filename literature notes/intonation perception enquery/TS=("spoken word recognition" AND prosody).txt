PT	AU	BA	BE	GP	AF	BF	CA	TI	SO	SE	BS	LA	DT	CT	CY	CL	SP	HO	DE	ID	AB	C1	C3	RP	EM	RI	OI	FU	FP	FX	CR	NR	TC	Z9	U1	U2	PU	PI	PA	SN	EI	BN	J9	JI	PD	PY	VL	IS	PN	SU	SI	MA	BP	EP	AR	DI	DL	D2	EA	PG	WC	WE	SC	GA	PM	OA	HC	HP	DA	UT
J	Kim, SK; Sumner, M				Kim, Seung Kyung; Sumner, Meghan			Beyond lexical meaning: The effect of emotional prosody on spoken word recognition	JOURNAL OF THE ACOUSTICAL SOCIETY OF AMERICA				Article								This study employs an auditory-visual associative priming paradigm to test whether non-emotional words uttered in emotional prosody (e.g., pineapple spoken in angry prosody or happy prosody) facilitate recognition of semantically emotional words (e.g., mad, upset or smile, joy). The results show an affective priming effect between emotional prosody and emotional words independent of lexical carriers of the prosody. Learned acoustic patterns in speech (e.g., emotional prosody) map directly to social concepts and representations, and this social information influences the spoken word recognition process. (C) 2017 Acoustical Society of America												12	19											JUL	2017	142	1					EL49	EL55		10.1121/1.4991328	http://dx.doi.org/10.1121/1.4991328												2026-01-16	WOS:000405656700009
J	Lindfield, KC; Wingfield, A; Goodglass, H				Lindfield, KC; Wingfield, A; Goodglass, H			The contribution of prosody to spoken word recognition	APPLIED PSYCHOLINGUISTICS				Article; Proceedings Paper	1st International Conference on the Mental Lexicon	SEP 03, 1998	UNIV ALBERTA, EDMONTON, CANADA		UNIV ALBERTA			The experiment reported here employed a word-onset gating technique to investigate the role of prosody in word recognition. Subjects were asked to identify words based on word onsets alone, word onsets followed by information about the word duration, or word onsets followed by information about full word prosody (i.e., both duration and stress). Results showed that words were correctly recognized with significantly less segmental onset information when word prosody was available to the subjects. Consistent with this finding, prerecognition error responses reflected correct length and prosody with less onset phonology when prosody information was provided in the stimulus than when only length information was provided. The findings of this experiment confirm the importance of word prosody for spoken word recognition.												20	28											SEP	1999	20	3					395	405		10.1017/S0142716499003045	http://dx.doi.org/10.1017/S0142716499003045												2026-01-16	WOS:000083718100004
J	Lindfield, KC; Wingfield, A; Goodglass, H				Lindfield, KC; Wingfield, A; Goodglass, H			The role of prosody in the mental lexicon	BRAIN AND LANGUAGE				Article; Proceedings Paper	1st International Conference on the Mental Lexicon	SEP 03, 1998	UNIV ALBERTA, EDMONTON, CANADA		UNIV ALBERTA			Current models of spoken word recognition take into account factors such as word frequency, word onset cohort size, and phonological neighborhood density. Using the word onset gating technique we tested word recognition when bandpass filtering was used to allow subjects to hear the full prosodic pattern of a word (number of syllables and syllabic stress), deprived of segmental information beyond that contained in the onset gate. Subjects also heard either word onsets plus duration information or only word onsets. Results suggest that word prosody is represented in the mental lexicon and is effectively used by listeners in spoken word recognition. (C) 1999 Academic Press.												27	34											JUN 1	1999	68	1-2					312	317		10.1006/brln.1999.2094	http://dx.doi.org/10.1006/brln.1999.2094												2026-01-16	WOS:000081530300044
J	Krestar, ML; McLennan, CT				Krestar, Maura L.; McLennan, Conor T.			Examining the effects of variation in emotional tone of voice on spoken word recognition	QUARTERLY JOURNAL OF EXPERIMENTAL PSYCHOLOGY				Article								Emotional tone of voice (ETV) is essential for optimal verbal communication. Research has found that the impact of variation in nonlinguistic features of speech on spoken word recognition differs according to a time course. In the current study, we investigated whether intratalker variation in ETV follows the same time course in two long-term repetition priming experiments. We found that intratalker variability in ETVs affected reaction times to spoken words only when processing was relatively slow and difficult, not when processing was relatively fast and easy. These results provide evidence for the use of both abstract and episodic lexical representations for processing within-talker variability in ETV, depending on the time course of spoken word recognition.												8	13											SEP 1	2013	66	9					1793	1802		10.1080/17470218.2013.766897	http://dx.doi.org/10.1080/17470218.2013.766897												2026-01-16	WOS:000324002200009
J	Jesse, A; McQueen, JM				Jesse, Alexandra; McQueen, James M.			Suprasegmental lexical stress cues in visual speech can guide spoken-word recognition	QUARTERLY JOURNAL OF EXPERIMENTAL PSYCHOLOGY				Article								Visual cues to the individual segments of speech and to sentence prosody guide speech recognition. The present study tested whether visual suprasegmental cues to the stress patterns of words can also constrain recognition. Dutch listeners use acoustic suprasegmental cues to lexical stress (changes in duration, amplitude, and pitch) in spoken-word recognition. We asked here whether they can also use visual suprasegmental cues. In two categorization experiments, Dutch participants saw a speaker say fragments of word pairs that were segmentally identical but differed in their stress realization (e.g., 'ca-vi from cavia guinea pig vs. ?ka-vi from kaviaar caviar). Participants were able to distinguish between these pairs from seeing a speaker alone. Only the presence of primary stress in the fragment, not its absence, was informative. Participants were able to distinguish visually primary from secondary stress on first syllables, but only when the fragment-bearing target word carried phrase-level emphasis. Furthermore, participants distinguished fragments with primary stress on their second syllable from those with secondary stress on their first syllable (e.g., pro-'jec from projector projector vs. ?pro-jec from projectiel projectile), independently of phrase-level emphasis. Seeing a speaker thus contributes to spoken-word recognition by providing suprasegmental information about the presence of primary lexical stress.												15	16											APR 3	2014	67	4					793	808		10.1080/17470218.2013.834371	http://dx.doi.org/10.1080/17470218.2013.834371												2026-01-16	WOS:000333989300011
J	Malins, JG; Joanisse, MF				Malins, Jeffrey G.; Joanisse, Marc F.			The roles of tonal and segmental information in Mandarin spoken word recognition: An eyetracking study	JOURNAL OF MEMORY AND LANGUAGE				Article								We used eyetracking to examine how tonal versus segmental information influence spoken word recognition in Mandarin Chinese. Participants heard an auditory word and were required to identify its corresponding picture from an array that included the target item (chuang2 'bed'), a phonological competitor (segmental: chuang1 'window'; cohort: chuan2 'ship'; rhyme: huang2 'yellow': tonal: niu2 'cow'), and two phonologically unrelated distractors. Growth curve analysis was used to characterize the trajectory of looks to target and competitor items during word processing. We found similar model fits for the segmental and cohort conditions characterized by slower eye movements to correct targets compared to baseline, suggesting that tonal and segmental information are accessed concurrently and play comparable roles in constraining activation. These findings are discussed with respect to current models of spoken word recognition that have not previously accounted for the role of tone. (C) 2010 Elsevier Inc. All rights reserved.												93	106											MAY	2010	62	4					407	420		10.1016/j.jml.2010.02.004	http://dx.doi.org/10.1016/j.jml.2010.02.004												2026-01-16	WOS:000277482100005
J	Katsuda, H; Steffman, J				Katsuda, Hironori; Steffman, Jeremy			Asymmetrical roles of segment and pitch accent in Japanese spoken word recognition	JASA EXPRESS LETTERS				Article								This study examines the roles of segment and pitch accent in Japanese spoken word recognition. In a lexical decision task, it replicates the finding of Cutler and Otake [(1999) J. Acoust. Soc. Am. 105(3), 1877-1888] that pitch accent restricts word activation with a more comprehensive, rigorous experimental design. Furthermore, results uncover an asymmetrical role of segment and pitch accent in word recognition in Japanese: words primed by a pitch accent-matching prime are recognized more slowly and less accurately than words primed by a segment-matching prime.												0	0											JUN	2022	2	6							065201	10.1121/10.0011573	http://dx.doi.org/10.1121/10.0011573												2026-01-16	WOS:000806494500002
J	Brown, M; Salverda, AP; Dilley, LC; Tanenhaus, MK				Brown, Meredith; Salverda, Anne Pier; Dilley, Laura C.; Tanenhaus, Michael K.			Expectations from preceding prosody influence segmentation in online sentence processing	PSYCHONOMIC BULLETIN & REVIEW				Article								Previous work examining prosodic cues in online spoken-word recognition has focused primarily on local cues to word identity. However, recent studies have suggested that utterance-level prosodic patterns can also influence the interpretation of subsequent sequences of lexically ambiguous syllables (Dilley, Mattys, & Vinke, Journal of Memory and Language, 63:274-294, 2010; Dilley & McAuley, Journal of Memory and Language, 59:294-311, 2008). To test the hypothesis that these distal prosody effects are based on expectations about the organization of upcoming material, we conducted a visual-world experiment. We examined fixations to competing alternatives such as pan and panda upon hearing the target word panda in utterances in which the acoustic properties of the preceding sentence material had been manipulated. The proportions of fixations to the monosyllabic competitor were higher beginning 200 ms after target word onset when the preceding prosody supported a prosodic constituent boundary following pan-, rather than following panda. These findings support the hypothesis that expectations based on perceived prosodic patterns in the distal context influence lexical segmentation and word recognition.												62	79											DEC	2011	18	6					1189	1196		10.3758/s13423-011-0167-9	http://dx.doi.org/10.3758/s13423-011-0167-9												2026-01-16	WOS:000297227500022
J	Kaplan, EC; Baskent, D; Wagner, AE				Kaplan, Elif Canseza; Baskent, Deniz; Wagner, Anita Eva			Musical Abilities Influence the Use of Durational Prosodic Cues in Spoken Word Recognition	JOURNAL OF EXPERIMENTAL PSYCHOLOGY-LEARNING MEMORY AND COGNITION				Article; Early Access								Prosody plays a fundamental role in both speech and music. In spoken language, word-level local prosodic cues, such as segment duration, contribute to word recognition. This study investigated whether individual differences in musical abilities are associated with the utilization of prosodic cues during spoken word recognition, both in speech-in-quiet and speech-on-speech conditions (i.e., in the presence of competing talkers). Using the visual world paradigm, we measured listeners' gaze fixations and pupil dilations toward images depicting a referent (e.g., hamster) and a competitor word (e.g., ham), while they simultaneously listened to utterances containing the referent word, whose segment duration either matched or mismatched the referent, with the mismatched duration signaling the competitor word. Participants with varying musical backgrounds completed tasks assessing rhythmic and melodic abilities, and a questionnaire evaluating overall musical sophistication. Our results revealed that listeners with higher scores across the three measures exhibited greater sensitivity to durational cues, as indicated by increased fixations to the competitor and greater pupil dilation when the durational cue mismatched the referent word, both in speech-in-quiet and speech-on-speech. These findings highlight that individual differences in musical abilities are associated with the use of prosodic cues during spoken word recognition.												0	0											2025 NOV 10	2025										10.1037/xlm0001517	http://dx.doi.org/10.1037/xlm0001517		NOV 2025										2026-01-16	WOS:001610917600001
J	Reinisch, E; Jesse, A; McQueen, JM				Reinisch, Eva; Jesse, Alexandra; McQueen, James M.			Early use of phonetic information in spoken word recognition: Lexical stress drives eye movements immediately	QUARTERLY JOURNAL OF EXPERIMENTAL PSYCHOLOGY				Article								For optimal word recognition listeners should use all relevant acoustic information as soon as it comes available. Using printed-word eye tracking we investigated when during word processing Dutch listeners use suprasegmental lexical stress information to recognize words. Fixations on targets such as oOCtopuso (capitals indicate stress) were more frequent than fixations on segmentally overlapping but differently stressed competitors (ookTObero) before segmental information could disambiguate the words. Furthermore, prior to segmental disambiguation, initially stressed words were stronger lexical competitors than noninitially stressed words. Listeners recognize words by immediately using all relevant information in the speech signal.												57	64												2010	63	4					772	783	PII 913995598	10.1080/17470210903104412	http://dx.doi.org/10.1080/17470210903104412												2026-01-16	WOS:000275845300013
J	Brown, M; Salverda, AP; Dilley, LC; Tanenhaus, MK				Brown, Meredith; Salverda, Anne Pier; Dilley, Laura C.; Tanenhaus, Michael K.			Metrical Expectations From Preceding Prosody Influence Perception of Lexical Stress	JOURNAL OF EXPERIMENTAL PSYCHOLOGY-HUMAN PERCEPTION AND PERFORMANCE				Article								Two visual-world experiments tested the hypothesis that expectations based on preceding prosody influence the perception of suprasegmental cues to lexical stress. The results demonstrate that listeners' consideration of competing alternatives with different stress patterns (e.g., 'jury/gi'raffe) can be influenced by the fundamental frequency and syllable timing patterns across material preceding a target word. When preceding stressed syllables distal to the target word shared pitch and timing characteristics with the first syllable of the target word, pictures of alternatives with primary lexical stress on the first syllable (e.g., jury) initially attracted more looks than alternatives with unstressed initial syllables (e.g., giraffe). This effect was modulated when preceding unstressed syllables had pitch and timing characteristics similar to the initial syllable of the target word, with more looks to alternatives with unstressed initial syllables (e.g., giraffe) than to those with stressed initial syllables (e.g., jury). These findings suggest that expectations about the acoustic realization of upcoming speech include information about metrical organization and lexical stress and that these expectations constrain the initial interpretation of suprasegmental stress cues. These distal prosody effects implicate online probabilistic inferences about the sources of acoustic-phonetic variation during spoken-word recognition.												33	41											APR	2015	41	2					306	323		10.1037/a0038689	http://dx.doi.org/10.1037/a0038689												2026-01-16	WOS:000355306300006
J	Friedrich, CK; Alter, K; Kotz, SA				Friedrich, CK; Alter, K; Kotz, SA			An electrophysiological response to different pitch contours in words	NEUROREPORT				Article								A spoken word with more than one syllable contains a specific stress pattern found to be processed during spoken word recognition. The present study investigated the word's pitch contour as a single auditory parameter that marks stress. Event-related brain potentials (ERPs) were recorded while subjects made decisions to artificially pitch manipulated words. ERPs revealed that pitch contours are discriminated already within the first syllable of a word. Furthermore, behavioral responses for words with incorrect pitch contours were longer than for words with correct pitch contours. The results suggest that the pitch contour is an auditory feature of the spoken word that a listener automatically processes during spoken word recognition. NeuroReport 12:3189-3191 (C) 2001 Lippincott Williams & Wilkins.												31	32											OCT 29	2001	12	15					3189	3191		10.1097/00001756-200110290-00009	http://dx.doi.org/10.1097/00001756-200110290-00009												2026-01-16	WOS:000171902600005
J	Arciuli, J; Slowiaczek, LM				Arciuli, Joanne; Slowiaczek, Louisa M.			The where and when of linguistic word-level prosody	NEUROPSYCHOLOGIA				Article								uDespite its presence in all natural languages prosodic processing remains under-researched in cognitive science. Hemispheric specialisation for linguistic word-level prosody, specifically, sensitivity to stress typicality was examined using dichotic listening. In Experiment 1, participants named targets and in Experiment 2 participants classified targets as nouns or verbs. In both studies stress typicality effects emerged in the left hemisphere only. These results suggest that: (1) the left hemisphere may be responsible for conveying accurate stress patterns prior to lexical access, (2) supra-segmental information reduces the set of potential candidates during lexical access, and (3) prosody and grammatical category interact in the language processing system. (c) 2007 Elsevier Ltd. All rights reserved.												26	28												2007	45	11					2638	2642		10.1016/j.neuropsychologia.2007.03.010	http://dx.doi.org/10.1016/j.neuropsychologia.2007.03.010												2026-01-16	WOS:000247865800025
J	Sagarra, N; Casillas, J				Sagarra, Nuria; Casillas, Joseph, V			Suprasegmental information cues morphological anticipation during L1/L2 lexical access	JOURNAL OF SECOND LANGUAGE STUDIES				Article								We use visual-world eye-tracking and gating methods to investigate whether Spanish monolinguals and English late learners of Spanish use prosodic cues (lexical stress) to anticipate morphological information (suffixes) during spoken word recognition, and if they do, whether L2 proficiency and working memory (WM) mediate their anticipatory abilities. Our findings show that the monolinguals used prosodic information to predict word endings in both tasks, regardless of first-syllable stress (stressed, unstressed) and structure (CV, CVC). In contrast, the beginning learners did not use prosodic information to anticipate word suffixes in any task or condition. Importantly, the advanced learners mirrored the monolinguals, except in words with first-syllable CV structure, but were slower than the monolinguals. Finally, WM was not associated with anticipatory eye movements, though results were inconclusive for offline processing. Taken together, the present study shows that suprasegmental information facilitates morphological anticipation during spoken word recognition, and that adult learners can gain anticipatory processing patterns qualitatively, but not quantitatively, similar to monolinguals.												15	19												2018	1	1					31	59		10.1075/jsls.17026.sag	http://dx.doi.org/10.1075/jsls.17026.sag												2026-01-16	WOS:000663804600003
J	McQueen, JM; Cutler, A; Norris, D				McQueen, JM; Cutler, A; Norris, D			Flow of information in the spoken word recognition system	SPEECH COMMUNICATION				Article								Spoken word recognition consists of two major component processes. First, at the prelexical stage, an abstract description of the utterance is generated from the information in the speech signal. Second, at the lexical stage, this description is used to activate all the words stored in the mental lexicon which match the input. These multiple candidate words then compete with each other. We review evidence which suggests that positive (match) and negative (mismatch) information of both a segmental and a suprasegmental nature is used to constrain this activation and competition process. We then ask whether, in addition to the necessary influence of the prelexical stage on the lexical stage, there is also feedback from the lexicon to the prelexical level. In two phonetic categorization experiments, Dutch listeners were asked to label both syllable-initial and syllable-final ambiguous fricatives (e.g., sounds ranging from [f] to [s]) in the word-nonword series maf-mas, and the nonword-word series jaf-jas. They tended to label the sounds in a lexically consistent manner (i.e., consistent with the word endpoints of the series). These lexical effects became smaller in listeners' slower responses, even when the listeners were put under pressure to respond as fast as possible. Our results challenge models of spoken word recognition in which feedback modulates the prelexical analysis of the component sounds of a word whenever that word is heard. (C) 2002 Elsevier Science B.V. All rights reserved.												16	20											AUG	2003	41	1					257	270		10.1016/S0167-6393(02)00108-5	http://dx.doi.org/10.1016/S0167-6393(02)00108-5												2026-01-16	WOS:000183840900021
J	Salverda, AP; Dahan, D; Tanenhaus, MK; Crosswhite, K; Masharov, M; McDonough, J				Salverda, Anne Pier; Dahan, Delphine; Tanenhaus, Michael K.; Crosswhite, Katherine; Masharov, Mikhail; McDonough, Joyce			Effects of prosodically modulated sub-phonetic variation on lexical competition	COGNITION				Article								Eye movements were monitored as participants followed spoken instructions to manipulate one of four objects pictured on a computer screen. Target words occurred in utterance-medial (e.g., Put the cap next to the square) or utterance-final position (e.g., Now click on the cap). Displays consisted of the target picture (e.g., a cap), a monosyllabic competitor picture (e.g., a cat), a polysyllabic competitor picture (e.g., a captain) and a distractor (e.g., a beaker). The relative proportion of fixations to the two types of competitor pictures changed as a function of the position of the target word in the utterance, demonstrating that lexical competition is modulated by prosodically conditioned phonetic variation. (C) 2006 Elsevier B.V. All rights reserved.												43	57											NOV	2007	105	2					466	476		10.1016/j.cognition.2006.10.008	http://dx.doi.org/10.1016/j.cognition.2006.10.008												2026-01-16	WOS:000250025500010
J	Cornew, L; Carver, L; Love, T				Cornew, Lauren; Carver, Leslie; Love, Tracy			There's more to emotion than meets the eye: A processing bias for neutral content in the domain of emotional prosody	COGNITION & EMOTION				Article								Research on emotion processing in the visual modality suggests a processing advantage for emotionally salient stimuli, even at early sensory stages; however, results concerning the auditory correlates are inconsistent. We present two experiments that employed a gating paradigm to investigate emotional prosody. In Experiment 1, participants heard successively building segments of Jabberwocky osentenceso spoken with happy, angry, or neutral intonation. After each segment, participants indicated the emotion conveyed and rated their confidence in their decision. Participants in Experiment 2 also heard Jabberwocky osentenceso in successive increments, with half discriminating happy from neutral prosody, and half discriminating angry from neutral prosody. Participants in both experiments identified neutral prosody more rapidly and accurately than happy or angry prosody. Confidence ratings were greater for neutral sentences, and error patterns also indicated a bias for recognising neutral prosody. Taken together, results suggest that enhanced processing of emotional content may be constrained by stimulus modality.												20	24												2010	24	7					1133	1152	PII 927614767	10.1080/02699930903247492	http://dx.doi.org/10.1080/02699930903247492												2026-01-16	WOS:000282580800004
J	Ariga, T; Hirose, Y				Ariga, Terumichi; Hirose, Yuki			Recognition of spoken words with mispronounced lexical prosody in Japanese	JOURNAL OF THE ACOUSTICAL SOCIETY OF AMERICA				Article								Lexical prosody plays a crucial role in Japanese spoken word recognition. However, listeners of Japanese can still recognize spoken words easily even when they are pronounced with mispronounced lexical prosody, i.e., prosody that differs from their lexical knowledge. The present study investigated how listeners recognize spoken words pronounced with mispronounced lexical pitch accent in Japanese. Two cross-modal semantic priming experiments addressed the process of lexical access during listening to prosodically mispronounced words under a sentential context. When words were presented with mispronounced prosody, semantic priming effects that reflected the access to contextually congruent words were obtained not under interstimulus interval (ISI) = 0 ms (experiment 1) but under ISI = 750 ms (experiment 2). These results suggested that a prosodically mispronounced input temporarily disturbed access to the appropriate meaning of the word, whereas appropriate access was achieved later within 750 ms with reference to the contextual information rather than the mispronounced lexical prosodic information. Thus, contextual information overrides lexical prosodic information to recognize spoken words appropriately even when lexical prosody is mispronounced.												1	1											JUN	2025	157	6					4102	4118		10.1121/10.0036775	http://dx.doi.org/10.1121/10.0036775												2026-01-16	WOS:001506844900001
J	Hayashi, R; Imaizumi, S; Mori, K; Niimi, S; Ueno, S; Kiritani, S				Hayashi, R; Imaizumi, S; Mori, K; Niimi, S; Ueno, S; Kiritani, S			Elicitation of N400m in sentence comprehension due to lexical prosody incongruity	NEUROREPORT				Article								The role of lexical prosody in the semantic integration of spoken sentences consisting of a quiz stem and an answer word was investigated analyzing the event-related magnetic response, N400m. Three conditions regarding the relations between the quiz and the answer word were prepared: pitch-accent violation, phonemic violation and no violation. Both the pitch-accent and phonemic violations elicited significant N400m without any significant differences in the peak latency and magnitude of the equivalent current dipoles, suggesting that the role of pitch-accent in semantic integration is equivalent to that of phonemes. However, the rate of violation detection and the successful N400m source estimation were lower for the pitch-accent violation than for the phonemic violation, suggesting differential neural processes for the phonemic and prosodic cues. NeuroReport 12:1753-1756 (C) 2001 Lippincott Williams & Wilkins.												13	14											JUN 13	2001	12	8					1753	1756		10.1097/00001756-200106130-00047	http://dx.doi.org/10.1097/00001756-200106130-00047												2026-01-16	WOS:000169185400043
J	Villani, C; Boux, IP; Pulvermüller, F; Tomasello, R				Villani, Caterina; Boux, Isabella P.; Pulvermueller, Friedemann; Tomasello, Rosario			The time course of speech act recognition conveyed by speech prosody: a gating study	LANGUAGE COGNITION AND NEUROSCIENCE				Article								Speech prosody is essential for conveying communicative intentions. Although neurophysiological data has shown that communicative functions conveyed through prosody are processed rapidly in the human brain, it is still unclear when and to what extent prosodic information is needed for the conscious speech act recognition as speech unfolds. Using a gating paradigm, we investigated the point at which listeners recognise the function of identical Italian sentences - whether they express a question or statement - based on vocal intonation. Comparing cross-spliced and natural sentences, we found that, rising or falling nuclear accentual movement on the sentence-final word seems to be the primary cue for recognition, with questions identified slightly later than statements. Furthermore, we discuss the limitations of splicing techniques in filtering out natural prosodic variations, the presence of a "statement bias" in perceiving incomplete sentences, along with a visual examination of interindividual responses. These findings offer valuable insights into the timing of conscious recognition of different communicative functions based on speech prosody.												3	4											SEP 14	2025	40	8					1065	1084		10.1080/23273798.2025.2506641	http://dx.doi.org/10.1080/23273798.2025.2506641		MAY 2025										2026-01-16	WOS:001503007800001
J	Schild, U; Becker, ABC; Friedrich, CK				Schild, Ulrike; Becker, Angelika B. C.; Friedrich, Claudia K.			Processing of syllable stress is functionally different from phoneme processing and does not profit from literacy acquisition	FRONTIERS IN PSYCHOLOGY				Article								Speech is characterized by phonemes and prosody. Neurocognitive evidence supports the separate processing of each type of information. Therefore, one might suggest individual development of both pathways. In this study, we examine literacy acquisition in middle childhood. Children become aware of the phonemes in speech at that time and refine phoneme processing when they acquire an alphabetic writing system. We test whether an enhanced sensitivity to phonemes in middle childhood extends to other aspects of the speech signal, such as prosody. To investigate prosodic processing, we used stress priming. Spoken stressed and unstressed syllables (primes) preceded spoken German words with stress on the first syllable (targets). We orthogonally varied stress overlap and phoneme overlap between the primes and onsets of the targets. Lexical decisions and Event-Related Potentials (ERPs) for the targets were obtained for pre-reading preschoolers, reading pupils and adults. The behavioral and ERR results were largely comparable across all groups. The fastest responses were observed when the first syllable of the target word shared stress and phonemes with the preceding prime. ERR stress priming and ERR phoneme priming started 200 ms after the target word onset. Bilateral ERR stress priming was characterized by enhanced ERR amplitudes for stress overlap. Left-lateralized ERR phoneme priming replicates previously observed reduced ERR amplitudes for phoneme overlap. Groups differed in the strength of the behavioral phoneme priming and in the late ERR phoneme priming effect. The present results show that enhanced phonological processing in middle childhood is restricted to phonemes and does not extend to prosody. These results are indicative of two parallel processing systems for phonemes and prosody that might follow different developmental trajectories in middle childhood as a function of alphabetic literacy.												14	14											JUN 3	2014	5								530	10.3389/fpsyg.2014.00530	http://dx.doi.org/10.3389/fpsyg.2014.00530												2026-01-16	WOS:000337666600001
J	Cutler, A; Van Donselaar, W				Cutler, A; Van Donselaar, W			Voornaam is not (really) a homophone: Lexical prosody and lexical access in Dutch	LANGUAGE AND SPEECH				Article								Four experiments examined Dutch listeners' use of suprasegmental information in spoken-word recognition. Isolated syllables excised from minimal stress pairs such as VOORnaam/voorNAAM could be reliably assigned to their source words. In lexical decision, no priming was observed from one member of minimal stress pairs to the other, suggesting that the pairs' segmental ambiguity was removed by suprasegmental information. Words embedded in nonsense strings were harder to detect if the nonsense string itself formed the beginning of a competing word, but a suprasegmental mismatch to the competing word significantly reduced this inhibition. The same nonsense strings facilitated recognition of the longer words of which they constituted the beginning, but again the facilitation was significantly reduced by suprasegmental mismatch. Together these results indicate that Dutch listeners effectively exploit suprasegmental cues in recognizing spoken words. Nonetheless, suprasegmental mismatch appears to be somewhat less effective in constraining activation than segmental mismatch.												120	138											JUN	2001	44		2				171	195		10.1177/00238309010440020301	http://dx.doi.org/10.1177/00238309010440020301												2026-01-16	WOS:000171605900003
J	Singh, L; Chee, M				Singh, Leher; Chee, Melissa			Rise and fall: Effects of tone and intonation on spoken word recognition in early childhood	JOURNAL OF PHONETICS				Article								A crucial component of word learning is the ability to recognize words in spite of the varying forms they assume. This may be particularly challenging in tone languages as learners have to develop tone representations in the face of intonational variation in order to accurately recognize words. The effects of intonational variation on word recognition of tone-marked words in Mandarin Chinese were investigated in toddlers and preschoolers using a cross-sectional design. Participants were presented with known words where intonation (question/statement) and tone (rising/falling) were independently manipulated. Results demonstrated that word recognition in toddlers was heavily influenced by changes in the pitch contour of a tone due to intonational variation. In contrast, preschool were able to recognize tone-marked words regardless of simultaneous intonational variation, demonstrating a comparatively robust representation of lexical tone. Results chart an evolution in integrating pitch cues to tone and intonation over the first few years of life. (C) 2016 Elsevier Ltd. All rights reserved.												30	31											MAR	2016	55						109	118		10.1016/j.wocn.2015.12.005	http://dx.doi.org/10.1016/j.wocn.2015.12.005												2026-01-16	WOS:000372394300007
J	Mattys, S; Samuel, AG				Mattys, S; Samuel, AG			Implications of stress-pattern differences in spoken-word recognition	JOURNAL OF MEMORY AND LANGUAGE				Article								Existing models of spoken-word recognition positing that stressed syllables tend to be perceived as word onsets have not provided an account of the processings of non-initial-stress words. The present study suggests that such words require additional, time-consuming processing. Two experiments showed that phoneme monitoring is slower in non-initial-stress than initial-stress words, even when the target-carrying syllable is made identical through splicing. In a third experiment, the processing of non-initial-stress words was also found to be more memory-taxing than that of initial-stress words, a result consistent with the need for additional memory storage generated by incorrect lexical activation in non-initial-stress words. Taken together, the results support the view that words bearing different stress patterns are processed differently, with extra processing required for non-initial-stress words. The implementation of such a distinction is discussed in the framework of current models of word recognition, with an emphasis on processing time-course differences. (C) 2000 Academic Press.												36	41											MAY	2000	42	4					571	596		10.1006/jmla.1999.2696	http://dx.doi.org/10.1006/jmla.1999.2696												2026-01-16	WOS:000086602400007
J	Kong, YY; Jesse, A				Kong, Ying-Yee; Jesse, Alexandra			Low-frequency fine-structure cues allow for the online use of lexical stress during spoken-word recognition in spectrally degraded speech	JOURNAL OF THE ACOUSTICAL SOCIETY OF AMERICA				Article								English listeners use suprasegmental cues to lexical stress during spoken-word recognition. Prosodic cues are, however, less salient in spectrally degraded speech, as provided by cochlear implants. The present study examined how spectral degradation with and without low-frequency fine-structure information affects normal-hearing listeners' ability to benefit from suprasegmen-tal cues to lexical stress in online spoken-word recognition. To simulate electric hearing, an eight-channel vocoder spectrally degraded the stimuli while preserving temporal envelope infor-mation. Additional lowpass-filtered speech was presented to the opposite ear to simulate bimodal hearing. Using a visual world paradigm, listeners' eye fixations to four printed words (target, competitor, two distractors) were tracked, while hearing a word. The target and competi-tor overlapped segmentally in their first two syllables but mismatched suprasegmentally in their first syllables, as the initial syllable received primary stress in one word and secondary stress in the other (e. g., "admiral," "admi'ration"). In the vocoder-only condition, listeners were unable to use lexical stress to recognize targets before segmental information disambiguated them from competitors. With additional lowpass-filtered speech, however, listeners efficiently processed prosodic information to speed up online word recognition. Low-frequency fine-structure cues in simulated bimodal hearing allowed listeners to benefit from suprasegmental cues to lexical stress during word recognition. (C) 2017 Acoustical Society of America.												4	5											JAN	2017	141	1					373	382		10.1121/1.4972569	http://dx.doi.org/10.1121/1.4972569												2026-01-16	WOS:000395308700050
J	Rohrer, PL; Bujok, R; van Maastricht, L; Bosker, HR				Rohrer, Patrick Louis; Bujok, Ronny; van Maastricht, Lieke; Bosker, Hans Rutger			From "I dance" to "she danced" with a flick of the hands: Audiovisual stress perception in Spanish	PSYCHONOMIC BULLETIN & REVIEW				Article								When talking, speakers naturally produce hand movements (co-speech gestures) that contribute to communication. Evidence in Dutch suggests that the timing of simple up-and-down, non-referential "beat" gestures influences spoken word recognition: the same auditory stimulus was perceived as CONtent (noun, capitalized letters indicate stressed syllables) when a beat gesture occurred on the first syllable, but as conTENT (adjective) when the gesture occurred on the second syllable. However, these findings were based on a small number of minimal pairs in Dutch, limiting the generalizability of the findings. We therefore tested this effect in Spanish, where lexical stress is highly relevant in the verb conjugation system, distinguishing bailo, "I dance" with word-initial stress from bail & oacute;, "she danced" with word-final stress. Testing a larger sample (N = 100), we also assessed whether individual differences in working memory capacity modulated how much individuals relied on the gestures in spoken word recognition. The results showed that, similar to Dutch, Spanish participants were biased to perceive lexical stress on the syllable that visually co-occurred with a beat gesture, with the effect being strongest when the acoustic stress cues were most ambiguous. No evidence was found for by-participant effect sizes to be influenced by individual differences in phonological or visuospatial working memory. These findings reveal gestural-speech coordination impacts lexical stress perception in a language where listeners are regularly confronted with such lexical stress contrasts, highlighting the impact of gestures' timing on prominence perception and spoken word recognition.												2	2											OCT	2025	32	5					2136	2145		10.3758/s13423-025-02683-9	http://dx.doi.org/10.3758/s13423-025-02683-9		APR 2025										2026-01-16	WOS:001461194700001
J	Huang, YT; Newman, RS; Catalano, A; Goupell, MJ				Huang, Yi Ting; Newman, Rochelle S.; Catalano, Allison; Goupell, Matthew J.			Using prosody to infer discourse prominence in cochlear-implant users and normal-hearing listeners	COGNITION				Article								Cochlear implants (CIs) provide speech perception to adults with severe-to-profound hearing loss, but the acoustic signal remains severely degraded. Limited access to pitch cues is thought to decrease sensitivity to prosody in CI users, but co-occurring changes in intensity and duration may provide redundant cues. The current study investigates how listeners use these cues to infer discourse prominence. CI users and normal-hearing (NH) listeners were presented with sentences varying in prosody (accented vs. unaccented words) while their eye-movements were measured to referents varying in discourse status (given vs. new categories). In Experiment 1, all listeners inferred prominence when prosody on nouns distinguished categories ("SANDWICH" -> not sandals). In Experiment 2, CI users and NH listeners presented with natural speech inferred prominence when prosody on adjectives implied contrast across both categories and properties ("PINK horse" -> not the orange horse). In contrast, NH listeners presented with simulated CI (vocoded) speech were sensitive to acoustic differences in prosody, but did not use these cues to infer discourse status. Together, this suggests that exploiting redundant cues for comprehension varies with the demands of language processing and prior experience with the degraded signal. (C) 2017 Elsevier B.V. All rights reserved.												16	19											SEP	2017	166						184	200		10.1016/j.cognition.2017.05.029	http://dx.doi.org/10.1016/j.cognition.2017.05.029												2026-01-16	WOS:000405160500018
J	Singh, L; Morgan, JL; White, KS				Singh, L; Morgan, JL; White, KS			Preference and processing: The role of speech affect in early spoken word recognition	JOURNAL OF MEMORY AND LANGUAGE				Article								Infants prefer to listen to happy speech. To assess influences of speech affect on early lexical processing, 7.5- and 10.5-month-old infants were familiarized with one word spoken with happy affect and another with neutral affect and then tested on recognition of these words in fluent passages. Infants heard all passages either with happy affect or with neutral affect. Contrary to initial expectations that positive affect would facilitate word recognition, younger infants recognized familiarized words only when affect matched across familiarization and testing. Older infants displayed a more mature pattern of word recognition, recognizing words across variations in affect regardless of the direction of change when the task was somewhat simplified. However, younger infants continued to be limited by affective matching in the simplified task. Early processing advantages thus do not necessarily follow listening preferences. Rather, infants' early lexical representations appear to be dominated by covarying properties of experienced exemplars, whether or not these are ultimately relevant for lexical distinctions. (C) 2004 Elsevier Inc. All rights reserved.												140	169											AUG	2004	51	2					173	189		10.1016/j.jml.2004.04.004	http://dx.doi.org/10.1016/j.jml.2004.04.004												2026-01-16	WOS:000222923800002
J	Michelas, A; Dufour, S				Michelas, Amandine; Dufour, Sophie			Are Prosodic Variants Stored in the French Mental Lexicon?	EXPERIMENTAL PSYCHOLOGY				Article								A long-term priming experiment examined the way stress information is processed and represented in French speakers' mind. Repeated prime and target words either matched (/ba'do/ - /ba'do/ "headband") or mismatched their stress pattern (/bado/ - /ba'do/). In comparison to a control condition (/makc/ - /ba'do/), the results showed that matching and mismatching primes were equally effective in facilitating the processing of the target words. Thus, despite the fact that French speakers routinely produce and hear words in their stressed and unstressed versions, this study suggests that stress in French is not integrated into lexical representations.												5	6											NOV	2019	66	6					393	401		10.1027/1618-3169/a000462	http://dx.doi.org/10.1027/1618-3169/a000462												2026-01-16	WOS:000514569700002
J	Wingfield, A; Lindfield, KC; Goodglass, H				Wingfield, A; Lindfield, KC; Goodglass, H			Effects of age and hearing sensitivity on the use of prosodic information in spoken word recognition	JOURNAL OF SPEECH LANGUAGE AND HEARING RESEARCH				Article								It is well known that spoken words can often be recognized From lust their onsets and that older adults require a greater word onset duration For recognition than young adults. In this study, young and older adults heard either just word onsets, word onsets followed by white noise indicating the full duration of the target word, or word onsets Followed by a low-pass-Filtered signal that indicated the number of syllables and syllabic stress (word prosody) in the absence of segmental information. Older adults required longer stimulus durations for word recognition under all conditions, with age differences in hearing sensitivity contributing significantly to this age difference. Within this difference, however, word recognition was facilitated by knowledge of word prosody to the same degree for young and older adults. These findings suggest, first, that listeners can detect and utilize word stress in making perceptual judgments and, second, that this ability remains spared in normal aging.												64	79											AUG	2000	43	4					915	925		10.1044/jslhr.4304.915	http://dx.doi.org/10.1044/jslhr.4304.915												2026-01-16	WOS:000088585300008
J	Lee, CY				Lee, Chao-Yang			Does horse activate mother? Processing lexical tone in form priming	LANGUAGE AND SPEECH				Article								Lexical tone languages make up the majority of all known languages of the world, but the role of tone in lexical processing remains unclear. In the present study, four form priming experiments examined the role of Mandarin tones in constraining lexical activation and the time course of the activation. When a prime and a target were related directly in form (e.g., lou3 'hug'-lou2 'hall'), competitors that differed from the prime in tone failed to be activated, indicating the use of tonal information to distinguish between segmentally identical words. When a prime and a target were not form-related but were related through a third word that was not actually presented (e.g., lou3 'hug'-jian4zhu0 'building', where lou3 is form-related to lou2 'hall', which was semantically related to jian4zhu0), a mismatch in tone prevented activation of minimal tone pairs at 250 ms interstimulus interval (ISI) but did not prevent activation at 50 ms ISI. These results indicate that tonal information is used on-line to reduce the number of activated candidates, but does not prevent the minimal tone pairs from being activated in the early phase of lexical activation.												57	70												2007	50		1				101	123		10.1177/00238309070500010501	http://dx.doi.org/10.1177/00238309070500010501												2026-01-16	WOS:000246228200005
J	Mattys, SL				Mattys, SL			The perception of primary and secondary stress in English	PERCEPTION & PSYCHOPHYSICS				Article								Most models of word recognition concerned with prosody are based on a distinction between strong syllables (containing a full vowel) and weak syllables (containing a schwa). In these models,the posslibility that listeners take advantage of finer grained prosodic distinctions, such as primary versus secondary stress, is usually rejected on the grounds that these two categories are not discriminable from each other without lexical information or normalization of the speaker's voice. In the present experiment, subjects were presented with word fragments that differed only by their degree of stress-namely, primary or secondary stress (e.g., /'prasi/ vs. /"prasi/). The task was to guess the origin of the fragment (e.g., "prosecutor" vs. "prosecution"). The results showed that guessing performance: significantly exceeds the chance level, which indicates that making fine stress distinctions is possible without lexical information and with minimal speech normalization This finding is discussed in the framework of prosody-based word recognition theories.												52	59											FEB	2000	62	2					253	265		10.3758/BF03205547	http://dx.doi.org/10.3758/BF03205547												2026-01-16	WOS:000085653500002
J	Sekerina, IA; Trueswell, JC				Sekerina, Irina A.; Trueswell, John C.			Processing of contrastiveness by heritage Russian bilinguals	BILINGUALISM-LANGUAGE AND COGNITION				Article								Two eye-tracking experiments in the Visual World paradigm compared how monolingual Russian (Experiment 1) and heritage Russian-English bilingual (Experiment 2) listeners process contrastiveness online in Russian. Materials were color adjective-noun phrases embedded into the split-constituent construction Krasnuju polozite zvezdocku ... " Red put star ... " whose inherent contrastiveness results from integration of multiple sources of information, i.e., word order, prosody and visual context. The results showed that while monolinguals rapidly used word order and visual context (but not contrastive prosody) to compute the contrast set even before the noun appeared in speech, heritage Russian bilinguals were very slow and took notice of multiple sources of information only when the lexical identity of the noun made the task superfluous. These results are similar to slowed processing reported in the literature for L2 learners. It is hypothesized that this slowdown in HL processing is due to cascading effects of covert competition between the two languages that starts at the level of spoken word recognition and culminates at the interfaces and, with time, it may become a major contributing force to heritage language attrition.												23	25											JUL	2011	14	3					280	300		10.1017/S1366728910000337	http://dx.doi.org/10.1017/S1366728910000337												2026-01-16	WOS:000291983500002
J	Koso, A; Hagiwara, H				Koso, Ayumi; Hagiwara, Hiroko			Event-related potential evidence of processing lexical pitch-accent in auditory Japanese sentences	NEUROREPORT				Article								Neural mechanisms that underlie the processing of lexical pitch-accent in auditory Japanese were investigated by using event-related potentials. Native speakers of Japanese listened to two types of short sentences, both consisting of a noun and a verb. The sentences ended with a verb with either congruous or incongruous pitch-accent pattern, where pitch-accent violations occur at the verb in the incongruent condition. The event-related potentials of the incongruent condition showed an increased widespread negativity that started 400 ms after the onset of the deviant lexical item and lasted for about 400 ms. These results suggest that the negativity evoked by violations in lexical-pitch accent indicates electrophysiological evidence for the online processing of lexical-pitch accent in auditory Japanese. NeuroReport 20:1270-1274 (C) 2009 Wolters Kluwer Health vertical bar Lippincott Williams & Wilkins.												6	6											SEP 23	2009	20	14					1270	1274		10.1097/WNR.0b013e32833017af	http://dx.doi.org/10.1097/WNR.0b013e32833017af												2026-01-16	WOS:000269808000009
J	Boutsen, FR; Dvorak, JD; Deweber, DD				Boutsen, Frank R.; Dvorak, Justin D.; Deweber, Derick D.			Prosody and Spoken Word Recognition in Early and Late Spanish-English Bilingual Individuals	JOURNAL OF SPEECH LANGUAGE AND HEARING RESEARCH				Article								Purpose: This study was conducted to compare the influence of word properties on gated single-word recognition in monolingual and bilingual individuals under conditions of native and nonnative accent and to determine whether wordform prosody facilitates recognition in bilingual individuals. Method: Word recognition was assessed in monolingual and bilingual participants when English words were presented with English and Spanish accents in 3 gating conditions: onset only, onset plus prosody/word length only, and onset plus prosody. Word properties were quantified to assess their influence on word recognition in the onset-only condition. Results: Word recognition speed was proportional to language experience. In the onset-only condition, only word frequency facilitated word recognition across groups. Addition of duration information or prosodic word form did not facilitate word recognition in bilingual individuals the way it did in monolingual individuals. For the bilingual groups, Spanish accent significantly facilitated recognition in the presence of prosodic information. Word attributes were far more consequential in the English accent than in the Spanish accent condition. Conclusions: Word rhyme information, word properties, and accent affect gated word recognition differently in monolingual and bilingual individuals. Top-down strategies emanating from word properties that may facilitate single-word recognition are experience and context dependent and become less available in the presence of a nonnative accent.												1	2											MAR	2017	60	3					712	724		10.1044/2016_JSLHR-H-15-0274	http://dx.doi.org/10.1044/2016_JSLHR-H-15-0274												2026-01-16	WOS:000399330100018
J	Cutler, A; Otake, T				Cutler, A; Otake, T			Pitch accent in spoken-word recognition in Japanese	JOURNAL OF THE ACOUSTICAL SOCIETY OF AMERICA				Article; Proceedings Paper	134th Meeting of the Acoustical-Society-of-America	DEC 01-05, 1997	SAN DIEGO, CALIFORNIA					Three experiments addressed the question of whether pitch-accent information may be exploited in the process of recognizing spoken words in Tokyo Japanese. In a two-choice classification task, listeners judged from which of two words, differing in accentual structure, isolated syllables had been extracted (e.g., ka from baka HL or gaka LH); most judgments were correct, and listeners' decisions were correlated with the fundamental frequency characteristics of the syllables. In a gating experiment, listeners heard initial fragments of words and guessed what the words were; their guesses overwhelmingly had the same initial accent structure as the gated word even when only the beginning CV of the stimulus (e.g., na- from nagasa HLL or nagashi LHH) was presented. In addition, listeners were more confident in guesses with the same initial accent structure as the stimulus than in guesses with different accent. In a lexical decision experiment, responses to spoken words (e.g., ame HL) were speeded by previous presentation of the same word (e.g., ame HL) but not by previous presentation of a word differing only in accent (e.g., ame LH). Together these findings provide strong evidence that accentual information constrains the activation and selection of candidates for spoken-word recognition. (C) 1999 Acoustical Society of America. [S0001-4966(99)03003-9].												90	108											MAR	1999	105	3					1877	1888		10.1121/1.426724	http://dx.doi.org/10.1121/1.426724												2026-01-16	WOS:000079078500045
J	Felder, V; Jönsson-Steiner, E; Eulitz, C; Lahiri, A				Felder, Verena; Joensson-Steiner, Elisabet; Eulitz, Carsten; Lahiri, Aditi			Asymmetric processing of lexical tonal contrast in Swedish	ATTENTION PERCEPTION & PSYCHOPHYSICS				Article								Languages such as Swedish use suprasegmental information such as tone, over and above segments, to mark lexical contrast. Theories differ with respect to the abstractness and specification of tone in the mental lexicon. In a forced choice task, we tested Swedish listeners' responses to words with segmentally identical first syllables differing in tonal contours (characterized as Accents 1 and 2). We assumed Accent I to be lexically specified for a subset of words and hypothesized that this specification would speed up word accent identification. As was predicted, listeners were fastest in choosing the tonally correct word when the accent was lexically specified. We conclude that the processing of surface tonal contours is governed by their underlying lexical structure with tonal specification.												9	9											NOV	2009	71	8					1890	1899		10.3758/APP.71.8.1890	http://dx.doi.org/10.3758/APP.71.8.1890												2026-01-16	WOS:000272722800017
J	Shiamizadeh, Z; Caspers, J; Schiller, NO				Shiamizadeh, Zohreh; Caspers, Johanneke; Schiller, Niels O.			When is a wh-in-situ question identified in standard Persian?	LANGUAGE COGNITION AND NEUROSCIENCE				Article								Previous literature demonstrated the influential role of prediction in processing speech [Brazil, 1981. The place of intonation in a discourse model. In C.Malcolm & M.Montgomery (Eds.), Studies in discourse analysis (pp.146-157). London: Routledge & Kegan Paul; Grosjean, 1983. How long is the sentence? Prediction and prosody in the on-line processing of language. Linguistics, 21, 501-529, 1996a. Using prosody to predict the end of sentences in English and French: Normal and brain damaged subjects. Language and Cognitive Processes, 11, 107-134; Snedeker & Trueswell, 2003. Using prosody to avoid ambiguity: Effects of speaker awareness and referential context. Journal of Memory and Language, 48, 103-130], and of prosody in predicting the eventual syntactic structure of ambiguous sentences [e.g. Snedeker & Trueswell, 2003. Using prosody to avoid ambiguity: Effects of speaker awareness and referential context. Journal of Memory and Language, 48, 103-130]. Wh-in-situ questions contain temporary syntactic ambiguity. One of the languages characterised by wh-in-situ questions is Persian. The current research adopted the gating paradigm [Grosjean, 1980. Spoken word recognition processes and the gating paradigm. Perception and Psychophysics, 28, 267-283] to investigate when distinctive prosodic cues of the pre-wh part enable correct identification of wh-in-situ questions in Persian. A perception experiment was designed in which gated stimuli were played to Persian native speakers in a forced-choice sentence identification task. In line with our expectation, correct identification responses were given from the beginning of the sentence. The result is discussed in the context of proposals regarding the need to integrate prosody and prediction into models of language and speech processing [Beach, 1991. The interpretation of prosodic patterns at points of syntactic structure ambiguity: Evidence for cue trading relations. Journal of Memory and Language, 30, 644-663; Grosjean, 1983. How long is the sentence? Prediction and prosody in the on-line processing of language. Linguistics, 21, 501-529, 1996a. Using prosody to predict the end of sentences in English and French: Normal and brain damaged subjects. Language and Cognitive Processes, 11, 107-134].												2	2												2018	33	9					1168	1183		10.1080/23273798.2018.1463444	http://dx.doi.org/10.1080/23273798.2018.1463444												2026-01-16	WOS:000443903200006
J	Cooper, N; Cutler, A; Wales, R				Cooper, N; Cutler, A; Wales, R			Constraints of lexical stress on lexical access in English: Evidence from native and non-native listeners	LANGUAGE AND SPEECH				Article								Four cross-modal priming experiments and two forced-choice identification experiments investigated the use of suprasegmental cues to stress in the recognition of spoken English words, by native (English-speaking) and non-native (Dutch) listeners. Previous results had indicated that suprasegmental information was exploited in lexical access by Dutch but not by English listeners. For both listener groups, recognition of visually presented target words was faster, in comparison to a control condition, after stress-matching spoken primes, either monosyllabic (mus-from MUsic/muSEum) or bisyllabic (admi-from ADmiral / admiRAtion). For native, listeners, the effect of stress-mismatching bisyllabic primes was not different from that of control primes, but mismatching monosyllabic primes produced partial facilitation. For non-native listeners, both bisyllabic and monosyllabic stress-mismatching primes produced partial facilitation. Native English listeners thus can exploit suprasegmental information in spoken-word recognition, but information from two syllables is used more effectively than information from one syllable. Dutch listeners are less proficient at using suprasegmental information in English than in their native language, but, as in their native language, use mono- and bisyllabic information to an equal extent. In forced-choice identification, Dutch listeners outperformed native listeners at correctly assigning a monosyllabic fragment (e.g., mus-) to one of two words differing in stress.												190	234											SEP	2002	45		3				207	228		10.1177/00238309020450030101	http://dx.doi.org/10.1177/00238309020450030101												2026-01-16	WOS:000182047200001
J	Bardovi-Harlig, K; Su, YW				Bardovi-Harlig, Kathleen; Su, Yunwen			Implementing discourse-gating tasks to study the timing of speech act recognition	RESEARCH METHODS IN APPLIED LINGUISTICS				Article								This paper presents the development of two novel discourse-gating tasks to investigate the processing of pragmatic information, namely, the timing of the recognition of genuine (sincere) and ostensible (transparently insincere) refusals in Chinese and provides preliminary validity evidence for the tasks. Gating tasks were introduced to investigate spoken word recognition and have been successfully extended to spoken language processing, most notably sentences. Following Grosjean's (1996) observation that gating tasks could be used to investigate a variety of linguistic features, we extended the gating tasks to spoken discourse using turns as gates. The open-prediction gating task allows participants to make a single prediction about the outcome of each of 12 recorded conversations as soon as they can. The fixed-prediction gating task asks participants to make predictions at regular intervals while listening to a second set of 12 conversations. One hundred and seven participants (60 L1 speakers and 47 third- and fourth-year learners of Chinese) were recruited to test the tasks. The tasks reveal a lag in speech-act identification not found when retrospective speech-act identification tasks are used. The fixedprediction task additionally reveals alternatives that are considered during processing. The paper discusses the benefits of the discourse gating tasks and the merits of each, the quantitative and qualitative evidence for the tasks, and future directions for discourse gating tasks.												2	2											DEC	2024	3	3							100122	10.1016/j.rmal.2024.100122	http://dx.doi.org/10.1016/j.rmal.2024.100122												2026-01-16	WOS:001574887800010
J	Koso, A; Ojima, S; Hagiwara, H				Koso, Ayumi; Ojima, Shiro; Hagiwara, Hiroko			An event-related potential investigation of lexical pitch-accent processing in auditory Japanese	BRAIN RESEARCH				Article								Lexical prosody plays an important role in speech comprehension. However, the electrophysiological nature and time course of processing lexical prosody in mora-timed languages are rarely known in contrast to the wealth of knowledge in stress-timed languages and syllable-timed languages like German and French. In the present study, lexical pitch-accent processing in Japanese is investigated using event-related potentials. Participants listened to sentences with verbs either correct or incorrect with respect to pitch-accent (phonological condition), word meaning (semantic condition) or sentence type (syntactic condition). When the brain potentials of correct and incorrect sentences were compared within conditions, the phonological and semantic conditions showed a negativity and positivity (P600), while the syntactic condition displayed a P600. Furthermore, the negativity in response to pitch-accent violations (pitch-accent negativity) appeared approximately 60 ms earlier than the response to semantic violations (N400), while no significant topographical distributions were found between the two components. These results suggest that the pitch-accent negativity reflects initial phonological processing followed by lexical access and word recognition. Moreover, the P600 displayed in all conditions was interpreted as a general integration process that is common across the three domains. (C) 2011 Elsevier B.V. All rights reserved.												11	12											APR 18	2011	1385						217	228		10.1016/j.brainres.2011.02.008	http://dx.doi.org/10.1016/j.brainres.2011.02.008												2026-01-16	WOS:000289810800023
J	Holliman, AJ; Wood, C; Sheehy, K				Holliman, Andrew J.; Wood, Clare; Sheehy, Kieron			Does Speech Rhythm Sensitivity Predict Children's Reading Ability 1 Year Later?	JOURNAL OF EDUCATIONAL PSYCHOLOGY				Article								There is a growing literature demonstrating that speech rhythm sensitivity is related to children's reading development, independent of phonological awareness. However, the precise nature of this relationship is less well understood, and further research is warranted to investigate whether speech rhythm sensitivity predicts the different components of reading over time. In this 1-year longitudinal study, 69 five- to 8-year-old English-speaking children completed a speech rhythm assessment at Time I along with other cognitive assessments and then completed a variety of reading assessments at Time 2 (1 year later). A series of hierarchical regression analyses revealed that after controlling for individual differences in age, vocabulary, and phonological awareness, speech rhythm sensitivity was able to predict unique variance in word reading and the phrasing component of the reading fluency measure I year later. The findings emphasize the contribution of speech rhythm sensitivity in children's reading development, and the authors argue that speech rhythm sensitivity should now be included in current models of children's reading development.												87	115											MAY	2010	102	2					356	366		10.1037/a0018049	http://dx.doi.org/10.1037/a0018049												2026-01-16	WOS:000277977100007
J	Arnold, JE; Kam, CLH				Arnold, Jennifer E.; Kam, Carla L. Hudson			If you say thee uh you are describing something hard:: The on-line attribution of disfluency during reference comprehension	JOURNAL OF EXPERIMENTAL PSYCHOLOGY-LEARNING MEMORY AND COGNITION				Article								Eye-tracking and gating experiments examined reference comprehension With fluent (Click on the red...) and disfluent (Click on [pause] thee uh red...) instructions while listeners viewed displays with 2 familiar (e.g., ice cream cones) and 2 unfamiliar objects (e.g., squiggly shapes). Disfluent instructions made unfamiliar objects more expected, which influenced listeners' on-line hypotheses from the onset of the color word. The unfamiliarity bias was sharply reduced by instructions that the speaker had object agnosia, and thus difficulty naming familiar objects (Experiment 2), but was not affected by intermittent sources of speaker distraction (beeps and construction noises; Experiments 3). The authors conclude that listeners can make situation-specific inferences about likely sources of disfluency, but there are some limitations to these attributions.												150	182											SEP	2007	33	5					914	930		10.1037/0278-7393.33.5.914	http://dx.doi.org/10.1037/0278-7393.33.5.914												2026-01-16	WOS:000248928300008
J	Pichora-Fuller, MK; Souza, PE				Pichora-Fuller, MK; Souza, PE			Effects of aging on auditory processing of speech	INTERNATIONAL JOURNAL OF AUDIOLOGY				Article; Proceedings Paper	Workshop on Candidature for and Delivery of Audiological Services - Special Needs of Older People	NOV, 2001	ERIKSHOLM, DENMARK					The focus of this paper is on the effects of age on speech perception, with reference to pertinent psychoacoustic findings. The difficulties of older listeners are related to the well-known effects of high-frequency hearing loss on speech perception in quiet, and to temporal processing declines not predictable from the audiogram that account for reduced ability to listen in complex, noisy conditions. We also discuss issues of research interpretation; e.g. the need for researchers and clinicians to be alert to the frequent confound between degree of hearing loss and age. The implications of age-related changes in auditory speech processing for future practice and research are discussed relative to interactions between older individuals and their acoustic environments.												284	337											JUL	2003	42			2			S11	S16															2026-01-16	WOS:000184591700003
J	Shin, J				Shin, Jeonghwa			Exploring lexical stress processing in L2 English: A comparative eye-tracking study of native English listeners and Japanese listeners	LINGUISTIC RESEARCH				Article								Shin, Jeonghwa. 2023. Exploring lexical stress processing in L2 English: A comparative eye-tracking study of native English listeners and Japanese listeners. Linguistic Research 40(3): 587-606. This study aims to explore how individuals with a native language characterized by a lexical pitch accent approach lexical stress in a stress-timed L2 during spoken word recognition. To this end, native English listeners and Japanese listeners of English participated in two phases of experiment: a three-day training and a subsequent eye-tracking experiment. The eye-tracking results revealed distinct processing patterns. Native English listeners predominantly recognized trochaic words by relying on the initial stressed syllable. In contrast, for iambic words, they utilized both the initial unstressed and the second stressed syllables for recognition. Japanese listeners of English demonstrated a different pattern of processing. They initiated lexical access within the first syllable of trochaic stress patterns and slightly later, still relying on first-syllable information, for iambic words. This finding implies that a single initial syllable is enough for Japanese listeners of English to utilize word stress information during L2 English spoken word recognition unlike native English listeners. The equal efficiency in employing two lexical stress patterns in L2 English suggests that lexical processing strategies transferred from the L2 listeners' native language could facilitate word recognition in the target language. While this study underscores the advantages of L1 prosodic structures in L2 English word recognition, it does not imply that Japanese listeners of English process English word stress in the same manner as native English listeners do during overall English word recognition. (Korea Military Academy)												0	0											DEC	2023	40	3					587	606		10.17250/khisli.40.3.202312.009	http://dx.doi.org/10.17250/khisli.40.3.202312.009												2026-01-16	WOS:001140726500006
J	Bosker, HR				Bosker, Hans Rutger			Evidence For Selective Adaptation and Recalibration in the Perception of Lexical Stress	LANGUAGE AND SPEECH				Article								Individuals vary in how they produce speech. This variability affects both the segments (vowels and consonants) and the suprasegmental properties of their speech (prosody). Previous literature has demonstrated that listeners can adapt to variability in how different talkers pronounce the segments of speech. This study shows that listeners can also adapt to variability in how talkers produce lexical stress. Experiment 1 demonstrates a selective adaptation effect in lexical stress perception: repeatedly hearing Dutch trochaic words biased perception of a subsequent lexical stress continuum towards more iamb responses. Experiment 2 demonstrates a recalibration effect in lexical stress perception: when ambiguous suprasegmental cues to lexical stress were disambiguated by lexical orthographic context as signaling a trochaic word in an exposure phase, Dutch participants categorized a subsequent test continuum as more trochee-like. Moreover, the selective adaptation and recalibration effects generalized to novel words, not encountered during exposure. Together, the experiments demonstrate that listeners also flexibly adapt to variability in the suprasegmental properties of speech, thus expanding our understanding of the utility of listener adaptation in speech perception. Moreover, the combined outcomes speak for an architecture of spoken word recognition involving abstract prosodic representations at a prelexical level of analysis.												10	11											JUN	2022	65	2					472	490	00238309211030307	10.1177/00238309211030307	http://dx.doi.org/10.1177/00238309211030307		JUL 2021										2026-01-16	WOS:000672088000001
J	Field, J				Field, John			Intelligibility and the listener: The role of lexical stress	TESOL QUARTERLY				Article								For some 30 years, intelligibility has been recognized as an appropriate goal for pronunciation instruction, yet remarkably little is known about the factors that make a language learner's speech intelligible. Studies have traced correlations between features of normative speech and native speakers' intelligibility judgements. They have tended to regard prosody as a global phenomenon and to view intelligibility as primarily a quality of the speaker. The present article focuses on a single prosodic element, lexical stress, and shifts the focus of study to the listener. It draws on findings in psycholinguistics that have rarely been applied to second language (L2) contexts. Groups of listeners were asked to transcribe recorded material in which the variables of lexical stress and vowel quality were manipulated. Recognizing the extent to which English is employed in international contexts, the study contrasted the effect of the variables on native listeners (NLs) with their effect on normative listeners (NNLs). NLs and NNLs were found to respond in remarkably similar ways to the problems posed by stress misallocation. For both groups, the extent to which intelligibility was compromised depended greatly on the direction in which stress was shifted and whether changes in vowel quality were involved.												253	364											SEP	2005	39	3					399	423		10.2307/3588487	http://dx.doi.org/10.2307/3588487												2026-01-16	WOS:000242311200004
J	Mitterer, H				Mitterer, Holger			A web-based mouse-tracking task for early perceptual language processing	BEHAVIOR RESEARCH METHODS				Article								The study of language processing requires data from a wide range of languages but also data that are free from demand characteristics and meta-linguistic strategies. While eye-tracking has been successfully used to address the later issue, pragmatically, eye-tracking is often difficult to achieve with less well-studied languages. Therefore, the current paper presents a web-based mouse-tracking task that generates data that seem to reflect early perceptual processes similar to eye-tracking but which can be performed remotely. The task uses a set-up similar to early video games to entice participants to use language input as early as possible. The data presented here replicate an earlier eye-tracking study focusing on how reduced words are recognized. Fillers from the same study are also used, which show that the paradigm also reflects predictive semantic processing. It is concluded that the paradigm can be used to investigate lexical access, prosodic processing, and predictive semantic processing.												0	0											OCT 10	2025	57	11							308	10.3758/s13428-025-02827-8	http://dx.doi.org/10.3758/s13428-025-02827-8												2026-01-16	WOS:001590824400001
J	Mattys, SL				Mattys, SL			Stress versus coarticulation: Toward an integrated approach to explicit speech segmentation	JOURNAL OF EXPERIMENTAL PSYCHOLOGY-HUMAN PERCEPTION AND PERFORMANCE				Article								Although word stress has been hailed as a powerful speech-segmentation cue, the results of 5 cross-modal fragment priming experiments revealed limitations to stress-based segmentation. Specifically, the stress pattern of auditory primes failed to have any effect on the lexical decision latencies to related visual targets. A determining factor was whether the onset of the prime was coarticulated with the preceding speech fragment. Uncoarticulated (i.e., concatenated) primes facilitated priming. Coarticulated ones did not. However, when the primes were presented in a background of noise, the pattern of results reversed, and a strong stress effect emerged: Stress-initial primes caused more priming than non-initial-stress primes, regardless of the coarticulatory cues. The results underscore the role of coarticulation in the segmentation of clear speech and that of stress in impoverished listening conditions. More generally, they call for an integrated and signal-contingent approach to speech segmentation.												58	73											APR	2004	30	2					397	408		10.1037/0096-1523.30.2.397	http://dx.doi.org/10.1037/0096-1523.30.2.397												2026-01-16	WOS:000220322500012
J	Saindon, MR; Trehub, SE; Schellenberg, EG; van Lieshout, PHHM				Saindon, Mathieu R.; Trehub, Sandra E.; Schellenberg, E. Glenn; van Lieshout, Pascal H. H. M.			When is a Question a Question for Children and Adults?	LANGUAGE LEARNING AND DEVELOPMENT				Article								Terminal changes in fundamental frequency provide the most salient acoustic cues to declarative questions, but adults sometimes identify such questions from pre-terminal cues. In the present study, adults and 7- to 10-year-old children judged a single speaker's adult-and child-directed utterances as questions or statements in a gating task with word-length increments. Listeners of all ages successfully used pre-terminal cues to identify utterance type, often only the initial word, and they were more accurate for child-directed than adult-directed utterances. There were age-related differences in identification accuracy and number of words required for correct identification. Age differences were already apparent on the initial {first five) utterances, confirming adults' superior explicit knowledge of intonation patterns that signify questions and statements. Adults' performance improved over the course of the test session, reflecting taker-specific learning, but children exhibited no such learning.												8	10												2017	13	3					274	285		10.1080/15475441.2016.1252681	http://dx.doi.org/10.1080/15475441.2016.1252681												2026-01-16	WOS:000418529200004
J	van Donselaar, W; Koster, M; Cutler, A				van Donselaar, W; Koster, M; Cutler, A			Exploring the role of lexical stress in lexical recognition	QUARTERLY JOURNAL OF EXPERIMENTAL PSYCHOLOGY SECTION A-HUMAN EXPERIMENTAL PSYCHOLOGY				Article								Three cross-modal priming experiments examined the role of suprasegmental information in the processing of spoken words. All primes consisted of truncated spoken Dutch words. Recognition of visually presented word targets was facilitated by prior auditory presentation of the first two syllables of the same words as primes, but only if they were appropriately stressed (e.g., OKTOBER preceded by ok TO-); inappropriate stress, compatible with another word (e.g., OKTOBER preceded by OCto-, the beginning of octopus), produced inhibition. Monosyllabic fragments (e.g., OC-) also produced facilitation when appropriately stressed; if inappropriately stressed, they produced neither facilitation nor inhibition. The bisyllabic fragments that were compatible with only one word produced facilitation to semantically associated words, but inappropriate stress caused no inhibition of associates. The results arc explained within a model of spoken-word recognition involving competition between simultaneously activated phonological representations followed by activation of separate conceptual representations for strongly supported lexical candidates; at the level of the phonological representations, activation is modulated by both segmental and suprasegmental information.												107	126											FEB	2005	58	2					251	273		10.1080/02724980343000927	http://dx.doi.org/10.1080/02724980343000927												2026-01-16	WOS:000227090600003
J	Tao, L				Tao, Liang			SYNTACTIC TONE AND DISCOURSE PROCESSING IN BEIJING MANDARIN: A CASE STUDY	JOURNAL OF CHINESE LINGUISTICS				Article; Proceedings Paper	Workshop on Spoken Word Access and Processes	2000	Max Planck Inst Psycholinguist, Nijmegen, NETHERLANDS		Max Planck Inst Psycholinguist			Three experiments tested the role of an emerging syntactic tone in spoken word recognition of Beijing Mandarin Chinese. The study examined the role of the new syntactic tone in lexical access and how synchronic change is perceived in the task of word recognition. Experiment 1 used an information-deprived condition where information for the standard interpretation of the word was provided prior to the crucial tone, but the syntactic tone based interpretation was not provided. Experiment 2 used a prosody-reduced condition where the prosodic cues were unclear while information for both standard and syntactic tone based interpretation was provided. Experiment 3 involved a story retell task to further assess tone comprehension. The results show that the emerging syntactic tone had an impact on participant's lexical interpretations, although the impact was more obvious when prosody information was clearly provided. The results also confirmed participants' tone comprehension through story retells. The results support the hypotheses that a) there is a new syntactic tone in spoken Beijing Mandarin whose function goes beyond lexical tone, which has become a precursor for word recognition in discourse processing; and, b) language processing reflects asymmetry in that speakers prefer the traditional grammatical interpretation more than the interpretation derived from the newly developed syntactic tone when prosodic information is unclear. The study demonstrates how usage-based grammatical changes affect speaker's mental model of lexical access.												2	2											JUN	2009	37	2					257	296															2026-01-16	WOS:000268967500004
J	Connell, K; Hüls, S; Martínez-García, MT; Qin, Z; Shin, S; Yan, HB; Tremblay, A				Connell, Katrina; Huels, Simone; Martinez-Garcia, Maria Teresa; Qin, Zhen; Shin, Seulgi; Yan, Hanbo; Tremblay, Annie			English Learners' Use of Segmental and Suprasegmental Cues to Stress in Lexical Access: An Eye-Tracking Study	LANGUAGE LEARNING				Article								This study investigated the use of segmental and suprasegmental cues to lexical stress in word recognition by Mandarin-speaking English learners, Korean-speaking English learners, and native English listeners. Unlike English and Mandarin, Korean does not have lexical stress. Participants completed a visual-world eye-tracking experiment that examined whether listeners' word recognition is constrained by suprasegmental cues to stress alone or by a combination of segmental and suprasegmental cues. Results showed that English listeners used both suprasegmental cues alone and segmental and suprasegmental cues together to recognize English words, with the effect of stress being greater for combined cues. Conversely, Mandarin listeners used stress in lexical access only when stress was signaled by suprasegmental cues alone, and Korean listeners did so only when stress was signaled by segmental and suprasegmental cues together. These results highlight the importance of a cue-based approach to the study of stress in word recognition.												30	34											SEP	2018	68	3					635	668		10.1111/lang.12288	http://dx.doi.org/10.1111/lang.12288												2026-01-16	WOS:000440413900002
J	Norris, D; Cutler, A; McQueen, JM; Butterfield, S				Norris, Dennis; Cutler, Anne; McQueen, James M.; Butterfield, Sally			Phonological and conceptual activation in speech comprehension	COGNITIVE PSYCHOLOGY				Article								We propose that speech comprehension involves the activation of token representations of the phonological forms of current lexical hypotheses, separately from the ongoing construction of a conceptual interpretation of the current utterance. In a series of cross-modal priming experiments, facilitation of lexical decision responses to visual target words (e.g., time) was found for targets that were semantic associates of auditory prime words (e.g., date) when the primes were isolated words, but not when the same primes appeared in sentence contexts. Identity priming (e.g., faster lexical decisions to visual date after spoken date than after an unrelated prime) appeared, however, both with isolated primes and with primes in prosodically neutral sentences. Associative priming in sentence contexts only emerged when sentence prosody involved contrastive accents, or when sentences were terminated immediately after the prime. Associative priming is therefore not an automatic consequence of speech processing. In no experiment was there associative priming from embedded words (e.g., sedate-time), but there was inhibitory identity priming (e.g., sedate-date) from embedded primes in sentence contexts. Speech comprehension therefore appears to involve separate distinct activation both of token phonological word representations and of conceptual word representations. Furthermore, both of these types of representation are distinct from the long-term memory representations of word form and meaning. (c) 2006 Elsevier Inc. All rights reserved.												68	82											SEP	2006	53	2					146	193		10.1016/j.cogpsych.2006.03.001	http://dx.doi.org/10.1016/j.cogpsych.2006.03.001												2026-01-16	WOS:000240666500002
J	Chien, PJ; Friederici, AD; Hartwigsen, G; Sammler, D				Chien, Pei-Ju; Friederici, Angela D.; Hartwigsen, Gesa; Sammler, Daniela			Neural correlates of intonation and lexical tone in tonal and non-tonal language speakers	HUMAN BRAIN MAPPING				Article								Intonation, the modulation of pitch in speech, is a crucial aspect of language that is processed in right-hemispheric regions, beyond the classical left-hemispheric language system. Whether or not this notion generalises across languages remains, however, unclear. Particularly, tonal languages are an interesting test case because of the dual linguistic function of pitch that conveys lexical meaning in form of tone, in addition to intonation. To date, only few studies have explored how intonation is processed in tonal languages, how this compares to tone and between tonal and non-tonal language speakers. The present fMRI study addressed these questions by testing Mandarin and German speakers with Mandarin material. Both groups categorised mono-syllabic Mandarin words in terms of intonation, tone, and voice gender. Systematic comparisons of brain activity of the two groups between the three tasks showed large cross-linguistic commonalities in the neural processing of intonation in left fronto-parietal, right frontal, and bilateral cingulo-opercular regions. These areas are associated with general phonological, specific prosodic, and controlled categorical decision-making processes, respectively. Tone processing overlapped with intonation processing in left fronto-parietal areas, in both groups, but evoked additional activity in bilateral temporo-parietal semantic regions and subcortical areas in Mandarin speakers only. Together, these findings confirm cross-linguistic commonalities in the neural implementation of intonation processing but dissociations for semantic processing of tone only in tonal language speakers.												27	28											MAY	2020	41	7					1842	1858		10.1002/hbm.24916	http://dx.doi.org/10.1002/hbm.24916		JAN 2020										2026-01-16	WOS:000508026600001
J	Böcker, KBE; Bastiaansen, MCM; Vroomen, J; Brunia, CHM; De Gelder, B				Böcker, KBE; Bastiaansen, MCM; Vroomen, J; Brunia, CHM; De Gelder, B			An ERP correlate of metrical stress in spoken word recognition	PSYCHOPHYSIOLOGY				Article								Rhythmic properties of spoken language such as metrical stress, that is, the alternation of strong and weak syllables, are important in speech recognition of stress-timed languages such as Dutch and English. Nineteen subjects Listened passively to or discriminated actively between sequences of bisyllabic Dutch words, which started with either a weak or a strong syllable. Weak-initial words, which constitute 12% of the Dutch lexicon, evoked more negativity than strong-initial words in the interval between P2 and N400 components of the auditory event-related potential. This negativity was denoted as N325. The N325 was larger during stress discrimination than during passive Listening. N325 was also larger when a weak-initial word followed a sequence of strong-initial words than when it followed words with the same stress pattern. The latter difference was larger for listeners who performed well on stress discrimination. It was concluded that the N325 is probably a manifestation of the extraction of metrical stress from the acoustic Signal and its transformation into task requirements.												39	43											NOV	1999	36	6					706	720		10.1111/1469-8986.3660706	http://dx.doi.org/10.1111/1469-8986.3660706												2026-01-16	WOS:000083311300005
J	Gout, A; Christophe, A; Morgan, JL				Gout, A; Christophe, A; Morgan, JL			Phonological phrase boundaries constrain lexical access II. Infant data	JOURNAL OF MEMORY AND LANGUAGE				Article								The location of phonological phrase boundaries was shown to affect lexical access by English-learning infants of 10 and 13 months of age. Experiments 1 and 2 used the head-turn preference procedure: infants were familiarized with two bisyllabic words, then presented with sentences that either contained the familiarized words or contained both their syllables separated by a phonological phrase boundary. Ten-month-olds did not show any listening preference, whereas 13-month-olds listened significantly longer to sentences containing the familiarized words. Experiments 3 and 4 relied on a variant of the conditioned head-turning technique. In a first session, infants were trained to turn their heads for an isolated bisyllabic word. In the second session, they were exposed to the same sentences as above. Both 10- and 12.5-month-old infants turned significantly more often when the target word truly appeared in the sentence. These results suggest that phonological phrase boundaries constrain on-line lexical access in infants. (C) 2004 Published by Elsevier Inc.												110	140											NOV	2004	51	4					548	567		10.1016/j.jml.2004.07.002	http://dx.doi.org/10.1016/j.jml.2004.07.002												2026-01-16	WOS:000224966200003
J	Yue, JX; Bastiaanse, R; Howard, D; Alter, K				Yue, Jinxing; Bastiaanse, Roelien; Howard, David; Alter, Kai			Representational level matters for tone-word recognition: Evidence from form priming	QUARTERLY JOURNAL OF EXPERIMENTAL PSYCHOLOGY				Article								In a form priming experiment with a lexical decision task, we investigated whether the representational structure of lexical tone in lexical memory impacts spoken-word recognition in Mandarin. Target monosyllabic words were preceded by five types of primes: (1) the same real words (/lun4/-/lun4/), (2) real words with only tone contrasts (/lun2/-/lun4/), (3) unrelated real words (/pie3/-/lun4/), (4) pseudowords with only tone contrasts (*/lun3/-/lun4/), and (5) unrelated pseudowords (*/tai3/-/lun4/). We found a facilitation effect in target words with pseudoword primes that share the segmental syllable but contrast in tones (*/lun3/-/lun4/). Moreover, no evident form priming effect was observed in target words primed by real words with only tone contrasts (/lun2/-/lun4/). These results suggest that the recognition of a tone word is influenced by the representational level of tone accessed by the prime word. The distinctive priming patterns between real-word and pseudoword primes are best explained by the connectionist models of tone-word recognition, which assume a hierarchical representation of lexical tone.												1	1											MAY	2024	77	5					1125	1135		10.1177/17470218231203615	http://dx.doi.org/10.1177/17470218231203615		OCT 2023										2026-01-16	WOS:001087883000001
J	Protopapas, A; Panagaki, E; Andrikopoulou, A; Palma, NG; Arvaniti, A				Protopapas, Athanassios; Panagaki, Eleonora; Andrikopoulou, Angeliki; Palma, Nicolas Gutierrez; Arvaniti, Amalia			Priming Stress Patterns in Word Recognition	JOURNAL OF EXPERIMENTAL PSYCHOLOGY-HUMAN PERCEPTION AND PERFORMANCE				Article								This study addresses the lexical representation of stress in a series of 5 intramodal and cross-modal priming experiments in the Greek language using lexical decision tasks with auditory and visual targets. Three-syllable primes and targets were matched in first syllable segments, length, and other variables, and differed segmentally in the second and third syllable. Primes matched or mismatched targets in stress, which was placed on the penultimate or antepenultimate syllable. There was no evidence for stress priming in either accuracy or latency of responses to either words or pseudowords in any of these experiments, either intramodally or cross-modally. In contrast, a control fragment priming experiment using only the first 2 syllables of the primes produced a significant effect of stress congruence for words but not for pseudowords. The results are interpreted in the context of previous findings in the literature as arising from lexical activation rather than from matching stress patterns. Overall, findings are consistent with lexical representations including stress information that is inseparable from segmental specification, rather than with abstract representations of metrical templates.												13	16											NOV	2016	42	11					1739	1760		10.1037/xhp0000259	http://dx.doi.org/10.1037/xhp0000259												2026-01-16	WOS:000387150100006
J	Slowiaczek, LM; Soltano, EG; Bernstein, HL				Slowiaczek, Louisa M.; Soltano, Emily G.; Bernstein, Hilary L.			Lexical and metrical stress in word recognition: Lexical or pre-lexical influences?	JOURNAL OF PSYCHOLINGUISTIC RESEARCH				Article								The influence of lexical stress and/or metrical stress on spoken word recognition was examined. Two experiments were designed to determine whether response times in lexical decision or shadowing tasks are influenced when primes and targets share lexical stress patterns (JUVenile-BIBlical [Syllables printed in capital letters indicate those syllables receiving primary lexical stress.]). The results did not support an effect of lexical stress on the organization of lexical memory. In Experiment 3 primes and targets whose first syllables shared lexical stress only (MUDdy-PASta), metrical stress only (alTHOUGH-PASta), both cues (LECtern-PASta), or neither cue (conTROL-PASta) revealed no priming effect. However, targets whose first syllables were strong were responded to faster than targets whose first syllables were weak. Experiment 4 manipulated the metrical stress patterns of bi-syllabic primes and targets. Targets with strong-weak metrical stress patterns were responded to more quickly than those with strong-strong or weak-strong patterns. Although the priming paradigm did not reveal an influence of lexical and metrical stress on the organization of lexical memory, the data do support an influence of strong syllables on the processing of auditorily presented words.												10	15											NOV	2006	35	6					491	512		10.1007/s10936-006-9026-7	http://dx.doi.org/10.1007/s10936-006-9026-7												2026-01-16	WOS:000242286500002
J	Creemers, A; Embick, D				Creemers, Ava; Embick, David			The Role of Semantic Transparency in the Processing of Spoken Compound Words	JOURNAL OF EXPERIMENTAL PSYCHOLOGY-LEARNING MEMORY AND COGNITION				Article								The question of whether lexical decomposition is driven by semantic transparency in the lexical processing of morphologically complex words, such as compounds, remains controversial. Prior research on compound processing has predominantly examined visual processing. Focusing instead on spoken word word recognition, the present study examined the processing of auditorily presented English compounds that were semantically transparent (e.g., farmyard) or partially opaque with an opaque head (e.g., airline) or opaque modifier (e.g., pothole). Three auditory primed lexical decision experiments were run to examine to what extent constituent priming effects are affected by the semantic transparency of a compound and whether semantic transparency affects the processing of heads and modifiers equally. The results showed priming effects for both modifiers and heads regardless of their semantic transparency, indicating that individual constituents are accessed in transparent as well as opaque compounds. In addition, the results showed smaller priming effects for semantically opaque heads compared with matched transparent compounds with the same head. These findings suggest that semantically opaque heads induce an increased processing cost, which may result from the need to suppress the meaning of the head in favor of the meaning of the opaque compound.												6	10											MAY	2022	48	5					734	751		10.1037/xlm0001132	http://dx.doi.org/10.1037/xlm0001132		APR 2022										2026-01-16	WOS:000778682100001
J	Spitzer, SM; Liss, JM; Mattys, SL				Spitzer, Stephanie M.; Liss, Julie M.; Mattys, Sven L.			Acoustic cues to lexical segmentation: A study of resynthesized speech	JOURNAL OF THE ACOUSTICAL SOCIETY OF AMERICA				Article								It has been posited that the role of prosody in lexical segmentation is elevated when the speech signal is degraded or unreliable. Using predictions from Cutler and Norris' [J. Exp. Psychol. Hum. Percept. Perform. 14, 113-121 (1988)] metrical segmentation strategy hypothesis as a framework, this investigation examined how individual suprasegmental and segmental cues to syllabic stress contribute differentially to the recognition of strong and weak syllables for the purpose of lexical segmentation. Syllabic contrastivity was reduced in resynthesized phrases by systematically (i) flattening the fundamental frequency (F0) contours, (ii) equalizing vowel durations, (iii) weakening strong vowels, (iv) combining the two suprasegmental cues., i.e., F0 and duration, and (v) combining the manipulation of all cues. Results indicated that, despite similar decrements in overall intelligibility, F0 flattening and the weakening of strong vowels had a greater impact on lexical segmentation than did equalizing vowel duration. Both combined-cue conditions resulted in greater decrements in intelligibility, but with no additional negative impact on lexical segmentation. The results support the notion of F0 variation and vowel quality as primary conduits for stress-based segmentation and suggest that the effectiveness of stress-based segmentation with degraded speech must be investigated relative to the suprasegmental and segmental impoverishments occasioned by each particular degradation. (c) 2007 Acoustical Society of America.												56	66											DEC	2007	122	6					3678	3687		10.1121/1.2801545	http://dx.doi.org/10.1121/1.2801545												2026-01-16	WOS:000251650700049
J	Severijnen, GGA; Di Dona, G; Bosker, HR; McQueen, JM				Severijnen, Giulio G. A.; Di Dona, Giuseppe; Bosker, Hans Rutger; McQueen, James M.			Tracking Talker-Specific Cues to Lexical Stress: Evidence from Perceptual Learning	JOURNAL OF EXPERIMENTAL PSYCHOLOGY-HUMAN PERCEPTION AND PERFORMANCE				Article								When recognizing spoken words, listeners are confronted by variability in the speech signal caused by talker differences. Previous research has focused on segmental talker variability; less is known about how suprasegmental variability is handled. Here we investigated the use of perceptual learning to deal with between-talker differences in lexical stress. Two groups of participants heard Dutch minimal stress pairs (e.g., VOORnaam vs. voorNAAM, "first name" vs. "respectable") spoken by two male talkers. Group 1 heard Talker 1 use only F0 to signal stress (intensity and duration values were ambiguous), while Talker 2 used only intensity (F0 and duration were ambiguous). Group 2 heard the reverse talker-cue mappings. After training, participants were tested on words from both talkers containing conflicting stress cues ("mixed items"; e.g., one spoken by Talker 1 with F0 signaling initial stress and intensity signaling final stress). We found that listeners used previously learned information about which talker used which cue to interpret the mixed items. For example, the mixed item described above tended to be interpreted as having initial stress by Group 1 but as having final stress by Group 2. This demonstrates that listeners learn how individual talkers signal stress and use that knowledge in spoken-word recognition.												2	2											APR	2023	49	4					549	565		10.1037/xhp0001105	http://dx.doi.org/10.1037/xhp0001105												2026-01-16	WOS:000988170100009
J	Warner, N; Cutler, A				Warner, Natasha; Cutler, Anne			Stress Effects in Vowel Perception as a Function of Language-Specific Vocabulary Patterns	PHONETICA				Article								Background/Aims: Evidence from spoken word recognition suggests that for English listeners, distinguishing full versus reduced vowels is important, but discerning stress differences involving the same full vowel (as in mu- from music or museum) is not. In Dutch, in contrast, the latter distinction is important. This difference arises from the relative frequency of unstressed full vowels in the two vocabularies. The goal of this paper is to determine how this difference in the lexicon influences the perception of stressed versus unstressed vowels. Methods: All possible sequences of two segments (diphones) in Dutch and in English were presented to native listeners in gated fragments. We recorded identification performance over time throughout the speech signal. The data were here analysed specifically for patterns in perception of stressed versus unstressed vowels. Results: The data reveal significantly larger stress effects (whereby unstressed vowels are harder to identify than stressed vowels) in English than in Dutch. Both language-specific and shared patterns appear regarding which vowels show stress effects. Conclusion: We explain the larger stress effect in English as reflecting the processing demands caused by the difference in use of unstressed vowels in the lexicon. The larger stress effect in English is due to relative inexperience with processing unstressed full vowels. (C) 2016 S. Karger AG, Basel												8	9												2017	74	2					81	106		10.1159/000447428	http://dx.doi.org/10.1159/000447428												2026-01-16	WOS:000401388400002
J	Holliman, AJ; Wood, C; Sheehy, K				Holliman, Andrew J.; Wood, Clare; Sheehy, Kieron			The contribution of sensitivity to speech rhythm and non-speech rhythm to early reading development	EDUCATIONAL PSYCHOLOGY				Article								Both sensitivity to speech rhythm and non-speech rhythm have been associated with successful phonological awareness and reading development in separate studies. However, the extent to which speech rhythm, non-speech rhythm and literacy skills are interrelated has not been examined. As a result, five- to seven-year-old English-speaking children were assessed on measures of speech rhythm sensitivity, non-speech rhythm sensitivity (both receptive and productive), reading attainment and phonological awareness. Hierarchical regression analyses revealed that productive non-speech rhythm was unable to predict variance in reading attainment independently of phonological awareness and speech rhythm sensitivity. Receptive sensitivity to speech rhythm and non-speech rhythm were both able to predict a significant amount of unique variance in reading attainment after controlling for age, vocabulary, phonological awareness, short-term memory and each other. The findings suggest that receptive sensitivity to speech rhythm and non-speech rhythm, while related to each other, also make contributions to reading attainment that are independent of each other. These findings provide only partial consistency with the general auditory processing deficit theory of reading difficulties, but are in line with the emerging theoretical claim that sensitivity to speech prosody may be implicated in successful literacy development.												57	77												2010	30	3					247	267	PII 919384362	10.1080/01443410903560922	http://dx.doi.org/10.1080/01443410903560922												2026-01-16	WOS:000277512000001
J	Mitterer, H; Kim, S; Cho, T				Mitterer, Holger; Kim, Sahyang; Cho, Taehong			Datasets on the production and perception of underlying and epenthetic glottal stops in Maltese	DATA IN BRIEF				Article; Data Paper								This article provides some supplementary analysis data of speech production and perception of glottal stops in the Semitic language Maltese. In Maltese, a glottal stop can occur as a phoneme, but also as a phonetic marker of vowel-initial words (as in the case with Germanic languages like English). Data from four experiments are provided, which will allow other researchers to reproduce the results and apply their own data-analysis techniques to these data for further data exploration. A production experiment (Experiment 1) investigates how often the glottal marking of vowel-initial words occurs (causing vowel-initial words to be ambiguous with words starting with a glottal stop as a phoneme) and whether the glottal gesture for this marking can be differentiated from an underlying (phonemic) glottal stop in its acoustic properties. Experiments 2 to 4 investigate how and to what extent Maltese listeners perceive glottal markings as lexical (phonemic) or epenthetic (phonetic), using a two-alternative forced choice task (Experiment 2), a visual-world eye tracking task with printed target words (Experiment 3) and a gating task (Experiment 4). A full account of theoretical consequences of these data can be found in the full length article entitled "The glottal stop between segmental and suprasegmental processing: The case of Maltese"[1]. (C) 2020 The Author(s). Published by Elsevier Inc.												0	0											JUN	2020	30								105543	10.1016/j.dib.2020.105543	http://dx.doi.org/10.1016/j.dib.2020.105543												2026-01-16	WOS:000541974600005
J	Becker, A; Schild, U; Friedrich, CK				Becker, Angelika; Schild, Ulrike; Friedrich, Claudia K.			Tracking independence and merging of prosodic and phonemic processing across infancy	DEVELOPMENTAL SCIENCE				Article								Recent evidence suggests division of labor in phonological analysis underlying speech recognition. Adults and children appear to decompose the speech stream into phoneme-relevant information and into syllable stress. Here we investigate whether both speech processing streams develop from a common path in infancy, or whether there are two separate streams from early on. We presented stressed and unstressed syllables (spoken primes) followed by initially stressed early learned disyllabic German words (spoken targets). Stress overlap and phoneme overlap between the primes and the initial syllable of the targets varied orthogonally. We tested infants 3, 6 and 9 months after birth. Event-related potentials (ERPs) revealed stress priming without phoneme priming in the 3-month-olds; phoneme priming without stress priming in the 6-month-olds; and phoneme priming, stress priming as well as an interaction of both in 9-month-olds. In general the present findings reveal that infants start with separate processing streams related to syllable stress and to phoneme-relevant information; and that they need to learn to merge both aspects of speech processing. In particular the present results suggest (i) that phoneme-free prosodic processing dominates in early infancy; (ii) that prosody-free phoneme processing dominates in middle infancy; and (iii) that both types of processing are operating in parallel and can be merged in late infancy.												8	8											MAR	2018	21	2							e12525	10.1111/desc.12525	http://dx.doi.org/10.1111/desc.12525												2026-01-16	WOS:000427006200008
J	Quam, C; Swingley, D				Quam, Carolyn; Swingley, Daniel			Processing of lexical stress cues by young children	JOURNAL OF EXPERIMENTAL CHILD PSYCHOLOGY				Article								Although infants learn an impressive amount about their native-language phonological system by the end of the first year of life, after the first year children still have much to learn about how acoustic dimensions cue linguistic categories in fluent speech. The current study investigated what children have learned about how the acoustic dimension of pitch indicates the location of the stressed syllable in familiar words. Preschoolers (2.5- to 5-year-olds) and adults were tested on their ability to use lexical-stress cues to identify familiar words. Both age groups saw pictures of a bunny and a banana and heard versions of "bunny" and "banana" in which stress either was indicated normally with convergent cues (pitch, duration, amplitude, and vowel quality) or was manipulated such that only pitch differentiated the words' initial syllables. Adults (n = 48) used both the convergent cues and the isolated pitch cue to identify the target words as they unfolded. Children (n = 206) used the convergent stress cues but not pitch alone in identifying words. We discuss potential reasons for children's difficulty in exploiting isolated pitch cues to stress despite children's early sensitivity to pitch in language. These findings contribute to a view in which phonological development progresses toward the adult state well past infancy. (C) 2014 Elsevier Inc. All rights reserved.												21	23											JUL	2014	123						73	89		10.1016/j.jecp.2014.01.010	http://dx.doi.org/10.1016/j.jecp.2014.01.010												2026-01-16	WOS:000336185700005
J	Cho, T; McQueen, JM				Cho, Taehong; McQueen, James M.			Perceptual Recovery from Consonant-Cluster Simplification in Korean Using Language-Specific Phonological Knowledge	JOURNAL OF PSYCHOLINGUISTIC RESEARCH				Article								Two experiments examined whether perceptual recovery from Korean consonant-cluster simplification is based on language-specific phonological knowledge. In tri-consonantal C1C2C3 sequences such as /lkt/ and /lpt/ in Seoul Korean, either C1 or C2 can be completely deleted. Seoul Koreans monitored for C2 targets (/p/ or /k/, deleted or preserved) in the second word of a two-word phrase with an underlying /l/-C2-/t/ sequence. In Experiment 1 the target-bearing words had contextual lexical-semantic support. Listeners recovered deleted targets as fast and as accurately as preserved targets with both Word and Intonational Phrase (IP) boundaries between the two words. In Experiment 2, contexts were low-pass filtered. Listeners were still able to recover deleted targets as well as preserved targets in IP-boundary contexts, but better with physically-present targets than with deleted targets in Word-boundary contexts. This suggests that the benefit of having target acoustic-phonetic information emerges only when higher-order (contextual and phrase-boundary) information is not available. The strikingly efficient recovery of deleted phonemes with neither acoustic-phonetic cues nor contextual support demonstrates that language-specific phonological knowledge, rather than language-universal perceptual processes which rely on fine-grained phonetic details, is employed when the listener perceives the results of a continuous-speech process in which reduction is phonetically complete.												2	2											AUG	2011	40	4					253	274		10.1007/s10936-011-9168-0	http://dx.doi.org/10.1007/s10936-011-9168-0												2026-01-16	WOS:000300174300002
J	[Anonymous]				[Anonymous]			Influences of high and low variability on infant word recognition	COGNITION				Article								Although infants begin to encode and track novel words in fluent speech by 7.5 months, their ability to recognize words is somewhat limited at this stage. In particular, when the surface form of a word is altered, by changing the gender or affective prosody of the speaker, infants begin to falter at spoken word recognition. Given that natural speech is replete with variability, only some of which determines the meaning of a word, it remains unclear how infants might ever overcome the effects of surface variability without appealing to meaning. In the current set of experiments, consequences of high and low variability are examined in preverbal infants. The source of variability, vocal affect, is a common property of infant-directed speech with which young learners have to contend. Across a series of four experiments, infants' abilities to recognize repeated encounters of words, as well as to reject similar-sounding words, are investigated in the context of high and low affective variation. Results point to positive consequences of affective variation, both in creating generalizable memory representations for words, but also in establishing phonologically precise memories for words. Conversely, low variability appears to degrade word recognition on both fronts, compromising infants' abilities to generalize across different affective forms of a word and to detect similar-sounding items. Findings are discussed in the context of principles of categorization that may potentiate the early growth of a lexicon. (C) 2007 Elsevier B.V. All rights reserved.												111	139											FEB	2008	106	2					833	870		10.1016/j.cognition.2007.05.002	http://dx.doi.org/10.1016/j.cognition.2007.05.002												2026-01-16	WOS:000252581900012
J	Arciuli, J				Arciuli, Joanne			The relationship between children's sensitivity to dominant and non-dominant patterns of lexical stress and reading accuracy	JOURNAL OF EXPERIMENTAL CHILD PSYCHOLOGY				Article								This study reports on a new task for assessing children's sensitivity to lexical stress for words with different stress patterns and demonstrates that this task is useful in examining predictors of reading accuracy during the elementary years. In English, polysyllabic words beginning with a strong syllable exhibit the most common or dominant pattern of lexical stress (e.g., "coconut"), whereas polysyllabic words beginning with a weak syllable exhibit a less common non-dominant pattern (e.g., "banana"). The new Aliens Talking Underwater task assesses children's ability to match low-pass filtered recordings of words to pictures of objects. Via filtering, phonetic detail is removed but prosodic contour information relating to lexical stress is retained. In a series of two-alternative forced choice trials, participants see a picture and are asked to choose which of two filtered recordings matches the name of that picture; one recording exhibits the correct lexical stress of the target word, and the other recording reverses the pattern of stress over the initial two syllables of the target word rendering it incorrect. Target words exhibit either dominant stress or non-dominant stress. Analysis of data collected from 192 typically developing children aged 5 to 12 years revealed that sensitivity to non dominant lexical stress was a significant predictor of reading accuracy even when age and phonological awareness were taken into account. A total of 76.3% of variance in children's reading accuracy was explained by these variables. Crown Copyright (C) 2016 Published by Elsevier Inc. All rights reserved.												5	7											MAY	2017	157						1	13		10.1016/j.jecp.2016.11.016	http://dx.doi.org/10.1016/j.jecp.2016.11.016												2026-01-16	WOS:000394628100001
J	Tang, P; Yuen, I; Demuth, K; Rattanasone, NX				Tang, Ping; Yuen, Ivan; Demuth, Katherine; Rattanasone, Nan Xu			The Acquisition of Contrastive Focus During Online Sentence-Comprehension by Children Learning Mandarin Chinese	DEVELOPMENTAL PSYCHOLOGY				Article								Contrastive focus, conveyed by prosodic cues, marks important information. Studies have shown that 6-year-olds learning English and Japanese can use contrastive focus during online sentence comprehension: focus used in a contrastive context facilitates the identification of a target referent (speeding up processing), whereas focus used inappropriately in a noncontrastive context misleads listeners to predict an incorrect referent, hindering the identification process (Ito et al., 2012, 2014). In Mandarin Chinese, the mapping between prosodic form and contrastive focus is less transparent, potentially delaying the acquisition of contrastive focus. This study assessed the online processing of contrastive focus by 196 Mandarin-speaking 4-10-year-olds and 34 adults in China, using the visual world paradigm. Stimuli contained a target NP in a mini discourse, with focus being used in contrastive (Experiment 1) versus Noncontrastive contexts (Experiment 2). Experiment 1 showed that the appropriate use of prosodic form for contrastive focus facilitated the identification of a target referent for 7-10-year-olds and adults, though not younger children. Experiment 2 showed that the inappropriate use of prosodic form for contrastive focus slowed the identification process only for 10-year-olds and adults. Thus, whereas 7-10-year-olds are sensitive to prosodic form for contrastive focus, only 10-year-olds use it as a primary cue to predict an upcoming referent like adults. The acquisition of contrastive focus in Mandarin is therefore a gradual process, with children showing sensitivity to contrastive focus during the early school years, and developing adult-like form-function mapping between prosody and focus until the end of primary school.												6	6											MAY	2023	59	5					845	861		10.1037/dev0001498	http://dx.doi.org/10.1037/dev0001498		DEC 2022										2026-01-16	WOS:000894788700001
J	Althaus, N; Wetterlin, A; Lahiri, A				Althaus, Nadja; Wetterlin, Allison; Lahiri, Aditi			Features of low functional load in mono- and bilinguals' lexical access: evidence from Swedish tonal accent	PHONETICA				Article								Swedish makes use of tonal accents (Accents 1 and 2) to contrast words, but the functional load is very low, with some regional dialects not even exhibiting the contrast. In particular given the low number of minimal pairs, the question is whether tonal word accent is used in lexical access. Here we present two cross-modal fragment semantic priming studies in order to address this question. Both experiments use first syllable fragments in order to prime semantically related targets. Experiment 1 utilises words whose first syllable occurs with both accent patterns, creating a situation in which there is lexical competition between words that differ solely in terms of accent. Experiment 2 removes this competition by using words that have no such accent competitors. Our results show that native speakers of Swedish use tonal word accent in lexical access: Accent mispronunciations failed to prime semantically related targets, regardless of whether primes had accent competitors or not. Results for a group of early bilingual speakers (who grew up with one Swedish-speaking parent and one other non-tonal language) showed no differences in processing compared to the monolinguals. This indicates that the extraction of accent features during acquisition and their use in lexical access is robust, even in a scenario where multiple input languages lead to tonal word accent being a useful feature for only some of the lexical items that are being acquired. There is no doubt that the accent system is well entrenched into the bilinguals' phonological system.												5	5												2021	78	3					175	199		10.1515/phon-2021-2002	http://dx.doi.org/10.1515/phon-2021-2002												2026-01-16	WOS:000705492900001
J	Ou, SC				Ou, Shu-chen			The role of lexical stress in spoken English word recognition by listeners of English and Taiwan Mandarin	LANGUAGE AND LINGUISTICS				Article								Two perceptual experiments investigated how the suprasegmental information of monosyllables is perceived and exploited in spoken English word recognition by listeners of English and Taiwan Mandarin (TM). Using an auditory lexical decision task in which correctly stressed English words and mis-stressed nonwords (e.g. camPAIGN vs. *CAMpaign) were presented for lexical decisions, Experiment I demonstrated that TM listeners could perceive the differences between stressed and unstressed syllables with native-like accuracy and rapidity. To examine how the perceived suprasegmental contrast would constrain English lexical access, Experiment II was conducted. It used a cross-modal fragment priming task in which a lexical decision had to be made for a visually presented English word or nonword following an auditory prime, which was a spoken word-initial syllable. The results showed that English and TM listeners recognized the displayed word (e.g. campus) faster both after a stress-matching (e.g. CAM-) prime and a stress-mismatching (e.g. cam-) prime than after a control prime (e.g. MOUN , with mismatching segments). This indicates that suprasegmental information does not inhibit a segmentally matching but suprasegmentally mismatching word candidate for both the two groups, although TM is a language where lexical prosody is expressed syllabically and its listeners tend to interpret lexical stress tonally. Yet, the two groups' responses were slower after the stressed primes than after the unstressed ones, presumably because the former generally had more possible continuations than the latter do. It is therefore concluded that when recognizing spoken English words, both the native and non-native (TM-speaking) listeners can exploit the suprasegmental cues of monosyllables, which, however, are not so effective that they will outweigh the segmental cues.												3	4												2019	20	4					569	600		10.1075/lali.00049.ou	http://dx.doi.org/10.1075/lali.00049.ou												2026-01-16	WOS:000496239100003
J	Armstrong, ME; Andreu, L; Esteve-Gibert, N; Prieto, P				Armstrong, Meghan E.; Andreu, Llorenc; Esteve-Gibert, Nuria; Prieto, Pilar			Children's processing of morphosyntactic and prosodic cues in overriding context-based hypotheses: an eye tracking study	PROBUS				Article								This research explores children's ability to integrate contextual and linguistic cues. Prior work has shown that children are not able to weigh contextual information in an adult-like way and that between the age of 4 and 6 they show difficulties in revising a hypothesis they have made based on early-arriving linguistic information in sentence processing. Therefore we considered children's ability to confirm or override a context-based hypothesis based on linguistic information. Our objective in this study was to test (1) children's (ages 4-6) ability to form a hypothesis based on contextual information, (2) their ability to override such a hypothesis based on linguistic information and (3) how children are able to use different types of linguistic cues (morphosyntactic versus prosodic) to confirm or override the initial hypothesis. Results from both offline (pointing) and online (eye tracking) tasks suggest that children in this age group indeed form hypotheses based on contextual information. Age effects were found regarding children's ability to override these hypotheses. Overall, 4-year-olds were not shown to be able to override their hypotheses using linguistic information of interest. For 5- and 6-year-olds, it depended on the types of linguistic cues that were available to them. Children were better at using morphosyntactic cues to override an initial hypothesis than they were at using prosodic cues to do so. Our results suggest that children slowly develop the ability to override hypotheses based on early-arriving information, even when that information is extralinguistic and contextual. Children must learn to weight different types of cues in an adult-like way. This developmental period of learning to prioritize different cues in an adult-like way is consistent with a constraint-based model of learning.												6	7											MAY	2016	28	1			SI		57	90		10.1515/probus-2016-0004	http://dx.doi.org/10.1515/probus-2016-0004												2026-01-16	WOS:000375180700004
